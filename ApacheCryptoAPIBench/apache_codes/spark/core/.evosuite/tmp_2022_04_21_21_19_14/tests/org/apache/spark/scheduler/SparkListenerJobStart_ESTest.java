/*
 * This file was automatically generated by EvoSuite
 * Thu Apr 21 22:13:02 GMT 2022
 */

package org.apache.spark.scheduler;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.util.Properties;
import org.apache.spark.scheduler.SparkListenerJobStart;
import org.apache.spark.scheduler.StageInfo;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.junit.runner.RunWith;
import scala.Function1;
import scala.Option;
import scala.PartialFunction;
import scala.Tuple4;
import scala.collection.Seq;
import scala.collection.immutable.Range;
import scala.collection.mutable.Queue;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true) 
public class SparkListenerJobStart_ESTest extends SparkListenerJobStart_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Range range0 = mock(Range.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SI)bLuUun", "SI)bLuUun", (String) null, (String) null).when(seq0).toString();
      doReturn(queue0, range0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(2, 40L, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.copy$default$3();
      SparkListenerJobStart sparkListenerJobStart1 = SparkListenerJobStart.apply(2, 2, seq1, (Properties) null);
      boolean boolean0 = sparkListenerJobStart1.equals(sparkListenerJobStart0);
      assertFalse(boolean0);
      assertEquals(2, sparkListenerJobStart1.copy$default$1());
      assertEquals(2L, sparkListenerJobStart1.time());
      assertFalse(sparkListenerJobStart0.equals((Object)sparkListenerJobStart1));
  }

  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("", "", "tU%").when(seq0).toString();
      doReturn((PartialFunction.Lifted<Range, Range>) null, (PartialFunction.Lifted<Range, Range>) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(2, 2, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.copy$default$3();
      SparkListenerJobStart sparkListenerJobStart1 = sparkListenerJobStart0.copy(1596, 2, seq1, (Properties) null);
      boolean boolean0 = sparkListenerJobStart1.equals(sparkListenerJobStart0);
      assertEquals(2L, sparkListenerJobStart1.copy$default$2());
      assertFalse(boolean0);
      assertFalse(sparkListenerJobStart0.equals((Object)sparkListenerJobStart1));
      assertEquals(1596, sparkListenerJobStart1.copy$default$1());
  }

  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("scala.collection.immutable.Range$Partial", "scala.collection.immutable.Range$Partial", "scala.collection.immutable.Range$Partial", "scala.collection.immutable.Range$Partial", "").when(seq0).toString();
      doReturn((PartialFunction.AndThen<Range, Range, Range>) null, (PartialFunction.AndThen<Range, Range, Range>) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.stageInfos();
      SparkListenerJobStart sparkListenerJobStart1 = SparkListenerJobStart.apply(0, 0, seq1, (Properties) null);
      sparkListenerJobStart1.time();
      assertEquals(389L, sparkListenerJobStart0.time());
      assertEquals((-889275714), sparkListenerJobStart0.copy$default$1());
      assertEquals((-889275714), sparkListenerJobStart0.jobId());
  }

  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(299, (-1301L), seq0, (Properties) null);
      long long0 = sparkListenerJobStart0.time();
      assertEquals((-1301L), long0);
  }

  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(queue0).toString();
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("Yw!YNE!4 ", "scala.Function4$$anonfun$tupled$1", "Qh:]Ny^@", "Qh:]Ny^@", "PR*-").when(seq0).toString();
      doReturn((Range) null, (PartialFunction.Lifted<Range, Range>) null, (Range) null, (Range) null, queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart((-273), 508L, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.copy$default$3();
      SparkListenerJobStart.apply((-273), (-836L), seq1, (Properties) null);
      SparkListenerJobStart sparkListenerJobStart1 = SparkListenerJobStart.apply((-536), 508L, seq1, (Properties) null);
      SparkListenerJobStart sparkListenerJobStart2 = sparkListenerJobStart1.copy((-536), (-1180L), seq1, (Properties) null);
      assertEquals((-536), sparkListenerJobStart2.jobId());
      assertEquals((-1180L), sparkListenerJobStart2.copy$default$2());
      
      SparkListenerJobStart sparkListenerJobStart3 = SparkListenerJobStart.apply(1, (-1348L), seq1, (Properties) null);
      sparkListenerJobStart3.stageIds();
      assertEquals((-1348L), sparkListenerJobStart3.time());
      assertEquals(1, sparkListenerJobStart3.copy$default$1());
  }

  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(299, (-1301L), seq0, (Properties) null);
      int int0 = sparkListenerJobStart0.jobId();
      assertEquals(299, int0);
  }

  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Range) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart((-273), 508L, seq0, (Properties) null);
      int int0 = sparkListenerJobStart0.jobId();
      assertEquals((-273), int0);
  }

  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null, (String) null, (String) null).when(seq0).toString();
      doReturn((Object) null, (Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply(0, 0, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.stageInfos();
      SparkListenerJobStart sparkListenerJobStart1 = sparkListenerJobStart0.copy(0, 0, seq1, (Properties) null);
      assertTrue(sparkListenerJobStart1.equals((Object)sparkListenerJobStart0));
  }

  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null, (String) null, (String) null, (String) null).when(seq0).toString();
      doReturn((Object) null, (Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.stageInfos();
      SparkListenerJobStart sparkListenerJobStart1 = SparkListenerJobStart.apply(0, 0, seq1, (Properties) null);
      sparkListenerJobStart1.copy$default$2();
      assertEquals((-889275714), sparkListenerJobStart0.copy$default$1());
      assertEquals(389L, sparkListenerJobStart0.time());
      assertEquals((-889275714), sparkListenerJobStart0.jobId());
  }

  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null, (String) null).when(seq0).toString();
      doReturn((Object) null, (Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.stageInfos();
      SparkListenerJobStart sparkListenerJobStart1 = new SparkListenerJobStart((-889275714), (-889275714), seq1, (Properties) null);
      long long0 = sparkListenerJobStart1.copy$default$2();
      assertEquals((-889275714), sparkListenerJobStart0.jobId());
      assertEquals((-889275714L), long0);
  }

  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("plpHutV&R", "plpHutV&R").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply(0, 14, seq0, (Properties) null);
      int int0 = sparkListenerJobStart0.copy$default$1();
      assertEquals(0, int0);
      assertEquals(14L, sparkListenerJobStart0.time());
  }

  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(4291, 0L, seq0, (Properties) null);
      int int0 = sparkListenerJobStart0.copy$default$1();
      assertEquals(4291, int0);
  }

  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SparkListenerJobStart", "SparkListenerJobStart").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      sparkListenerJobStart0.canEqual((Object) null);
      assertEquals(389L, sparkListenerJobStart0.copy$default$2());
      assertEquals((-889275714), sparkListenerJobStart0.jobId());
  }

  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      PartialFunction.Lifted<Range, Range> partialFunction_Lifted0 = (PartialFunction.Lifted<Range, Range>) mock(PartialFunction.Lifted.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null, (String) null, (String) null).when(seq0).toString();
      doReturn((Object) null, (Object) null, partialFunction_Lifted0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(28, 28, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.copy$default$3();
      SparkListenerJobStart sparkListenerJobStart1 = SparkListenerJobStart.apply(28, 28, seq1, (Properties) null);
      // Undeclared exception!
      try { 
        sparkListenerJobStart1.copy(28, 28, seq1, (Properties) null);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // scala.PartialFunction$Lifted$MockitoMock$121135128 cannot be cast to scala.collection.Seq
         //
         verifyException("org.apache.spark.scheduler.SparkListenerJobStart", e);
      }
  }

  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Tuple4<Range, Range, Range, Range> tuple4_0 = (Tuple4<Range, Range, Range, Range>) mock(Tuple4.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null).when(seq0).toString();
      doReturn(queue0, tuple4_0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart((-5), 2L, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.copy$default$3();
      // Undeclared exception!
      try { 
        SparkListenerJobStart.apply((-5), (-5), seq1, (Properties) null);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // scala.Tuple4$MockitoMock$1423610901 cannot be cast to scala.collection.Seq
         //
         verifyException("org.apache.spark.scheduler.SparkListenerJobStart", e);
      }
  }

  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      SparkListenerJobStart sparkListenerJobStart0 = null;
      try {
        sparkListenerJobStart0 = new SparkListenerJobStart(3559, 3559, (Seq<StageInfo>) null, (Properties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.scheduler.SparkListenerJobStart", e);
      }
  }

  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      Tuple4<Range, Range, Range, Range> tuple4_0 = (Tuple4<Range, Range, Range, Range>) mock(Tuple4.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn(tuple4_0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = null;
      try {
        sparkListenerJobStart0 = new SparkListenerJobStart(2, 2L, seq0, (Properties) null);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // scala.Tuple4$MockitoMock$1423610901 cannot be cast to scala.collection.Seq
         //
         verifyException("org.apache.spark.scheduler.SparkListenerJobStart", e);
      }
  }

  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SparkListenerJobStart", "").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      Object object0 = sparkListenerJobStart0.productElement(1);
      assertEquals((-889275714), sparkListenerJobStart0.copy$default$1());
      assertEquals(389L, object0);
  }

  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null).when(seq0).toString();
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      Object object0 = sparkListenerJobStart0.productElement(0);
      assertEquals(389L, sparkListenerJobStart0.time());
      assertEquals((-889275714), object0);
  }

  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(3, 3, seq0, (Properties) null);
      Object object0 = sparkListenerJobStart0.productElement(3);
      assertNull(object0);
  }

  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SparkListeVerJbStart", "SparkListeVerJbStart", "SparkListeVerJbStart", "SparkListeVerJbStart").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), (-889275714), seq0, (Properties) null);
      sparkListenerJobStart0.productElement(2);
      assertEquals((-889275714), sparkListenerJobStart0.copy$default$1());
      assertEquals((-889275714L), sparkListenerJobStart0.time());
  }

  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(4291, 0L, seq0, (Properties) null);
      String string0 = sparkListenerJobStart0.productPrefix();
      assertEquals("SparkListenerJobStart", string0);
  }

  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SparkListenerJobStart", "SparkListenerJobStart").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      int int0 = sparkListenerJobStart0.productArity();
      assertEquals(4, int0);
      assertEquals((-889275714), sparkListenerJobStart0.jobId());
      assertEquals(389L, sparkListenerJobStart0.copy$default$2());
  }

  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null).when(seq0).toString();
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply(0, (-390), seq0, (Properties) null);
      int int0 = sparkListenerJobStart0.jobId();
      assertEquals(0, int0);
      assertEquals((-390L), sparkListenerJobStart0.copy$default$2());
  }

  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(28, 28, seq0, (Properties) null);
      sparkListenerJobStart0.productIterator();
      assertEquals(4, sparkListenerJobStart0.productArity());
  }

  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SparkListenerJobStart", "").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      sparkListenerJobStart0.properties();
      assertEquals((-889275714), sparkListenerJobStart0.copy$default$1());
      assertEquals(389L, sparkListenerJobStart0.time());
  }

  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("", "").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply(7, 7, seq0, (Properties) null);
      sparkListenerJobStart0.canEqual(sparkListenerJobStart0);
      assertEquals(7, sparkListenerJobStart0.copy$default$1());
      assertEquals(7L, sparkListenerJobStart0.time());
  }

  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SparkListenerJobStart", "SparkListenerJobStart").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      long long0 = sparkListenerJobStart0.time();
      assertEquals(389L, long0);
      assertEquals((-889275714), sparkListenerJobStart0.jobId());
  }

  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null, (String) null, (String) null).when(seq0).toString();
      doReturn((Object) null, (Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(5, 5, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.copy$default$3();
      SparkListenerJobStart sparkListenerJobStart1 = SparkListenerJobStart.apply(5, 45, seq1, (Properties) null);
      boolean boolean0 = sparkListenerJobStart1.equals(sparkListenerJobStart0);
      assertFalse(boolean0);
      assertFalse(sparkListenerJobStart0.equals((Object)sparkListenerJobStart1));
      assertEquals(45L, sparkListenerJobStart1.copy$default$2());
      assertEquals(5, sparkListenerJobStart1.copy$default$1());
  }

  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null, (String) null).when(seq0).toString();
      doReturn((Object) null, (Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart((-34), (-34), seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.stageInfos();
      SparkListenerJobStart sparkListenerJobStart1 = SparkListenerJobStart.apply((-41), (-34), seq1, (Properties) null);
      boolean boolean0 = sparkListenerJobStart1.equals(sparkListenerJobStart0);
      assertFalse(boolean0);
      assertEquals((-34L), sparkListenerJobStart1.time());
      assertEquals((-41), sparkListenerJobStart1.jobId());
      assertFalse(sparkListenerJobStart0.equals((Object)sparkListenerJobStart1));
  }

  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("", "").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply(2, 2, seq0, (Properties) null);
      boolean boolean0 = sparkListenerJobStart0.equals((Object) null);
      assertFalse(boolean0);
      assertEquals(2L, sparkListenerJobStart0.copy$default$2());
      assertEquals(2, sparkListenerJobStart0.jobId());
  }

  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(28, 28, seq0, (Properties) null);
      boolean boolean0 = sparkListenerJobStart0.equals(sparkListenerJobStart0);
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(28, 28, seq0, (Properties) null);
      // Undeclared exception!
      try { 
        sparkListenerJobStart0.productElement(3915);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // java.lang.Integer@0000000003
         //
         verifyException("org.apache.spark.scheduler.SparkListenerJobStart", e);
      }
  }

  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("]", "]", "]", "]", "]").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275703), (-889275703), seq0, (Properties) null);
      SparkListenerJobStart.unapply(sparkListenerJobStart0);
      assertEquals((-889275703), sparkListenerJobStart0.jobId());
      assertEquals((-889275703L), sparkListenerJobStart0.time());
      assertEquals((-889275703), sparkListenerJobStart0.copy$default$1());
  }

  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(24, 24, seq0, (Properties) null);
      boolean boolean0 = sparkListenerJobStart0.logEvent();
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      Function1<Tuple4<Object, Object, Seq<StageInfo>, Properties>, SparkListenerJobStart> function1_0 = SparkListenerJobStart.tupled();
      assertNotNull(function1_0);
  }

  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((PartialFunction.AndThen<Range, Range, Range>) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart((-2074), (-258L), seq0, (Properties) null);
      Seq<Object> seq1 = sparkListenerJobStart0.stageIds();
      assertNull(seq1);
  }

  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null, (String) null, (String) null, (String) null).when(seq0).toString();
      doReturn((Object) null, (Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(2, 2L, seq0, (Properties) null);
      Seq<StageInfo> seq1 = sparkListenerJobStart0.copy$default$3();
      SparkListenerJobStart sparkListenerJobStart1 = SparkListenerJobStart.apply(2, 2, seq1, (Properties) null);
      boolean boolean0 = sparkListenerJobStart1.equals(sparkListenerJobStart0);
      assertTrue(boolean0);
      assertEquals(2, sparkListenerJobStart0.jobId());
      assertEquals(2L, sparkListenerJobStart1.time());
  }

  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("", "").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply(2, 2, seq0, (Properties) null);
      // Undeclared exception!
      try { 
        sparkListenerJobStart0.copy(2, 2, (Seq<StageInfo>) null, (Properties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.scheduler.SparkListenerJobStart", e);
      }
  }

  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      Option<Tuple4<Object, Object, Seq<StageInfo>, Properties>> option0 = SparkListenerJobStart.unapply((SparkListenerJobStart) null);
      assertNotNull(option0);
  }

  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("", "").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply(2, 2, seq0, (Properties) null);
      sparkListenerJobStart0.copy$default$4();
      assertEquals(2, sparkListenerJobStart0.copy$default$1());
      assertEquals(2L, sparkListenerJobStart0.copy$default$2());
  }

  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(seq0).toString();
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart(12, 12, seq0, (Properties) null);
      sparkListenerJobStart0.hashCode();
      assertEquals(12, sparkListenerJobStart0.jobId());
      assertEquals(12L, sparkListenerJobStart0.copy$default$2());
  }

  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SparkListenerJobStart", "SparkListenerJobStart").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), 389L, seq0, (Properties) null);
      long long0 = sparkListenerJobStart0.copy$default$2();
      assertEquals(389L, long0);
      assertEquals((-889275714), sparkListenerJobStart0.copy$default$1());
  }

  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      Queue<Range> queue0 = (Queue<Range>) mock(Queue.class, new ViolatedAssumptionAnswer());
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn("SparkListenerJobStart", "SparkListenerJobStart").when(seq0).toString();
      doReturn(queue0).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = SparkListenerJobStart.apply((-889275714), (-146L), seq0, (Properties) null);
      int int0 = sparkListenerJobStart0.copy$default$1();
      assertEquals((-146L), sparkListenerJobStart0.copy$default$2());
      assertEquals((-889275714), int0);
  }

  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      Seq<StageInfo> seq0 = (Seq<StageInfo>) mock(Seq.class, new ViolatedAssumptionAnswer());
      doReturn((String) null, (String) null, (String) null).when(seq0).toString();
      doReturn((Object) null).when(seq0).map(any(scala.Function1.class) , any(scala.collection.generic.CanBuildFrom.class));
      SparkListenerJobStart sparkListenerJobStart0 = new SparkListenerJobStart((-2447), (-2447), seq0, (Properties) null);
      String string0 = sparkListenerJobStart0.toString();
      assertEquals(4, sparkListenerJobStart0.productArity());
      assertEquals("SparkListenerJobStart(-2447,-2447,null,null)", string0);
  }

  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      Function1<Object, Function1<Object, Function1<Seq<StageInfo>, Function1<Properties, SparkListenerJobStart>>>> function1_0 = SparkListenerJobStart.curried();
      assertNotNull(function1_0);
  }

  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      Properties properties0 = SparkListenerJobStart.$lessinit$greater$default$4();
      assertNull(properties0);
  }

  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      Properties properties0 = SparkListenerJobStart.apply$default$4();
      assertNull(properties0);
  }

  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      // Undeclared exception!
      try { 
        SparkListenerJobStart.apply((-991), (-991), (Seq<StageInfo>) null, (Properties) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.scheduler.SparkListenerJobStart", e);
      }
  }
}
