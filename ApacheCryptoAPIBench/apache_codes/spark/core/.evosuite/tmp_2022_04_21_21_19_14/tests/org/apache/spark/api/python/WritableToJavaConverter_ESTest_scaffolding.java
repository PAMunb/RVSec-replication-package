/**
 * Scaffolding file used to store all the setups needed to run 
 * tests automatically generated by EvoSuite
 * Thu Apr 21 22:41:33 GMT 2022
 */

package org.apache.spark.api.python;

import org.evosuite.runtime.annotation.EvoSuiteClassExclude;
import org.junit.BeforeClass;
import org.junit.Before;
import org.junit.After;
import org.junit.AfterClass;
import org.evosuite.runtime.sandbox.Sandbox;
import org.evosuite.runtime.sandbox.Sandbox.SandboxMode;

import static org.evosuite.shaded.org.mockito.Mockito.*;
@EvoSuiteClassExclude
public class WritableToJavaConverter_ESTest_scaffolding {

  @org.junit.Rule
  public org.evosuite.runtime.vnet.NonFunctionalRequirementRule nfr = new org.evosuite.runtime.vnet.NonFunctionalRequirementRule();

  private static final java.util.Properties defaultProperties = (java.util.Properties) java.lang.System.getProperties().clone(); 

  private org.evosuite.runtime.thread.ThreadStopper threadStopper =  new org.evosuite.runtime.thread.ThreadStopper (org.evosuite.runtime.thread.KillSwitchHandler.getInstance(), 3000);


  @BeforeClass
  public static void initEvoSuiteFramework() { 
    org.evosuite.runtime.RuntimeSettings.className = "org.apache.spark.api.python.WritableToJavaConverter"; 
    org.evosuite.runtime.GuiSupport.initialize(); 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfThreads = 100; 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfIterationsPerLoop = 10000; 
    org.evosuite.runtime.RuntimeSettings.mockSystemIn = true; 
    org.evosuite.runtime.RuntimeSettings.sandboxMode = org.evosuite.runtime.sandbox.Sandbox.SandboxMode.RECOMMENDED; 
    org.evosuite.runtime.sandbox.Sandbox.initializeSecurityManagerForSUT(); 
    org.evosuite.runtime.classhandling.JDKClassResetter.init();
    setSystemProperties();
    initializeClasses();
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    try { initMocksToAvoidTimeoutsInTheTests(); } catch(ClassNotFoundException e) {} 
  } 

  @AfterClass
  public static void clearEvoSuiteFramework(){ 
    Sandbox.resetDefaultSecurityManager(); 
    java.lang.System.setProperties((java.util.Properties) defaultProperties.clone()); 
  } 

  @Before
  public void initTestCase(){ 
    threadStopper.storeCurrentThreads();
    threadStopper.startRecordingTime();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().initHandler(); 
    org.evosuite.runtime.sandbox.Sandbox.goingToExecuteSUTCode(); 
    setSystemProperties(); 
    org.evosuite.runtime.GuiSupport.setHeadless(); 
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    org.evosuite.runtime.agent.InstrumentingAgent.activate(); 
  } 

  @After
  public void doneWithTestCase(){ 
    threadStopper.killAndJoinClientThreads();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().safeExecuteAddedHooks(); 
    org.evosuite.runtime.classhandling.JDKClassResetter.reset(); 
    resetClasses(); 
    org.evosuite.runtime.sandbox.Sandbox.doneWithExecutingSUTCode(); 
    org.evosuite.runtime.agent.InstrumentingAgent.deactivate(); 
    org.evosuite.runtime.GuiSupport.restoreHeadlessMode(); 
  } 

  public static void setSystemProperties() {
 
    java.lang.System.setProperties((java.util.Properties) defaultProperties.clone()); 
    java.lang.System.setProperty("user.dir", "/home/pedro/projects/RVSec-replication-package/ApacheCryptoAPIBench/apache_codes/spark/core"); 
    java.lang.System.setProperty("java.io.tmpdir", "/tmp"); 
  }

  private static void initializeClasses() {
    org.evosuite.runtime.classhandling.ClassStateSupport.initializeClasses(WritableToJavaConverter_ESTest_scaffolding.class.getClassLoader() ,
      "scala.collection.Parallelizable",
      "org.apache.hadoop.io.NullWritable",
      "scala.Serializable",
      "scala.reflect.ScalaSignature",
      "org.apache.hadoop.io.Text",
      "org.apache.hadoop.io.Writable",
      "org.apache.hadoop.util.ReflectionUtils$CopyInCopyOutBuffer",
      "org.apache.hadoop.io.LongWritable",
      "scala.reflect.ClassManifestDeprecatedApis",
      "scala.collection.GenIterable",
      "org.apache.hadoop.io.serializer.WritableSerialization",
      "org.apache.hadoop.conf.Configured",
      "org.apache.hadoop.conf.Configuration",
      "org.apache.hadoop.io.serializer.avro.AvroReflectSerialization",
      "org.apache.hadoop.classification.InterfaceAudience$Public",
      "org.apache.hadoop.conf.Configurable",
      "org.apache.hadoop.io.ArrayWritable",
      "org.apache.hadoop.io.IntWritable",
      "org.apache.hadoop.classification.InterfaceStability$Stable",
      "org.apache.spark.broadcast.Broadcast",
      "org.apache.spark.api.python.WritableToJavaConverter",
      "scala.PartialFunction",
      "scala.reflect.OptManifest",
      "scala.collection.Seq",
      "org.apache.hadoop.io.DataOutputBuffer$Buffer",
      "scala.collection.TraversableOnce",
      "org.apache.hadoop.io.DataInputBuffer$Buffer",
      "org.apache.hadoop.io.BooleanWritable",
      "org.apache.hadoop.io.DataOutputBuffer",
      "scala.collection.TraversableLike",
      "scala.collection.IterableLike",
      "org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization",
      "org.apache.hadoop.util.ReflectionUtils$1",
      "scala.collection.generic.FilterMonadic",
      "org.apache.spark.api.python.Converter",
      "scala.reflect.ClassTag",
      "org.apache.spark.util.SerializableConfiguration",
      "scala.collection.GenIterableLike",
      "scala.Function0",
      "scala.Equals",
      "scala.Function1",
      "org.apache.hadoop.io.WritableComparable",
      "scala.collection.generic.HasNewBuilder",
      "org.apache.hadoop.io.BinaryComparable",
      "scala.collection.GenTraversableOnce",
      "org.apache.hadoop.io.MapWritable",
      "org.apache.hadoop.io.DoubleWritable",
      "scala.collection.GenTraversableLike",
      "scala.collection.generic.GenericTraversableTemplate",
      "org.apache.hadoop.io.serializer.SerializationFactory",
      "scala.collection.GenTraversable",
      "scala.collection.GenSeq",
      "org.apache.hadoop.io.BytesWritable",
      "org.apache.spark.SparkException",
      "org.apache.hadoop.io.DataInputBuffer",
      "scala.collection.Traversable",
      "org.apache.hadoop.io.serializer.Serialization",
      "org.apache.hadoop.io.AbstractMapWritable",
      "org.apache.hadoop.io.serializer.avro.AvroSerialization",
      "scala.collection.GenSeqLike",
      "org.apache.spark.internal.Logging",
      "scala.collection.Iterable",
      "scala.collection.SeqLike",
      "org.apache.hadoop.io.FloatWritable",
      "org.apache.hadoop.util.ReflectionUtils",
      "org.apache.hadoop.io.WritableUtils"
    );
  } 
  private static void initMocksToAvoidTimeoutsInTheTests() throws ClassNotFoundException { 
    mock(Class.forName("org.apache.hadoop.io.Writable", false, WritableToJavaConverter_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.broadcast.Broadcast", false, WritableToJavaConverter_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.util.SerializableConfiguration", false, WritableToJavaConverter_ESTest_scaffolding.class.getClassLoader()));
  }

  private static void resetClasses() {
    org.evosuite.runtime.classhandling.ClassResetter.getInstance().setClassLoader(WritableToJavaConverter_ESTest_scaffolding.class.getClassLoader()); 

    org.evosuite.runtime.classhandling.ClassStateSupport.resetClasses(
      "org.apache.spark.api.python.WritableToJavaConverter",
      "scala.runtime.AbstractFunction1",
      "org.apache.spark.api.python.WritableToJavaConverter$$anonfun$org$apache$spark$api$python$WritableToJavaConverter$$convertWritable$1",
      "org.apache.spark.api.python.WritableToJavaConverter$$anonfun$org$apache$spark$api$python$WritableToJavaConverter$$convertWritable$2",
      "scala.LowPriorityImplicits",
      "scala.DeprecatedPredef$class",
      "scala.package$$anon$1",
      "scala.collection.generic.GenericCompanion",
      "scala.collection.generic.GenTraversableFactory",
      "scala.collection.generic.GenTraversableFactory$GenericCanBuildFrom",
      "scala.collection.generic.GenTraversableFactory$$anon$1",
      "scala.util.control.Breaks",
      "scala.util.control.BreakControl",
      "scala.util.control.NoStackTrace$class",
      "scala.sys.SystemProperties$",
      "scala.sys.BooleanProp$",
      "scala.sys.PropImpl",
      "scala.sys.BooleanProp$BooleanPropImpl",
      "scala.sys.BooleanProp$$anonfun$keyExists$1",
      "scala.Function1$class",
      "scala.collection.generic.GenMapFactory",
      "scala.collection.generic.MapFactory",
      "scala.collection.generic.MutableMapFactory",
      "scala.collection.mutable.Map$",
      "scala.collection.AbstractTraversable",
      "scala.collection.AbstractIterable",
      "scala.collection.AbstractSeq",
      "scala.collection.immutable.List",
      "scala.collection.TraversableOnce$class",
      "scala.collection.Parallelizable$class",
      "scala.collection.TraversableLike$class",
      "scala.collection.generic.GenericTraversableTemplate$class",
      "scala.collection.GenTraversable$class",
      "scala.collection.Traversable$class",
      "scala.collection.GenIterable$class",
      "scala.collection.IterableLike$class",
      "scala.collection.Iterable$class",
      "scala.PartialFunction$class",
      "scala.collection.GenSeqLike$class",
      "scala.collection.GenSeq$class",
      "scala.collection.SeqLike$class",
      "scala.collection.Seq$class",
      "scala.collection.immutable.Traversable$class",
      "scala.collection.immutable.Iterable$class",
      "scala.collection.immutable.Seq$class",
      "scala.collection.LinearSeqLike$class",
      "scala.collection.LinearSeq$class",
      "scala.collection.immutable.LinearSeq$class",
      "scala.Product$class",
      "scala.collection.LinearSeqOptimized$class",
      "scala.collection.immutable.Nil$",
      "scala.collection.AbstractMap",
      "scala.collection.mutable.AbstractMap",
      "scala.collection.mutable.HashMap",
      "scala.collection.GenMapLike$class",
      "scala.collection.generic.Subtractable$class",
      "scala.collection.MapLike$class",
      "scala.collection.Map$class",
      "scala.collection.mutable.Traversable$class",
      "scala.collection.mutable.Iterable$class",
      "scala.collection.generic.Growable$class",
      "scala.collection.mutable.Builder$class",
      "scala.collection.generic.Shrinkable$class",
      "scala.collection.mutable.Cloneable$class",
      "scala.collection.mutable.MapLike$class",
      "scala.collection.mutable.Map$class",
      "scala.collection.mutable.HashTable$HashUtils$class",
      "scala.collection.mutable.HashTable$class",
      "scala.collection.mutable.HashTable$",
      "scala.collection.CustomParallelizable$class",
      "scala.runtime.BoxedUnit",
      "scala.runtime.ScalaRunTime$",
      "scala.util.hashing.package$",
      "scala.collection.mutable.DefaultEntry",
      "scala.collection.mutable.HashEntry$class",
      "scala.Option",
      "scala.None$",
      "scala.sys.package$",
      "scala.sys.SystemProperties",
      "scala.runtime.AbstractFunction0",
      "scala.runtime.AbstractFunction0$mcZ$sp",
      "scala.sys.SystemProperties$$anonfun$contains$1",
      "scala.Function0$class",
      "scala.Function0$mcZ$sp$class",
      "scala.Some",
      "scala.sys.SystemProperties$$anonfun$get$1",
      "scala.Option$",
      "scala.runtime.BoxesRunTime",
      "scala.util.control.NoStackTrace$",
      "scala.collection.Traversable$",
      "scala.collection.Iterable$",
      "scala.collection.generic.GenSeqFactory",
      "scala.collection.generic.SeqFactory",
      "scala.collection.Seq$",
      "scala.collection.generic.IndexedSeqFactory",
      "scala.collection.IndexedSeq$$anon$1",
      "scala.collection.IndexedSeq$",
      "scala.collection.AbstractIterator",
      "scala.collection.Iterator$$anon$2",
      "scala.collection.Iterator$class",
      "scala.collection.Iterator$",
      "scala.collection.immutable.List$$anon$1",
      "scala.collection.immutable.List$",
      "scala.collection.immutable.$colon$colon$",
      "scala.collection.$plus$colon$",
      "scala.collection.$colon$plus$",
      "scala.collection.immutable.Stream$",
      "scala.collection.immutable.Stream$$hash$colon$colon$",
      "scala.collection.immutable.Vector",
      "scala.collection.IndexedSeqLike$class",
      "scala.collection.IndexedSeq$class",
      "scala.collection.immutable.IndexedSeq$class",
      "scala.collection.immutable.VectorPointer$class",
      "scala.collection.immutable.Vector$",
      "scala.collection.mutable.StringBuilder$",
      "scala.collection.immutable.Range$",
      "scala.math.BigDecimal$",
      "scala.math.BigInt$",
      "scala.math.LowPriorityEquiv$class",
      "scala.math.Equiv$",
      "scala.math.Fractional$",
      "scala.math.Integral$",
      "scala.math.Numeric$",
      "scala.math.Ordered$",
      "scala.math.LowPriorityOrderingImplicits$class",
      "scala.math.Ordering$",
      "scala.util.Either$",
      "scala.util.Left$",
      "scala.util.Right$",
      "scala.package$",
      "scala.collection.generic.ImmutableMapFactory",
      "scala.collection.immutable.Map$",
      "scala.collection.generic.GenSetFactory",
      "scala.collection.generic.SetFactory",
      "scala.collection.generic.ImmutableSetFactory",
      "scala.collection.immutable.Set$",
      "scala.reflect.AnyValManifest",
      "scala.reflect.ManifestFactory$$anon$6",
      "scala.reflect.ClassManifestDeprecatedApis$class",
      "scala.reflect.ClassTag$class",
      "scala.reflect.Manifest$class",
      "scala.reflect.ManifestFactory$$anon$7",
      "scala.reflect.ManifestFactory$$anon$8",
      "scala.reflect.ManifestFactory$$anon$9",
      "scala.reflect.ManifestFactory$$anon$10",
      "scala.reflect.ManifestFactory$$anon$11",
      "scala.reflect.ManifestFactory$$anon$12",
      "scala.reflect.ManifestFactory$$anon$13",
      "scala.reflect.ManifestFactory$$anon$14",
      "scala.reflect.ManifestFactory$ClassTypeManifest",
      "scala.reflect.ManifestFactory$PhantomManifest",
      "scala.reflect.ManifestFactory$$anon$1",
      "scala.reflect.ManifestFactory$$anon$2",
      "scala.reflect.ManifestFactory$$anon$3",
      "scala.reflect.ManifestFactory$$anon$4",
      "scala.reflect.ManifestFactory$$anon$5",
      "scala.reflect.ManifestFactory$",
      "scala.reflect.ClassManifestFactory$",
      "scala.reflect.package$",
      "scala.reflect.NoManifest$",
      "scala.Predef$$anon$3",
      "scala.Predef$$less$colon$less",
      "scala.Predef$$anon$1",
      "scala.Predef$$eq$colon$eq",
      "scala.Predef$$anon$2",
      "scala.Predef$",
      "scala.FallbackArrayBuilding",
      "scala.Array$",
      "scala.reflect.ClassTag$",
      "scala.collection.convert.DecorateAsJava$class",
      "scala.collection.convert.DecorateAsScala$class",
      "scala.collection.JavaConverters$",
      "org.apache.hadoop.util.ReflectionUtils$1",
      "org.apache.hadoop.util.ReflectionUtils",
      "org.apache.spark.broadcast.Broadcast",
      "org.apache.spark.util.SerializableConfiguration",
      "org.apache.hadoop.io.WritableUtils",
      "org.apache.hadoop.util.ReflectionUtils$CopyInCopyOutBuffer",
      "org.apache.hadoop.io.DataOutputBuffer",
      "org.apache.hadoop.io.DataOutputBuffer$Buffer",
      "org.apache.hadoop.io.DataInputBuffer",
      "org.apache.hadoop.io.DataInputBuffer$Buffer",
      "org.apache.hadoop.conf.Configured",
      "org.apache.hadoop.io.serializer.SerializationFactory",
      "org.apache.hadoop.conf.Configuration$DeprecationDelta",
      "com.google.common.base.Preconditions",
      "org.apache.hadoop.conf.Configuration$DeprecationContext",
      "org.apache.hadoop.conf.Configuration$DeprecatedKeyInfo",
      "org.apache.commons.collections.map.AbstractMapDecorator",
      "org.apache.commons.collections.map.UnmodifiableMap",
      "org.apache.hadoop.conf.Configuration"
    );
  }
}
