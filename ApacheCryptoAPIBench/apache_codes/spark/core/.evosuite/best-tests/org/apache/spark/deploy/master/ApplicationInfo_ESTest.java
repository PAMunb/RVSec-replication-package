/*
 * This file was automatically generated by EvoSuite
 * Thu Apr 21 22:54:53 GMT 2022
 */

package org.apache.spark.deploy.master;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.util.Date;
import org.apache.spark.deploy.ApplicationDescription;
import org.apache.spark.deploy.master.ApplicationInfo;
import org.apache.spark.deploy.master.ApplicationSource;
import org.apache.spark.deploy.master.ExecutorDesc;
import org.apache.spark.deploy.master.WorkerInfo;
import org.apache.spark.rpc.RpcEndpointRef;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.junit.runner.RunWith;
import scala.Enumeration;
import scala.Option;
import scala.Some;
import scala.collection.mutable.ArrayBuffer;
import scala.collection.mutable.HashMap;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true) 
public class ApplicationInfo_ESTest extends ApplicationInfo_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("9", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(9223372036854775807L, "9", applicationDescription0, date0, rpcEndpointRef0, (-6));
      assertNotNull(applicationInfo0);
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("9", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      
      applicationInfo0.endTime_$eq(0L);
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("9", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals((-9223372036854775807L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      
      long long0 = applicationInfo0.duration();
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("9", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals((-9223372036854775807L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-9223372036854775807L), long0);
  }

  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, (Date) null, (RpcEndpointRef) null, 1647);
      assertNotNull(applicationInfo0);
      assertEquals(1647, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      
      Date date0 = applicationInfo0.submitDate();
      assertNull(date0);
      assertEquals(1647, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
  }

  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      
      applicationInfo0.markFinished((Enumeration.Value) null);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(1392409281320L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
      
      Enumeration.Value enumeration_Value0 = applicationInfo0.state();
      assertNull(enumeration_Value0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(1392409281320L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
  }

  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(9223372036854775807L, "", applicationDescription0, date0, rpcEndpointRef0, (-6));
      assertNotNull(applicationInfo0);
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("", applicationInfo0.id());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      
      long long0 = applicationInfo0.startTime();
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("", applicationInfo0.id());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(9223372036854775807L, long0);
  }

  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-3103L), "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, (-2470));
      assertNotNull(applicationInfo0);
      assertEquals((-2470), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals(1392409284423L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      
      long long0 = applicationInfo0.startTime();
      assertEquals((-2470), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals(1392409284423L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-3103L), long0);
  }

  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-3103L), "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, (-2470));
      assertNotNull(applicationInfo0);
      assertEquals((-2470), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1392409284423L, applicationInfo0.duration());
      
      String string0 = applicationInfo0.id();
      assertNotNull(string0);
      assertEquals((-2470), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1392409284423L, applicationInfo0.duration());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", string0);
  }

  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(9223372036854775807L, "", applicationDescription0, date0, rpcEndpointRef0, (-6));
      assertNotNull(applicationInfo0);
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      
      String string0 = applicationInfo0.id();
      assertNotNull(string0);
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("", string0);
  }

  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-2085L), (String) null, applicationDescription0, date0, (RpcEndpointRef) null, 3181);
      assertNotNull(applicationInfo0);
      assertEquals(3181, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertNull(applicationInfo0.id());
      assertEquals(1392409283405L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals((-2085L), applicationInfo0.startTime());
      
      applicationInfo0.executorLimit_$eq(3181);
      assertEquals(3181, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertNull(applicationInfo0.id());
      assertEquals(1392409283405L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(3181, applicationInfo0.getExecutorLimit());
      assertEquals(3181, applicationInfo0.executorLimit());
      assertEquals((-2085L), applicationInfo0.startTime());
      
      int int0 = applicationInfo0.executorLimit();
      assertEquals(3181, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertNull(applicationInfo0.id());
      assertEquals(1392409283405L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(3181, applicationInfo0.getExecutorLimit());
      assertEquals(3181, applicationInfo0.executorLimit());
      assertEquals((-2085L), applicationInfo0.startTime());
      assertEquals(3181, int0);
  }

  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(0, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 0);
      assertNotNull(applicationInfo0);
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      applicationInfo0.executorLimit_$eq((-1139));
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-1139), applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals((-1139), applicationInfo0.executorLimit());
      assertEquals(0L, applicationInfo0.startTime());
      
      int int0 = applicationInfo0.executorLimit();
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-1139), applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals((-1139), applicationInfo0.executorLimit());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals((-1139), int0);
  }

  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(0, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 0);
      assertNotNull(applicationInfo0);
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      
      applicationInfo0.endTime_$eq(0);
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0L, applicationInfo0.duration());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      
      long long0 = applicationInfo0.endTime();
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0L, applicationInfo0.duration());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0L, long0);
  }

  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1048576L, "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, (-1));
      assertNotNull(applicationInfo0);
      assertEquals((-1), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1392408232744L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1048576L, applicationInfo0.startTime());
      
      applicationInfo0.endTime_$eq(495L);
      assertEquals((-1), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(495L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1048081L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1048576L, applicationInfo0.startTime());
      
      long long0 = applicationInfo0.endTime();
      assertEquals((-1), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(495L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1048081L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1048576L, applicationInfo0.startTime());
      assertEquals(495L, long0);
  }

  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      System.setCurrentTimeMillis((-1618L));
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-1618L), "", applicationDescription0, date0, (RpcEndpointRef) null, Integer.MIN_VALUE);
      assertNotNull(applicationInfo0);
      assertEquals(Integer.MIN_VALUE, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("", applicationInfo0.id());
      assertEquals((-1618L), applicationInfo0.startTime());
      
      long long0 = applicationInfo0.duration();
      assertEquals(Integer.MIN_VALUE, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("", applicationInfo0.id());
      assertEquals((-1618L), applicationInfo0.startTime());
      assertEquals(0L, long0);
  }

  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(9223372036854775807L, "", applicationDescription0, date0, rpcEndpointRef0, (-6));
      assertNotNull(applicationInfo0);
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      applicationInfo0.coresGranted_$eq(328);
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("", applicationInfo0.id());
      assertEquals(328, applicationInfo0.coresGranted());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-328), applicationInfo0.coresLeft());
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      int int0 = applicationInfo0.coresLeft();
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("", applicationInfo0.id());
      assertEquals(328, applicationInfo0.coresGranted());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-328), applicationInfo0.coresLeft());
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals((-328), int0);
  }

  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      Some<ExecutorDesc> some0 = (Some<ExecutorDesc>) mock(Some.class, new ViolatedAssumptionAnswer());
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn(some0).when(option0).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = null;
      try {
        applicationInfo0 = new ApplicationInfo((-2470), "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, (-2470));
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // scala.Some$MockitoMock$1345963600 cannot be cast to java.lang.Integer
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-3103L), "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, (-2464));
      assertNotNull(applicationInfo0);
      assertEquals((-2464), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1392409284423L, applicationInfo0.duration());
      
      ArrayBuffer<ExecutorDesc> arrayBuffer0 = applicationInfo0.removedExecutors();
      assertNotNull(arrayBuffer0);
      assertEquals((-2464), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1392409284423L, applicationInfo0.duration());
      assertEquals("ArrayBuffer", arrayBuffer0.stringPrefix());
      assertEquals(16, arrayBuffer0.initialSize());
      assertEquals(0, arrayBuffer0.size0());
      assertEquals(0, arrayBuffer0.length());
      assertTrue(arrayBuffer0.isTraversableAgain());
      
      applicationInfo0.removedExecutors_$eq(arrayBuffer0);
      assertEquals((-2464), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1392409284423L, applicationInfo0.duration());
      assertEquals("ArrayBuffer", arrayBuffer0.stringPrefix());
      assertEquals(16, arrayBuffer0.initialSize());
      assertEquals(0, arrayBuffer0.size0());
      assertEquals(0, arrayBuffer0.length());
      assertTrue(arrayBuffer0.isTraversableAgain());
  }

  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(0, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 0);
      assertNotNull(applicationInfo0);
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      
      long long0 = applicationInfo0.endTime();
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-1L), long0);
  }

  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0, (Option) null).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null, (String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", (String) null, (String) null).when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-358L), "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, (-574));
      assertNotNull(applicationInfo0);
      assertEquals((-574), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals((-358L), applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1392409281678L, applicationInfo0.duration());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      
      // Undeclared exception!
      try { 
        applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$init();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.deploy.master.ApplicationInfo", e);
      }
  }

  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(403, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 403);
      assertNotNull(applicationInfo0);
      assertEquals(403, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(403L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(1392409280917L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      applicationInfo0.coresGranted_$eq((-1));
      assertEquals(403, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(403L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-1), applicationInfo0.coresGranted());
      assertEquals(1, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(1392409280917L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      int int0 = applicationInfo0.coresLeft();
      assertEquals(403, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(403L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals((-1), applicationInfo0.coresGranted());
      assertEquals(1, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(1392409280917L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1, int0);
  }

  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-3103L), "p<W8+SR", applicationDescription0, date0, rpcEndpointRef0, (-2470));
      assertNotNull(applicationInfo0);
      assertEquals((-2470), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(1392409284423L, applicationInfo0.duration());
      assertEquals("p<W8+SR", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      
      Enumeration.Val enumeration_Val0 = (Enumeration.Val)applicationInfo0.state();
      assertNotNull(enumeration_Val0);
      assertEquals((-2470), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, enumeration_Val0.scala$Enumeration$Val$$i);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(1392409284423L, applicationInfo0.duration());
      assertEquals("p<W8+SR", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, enumeration_Val0.id());
      
      applicationInfo0.state_$eq(enumeration_Val0);
      assertEquals((-2470), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, enumeration_Val0.scala$Enumeration$Val$$i);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-3103L), applicationInfo0.startTime());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(1392409284423L, applicationInfo0.duration());
      assertEquals("p<W8+SR", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, enumeration_Val0.id());
  }

  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(9223372036854775807L, "", applicationDescription0, date0, rpcEndpointRef0, (-6));
      assertNotNull(applicationInfo0);
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals("", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      
      int int0 = applicationInfo0.coresGranted();
      assertEquals((-6), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals((-9223370644445494487L), applicationInfo0.duration());
      assertEquals(9223372036854775807L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals("", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, int0);
  }

  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(Integer.MAX_VALUE, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, Integer.MAX_VALUE);
      assertNotNull(applicationInfo0);
      assertEquals(Integer.MAX_VALUE, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1390261797673L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(2147483647L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      
      applicationInfo0.executorLimit_$eq(Integer.MAX_VALUE);
      assertEquals(Integer.MAX_VALUE, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(Integer.MAX_VALUE, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(Integer.MAX_VALUE, applicationInfo0.getExecutorLimit());
      assertEquals(1390261797673L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(2147483647L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      
      int int0 = applicationInfo0.getExecutorLimit();
      assertEquals(Integer.MAX_VALUE, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(Integer.MAX_VALUE, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(Integer.MAX_VALUE, applicationInfo0.getExecutorLimit());
      assertEquals(1390261797673L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(2147483647L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(Integer.MAX_VALUE, int0);
  }

  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", (String) null).when(applicationDescription0).toString();
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, (Date) null, (RpcEndpointRef) null, 1647);
      assertNotNull(applicationInfo0);
      assertEquals(1647, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      ApplicationDescription applicationDescription1 = applicationInfo0.desc();
      assertNotNull(applicationDescription1);
      assertEquals(1647, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertNull(applicationDescription1.copy$default$1());
      assertNull(applicationDescription1.copy$default$10());
      assertEquals(0, applicationDescription1.productArity());
      assertNull(applicationDescription1.user());
      assertNull(applicationDescription1.copy$default$5());
      assertEquals(0, applicationDescription1.copy$default$3());
      assertNull(applicationDescription1.appUiUrl());
      assertEquals(0, applicationDescription1.memoryPerExecutorMB());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription1.name());
      assertNull(applicationDescription1.productPrefix());
      assertSame(applicationDescription1, applicationDescription0);
  }

  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-358L), "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, (-574));
      assertNotNull(applicationInfo0);
      assertEquals((-574), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1392409281678L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals((-358L), applicationInfo0.startTime());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      
      ApplicationSource applicationSource0 = applicationInfo0.appSource();
      assertNotNull(applicationSource0);
      assertEquals((-574), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1392409281678L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals((-358L), applicationInfo0.startTime());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals("application.null.1392409281320", applicationSource0.sourceName());
      
      applicationInfo0.appSource_$eq(applicationSource0);
      assertEquals((-574), applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1392409281678L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals((-358L), applicationInfo0.startTime());
      assertEquals("org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals("application.null.1392409281320", applicationSource0.sourceName());
  }

  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(0, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 0);
      assertNotNull(applicationInfo0);
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      
      int int0 = applicationInfo0.executorLimit();
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, int0);
  }

  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("").when(applicationDescription0).name();
      doReturn("'kz)Zh", "").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(0L, "'kz)Zh", applicationDescription0, date0, rpcEndpointRef0, 2826);
      assertNotNull(applicationInfo0);
      assertEquals(2826, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals("'kz)Zh", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      HashMap<Object, ExecutorDesc> hashMap0 = applicationInfo0.executors();
      assertNotNull(hashMap0);
      assertEquals(2826, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals("'kz)Zh", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertTrue(hashMap0.isTraversableAgain());
      assertFalse(hashMap0.alwaysInitSizeMap());
      assertFalse(hashMap0.isSizeMapDefined());
      assertEquals(12, hashMap0.threshold());
      assertEquals(16, hashMap0.initialSize());
      assertEquals(32, hashMap0.sizeMapBucketSize());
      assertEquals(5, hashMap0.sizeMapBucketBitSize());
      assertEquals("Map", hashMap0.stringPrefix());
      assertEquals(0, hashMap0.size());
      assertEquals(4, hashMap0.seedvalue());
      assertEquals(0, hashMap0.tableSize());
      assertEquals(750, hashMap0._loadFactor());
      assertEquals(4, hashMap0.tableSizeSeed());
      
      applicationInfo0.executors_$eq(hashMap0);
      assertEquals(2826, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals("'kz)Zh", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertTrue(hashMap0.isTraversableAgain());
      assertFalse(hashMap0.alwaysInitSizeMap());
      assertFalse(hashMap0.isSizeMapDefined());
      assertEquals(12, hashMap0.threshold());
      assertEquals(16, hashMap0.initialSize());
      assertEquals(32, hashMap0.sizeMapBucketSize());
      assertEquals(5, hashMap0.sizeMapBucketBitSize());
      assertEquals("Map", hashMap0.stringPrefix());
      assertEquals(0, hashMap0.size());
      assertEquals(4, hashMap0.seedvalue());
      assertEquals(0, hashMap0.tableSize());
      assertEquals(750, hashMap0._loadFactor());
      assertEquals(4, hashMap0.tableSizeSeed());
  }

  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(0, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 0);
      assertNotNull(applicationInfo0);
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      
      long long0 = applicationInfo0.startTime();
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0L, long0);
  }

  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      
      applicationInfo0.endTime_$eq((-441L));
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-441L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals((-1073742265L), applicationInfo0.duration());
      
      long long0 = applicationInfo0.duration();
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-441L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals((-1073742265L), applicationInfo0.duration());
      assertEquals((-1073742265L), long0);
  }

  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaRe.sark.deploy.master.AppPihaionInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaRe.sark.deploy.master.AppPihaionInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaRe.sark.deploy.master.AppPihaionInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaRe.sark.deploy.master.AppPihaionInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaRe.sark.deploy.master.AppPihaionInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.coresGranted());
      
      int int0 = applicationInfo0.incrementRetryCount();
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1, applicationInfo0.retryCount());
      assertEquals("org.apaRe.sark.deploy.master.AppPihaionInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(1, int0);
  }

  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      
      RpcEndpointRef rpcEndpointRef0 = applicationInfo0.driver();
      assertNull(rpcEndpointRef0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
  }

  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(date0).toString();
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(0, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 0);
      assertNotNull(applicationInfo0);
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      
      Date date1 = applicationInfo0.submitDate();
      assertNotNull(date1);
      assertEquals(0, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(1392409281320L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$AplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.retryCount());
      assertNull(date1.toString());
      assertSame(date1, date0);
  }

  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      
      Option<Object> option2 = applicationInfo0.addExecutor$default$3();
      assertNotNull(option2);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("None", option2.productPrefix());
      assertFalse(option2.equals((Object)option1));
      assertFalse(option2.equals((Object)option0));
  }

  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(Integer.MAX_VALUE, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, Integer.MAX_VALUE);
      assertNotNull(applicationInfo0);
      assertEquals(Integer.MAX_VALUE, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(2147483647L, applicationInfo0.startTime());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1390261797673L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      // Undeclared exception!
      try { 
        applicationInfo0.removeExecutor((ExecutorDesc) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.deploy.master.ApplicationInfo", e);
      }
  }

  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$sparkdeploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$sparkdeploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(758, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$sparkdeploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, rpcEndpointRef0, 758);
      assertNotNull(applicationInfo0);
      assertEquals(758, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(1392409280562L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$sparkdeploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(758L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      // Undeclared exception!
      try { 
        applicationInfo0.addExecutor((WorkerInfo) null, 758, option0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // scala.Option$MockitoMock$808779208@0000000015 (of class scala.Option$MockitoMock$808779208)
         //
         verifyException("org.apache.spark.deploy.master.ApplicationInfo", e);
      }
  }

  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      
      boolean boolean0 = applicationInfo0.isFinished();
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      
      int int0 = applicationInfo0.getExecutorLimit();
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, int0);
  }

  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      applicationInfo0.markFinished((Enumeration.Value) null);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1392409281320L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      
      boolean boolean0 = applicationInfo0.isFinished();
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1392409281320L, applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertTrue(boolean0);
  }

  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      assertNotNull(applicationInfo0);
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      
      int int0 = applicationInfo0.coresLeft();
      assertEquals(1073741824, applicationInfo0.org$apache$spark$deploy$master$ApplicationInfo$$defaultCores);
      assertEquals(0, applicationInfo0.getExecutorLimit());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationInfo0.id());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(1073741824L, applicationInfo0.startTime());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, int0);
  }

  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      int int0 = applicationInfo0.retryCount();
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, int0);
      assertEquals(1391335539496L, applicationInfo0.duration());
  }

  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn("", "org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(758, (String) null, applicationDescription0, date0, rpcEndpointRef0, 758);
      applicationInfo0.id();
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals((-1L), applicationInfo0.endTime());
      assertEquals(0, applicationInfo0.executorLimit());
  }

  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("", "org.apace.spark.deploy.master.ApplihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo((-1618L), "", applicationDescription0, date0, (RpcEndpointRef) null, Integer.MIN_VALUE);
      long long0 = applicationInfo0.duration();
      assertEquals(1392409282938L, long0);
      assertEquals(0, applicationInfo0.coresLeft());
      assertEquals(0, applicationInfo0.executorLimit());
      assertEquals(0, applicationInfo0.retryCount());
  }

  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      Option<Object> option0 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option0).getOrElse(any(scala.Function0.class));
      Option<Object> option1 = (Option<Object>) mock(Option.class, new ViolatedAssumptionAnswer());
      doReturn((ExecutorDesc) null).when(option1).getOrElse(any(scala.Function0.class));
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn(option0).when(applicationDescription0).initialExecutorLimit();
      doReturn(option1).when(applicationDescription0).maxCores();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).name();
      doReturn("org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1").when(applicationDescription0).toString();
      Date date0 = mock(Date.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = new ApplicationInfo(1073741824, "org.apaie.spark.deploy.master.AppPihationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1", applicationDescription0, date0, (RpcEndpointRef) null, 1073741824);
      applicationInfo0.resetRetryCount();
      assertEquals(0, applicationInfo0.coresGranted());
      assertEquals(0, applicationInfo0.retryCount());
      assertEquals(1391335539496L, applicationInfo0.duration());
      assertEquals(0, applicationInfo0.getExecutorLimit());
  }

  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      ApplicationDescription applicationDescription0 = mock(ApplicationDescription.class, new ViolatedAssumptionAnswer());
      doReturn((Option) null).when(applicationDescription0).initialExecutorLimit();
      doReturn((String) null).when(applicationDescription0).name();
      doReturn((String) null, (String) null).when(applicationDescription0).toString();
      RpcEndpointRef rpcEndpointRef0 = mock(RpcEndpointRef.class, new ViolatedAssumptionAnswer());
      ApplicationInfo applicationInfo0 = null;
      try {
        applicationInfo0 = new ApplicationInfo(0, (String) null, applicationDescription0, (Date) null, rpcEndpointRef0, 0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.deploy.master.ApplicationInfo", e);
      }
  }
}
