/*
 * This file was automatically generated by EvoSuite
 * Thu Apr 21 21:56:41 GMT 2022
 */

package org.apache.spark.util.collection;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import org.apache.spark.util.collection.BitSet;
import org.apache.spark.util.collection.OpenHashSet;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.junit.runner.RunWith;
import scala.Function1;
import scala.Function2;
import scala.collection.Iterator;
import scala.reflect.ClassTag;
import scala.runtime.BoxedUnit;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true) 
public class OpenHashSet_ESTest extends OpenHashSet_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test000()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(1, openHashSet2.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Object object0 = openHashSet2._data();
      assertNotNull(object0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(1, openHashSet2.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet0._data = object0;
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(1, openHashSet2.size());
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals((-1), int0);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
  }

  @Test(timeout = 4000)
  public void test001()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(16, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.add$mcJ$sp(15);
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash$mcJ$sp((-3553L), function1_0, function2_0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test002()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity = 33554432;
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(33554432, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(33554432, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash(boxedUnit0, function1_0, function2_0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test003()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = openHashSet0.contains(boxedUnit0);
      assertFalse(boolean0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      boolean boolean1 = openHashSet0.contains$mcJ$sp(0L);
      assertTrue(boolean1 == boolean0);
      assertFalse(boolean1);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValue$mcI$sp(2);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Long cannot be cast to java.lang.Integer
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test004()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask_$eq((-1944));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1944), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1944), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.getPos$mcI$sp(46);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test005()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit0, function1_0, function2_0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(61, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet1.union(openHashSet0);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet2, openHashSet0);
      assertSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int0 = openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask();
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet2, openHashSet0);
      assertSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(63, int0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet.Hasher<Object> openHashSet_Hasher0 = openHashSet2.hasher$mcI$sp();
      assertNotNull(openHashSet_Hasher0);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet2, openHashSet0);
      assertSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValue(63);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test006()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask_$eq(5870);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(5870, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(5870, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      // Undeclared exception!
      try { 
        openHashSet0.add(boxedUnit0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test007()  throws Throwable  {
      int int0 = 5885;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(5885, classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      boolean boolean0 = openHashSet1.contains$mcJ$sp((-1544L));
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehashIfNeeded(boxedUnit0, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int1 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int1 == int0);
      assertEquals(0, int1);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BitSet bitSet0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset();
      assertNotNull(bitSet0);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(8192, bitSet0.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int2 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals(5734, int2);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask = 0;
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      
      int int3 = openHashSet0.nextPos(5734);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int3 == int2);
      assertFalse(int3 == int0);
      assertFalse(int3 == int1);
      assertEquals((-1), int3);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      Iterator<BoxedUnit> iterator0 = openHashSet0.iterator();
      assertNotNull(iterator0);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int4 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask();
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(int4 == int0);
      assertFalse(int4 == int3);
      assertTrue(int4 == int1);
      assertFalse(int4 == int2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(0, int4);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcJ$sp(0);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test008()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(4096, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      Function1<Object, BoxedUnit> function1_0 = null;
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash$mcI$sp(1, (Function1<Object, BoxedUnit>) null, function2_0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test009()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask = 5884;
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(5884, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize(boxedUnit0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test010()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity = (-898);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals((-898), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-898), openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals((-898), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-898), openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-898), openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-898), openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-898), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals((-898), openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int0 = openHashSet1.capacity();
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals((-898), int0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals((-898), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-898), openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-898), openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-898), openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-898), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals((-898), openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test011()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int0 = openHashSet0.addWithoutResize((BoxedUnit) null);
      assertEquals(Integer.MIN_VALUE, int0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test012()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      boolean boolean0 = openHashSet0.contains$mcI$sp(2);
      assertFalse(boolean0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      // Undeclared exception!
      try { 
        openHashSet0.add$mcI$sp((-1024));
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Integer cannot be cast to java.lang.Long
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test013()  throws Throwable  {
      int int0 = 2;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = openHashSet0.contains(boxedUnit0);
      assertFalse(boolean0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.getValue(1073741824);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1073741824
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test014()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit0);
      assertEquals((-1), int0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test015()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset = null;
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize(boxedUnit0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test016()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.add(boxedUnit0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // scala.runtime.BoxedUnit$MockitoMock$197499384 cannot be cast to java.lang.Long
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test017()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      boolean boolean0 = openHashSet0.contains$mcI$sp(2);
      assertFalse(boolean0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      // Undeclared exception!
      try { 
        openHashSet0._data$mcI$sp();
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // [J cannot be cast to [I
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test018()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit1);
      assertEquals((-1), int0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size = (-1);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.size());
      
      int int1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size;
      assertTrue(int1 == int0);
      assertEquals((-1), int1);
      
      int int2 = openHashSet0.size();
      assertTrue(int2 == int0);
      assertTrue(int2 == int1);
      assertEquals((-1), int2);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      boolean boolean0 = openHashSet0.specInstance$();
      assertFalse(boolean0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int3 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertFalse(int3 == int0);
      assertFalse(int3 == int1);
      assertFalse(int3 == int2);
      assertEquals(64, int3);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
  }

  @Test(timeout = 4000)
  public void test019()  throws Throwable  {
      int int0 = 2;
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>(2, 0.7, (ClassTag<BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test020()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(64, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      Object object0 = openHashSet1._data;
      assertNull(object0);
      
      ClassTag<BoxedUnit> classTag1 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag1).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet2 = new OpenHashSet<BoxedUnit>(64, classTag1);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(64, openHashSet2.capacity());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag2 = openHashSet2.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag2);
      assertNotSame(classTag2, classTag0);
      assertSame(classTag2, classTag1);
      assertFalse(classTag2.equals((Object)classTag0));
      
      OpenHashSet<BoxedUnit> openHashSet3 = new OpenHashSet<BoxedUnit>(classTag2);
      assertNotNull(openHashSet3);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(classTag2.equals((Object)classTag0));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(64, openHashSet2.capacity());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet3.capacity());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      Object object1 = openHashSet3._data;
      assertNull(object1);
      
      ClassTag<BoxedUnit> classTag3 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag3).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet4 = new OpenHashSet<BoxedUnit>(2, classTag3);
      assertNotNull(openHashSet4);
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertEquals(2, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(2, openHashSet4.capacity());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(0, openHashSet4.size());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      long[] longArray0 = new long[5];
      openHashSet4._data$mcJ$sp_$eq(longArray0);
      assertNotSame(openHashSet4, openHashSet0);
      assertNotSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet3);
      assertNotSame(openHashSet4, openHashSet2);
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(2, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(2, openHashSet4.capacity());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(0, openHashSet4.size());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet4.add$mcJ$sp(1);
      assertNotSame(openHashSet4, openHashSet0);
      assertNotSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet3);
      assertNotSame(openHashSet4, openHashSet2);
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertEquals(2, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet4.capacity());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(1, openHashSet4.size());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet4.add$mcJ$sp(2);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test021()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2304, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash$mcI$sp(5885, function1_0, function2_0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(4667, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(8192, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(5734, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(8192, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(8191, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(8191, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(5734, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(8192, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Function1<Object, BoxedUnit> function1_1 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_1 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      openHashSet1.rehash$mcI$sp(4667, function1_1, function2_1);
  }

  @Test(timeout = 4000)
  public void test022()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(64, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      Object object0 = openHashSet1._data;
      assertNull(object0);
      
      ClassTag<BoxedUnit> classTag2 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag2).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet2 = new OpenHashSet<BoxedUnit>(2, classTag2);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      long[] longArray0 = new long[5];
      openHashSet2._data$mcJ$sp_$eq(longArray0);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet2.add$mcJ$sp(1);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet2.size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet2.add$mcJ$sp(2);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test023()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize$mcI$sp(2);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Integer cannot be cast to java.lang.Long
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test024()  throws Throwable  {
      int int0 = 2;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize(boxedUnit0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // scala.runtime.BoxedUnit$MockitoMock$197499384 cannot be cast to java.lang.Long
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test025()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet1.union(openHashSet0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test026()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash$mcI$sp(2, function1_0, function2_0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test027()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      boolean boolean0 = openHashSet0.contains$mcJ$sp(1);
      assertTrue(boolean0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test028()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int0 = openHashSet0.addWithoutResize$mcJ$sp(2);
      assertEquals((-2147483647), int0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded$mcI$sp(2, (Function1<Object, BoxedUnit>) null, function2_0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0._data$mcI$sp_$eq((int[]) null);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcJ$sp(2);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test029()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash(boxedUnit0, function1_0, function2_0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test030()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size = 2;
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.size());
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      // Undeclared exception!
      try { 
        openHashSet0.add$mcJ$sp(1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test031()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int[] intArray0 = openHashSet1._data$mcI$sp();
      assertNull(intArray0);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
  }

  @Test(timeout = 4000)
  public void test032()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int[] intArray0 = new int[4];
      intArray0[0] = 53;
      intArray0[1] = 46;
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity_$eq(21);
      assertEquals(21, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(21, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(21, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      intArray0[2] = 0;
      intArray0[3] = 21;
      openHashSet0._data$mcI$sp_$eq(intArray0);
      assertArrayEquals(new int[] {53, 46, 0, 21}, intArray0);
      assertEquals(4, intArray0.length);
      assertEquals(21, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(21, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(21, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.add$mcJ$sp(53);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Long cannot be cast to java.lang.Integer
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test033()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(2, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet0.add$mcJ$sp(1);
      assertSame(openHashSet0, openHashSet1);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet1.getValueSafe$mcJ$sp(1688);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test034()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2070, classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash$mcI$sp(2070, function1_0, function2_0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Function1<Object, BoxedUnit> function1_1 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      openHashSet0.rehash(boxedUnit0, function1_1, (Function2<Object, Object, BoxedUnit>) null);
  }

  @Test(timeout = 4000)
  public void test035()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int[] intArray0 = new int[2];
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit0);
      assertEquals((-1), int0);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      intArray0[0] = 1;
      intArray0[1] = 0;
      openHashSet0._data$mcI$sp_$eq(intArray0);
      assertArrayEquals(new int[] {1, 0}, intArray0);
      assertEquals(2, intArray0.length);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      // Undeclared exception!
      try { 
        openHashSet0.add$mcI$sp(1);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 61
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test036()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1980, classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash$mcJ$sp(1980, (Function1<Object, BoxedUnit>) null, function2_0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test037()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded$mcJ$sp(0L, function1_0, (Function2<Object, Object, BoxedUnit>) null);
      assertSame(openHashSet0, openHashSet1);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int0 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold;
      assertEquals(44, int0);
      
      int int1 = openHashSet0.size();
      assertSame(openHashSet0, openHashSet1);
      assertFalse(int1 == int0);
      assertEquals(0, int1);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test038()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset_$eq((BitSet) null);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      // Undeclared exception!
      try { 
        openHashSet0.contains$mcI$sp(2300);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test039()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity_$eq(1484);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1484, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1484, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1484, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1484, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1484, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1484, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = openHashSet1._data$mcJ$sp();
      assertNull(longArray0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1484, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1484, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1484, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test040()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      long[] longArray0 = openHashSet1._data$mcJ$sp();
      assertNull(longArray0);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test041()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash(boxedUnit0, function1_0, function2_0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold;
      assertEquals(89, int0);
      
      OpenHashSet.IntHasher openHashSet_IntHasher0 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher0);
      
      int int1 = openHashSet_IntHasher0.hash(127);
      assertFalse(int1 == int0);
      assertEquals(127, int1);
  }

  @Test(timeout = 4000)
  public void test042()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2027, classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(1, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehashIfNeeded(boxedUnit0, (Function1<Object, BoxedUnit>) null, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      // Undeclared exception!
      try { 
        openHashSet1.add$mcI$sp(2047);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test043()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = openHashSet0.contains(boxedUnit0);
      assertFalse(boolean0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet0.rehashIfNeeded$mcJ$sp(21L, (Function1<Object, BoxedUnit>) null, (Function2<Object, Object, BoxedUnit>) null);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit1, (Function1<Object, BoxedUnit>) null, function2_0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int0 = openHashSet0.getPos$mcJ$sp(54);
      assertEquals((-1), int0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int1 = OpenHashSet.NONEXISTENCE_MASK();
      assertFalse(int1 == int0);
      assertEquals(Integer.MIN_VALUE, int1);
  }

  @Test(timeout = 4000)
  public void test044()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded$mcJ$sp((-543L), function1_0, function2_0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
  }

  @Test(timeout = 4000)
  public void test045()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      BitSet bitSet0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset();
      assertNotNull(bitSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(64, bitSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset_$eq(bitSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(64, bitSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      // Undeclared exception!
      try { 
        openHashSet0.rehash(boxedUnit0, (Function1<Object, BoxedUnit>) null, (Function2<Object, Object, BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test046()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2027, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      int int0 = openHashSet0.getPos$mcI$sp(2027);
      assertEquals((-1), int0);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash(boxedUnit0, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = openHashSet1.hasher();
      assertNotNull(openHashSet_Hasher0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      long long0 = 540L;
      // Undeclared exception!
      try { 
        openHashSet1.addWithoutResize$mcJ$sp(540L);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test047()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize$mcJ$sp(1859L);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test048()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2027, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash(boxedUnit0, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      Iterator<BoxedUnit> iterator0 = openHashSet0.iterator();
      assertNotNull(iterator0);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.union$mcI$sp((OpenHashSet<Object>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test049()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit0, (Function1<Object, BoxedUnit>) null, function2_0);
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold;
      assertEquals(1, int0);
      
      int int1 = OpenHashSet.NONEXISTENCE_MASK();
      assertFalse(int1 == int0);
      assertEquals(Integer.MIN_VALUE, int1);
      
      int int2 = OpenHashSet.INVALID_POS();
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertEquals((-1), int2);
  }

  @Test(timeout = 4000)
  public void test050()  throws Throwable  {
      int int0 = OpenHashSet.MAX_CAPACITY();
      assertEquals(1073741824, int0);
      
      int int1 = OpenHashSet.NONEXISTENCE_MASK();
      assertFalse(int1 == int0);
      assertEquals(Integer.MIN_VALUE, int1);
  }

  @Test(timeout = 4000)
  public void test051()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$hashcode(2);
      assertEquals(1085422463, int0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit0, (Function1<Object, BoxedUnit>) null, function2_0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      // Undeclared exception!
      try { 
        openHashSet0.add$mcI$sp((-1561));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test052()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset_$eq((BitSet) null);
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.rehashIfNeeded$mcI$sp(3365, function1_0, function2_0);
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet0.getPos(boxedUnit0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test053()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(36, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag2);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet2 = new OpenHashSet<BoxedUnit>(classTag2);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet2.rehash(boxedUnit0, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertSame(classTag1, classTag2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(128, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(127, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet2.size());
      assertEquals(128, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(128, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<Object> openHashSet3 = new OpenHashSet<Object>(openHashSet2.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(128, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(127, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet2.size());
      assertEquals(128, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet3.size());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(128, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      // Undeclared exception!
      try { 
        openHashSet3.union$mcJ$sp((OpenHashSet<Object>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test054()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(469, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(512, openHashSet1.capacity());
      assertEquals(358, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(512, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(511, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(511, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(358, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(512, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet1.union(openHashSet0);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(512, openHashSet1.capacity());
      assertEquals(358, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(512, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(511, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(512, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(358, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.size());
      assertEquals(512, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(511, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(511, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(358, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(512, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(511, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(358, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(512, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BitSet bitSet0 = openHashSet2.getBitSet();
      assertNotNull(bitSet0);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(512, openHashSet1.capacity());
      assertEquals(358, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(512, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(511, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(512, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(358, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.size());
      assertEquals(512, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(511, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(512, bitSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(511, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(358, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(512, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(511, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(358, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(512, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_bitset_$eq(bitSet0);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(512, openHashSet1.capacity());
      assertEquals(358, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(512, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(511, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(512, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(358, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.size());
      assertEquals(512, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(511, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(512, bitSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(511, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(358, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(512, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(511, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(358, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(512, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet.IntHasher openHashSet_IntHasher0 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher0);
      
      // Undeclared exception!
      try { 
        openHashSet_IntHasher0.hash$mcJ$sp(0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Long cannot be cast to java.lang.Integer
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test055()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcJ$sp(0);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test056()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = null;
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit0, (Function1<Object, BoxedUnit>) null, function2_0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<Object> openHashSet2 = new OpenHashSet<Object>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size_$eq(0);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<Object> openHashSet3 = openHashSet1.union$mcI$sp(openHashSet2);
      assertNotNull(openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet3, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet3.capacity());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet4 = openHashSet1.union(openHashSet0);
      assertNotNull(openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertSame(openHashSet1, openHashSet4);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(1, openHashSet4.capacity());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(0, openHashSet4.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet5 = new OpenHashSet<BoxedUnit>(openHashSet2.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet5);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet5.equals((Object)openHashSet4));
      assertFalse(openHashSet5.equals((Object)openHashSet0));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertEquals(44, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet5.capacity());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(63, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals(64, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(0, openHashSet5.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(63, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet5.getPos(boxedUnit1);
      assertNotSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertSame(openHashSet1, openHashSet4);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet5, openHashSet4);
      assertNotSame(openHashSet5, openHashSet0);
      assertNotSame(openHashSet5, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet5));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet5.equals((Object)openHashSet4));
      assertFalse(openHashSet5.equals((Object)openHashSet0));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertEquals((-1), int0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertEquals(44, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet5.capacity());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(63, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals(64, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(0, openHashSet5.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(63, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet2.union$mcI$sp((OpenHashSet<Object>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test057()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit0, (Function1<Object, BoxedUnit>) null, function2_0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<Object> openHashSet2 = new OpenHashSet<Object>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      boolean boolean0 = openHashSet1.contains$mcJ$sp(2);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      boolean boolean1 = openHashSet1.contains((BoxedUnit) null);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertTrue(boolean1 == boolean0);
      assertFalse(boolean1);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize$mcI$sp(0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test058()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehashIfNeeded(boxedUnit0, function1_0, (Function2<Object, Object, BoxedUnit>) null);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet2 = new OpenHashSet<BoxedUnit>(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(0, openHashSet2.size());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet2.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<Object> classTag2 = (ClassTag<Object>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag2).newArray(anyInt());
      OpenHashSet<Object> openHashSet3 = new OpenHashSet<Object>(classTag2);
      assertNotNull(openHashSet3);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.size());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<Object> openHashSet4 = openHashSet1.union$mcI$sp(openHashSet3);
      assertNotNull(openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet3, openHashSet4);
      assertNotSame(openHashSet4, openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.size());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(0, openHashSet4.size());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet4.specInstance$());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet5 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet5);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet5, openHashSet1);
      assertSame(openHashSet5, openHashSet0);
      assertNotSame(openHashSet5, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertFalse(openHashSet5.equals((Object)openHashSet2));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet5.size());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(2, openHashSet5.capacity());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet6 = new OpenHashSet<BoxedUnit>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet6);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet6.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag3 = openHashSet6.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag3);
      assertSame(classTag3, classTag1);
      assertSame(classTag3, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet7 = new OpenHashSet<BoxedUnit>(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet7);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet7.equals((Object)openHashSet6));
      assertFalse(openHashSet7.equals((Object)openHashSet0));
      assertFalse(openHashSet7.equals((Object)openHashSet5));
      assertFalse(openHashSet7.equals((Object)openHashSet2));
      assertFalse(openHashSet7.equals((Object)openHashSet1));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet6.capacity());
      assertEquals((-1), openHashSet7.INVALID_POS());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet7.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet7.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet7.POSITION_MASK());
      assertEquals(0, openHashSet7.size());
      assertFalse(openHashSet7.specInstance$());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet7.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet8 = new OpenHashSet<BoxedUnit>(62, classTag3);
      assertNotNull(openHashSet8);
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet6.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet6));
      assertFalse(openHashSet8.equals((Object)openHashSet2));
      assertFalse(openHashSet8.equals((Object)openHashSet0));
      assertFalse(openHashSet8.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet5));
      assertFalse(openHashSet8.equals((Object)openHashSet1));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet6.capacity());
      assertEquals(64, openHashSet8.capacity());
      assertEquals((-1), openHashSet8.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet8.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet8.POSITION_MASK());
      assertEquals(0, openHashSet8.size());
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet8.specInstance$());
      assertEquals(1073741824, openHashSet8.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int0 = openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size();
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet7);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(classTag1, classTag0);
      assertSame(classTag1, classTag3);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet6);
      assertNotSame(openHashSet6, openHashSet8);
      assertNotSame(openHashSet6, openHashSet0);
      assertNotSame(openHashSet6, openHashSet2);
      assertNotSame(openHashSet6, openHashSet5);
      assertNotSame(openHashSet6, openHashSet1);
      assertNotSame(openHashSet6, openHashSet7);
      assertSame(classTag3, classTag1);
      assertSame(classTag3, classTag0);
      assertNotSame(openHashSet8, openHashSet6);
      assertNotSame(openHashSet8, openHashSet2);
      assertNotSame(openHashSet8, openHashSet0);
      assertNotSame(openHashSet8, openHashSet7);
      assertNotSame(openHashSet8, openHashSet5);
      assertNotSame(openHashSet8, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet6.equals((Object)openHashSet8));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet6.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet6));
      assertFalse(openHashSet8.equals((Object)openHashSet2));
      assertFalse(openHashSet8.equals((Object)openHashSet0));
      assertFalse(openHashSet8.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet5));
      assertFalse(openHashSet8.equals((Object)openHashSet1));
      assertEquals(0, int0);
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet6.capacity());
      assertEquals(64, openHashSet8.capacity());
      assertEquals((-1), openHashSet8.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet8.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet8.POSITION_MASK());
      assertEquals(0, openHashSet8.size());
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet8.specInstance$());
      assertEquals(1073741824, openHashSet8.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      Function1<Object, BoxedUnit> function1_1 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehash$mcI$sp((-102), function1_1, (Function2<Object, Object, BoxedUnit>) null);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet7);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(classTag1, classTag0);
      assertSame(classTag1, classTag3);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet6);
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_2 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet7.rehash(boxedUnit1, function1_2, (Function2<Object, Object, BoxedUnit>) null);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet7);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(classTag1, classTag0);
      assertSame(classTag1, classTag3);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet6);
      assertNotSame(openHashSet6, openHashSet8);
      assertNotSame(openHashSet6, openHashSet0);
      assertNotSame(openHashSet6, openHashSet2);
      assertNotSame(openHashSet6, openHashSet5);
      assertNotSame(openHashSet6, openHashSet1);
      assertNotSame(openHashSet6, openHashSet7);
      assertNotSame(openHashSet7, openHashSet8);
      assertNotSame(openHashSet7, openHashSet6);
      assertNotSame(openHashSet7, openHashSet0);
      assertNotSame(openHashSet7, openHashSet5);
      assertNotSame(openHashSet7, openHashSet2);
      assertNotSame(openHashSet7, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet6.equals((Object)openHashSet8));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet6.equals((Object)openHashSet7));
      assertFalse(openHashSet7.equals((Object)openHashSet8));
      assertFalse(openHashSet7.equals((Object)openHashSet6));
      assertFalse(openHashSet7.equals((Object)openHashSet0));
      assertFalse(openHashSet7.equals((Object)openHashSet5));
      assertFalse(openHashSet7.equals((Object)openHashSet2));
      assertFalse(openHashSet7.equals((Object)openHashSet1));
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet6.capacity());
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet7.INVALID_POS());
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet7.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet7.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet7.POSITION_MASK());
      assertEquals(0, openHashSet7.size());
      assertFalse(openHashSet7.specInstance$());
      assertEquals(2, openHashSet7.capacity());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet6.add$mcI$sp(2);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test059()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2070, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash$mcI$sp(2070, function1_0, function2_0);
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcI$sp(2070);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test060()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit0, (Function1<Object, BoxedUnit>) null, function2_0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size_$eq(2);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      boolean boolean0 = openHashSet0.contains$mcJ$sp((-1L));
      assertFalse(boolean0);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet1.capacity());
      assertEquals(2, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Object object0 = openHashSet1._data;
      assertNull(object0);
      
      openHashSet0._data_$eq((Object) null);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      Function2<Object, Object, BoxedUnit> function2_1 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash(boxedUnit1, (Function1<Object, BoxedUnit>) null, function2_1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test061()  throws Throwable  {
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = new OpenHashSet.Hasher<BoxedUnit>();
      assertNotNull(openHashSet_Hasher0);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet_Hasher0.hash(boxedUnit0);
      assertEquals(2, int0);
      
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = null;
      try {
        openHashSet1 = new OpenHashSet<BoxedUnit>(2, (-1091.0513349416), classTag1);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Load factor must be greater than 0.0
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test062()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      int int0 = openHashSet0.getPos$mcI$sp(519);
      assertEquals((-1), int0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int1 = openHashSet0.getPos(boxedUnit0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertTrue(int1 == int0);
      assertEquals((-1), int1);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehashIfNeeded((BoxedUnit) null, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet3 = new OpenHashSet<BoxedUnit>(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(1, openHashSet3.capacity());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int2 = openHashSet3.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2((-1));
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet3, openHashSet0);
      assertNotSame(openHashSet3, openHashSet1);
      assertNotSame(openHashSet3, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertEquals(0, int2);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(1, openHashSet3.capacity());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet4 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet4);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet4.size());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq(0);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int3 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertTrue(int3 == int2);
      assertFalse(int3 == int0);
      assertFalse(int3 == int1);
      assertEquals(0, int3);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<Object> openHashSet5 = new OpenHashSet<Object>(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet5);
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertEquals(64, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(0, openHashSet5.size());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(63, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet5.capacity());
      assertEquals(44, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet4.size());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<Object> openHashSet6 = openHashSet0.union$mcI$sp(openHashSet5);
      assertNotNull(openHashSet6);
      assertNotSame(openHashSet5, openHashSet6);
      assertNotSame(openHashSet6, openHashSet5);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet0);
      assertNotSame(openHashSet4, openHashSet2);
      assertNotSame(openHashSet4, openHashSet3);
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertEquals(64, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(0, openHashSet5.size());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(63, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet5.capacity());
      assertEquals(44, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(0, openHashSet6.size());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.capacity());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet4.size());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag2);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet7 = new OpenHashSet<BoxedUnit>(classTag2);
      assertNotNull(openHashSet7);
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet7.equals((Object)openHashSet2));
      assertFalse(openHashSet7.equals((Object)openHashSet3));
      assertFalse(openHashSet7.equals((Object)openHashSet0));
      assertFalse(openHashSet7.equals((Object)openHashSet1));
      assertFalse(openHashSet7.equals((Object)openHashSet4));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet4));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet7.INVALID_POS());
      assertEquals(64, openHashSet7.capacity());
      assertEquals(44, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet7.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet7.size());
      assertEquals(Integer.MAX_VALUE, openHashSet7.POSITION_MASK());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet7.MAX_CAPACITY());
      assertFalse(openHashSet7.specInstance$());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet8 = openHashSet7.union(openHashSet4);
      assertNotNull(openHashSet8);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet7);
      assertNotSame(openHashSet0, openHashSet3);
      assertNotSame(openHashSet0, openHashSet8);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      assertSame(classTag1, classTag2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet7, openHashSet2);
      assertSame(openHashSet7, openHashSet8);
      assertNotSame(openHashSet7, openHashSet3);
      assertNotSame(openHashSet7, openHashSet0);
      assertNotSame(openHashSet7, openHashSet1);
      assertNotSame(openHashSet7, openHashSet4);
      assertNotSame(openHashSet8, openHashSet2);
      assertNotSame(openHashSet8, openHashSet0);
      assertNotSame(openHashSet8, openHashSet1);
      assertNotSame(openHashSet8, openHashSet3);
      assertNotSame(openHashSet8, openHashSet4);
      assertSame(openHashSet8, openHashSet7);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet4);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet7);
      assertNotSame(openHashSet4, openHashSet0);
      assertNotSame(openHashSet4, openHashSet2);
      assertNotSame(openHashSet4, openHashSet3);
      assertNotSame(openHashSet4, openHashSet8);
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet7.equals((Object)openHashSet2));
      assertFalse(openHashSet7.equals((Object)openHashSet3));
      assertFalse(openHashSet7.equals((Object)openHashSet0));
      assertFalse(openHashSet7.equals((Object)openHashSet1));
      assertFalse(openHashSet7.equals((Object)openHashSet4));
      assertFalse(openHashSet8.equals((Object)openHashSet2));
      assertFalse(openHashSet8.equals((Object)openHashSet0));
      assertFalse(openHashSet8.equals((Object)openHashSet1));
      assertFalse(openHashSet8.equals((Object)openHashSet3));
      assertFalse(openHashSet8.equals((Object)openHashSet4));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet4));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet7));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet7.INVALID_POS());
      assertEquals(64, openHashSet7.capacity());
      assertEquals(44, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet7.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet7.size());
      assertEquals(Integer.MAX_VALUE, openHashSet7.POSITION_MASK());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet7.MAX_CAPACITY());
      assertFalse(openHashSet7.specInstance$());
      assertEquals(64, openHashSet8.capacity());
      assertEquals(1073741824, openHashSet8.MAX_CAPACITY());
      assertEquals((-1), openHashSet8.INVALID_POS());
      assertEquals(0, openHashSet8.size());
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet8.POSITION_MASK());
      assertFalse(openHashSet8.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet8.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet4.size());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet8.add$mcI$sp(0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test063()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      int int0 = openHashSet0.getPos$mcI$sp(519);
      assertEquals((-1), int0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int1 = openHashSet0.getPos(boxedUnit0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertTrue(int1 == int0);
      assertEquals((-1), int1);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet3 = new OpenHashSet<BoxedUnit>(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet3.capacity());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int2 = openHashSet3.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2((-1));
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet3);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet3, openHashSet1);
      assertNotSame(openHashSet3, openHashSet0);
      assertNotSame(openHashSet3, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertEquals(0, int2);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet3.capacity());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet4 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet4);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(0, openHashSet4.size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq(0);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet3);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int3 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet3);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(int3 == int0);
      assertTrue(int3 == int2);
      assertFalse(int3 == int1);
      assertEquals(0, int3);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size_$eq(1073741824);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet3);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      boolean boolean0 = openHashSet4.contains$mcJ$sp((-1));
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet3);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet2);
      assertNotSame(openHashSet4, openHashSet3);
      assertNotSame(openHashSet4, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(0, openHashSet4.size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      int int4 = openHashSet3.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2(0);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet3);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet4);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet3, openHashSet1);
      assertNotSame(openHashSet3, openHashSet0);
      assertNotSame(openHashSet3, openHashSet2);
      assertNotSame(openHashSet3, openHashSet4);
      assertFalse(int4 == int0);
      assertFalse(int4 == int2);
      assertFalse(int4 == int3);
      assertFalse(int4 == int1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet4));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet4));
      assertEquals(1, int4);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet3.capacity());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
  }

  @Test(timeout = 4000)
  public void test064()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcI$sp(63);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test065()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1191, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit0);
      assertEquals((-1), int0);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int1 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2(3059);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int1 == int0);
      assertEquals(4096, int1);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq(4096);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int2 == int0);
      assertTrue(int2 == int1);
      assertEquals(4096, int2);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset;
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.cardinality());
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.capacity());
      
      int int3 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int3 == int1);
      assertFalse(int3 == int2);
      assertFalse(int3 == int0);
      assertEquals(64, int3);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size_$eq((-1));
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = openHashSet1.contains$mcJ$sp(1191);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehash(boxedUnit1, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet2.size());
      assertEquals(2048, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1433, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = openHashSet1.hasher;
      assertNotNull(openHashSet_Hasher0);
      
      int int4 = openHashSet_Hasher0.hash$mcI$sp(89);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int4 == int2);
      assertFalse(int4 == int1);
      assertFalse(int4 == int0);
      assertFalse(int4 == int3);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertEquals(23, int4);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BitSet bitSet0 = openHashSet0.getBitSet();
      assertNotNull(bitSet0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, bitSet0.capacity());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int5 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int5 == int4);
      assertFalse(int5 == int2);
      assertFalse(int5 == int1);
      assertFalse(int5 == int0);
      assertFalse(int5 == int3);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertEquals(127, int5);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet2.getValueSafe$mcI$sp(2047);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test066()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcI$sp(2036);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test067()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      int int0 = openHashSet0.getPos$mcI$sp(519);
      assertEquals((-1), int0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int1 = openHashSet0.getPos(boxedUnit0);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertTrue(int1 == int0);
      assertEquals((-1), int1);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet3 = new OpenHashSet<BoxedUnit>(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet3.capacity());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int2 = openHashSet3.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2((-1));
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet3, openHashSet1);
      assertNotSame(openHashSet3, openHashSet0);
      assertNotSame(openHashSet3, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals(0, int2);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet3.capacity());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet4 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet4);
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(0, openHashSet4.size());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq(0);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int3 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertTrue(int3 == int2);
      assertFalse(int3 == int1);
      assertFalse(int3 == int0);
      assertEquals(0, int3);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size_$eq(1073741824);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      boolean boolean0 = openHashSet4.contains$mcJ$sp((-1));
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet4, openHashSet2);
      assertNotSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet0);
      assertNotSame(openHashSet4, openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet3));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertFalse(boolean0);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet0.size());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(0, openHashSet4.size());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize$mcI$sp((-1));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test068()  throws Throwable  {
      OpenHashSet.LongHasher openHashSet_LongHasher0 = new OpenHashSet.LongHasher();
      assertNotNull(openHashSet_LongHasher0);
      
      int int0 = openHashSet_LongHasher0.hash$mcJ$sp(0L);
      assertEquals(0, int0);
      
      int int1 = openHashSet_LongHasher0.hash$mcJ$sp(0L);
      assertTrue(int1 == int0);
      assertEquals(0, int1);
      
      int int2 = openHashSet_LongHasher0.hash$mcJ$sp((-1402L));
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertEquals(1401, int2);
      
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>((-3158), classTag0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Invalid initial capacity
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test069()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(127, classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(128, openHashSet0.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      boolean boolean0 = openHashSet1.specInstance$();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(128, openHashSet0.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet.Hasher<Object> openHashSet_Hasher0 = openHashSet0.hasher$mcJ$sp();
      assertNotNull(openHashSet_Hasher0);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test070()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      int int0 = openHashSet0.getPos$mcI$sp(519);
      assertEquals((-1), int0);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit0, function1_0, (Function2<Object, Object, BoxedUnit>) null);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(519, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<Object> openHashSet2 = new OpenHashSet<Object>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<Object> openHashSet3 = openHashSet1.union$mcI$sp(openHashSet2);
      assertNotNull(openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet3, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1024, openHashSet3.capacity());
      assertEquals(1024, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet3.size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(716, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1023, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(716, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1023, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1024, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet4 = openHashSet1.union(openHashSet0);
      assertNotNull(openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet1, openHashSet4);
      assertSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1023, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(0, openHashSet4.size());
      assertEquals(1024, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1024, openHashSet4.capacity());
      assertEquals(716, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      ClassTag<BoxedUnit> classTag2 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag2);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet5 = new OpenHashSet<BoxedUnit>(1047, classTag2);
      assertNotNull(openHashSet5);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet5.equals((Object)openHashSet0));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertFalse(openHashSet5.equals((Object)openHashSet4));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(2047, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet5.capacity());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals(2048, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet5.size());
      assertEquals(1433, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet6 = new OpenHashSet<BoxedUnit>(43, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet6);
      assertFalse(openHashSet0.equals((Object)openHashSet5));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet5.equals((Object)openHashSet0));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertFalse(openHashSet5.equals((Object)openHashSet4));
      assertFalse(openHashSet6.equals((Object)openHashSet4));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(2047, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet5.capacity());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals(2048, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet5.size());
      assertEquals(1433, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(64, openHashSet6.capacity());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(0, openHashSet6.size());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size();
      assertNotSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet6);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertFalse(openHashSet0.equals((Object)openHashSet5));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(int1 == int0);
      assertEquals(0, int1);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_1 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet5.rehash(boxedUnit1, function1_1, (Function2<Object, Object, BoxedUnit>) null);
      assertNotSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet6);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      assertNotSame(openHashSet5, openHashSet0);
      assertNotSame(openHashSet5, openHashSet6);
      assertNotSame(openHashSet5, openHashSet1);
      assertNotSame(openHashSet5, openHashSet4);
      assertFalse(openHashSet0.equals((Object)openHashSet5));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet5.equals((Object)openHashSet0));
      assertFalse(openHashSet5.equals((Object)openHashSet6));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertFalse(openHashSet5.equals((Object)openHashSet4));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals(4095, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2867, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(4096, openHashSet5.capacity());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals(4096, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet5.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4096, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2867, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4095, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet.Hasher<Object> openHashSet_Hasher0 = openHashSet6.hasher$mcJ$sp();
      assertNotNull(openHashSet_Hasher0);
      assertNotSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet6);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet4);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      assertNotSame(openHashSet5, openHashSet0);
      assertNotSame(openHashSet5, openHashSet6);
      assertNotSame(openHashSet5, openHashSet1);
      assertNotSame(openHashSet5, openHashSet4);
      assertNotSame(openHashSet6, openHashSet4);
      assertNotSame(openHashSet6, openHashSet0);
      assertNotSame(openHashSet6, openHashSet5);
      assertNotSame(openHashSet6, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet5));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet5.equals((Object)openHashSet0));
      assertFalse(openHashSet5.equals((Object)openHashSet6));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertFalse(openHashSet5.equals((Object)openHashSet4));
      assertFalse(openHashSet6.equals((Object)openHashSet4));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals(4095, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2867, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(4096, openHashSet5.capacity());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals(4096, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet5.size());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(64, openHashSet6.capacity());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(0, openHashSet6.size());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4096, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2867, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4095, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test071()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<Object> openHashSet1 = new OpenHashSet<Object>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<Object> openHashSet2 = openHashSet0.union$mcJ$sp(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int0 = (-2225);
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcI$sp((-2225));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test072()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehashIfNeeded(boxedUnit0, function1_0, (Function2<Object, Object, BoxedUnit>) null);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet2 = new OpenHashSet<BoxedUnit>(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet2.capacity());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<Object> classTag2 = (ClassTag<Object>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag2).newArray(anyInt());
      OpenHashSet<Object> openHashSet3 = new OpenHashSet<Object>(classTag2);
      assertNotNull(openHashSet3);
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<Object> openHashSet4 = openHashSet1.union$mcI$sp(openHashSet3);
      assertNotNull(openHashSet4);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet3, openHashSet4);
      assertNotSame(openHashSet4, openHashSet3);
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(0, openHashSet4.size());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet5 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet5);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet5, openHashSet1);
      assertSame(openHashSet5, openHashSet0);
      assertNotSame(openHashSet5, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertFalse(openHashSet5.equals((Object)openHashSet2));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet5.size());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(2, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals(2, openHashSet5.capacity());
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet6 = new OpenHashSet<BoxedUnit>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet6);
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.capacity());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag3 = openHashSet6.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag3);
      assertSame(classTag3, classTag1);
      assertSame(classTag3, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet7 = new OpenHashSet<BoxedUnit>(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet7);
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet7.equals((Object)openHashSet6));
      assertFalse(openHashSet7.equals((Object)openHashSet5));
      assertFalse(openHashSet7.equals((Object)openHashSet0));
      assertFalse(openHashSet7.equals((Object)openHashSet1));
      assertFalse(openHashSet7.equals((Object)openHashSet2));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.capacity());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet7.specInstance$());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet7.POSITION_MASK());
      assertEquals(0, openHashSet7.size());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet7.INVALID_POS());
      assertEquals(1, openHashSet7.capacity());
      assertEquals(1073741824, openHashSet7.MAX_CAPACITY());
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet7.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet8 = new OpenHashSet<BoxedUnit>(62, classTag3);
      assertNotNull(openHashSet8);
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet6.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet2));
      assertFalse(openHashSet8.equals((Object)openHashSet5));
      assertFalse(openHashSet8.equals((Object)openHashSet6));
      assertFalse(openHashSet8.equals((Object)openHashSet1));
      assertFalse(openHashSet8.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet0));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.capacity());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet8.specInstance$());
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet8.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet8.MAX_CAPACITY());
      assertEquals(64, openHashSet8.capacity());
      assertEquals((-1), openHashSet8.INVALID_POS());
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet8.POSITION_MASK());
      assertEquals(0, openHashSet8.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int0 = openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size();
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet7);
      assertSame(classTag1, classTag3);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet6);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet6, openHashSet8);
      assertNotSame(openHashSet6, openHashSet2);
      assertNotSame(openHashSet6, openHashSet5);
      assertNotSame(openHashSet6, openHashSet0);
      assertNotSame(openHashSet6, openHashSet1);
      assertNotSame(openHashSet6, openHashSet7);
      assertSame(classTag3, classTag1);
      assertSame(classTag3, classTag0);
      assertNotSame(openHashSet8, openHashSet2);
      assertNotSame(openHashSet8, openHashSet5);
      assertNotSame(openHashSet8, openHashSet6);
      assertNotSame(openHashSet8, openHashSet1);
      assertNotSame(openHashSet8, openHashSet7);
      assertNotSame(openHashSet8, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet6.equals((Object)openHashSet8));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet6.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet2));
      assertFalse(openHashSet8.equals((Object)openHashSet5));
      assertFalse(openHashSet8.equals((Object)openHashSet6));
      assertFalse(openHashSet8.equals((Object)openHashSet1));
      assertFalse(openHashSet8.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet0));
      assertEquals(0, int0);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.capacity());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet8.specInstance$());
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet8.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet8.MAX_CAPACITY());
      assertEquals(64, openHashSet8.capacity());
      assertEquals((-1), openHashSet8.INVALID_POS());
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet8.POSITION_MASK());
      assertEquals(0, openHashSet8.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_1 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet7.rehash(boxedUnit1, function1_1, (Function2<Object, Object, BoxedUnit>) null);
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet7);
      assertSame(classTag1, classTag3);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet6);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet6, openHashSet8);
      assertNotSame(openHashSet6, openHashSet2);
      assertNotSame(openHashSet6, openHashSet5);
      assertNotSame(openHashSet6, openHashSet0);
      assertNotSame(openHashSet6, openHashSet1);
      assertNotSame(openHashSet6, openHashSet7);
      assertNotSame(openHashSet7, openHashSet6);
      assertNotSame(openHashSet7, openHashSet5);
      assertNotSame(openHashSet7, openHashSet8);
      assertNotSame(openHashSet7, openHashSet0);
      assertNotSame(openHashSet7, openHashSet1);
      assertNotSame(openHashSet7, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet6.equals((Object)openHashSet8));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet6.equals((Object)openHashSet7));
      assertFalse(openHashSet7.equals((Object)openHashSet6));
      assertFalse(openHashSet7.equals((Object)openHashSet5));
      assertFalse(openHashSet7.equals((Object)openHashSet8));
      assertFalse(openHashSet7.equals((Object)openHashSet0));
      assertFalse(openHashSet7.equals((Object)openHashSet1));
      assertFalse(openHashSet7.equals((Object)openHashSet2));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.capacity());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet7.specInstance$());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet7.POSITION_MASK());
      assertEquals(0, openHashSet7.size());
      assertEquals((-1), openHashSet7.INVALID_POS());
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet7.MAX_CAPACITY());
      assertEquals(2, openHashSet7.capacity());
      assertEquals(2, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet7.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<Object> openHashSet9 = openHashSet7.union$mcI$sp(openHashSet4);
      assertNotNull(openHashSet9);
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet7);
      assertSame(classTag1, classTag3);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet6);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet9, openHashSet3);
      assertNotSame(openHashSet9, openHashSet4);
      assertNotSame(openHashSet3, openHashSet9);
      assertNotSame(openHashSet3, openHashSet4);
      assertNotSame(openHashSet4, openHashSet3);
      assertNotSame(openHashSet4, openHashSet9);
      assertNotSame(openHashSet6, openHashSet8);
      assertNotSame(openHashSet6, openHashSet2);
      assertNotSame(openHashSet6, openHashSet5);
      assertNotSame(openHashSet6, openHashSet0);
      assertNotSame(openHashSet6, openHashSet1);
      assertNotSame(openHashSet6, openHashSet7);
      assertNotSame(openHashSet7, openHashSet6);
      assertNotSame(openHashSet7, openHashSet5);
      assertNotSame(openHashSet7, openHashSet8);
      assertNotSame(openHashSet7, openHashSet0);
      assertNotSame(openHashSet7, openHashSet1);
      assertNotSame(openHashSet7, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet9.equals((Object)openHashSet3));
      assertFalse(openHashSet9.equals((Object)openHashSet4));
      assertFalse(openHashSet3.equals((Object)openHashSet4));
      assertFalse(openHashSet4.equals((Object)openHashSet3));
      assertFalse(openHashSet6.equals((Object)openHashSet8));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet6.equals((Object)openHashSet7));
      assertFalse(openHashSet7.equals((Object)openHashSet6));
      assertFalse(openHashSet7.equals((Object)openHashSet5));
      assertFalse(openHashSet7.equals((Object)openHashSet8));
      assertFalse(openHashSet7.equals((Object)openHashSet0));
      assertFalse(openHashSet7.equals((Object)openHashSet1));
      assertFalse(openHashSet7.equals((Object)openHashSet2));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet9.POSITION_MASK());
      assertFalse(openHashSet9.specInstance$());
      assertEquals(0, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet9.size());
      assertEquals(1073741824, openHashSet9.MAX_CAPACITY());
      assertEquals(2, openHashSet9.capacity());
      assertEquals(1, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet9.INVALID_POS());
      assertEquals(1, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet9.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(0, openHashSet4.size());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.capacity());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet7.specInstance$());
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet7.POSITION_MASK());
      assertEquals(0, openHashSet7.size());
      assertEquals((-1), openHashSet7.INVALID_POS());
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet7.MAX_CAPACITY());
      assertEquals(2, openHashSet7.capacity());
      assertEquals(2, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet7.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet9.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet7.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2(64);
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet7);
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(int1 == int0);
      assertEquals(64, int1);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size();
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet7);
      assertSame(classTag1, classTag3);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet6);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet7);
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertTrue(int2 == int0);
      assertFalse(int2 == int1);
      assertEquals(0, int2);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int3 = openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet7);
      assertSame(classTag1, classTag3);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet6);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet6, openHashSet8);
      assertNotSame(openHashSet6, openHashSet2);
      assertNotSame(openHashSet6, openHashSet5);
      assertNotSame(openHashSet6, openHashSet0);
      assertNotSame(openHashSet6, openHashSet1);
      assertNotSame(openHashSet6, openHashSet7);
      assertSame(classTag3, classTag1);
      assertSame(classTag3, classTag0);
      assertNotSame(openHashSet8, openHashSet2);
      assertNotSame(openHashSet8, openHashSet5);
      assertNotSame(openHashSet8, openHashSet6);
      assertNotSame(openHashSet8, openHashSet1);
      assertNotSame(openHashSet8, openHashSet7);
      assertNotSame(openHashSet8, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(int3 == int2);
      assertTrue(int3 == int1);
      assertFalse(int3 == int0);
      assertFalse(openHashSet6.equals((Object)openHashSet8));
      assertFalse(openHashSet6.equals((Object)openHashSet2));
      assertFalse(openHashSet6.equals((Object)openHashSet5));
      assertFalse(openHashSet6.equals((Object)openHashSet0));
      assertFalse(openHashSet6.equals((Object)openHashSet1));
      assertFalse(openHashSet6.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet2));
      assertFalse(openHashSet8.equals((Object)openHashSet5));
      assertFalse(openHashSet8.equals((Object)openHashSet6));
      assertFalse(openHashSet8.equals((Object)openHashSet1));
      assertFalse(openHashSet8.equals((Object)openHashSet7));
      assertFalse(openHashSet8.equals((Object)openHashSet0));
      assertEquals(64, int3);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet6.MAX_CAPACITY());
      assertEquals(64, openHashSet6.capacity());
      assertEquals((-1), openHashSet6.INVALID_POS());
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet6.specInstance$());
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet6.size());
      assertEquals(Integer.MIN_VALUE, openHashSet6.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet6.POSITION_MASK());
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet8.specInstance$());
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet8.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet8.MAX_CAPACITY());
      assertEquals(64, openHashSet8.capacity());
      assertEquals((-1), openHashSet8.INVALID_POS());
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet8.POSITION_MASK());
      assertEquals(0, openHashSet8.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet6.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(63, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet8.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<Object> openHashSet10 = openHashSet5.union$mcJ$sp(openHashSet3);
      assertNotNull(openHashSet10);
      assertNotSame(openHashSet0, openHashSet8);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet6);
      assertSame(openHashSet0, openHashSet5);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet7);
      assertSame(classTag1, classTag3);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet6);
      assertNotSame(openHashSet1, openHashSet5);
      assertNotSame(openHashSet1, openHashSet8);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet7);
      assertNotSame(openHashSet10, openHashSet3);
      assertNotSame(openHashSet10, openHashSet4);
      assertNotSame(openHashSet10, openHashSet9);
      assertNotSame(openHashSet3, openHashSet9);
      assertNotSame(openHashSet3, openHashSet10);
      assertNotSame(openHashSet3, openHashSet4);
      assertNotSame(openHashSet5, openHashSet6);
      assertNotSame(openHashSet5, openHashSet1);
      assertSame(openHashSet5, openHashSet0);
      assertNotSame(openHashSet5, openHashSet2);
      assertNotSame(openHashSet5, openHashSet7);
      assertNotSame(openHashSet5, openHashSet8);
      assertFalse(openHashSet0.equals((Object)openHashSet8));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet6));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet7));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet6));
      assertFalse(openHashSet1.equals((Object)openHashSet5));
      assertFalse(openHashSet1.equals((Object)openHashSet8));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet7));
      assertFalse(openHashSet10.equals((Object)openHashSet3));
      assertFalse(openHashSet10.equals((Object)openHashSet4));
      assertFalse(openHashSet10.equals((Object)openHashSet9));
      assertFalse(openHashSet3.equals((Object)openHashSet9));
      assertFalse(openHashSet3.equals((Object)openHashSet4));
      assertFalse(openHashSet5.equals((Object)openHashSet6));
      assertFalse(openHashSet5.equals((Object)openHashSet1));
      assertFalse(openHashSet5.equals((Object)openHashSet2));
      assertFalse(openHashSet5.equals((Object)openHashSet7));
      assertFalse(openHashSet5.equals((Object)openHashSet8));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet10.INVALID_POS());
      assertEquals(1, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2, openHashSet10.capacity());
      assertEquals(1, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet10.specInstance$());
      assertEquals(1073741824, openHashSet10.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet10.POSITION_MASK());
      assertEquals(0, openHashSet10.size());
      assertEquals(2, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet10.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet5.size());
      assertEquals(Integer.MAX_VALUE, openHashSet5.POSITION_MASK());
      assertEquals(2, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet5.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet5.specInstance$());
      assertEquals(1073741824, openHashSet5.MAX_CAPACITY());
      assertEquals(2, openHashSet5.capacity());
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet5.INVALID_POS());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet10.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2, openHashSet5.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test073()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int0 = (-60);
      ClassTag<BoxedUnit> classTag1 = null;
      // Undeclared exception!
      try { 
        openHashSet0.add$mcI$sp((-60));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test074()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcJ$sp(1552);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test075()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(5374, classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(8192, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(8192, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Object object0 = openHashSet1._data;
      assertNull(object0);
      
      ClassTag<BoxedUnit> classTag2 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag2).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet2 = new OpenHashSet<BoxedUnit>(classTag2);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(64, openHashSet2.capacity());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag3 = openHashSet2.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag3);
      assertNotSame(classTag3, classTag0);
      assertSame(classTag3, classTag2);
      assertNotSame(classTag3, classTag1);
      assertFalse(classTag3.equals((Object)classTag0));
      assertFalse(classTag3.equals((Object)classTag1));
      
      int int0 = openHashSet2.getPos$mcI$sp(519);
      assertNotSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals((-1), int0);
      assertEquals(64, openHashSet2.capacity());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet2.rehashIfNeeded(boxedUnit0, function1_0, (Function2<Object, Object, BoxedUnit>) null);
      assertNotSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(64, openHashSet2.capacity());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet3 = new OpenHashSet<BoxedUnit>(519, classTag3);
      assertNotNull(openHashSet3);
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(classTag3.equals((Object)classTag0));
      assertFalse(classTag3.equals((Object)classTag1));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertEquals(64, openHashSet2.capacity());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(716, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(1023, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1024, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1024, openHashSet3.capacity());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.size());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(716, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<Object> openHashSet4 = new OpenHashSet<Object>(openHashSet3.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet4);
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(classTag3.equals((Object)classTag0));
      assertFalse(classTag3.equals((Object)classTag1));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertEquals(64, openHashSet2.capacity());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(716, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(1023, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1024, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1024, openHashSet3.capacity());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(64, openHashSet4.capacity());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(0, openHashSet4.size());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(716, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet2.getValueSafe$mcJ$sp(1024);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test076()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet0.union$mcI$sp((OpenHashSet<Object>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test077()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1191, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit0);
      assertEquals((-1), int0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int1 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2(3059);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int1 == int0);
      assertEquals(4096, int1);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq(4096);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertTrue(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals(4096, int2);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset;
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.cardinality());
      
      int int3 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int3 == int1);
      assertFalse(int3 == int2);
      assertFalse(int3 == int0);
      assertEquals(64, int3);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size_$eq((-1));
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = openHashSet1.contains$mcJ$sp(1191);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehash(boxedUnit1, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2047, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet2.capacity());
      assertEquals((-1), openHashSet2.size());
      assertEquals(1433, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(2048, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(1433, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2047, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = openHashSet1.hasher;
      assertNotNull(openHashSet_Hasher0);
      
      int int4 = openHashSet_Hasher0.hash$mcI$sp(89);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int4 == int2);
      assertFalse(int4 == int3);
      assertFalse(int4 == int0);
      assertFalse(int4 == int1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertEquals(23, int4);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BitSet bitSet0 = openHashSet0.getBitSet();
      assertNotNull(bitSet0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(2048, bitSet0.capacity());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int5 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int5 == int0);
      assertFalse(int5 == int3);
      assertFalse(int5 == int4);
      assertFalse(int5 == int2);
      assertFalse(int5 == int1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertEquals(127, int5);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int6 = OpenHashSet.POSITION_MASK();
      assertFalse(int6 == int0);
      assertFalse(int6 == int1);
      assertFalse(int6 == int3);
      assertFalse(int6 == int5);
      assertFalse(int6 == int4);
      assertFalse(int6 == int2);
      assertEquals(Integer.MAX_VALUE, int6);
  }

  @Test(timeout = 4000)
  public void test078()  throws Throwable  {
      int int0 = OpenHashSet.POSITION_MASK();
      assertEquals(Integer.MAX_VALUE, int0);
  }

  @Test(timeout = 4000)
  public void test079()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash$mcJ$sp(2433880, function1_0, function2_0);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(128, 0.7, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int0 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(128, int0);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask_$eq(89);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Function1<Object, BoxedUnit> function1_1 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_1 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehashIfNeeded$mcI$sp(0, function1_1, function2_1);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask_$eq(128);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
  }

  @Test(timeout = 4000)
  public void test080()  throws Throwable  {
      int int0 = 5893;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(5893, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.add$mcJ$sp(8191);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 1265
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test081()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      long[] longArray0 = new long[5];
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash$mcJ$sp((-1L), function1_0, function2_0);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      long[] longArray1 = openHashSet0._data$mcJ$sp();
      assertNull(longArray1);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(128, openHashSet0.capacity());
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(127, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(89, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
  }

  @Test(timeout = 4000)
  public void test082()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1191, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit0);
      assertEquals((-1), int0);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int1 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2(3059);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int1 == int0);
      assertEquals(4096, int1);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq(4096);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertTrue(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals(4096, int2);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset;
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.cardinality());
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.capacity());
      
      int int3 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int3 == int0);
      assertFalse(int3 == int1);
      assertFalse(int3 == int2);
      assertEquals(64, int3);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size_$eq((-1));
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehash$mcJ$sp((-1), function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = openHashSet1.contains$mcJ$sp(1191);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      Function1<Object, BoxedUnit> function1_1 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_1 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehash(boxedUnit1, function1_1, function2_1);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(4096, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet2.size());
      assertEquals(4096, openHashSet2.capacity());
      assertEquals(2867, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2867, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4095, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4096, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = openHashSet1.hasher;
      assertNotNull(openHashSet_Hasher0);
      
      int int4 = openHashSet_Hasher0.hash$mcI$sp(89);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int4 == int0);
      assertFalse(int4 == int1);
      assertFalse(int4 == int3);
      assertFalse(int4 == int2);
      assertEquals(25, int4);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BitSet bitSet0 = openHashSet0.getBitSet();
      assertNotNull(bitSet0);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(4096, bitSet0.capacity());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int5 = openHashSet_Hasher0.hash$mcJ$sp(0L);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int5 == int3);
      assertFalse(int5 == int4);
      assertFalse(int5 == int2);
      assertFalse(int5 == int0);
      assertFalse(int5 == int1);
      assertEquals(26, int5);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      boolean boolean1 = openHashSet2.specInstance$();
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertTrue(boolean1 == boolean0);
      assertFalse(boolean1);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet0.capacity());
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(4096, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet2.size());
      assertEquals(4096, openHashSet2.capacity());
      assertEquals(2867, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2867, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4095, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4096, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
  }

  @Test(timeout = 4000)
  public void test083()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash(boxedUnit0, (Function1<Object, BoxedUnit>) null, (Function2<Object, Object, BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test084()  throws Throwable  {
      OpenHashSet.IntHasher openHashSet_IntHasher0 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher0);
      
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(4021, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet1.union(openHashSet0);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet0);
      assertSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(0, openHashSet2.size());
      assertEquals(4096, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(2867, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(4095, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet2.capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4095, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      OpenHashSet.IntHasher openHashSet_IntHasher1 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher1);
      assertFalse(openHashSet_IntHasher1.equals((Object)openHashSet_IntHasher0));
      
      int int0 = openHashSet_IntHasher0.hash$mcI$sp(44);
      assertNotSame(openHashSet_IntHasher0, openHashSet_IntHasher1);
      assertFalse(openHashSet_IntHasher0.equals((Object)openHashSet_IntHasher1));
      assertEquals(44, int0);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity_$eq(64);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
  }

  @Test(timeout = 4000)
  public void test085()  throws Throwable  {
      OpenHashSet.IntHasher openHashSet_IntHasher0 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher0);
      
      int int0 = openHashSet_IntHasher0.hash$mcI$sp((-699));
      assertEquals((-699), int0);
      
      int int1 = openHashSet_IntHasher0.hash$mcI$sp(1769);
      assertFalse(int1 == int0);
      assertEquals(1769, int1);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
  }

  @Test(timeout = 4000)
  public void test086()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      Object object0 = openHashSet0._data();
      assertNull(object0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null, (Object) null).when(classTag1).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(1191, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag2);
      assertNotSame(classTag2, classTag0);
      assertSame(classTag2, classTag1);
      assertFalse(classTag2.equals((Object)classTag0));
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet1.getPos(boxedUnit0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), int0);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet2 = new OpenHashSet<BoxedUnit>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int1 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2((-1));
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int1 == int0);
      assertEquals(0, int1);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet3 = new OpenHashSet<BoxedUnit>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet3);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq((-1080));
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet3, openHashSet0);
      assertNotSame(openHashSet3, openHashSet2);
      assertNotSame(openHashSet3, openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1080), openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1080), openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals(1433, int2);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int3 = openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(int3 == int0);
      assertFalse(int3 == int1);
      assertFalse(int3 == int2);
      assertEquals(64, int3);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size_$eq((-573));
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-573), openHashSet2.size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      boolean boolean0 = openHashSet2.contains$mcJ$sp(0L);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(2048, openHashSet1.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-573), openHashSet2.size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2047, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehash((BoxedUnit) null, function1_0, function2_0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet4 = openHashSet3.union(openHashSet2);
      assertNotNull(openHashSet4);
      assertNotSame(openHashSet4, openHashSet0);
      assertNotSame(openHashSet4, openHashSet2);
      assertNotSame(openHashSet4, openHashSet1);
      assertSame(openHashSet4, openHashSet3);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet1, openHashSet4);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet2, openHashSet4);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet3, openHashSet0);
      assertSame(openHashSet3, openHashSet4);
      assertNotSame(openHashSet3, openHashSet2);
      assertNotSame(openHashSet3, openHashSet1);
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1080), openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(0, openHashSet4.size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-573), openHashSet2.size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1080), openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1080), openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1080), openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = openHashSet4.hasher;
      assertNotNull(openHashSet_Hasher0);
      
      int int4 = openHashSet1.hasher.hash$mcI$sp(110);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet1, openHashSet4);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet4));
      assertFalse(int4 == int2);
      assertFalse(int4 == int3);
      assertFalse(int4 == int0);
      assertFalse(int4 == int1);
      assertEquals(37, int4);
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BitSet bitSet0 = openHashSet1.getBitSet();
      assertNotNull(bitSet0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet1, openHashSet4);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet4));
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(4096, bitSet0.capacity());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      boolean boolean1 = openHashSet4.contains$mcI$sp(0);
      assertNotSame(openHashSet4, openHashSet0);
      assertNotSame(openHashSet4, openHashSet2);
      assertNotSame(openHashSet4, openHashSet1);
      assertSame(openHashSet4, openHashSet3);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet1, openHashSet4);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet2, openHashSet4);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet3, openHashSet0);
      assertSame(openHashSet3, openHashSet4);
      assertNotSame(openHashSet3, openHashSet2);
      assertNotSame(openHashSet3, openHashSet1);
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet4));
      assertTrue(boolean1 == boolean0);
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet4));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(boolean1);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1080), openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(0, openHashSet4.size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-573), openHashSet2.size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1080), openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1080), openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1080), openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int5 = openHashSet4.hasher.hash$mcJ$sp(1537L);
      assertNotSame(openHashSet4, openHashSet0);
      assertNotSame(openHashSet4, openHashSet2);
      assertNotSame(openHashSet4, openHashSet1);
      assertSame(openHashSet4, openHashSet3);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet1, openHashSet4);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet2, openHashSet4);
      assertNotSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet3, openHashSet0);
      assertSame(openHashSet3, openHashSet4);
      assertNotSame(openHashSet3, openHashSet2);
      assertNotSame(openHashSet3, openHashSet1);
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet2));
      assertFalse(openHashSet4.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet1.equals((Object)openHashSet3));
      assertFalse(openHashSet1.equals((Object)openHashSet4));
      assertFalse(int5 == int2);
      assertFalse(int5 == int0);
      assertFalse(int5 == int1);
      assertFalse(int5 == int4);
      assertFalse(int5 == int3);
      assertFalse(openHashSet2.equals((Object)openHashSet3));
      assertFalse(openHashSet2.equals((Object)openHashSet4));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertEquals(40, int5);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet4.capacity());
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1080), openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(0, openHashSet4.size());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-573), openHashSet2.size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1080), openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet3.capacity());
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-1080), openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals((-573), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1080), openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      // Undeclared exception!
      try { 
        openHashSet4.add((BoxedUnit) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test087()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      ClassTag<BoxedUnit> classTag2 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag2);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet2 = new OpenHashSet<BoxedUnit>(0, classTag2);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet3 = openHashSet2.union(openHashSet0);
      assertNotNull(openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet0, openHashSet3);
      assertSame(classTag2, classTag1);
      assertSame(classTag2, classTag0);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet3, openHashSet1);
      assertSame(openHashSet3, openHashSet2);
      assertNotSame(openHashSet3, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet2));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.size());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet3.capacity());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet3.addWithoutResize(boxedUnit0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test088()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2028, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(0, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size_$eq(2048);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(2048, openHashSet1.size());
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1, openHashSet1.capacity());
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet1.rehashIfNeeded(boxedUnit0, (Function1<Object, BoxedUnit>) null, function2_0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test089()  throws Throwable  {
      int int0 = 519;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      int int1 = openHashSet0.getPos$mcI$sp(519);
      assertFalse(int1 == int0);
      assertEquals((-1), int1);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded(boxedUnit0, function1_0, (Function2<Object, Object, BoxedUnit>) null);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(519, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<Object> openHashSet2 = new OpenHashSet<Object>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.size());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<Object> openHashSet3 = openHashSet1.union$mcI$sp(openHashSet2);
      assertNotNull(openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet3, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.size());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(1024, openHashSet3.capacity());
      assertEquals(1023, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(1024, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(716, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet4 = openHashSet1.union(openHashSet0);
      assertNotNull(openHashSet4);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet1, openHashSet4);
      assertSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(1024, openHashSet4.capacity());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(1023, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(0, openHashSet4.size());
      assertEquals(716, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(1024, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int2 = openHashSet4.getPos$mcI$sp(716);
      assertNotSame(openHashSet0, openHashSet4);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet1, openHashSet4);
      assertSame(openHashSet4, openHashSet1);
      assertNotSame(openHashSet4, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet4));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet4.equals((Object)openHashSet0));
      assertFalse(int2 == int0);
      assertTrue(int2 == int1);
      assertEquals((-1), int2);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1024, openHashSet1.capacity());
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(1024, openHashSet4.capacity());
      assertEquals((-1), openHashSet4.INVALID_POS());
      assertEquals(1073741824, openHashSet4.MAX_CAPACITY());
      assertEquals(1023, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet4.POSITION_MASK());
      assertEquals(0, openHashSet4.size());
      assertEquals(716, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet4.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet4.NONEXISTENCE_MASK());
      assertEquals(1024, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1023, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet4.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      // Undeclared exception!
      try { 
        openHashSet4.getValue(519);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test090()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      // Undeclared exception!
      try { 
        openHashSet0.add((BoxedUnit) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test091()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1191, classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit0);
      assertEquals((-1), int0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int1 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2(3059);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int1 == int0);
      assertEquals(4096, int1);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq(4096);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertTrue(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals(4096, int2);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset;
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.cardinality());
      
      BoxedUnit boxedUnit1 = null;
      // Undeclared exception!
      try { 
        openHashSet0.add((BoxedUnit) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test092()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<Object> openHashSet2 = new OpenHashSet<Object>(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet2);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<Object> openHashSet3 = openHashSet1.union$mcI$sp(openHashSet2);
      assertNotNull(openHashSet3);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet3);
      assertNotSame(openHashSet3, openHashSet2);
      assertFalse(openHashSet3.equals((Object)openHashSet2));
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet2.specInstance$());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet2.capacity());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(0, openHashSet3.size());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet3.capacity());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test093()  throws Throwable  {
      int int0 = 2;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<Object> openHashSet1 = new OpenHashSet<Object>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<Object> openHashSet2 = openHashSet0.union$mcI$sp(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.size());
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet3 = null;
      try {
        openHashSet3 = new OpenHashSet<BoxedUnit>(2, 1.0, classTag1);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Load factor must be less than 1.0
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test094()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet0.union((OpenHashSet<BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test095()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      Object object0 = openHashSet0._data();
      assertNull(object0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag1).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(25, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(31, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(32, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(22, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(32, openHashSet1.capacity());
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(31, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(22, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(32, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int0 = openHashSet1.getPos$mcI$sp(25);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), int0);
      assertEquals(31, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(32, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(22, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(32, openHashSet1.capacity());
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(31, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(22, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(32, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet1.add$mcJ$sp((-1));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test096()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe(1287);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test097()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(65535, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(65536, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(65535, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(65536, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(45875, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(65535, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(45875, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(65536, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      // Undeclared exception!
      try { 
        openHashSet1.getValueSafe((-2146131975));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test098()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe(63);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test099()  throws Throwable  {
      int int0 = OpenHashSet.INVALID_POS();
      assertEquals((-1), int0);
      
      int int1 = (-1746);
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>((-1746), classTag0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Invalid initial capacity
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test100()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet0.rehashIfNeeded$mcI$sp(4262, function1_0, function2_0);
      assertSame(openHashSet0, openHashSet1);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
  }

  @Test(timeout = 4000)
  public void test101()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(2433880, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2936012, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(4194303, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(4194304, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(4194304, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4194303, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4194304, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2936012, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int int0 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(4194304, int0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2936012, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(4194303, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(4194304, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(4194304, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4194303, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4194304, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2936012, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehashIfNeeded$mcI$sp(0, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2936012, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(4194303, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(4194304, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(4194304, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4194303, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4194304, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2936012, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
  }

  @Test(timeout = 4000)
  public void test102()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(10, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int0 = 1021;
      int int1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$hashcode(1021);
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int1 == int0);
      assertEquals((-307660904), int1);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int2 = openHashSet1.getPos$mcJ$sp((-4684L));
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertEquals((-1), int2);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int3 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int3 == int2);
      assertFalse(int3 == int0);
      assertFalse(int3 == int1);
      assertEquals(0, int3);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = openHashSet1.hasher;
      assertNotNull(openHashSet_Hasher0);
      
      int int4 = openHashSet_Hasher0.hash$mcJ$sp(11);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int4 == int3);
      assertFalse(int4 == int0);
      assertFalse(int4 == int1);
      assertFalse(int4 == int2);
      assertEquals(18, int4);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(16, openHashSet0.capacity());
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(15, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(11, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(16, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize$mcI$sp(44);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test103()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold;
      assertEquals(44, int0);
      
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize$mcI$sp((-1024));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test104()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test105()  throws Throwable  {
      int int0 = 47;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      long[] longArray0 = new long[0];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {}, longArray0);
      assertEquals(0, longArray0.length);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$hashcode(1092);
      assertFalse(int1 == int0);
      assertEquals((-1707376050), int1);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(2, openHashSet2.capacity());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet1.addWithoutResize((BoxedUnit) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test106()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>(Integer.MAX_VALUE, 2020.0, classTag0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Can't make capacity bigger than 1073741824 elements
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test107()  throws Throwable  {
      int int0 = Integer.MAX_VALUE;
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>(Integer.MAX_VALUE, (ClassTag<BoxedUnit>) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Can't make capacity bigger than 1073741824 elements
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test108()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      long[] longArray0 = new long[5];
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size = 46;
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(46, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(46, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(46, openHashSet0.size());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(46, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(46, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.add$mcJ$sp(1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test109()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2027, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity_$eq((-4968));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-4968), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-4968), openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals((-4968), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-4968), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-4968), openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals((-4968), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask_$eq(1433);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-4968), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-4968), openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals((-4968), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1433, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.rehash(boxedUnit0, function1_0, function2_0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Can't contain more than 751619276 elements
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test110()  throws Throwable  {
      OpenHashSet.LongHasher openHashSet_LongHasher0 = new OpenHashSet.LongHasher();
      assertNotNull(openHashSet_LongHasher0);
      
      // Undeclared exception!
      try { 
        openHashSet_LongHasher0.hash$mcI$sp((-1564));
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Integer cannot be cast to java.lang.Long
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test111()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      boolean boolean0 = openHashSet1.contains$mcI$sp(64);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertFalse(boolean0);
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
  }

  @Test(timeout = 4000)
  public void test112()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int0 = openHashSet1.capacity();
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(64, int0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test113()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size_$eq(2130);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2130, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2130, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2130, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      boolean boolean0 = openHashSet0.contains$mcI$sp(2130);
      assertFalse(boolean0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(2130, openHashSet0.size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(2130, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2130, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size;
      assertEquals(2130, int0);
  }

  @Test(timeout = 4000)
  public void test114()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      boolean boolean0 = openHashSet0.contains$mcJ$sp(0);
      assertSame(openHashSet0, openHashSet1);
      assertFalse(boolean0);
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test115()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      int int0 = OpenHashSet.INVALID_POS();
      assertEquals((-1), int0);
      
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertFalse(int1 == int0);
      assertEquals(44, int1);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test116()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq((-2758));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals((-2758), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-2758), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe(63);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test117()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset_$eq(openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      boolean boolean0 = openHashSet0.specInstance$();
      assertSame(openHashSet0, openHashSet1);
      assertFalse(boolean0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      Iterator<BoxedUnit> iterator0 = openHashSet1.iterator();
      assertNotNull(iterator0);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test118()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask_$eq(63);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      boolean boolean0 = openHashSet0.contains$mcJ$sp(0);
      assertSame(openHashSet0, openHashSet1);
      assertFalse(boolean0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
  }

  @Test(timeout = 4000)
  public void test119()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BitSet bitSet0 = openHashSet0.getBitSet();
      assertNotNull(bitSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, bitSet0.capacity());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset = bitSet0;
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, bitSet0.capacity());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset.cardinality());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset.capacity());
      
      boolean boolean0 = openHashSet0.specInstance$();
      assertFalse(boolean0);
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test120()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity_$eq((-568));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-568), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals((-568), openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals((-568), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-568), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals((-568), openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals((-568), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
  }

  @Test(timeout = 4000)
  public void test121()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1191, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int0 = openHashSet0.getPos(boxedUnit0);
      assertEquals((-1), int0);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int1 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$nextPowerOf2(3059);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int1 == int0);
      assertEquals(4096, int1);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold_$eq(4096);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      int int2 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertTrue(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals(4096, int2);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_bitset;
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.cardinality());
      assertEquals(2048, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_bitset.capacity());
      
      int int3 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(int3 == int0);
      assertFalse(int3 == int1);
      assertFalse(int3 == int2);
      assertEquals(64, int3);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size_$eq((-1));
      assertNotSame(openHashSet0, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      BoxedUnit boxedUnit1 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = openHashSet1.contains$mcJ$sp(1191);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      Function1<Object, BoxedUnit> function1_0 = (Function1<Object, BoxedUnit>) mock(Function1.class, new ViolatedAssumptionAnswer());
      Function2<Object, Object, BoxedUnit> function2_0 = (Function2<Object, Object, BoxedUnit>) mock(Function2.class, new ViolatedAssumptionAnswer());
      openHashSet1.rehash(boxedUnit1, function1_0, function2_0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1433, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals((-1), openHashSet2.size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(2048, openHashSet2.capacity());
      assertEquals(2047, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(2048, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(2047, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1433, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(2048, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals((-1), openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = openHashSet1.hasher;
      assertNotNull(openHashSet_Hasher0);
      
      int int4 = openHashSet_Hasher0.hash$mcI$sp(89);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int4 == int1);
      assertFalse(int4 == int0);
      assertFalse(int4 == int3);
      assertFalse(int4 == int2);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(23, int4);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BitSet bitSet0 = openHashSet0.getBitSet();
      assertNotNull(bitSet0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, bitSet0.cardinality());
      assertEquals(2048, bitSet0.capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int5 = openHashSet_Hasher0.hash$mcJ$sp(0L);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(int5 == int0);
      assertFalse(int5 == int2);
      assertFalse(int5 == int1);
      assertFalse(int5 == int3);
      assertFalse(int5 == int4);
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(24, int5);
      assertEquals(2048, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.size());
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(128, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(0, openHashSet1.size());
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1433, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals((-1), openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2047, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2048, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(128, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(89, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(127, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
  }

  @Test(timeout = 4000)
  public void test122()  throws Throwable  {
      OpenHashSet.IntHasher openHashSet_IntHasher0 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher0);
      
      // Undeclared exception!
      try { 
        openHashSet_IntHasher0.hash$mcJ$sp(0L);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Long cannot be cast to java.lang.Integer
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test123()  throws Throwable  {
      int int0 = OpenHashSet.INVALID_POS();
      assertEquals((-1), int0);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      int int1 = 3868;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(0, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      boolean boolean0 = openHashSet1.contains(boxedUnit0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(boolean0);
      assertEquals(1, openHashSet0.capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet.IntHasher openHashSet_IntHasher0 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher0);
      
      // Undeclared exception!
      try { 
        openHashSet_IntHasher0.hash$mcJ$sp(0L);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Long cannot be cast to java.lang.Integer
         //
         verifyException("scala.runtime.BoxesRunTime", e);
      }
  }

  @Test(timeout = 4000)
  public void test124()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.addWithoutResize(boxedUnit0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test125()  throws Throwable  {
      OpenHashSet.IntHasher openHashSet_IntHasher0 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher0);
      
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>((ClassTag<BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test126()  throws Throwable  {
      OpenHashSet.IntHasher openHashSet_IntHasher0 = new OpenHashSet.IntHasher();
      assertNotNull(openHashSet_IntHasher0);
      
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(4021, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet1.union(openHashSet0);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertNotSame(openHashSet0, openHashSet2);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertSame(openHashSet1, openHashSet2);
      assertSame(openHashSet2, openHashSet1);
      assertNotSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(4095, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(4096, openHashSet2.capacity());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(2867, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet2.size());
      assertEquals(4096, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(2867, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4096, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4095, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet2.addWithoutResize(boxedUnit0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test127()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int[] intArray0 = new int[1];
      intArray0[0] = 0;
      openHashSet1._data$mcI$sp_$eq(intArray0);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertArrayEquals(new int[] {0}, intArray0);
      assertEquals(1, intArray0.length);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      boolean boolean0 = openHashSet0.specInstance$();
      assertSame(openHashSet0, openHashSet1);
      assertFalse(boolean0);
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      // Undeclared exception!
      try { 
        openHashSet0.getValueSafe$mcJ$sp(0);
        fail("Expecting exception: AssertionError");
      
      } catch(AssertionError e) {
         //
         // assertion failed
         //
      }
  }

  @Test(timeout = 4000)
  public void test128()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet1 = openHashSet0.union(openHashSet0);
      assertNotNull(openHashSet1);
      assertSame(openHashSet0, openHashSet1);
      assertSame(openHashSet1, openHashSet0);
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      try { 
        openHashSet1.getValue$mcI$sp(44);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test129()  throws Throwable  {
      int int0 = 842;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(842, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1024, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1023, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(716, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1024, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1024, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1023, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(716, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1024, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      int[] intArray0 = new int[6];
      intArray0[0] = 63;
      intArray0[1] = 1023;
      intArray0[2] = 44;
      intArray0[3] = 44;
      intArray0[4] = 1024;
      intArray0[5] = 0;
      openHashSet1._data$mcI$sp_$eq(intArray0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertArrayEquals(new int[] {63, 1023, 44, 44, 1024, 0}, intArray0);
      assertEquals(6, intArray0.length);
      assertEquals(1024, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1023, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(716, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1024, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet.Hasher<BoxedUnit> openHashSet_Hasher0 = openHashSet1.hasher();
      assertNotNull(openHashSet_Hasher0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1024, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1023, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(716, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1024, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet1.size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1024, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(716, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1023, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      BoxedUnit boxedUnit0 = mock(BoxedUnit.class, new ViolatedAssumptionAnswer());
      // Undeclared exception!
      try { 
        openHashSet0.getValue$mcI$sp((-1640532531));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test130()  throws Throwable  {
      OpenHashSet.LongHasher openHashSet_LongHasher0 = new OpenHashSet.LongHasher();
      assertNotNull(openHashSet_LongHasher0);
      
      OpenHashSet.LongHasher openHashSet_LongHasher1 = new OpenHashSet.LongHasher();
      assertNotNull(openHashSet_LongHasher1);
      assertFalse(openHashSet_LongHasher1.equals((Object)openHashSet_LongHasher0));
      
      int int0 = openHashSet_LongHasher1.hash((long) 1191);
      assertNotSame(openHashSet_LongHasher1, openHashSet_LongHasher0);
      assertFalse(openHashSet_LongHasher1.equals((Object)openHashSet_LongHasher0));
      assertEquals(1191, int0);
      
      int int1 = 45;
      ClassTag<BoxedUnit> classTag0 = null;
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>((ClassTag<BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test131()  throws Throwable  {
      OpenHashSet.LongHasher openHashSet_LongHasher0 = new OpenHashSet.LongHasher();
      assertNotNull(openHashSet_LongHasher0);
      
      int int0 = openHashSet_LongHasher0.hash$mcJ$sp(0L);
      assertEquals(0, int0);
      
      int int1 = openHashSet_LongHasher0.hash$mcJ$sp(0L);
      assertTrue(int1 == int0);
      assertEquals(0, int1);
  }

  @Test(timeout = 4000)
  public void test132()  throws Throwable  {
      int int0 = OpenHashSet.MAX_CAPACITY();
      assertEquals(1073741824, int0);
      
      OpenHashSet.LongHasher openHashSet_LongHasher0 = new OpenHashSet.LongHasher();
      assertNotNull(openHashSet_LongHasher0);
      
      int int1 = openHashSet_LongHasher0.hash((long) 1073741824);
      assertTrue(int1 == int0);
      assertEquals(1073741824, int1);
      
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1073741824, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(751619276, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741823, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(751619276, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1073741823, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(751619276, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1073741824, openHashSet0.capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(1073741823, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(64, openHashSet1.capacity());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1073741824, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(751619276, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1073741823, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      // Undeclared exception!
      openHashSet1.union(openHashSet0);
  }

  @Test(timeout = 4000)
  public void test133()  throws Throwable  {
      int int0 = 1073741824;
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>(1073741824, (ClassTag<BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test134()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2433880, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(4194304, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(2936012, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(4194303, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(4194304, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(4194303, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2936012, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4194304, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int0 = 1073741824;
      OpenHashSet<BoxedUnit> openHashSet1 = null;
      try {
        openHashSet1 = new OpenHashSet<BoxedUnit>(1073741824, 1.0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Load factor must be less than 1.0
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test135()  throws Throwable  {
      int int0 = OpenHashSet.MAX_CAPACITY();
      assertEquals(1073741824, int0);
      
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(64, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(64, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = null;
      try {
        openHashSet1 = new OpenHashSet<BoxedUnit>(0, 1073741824, classTag1);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Load factor must be less than 1.0
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test136()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(4934, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int0 = openHashSet1.nextPos(2424);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals((-1), int0);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(8192, openHashSet0.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(8191, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(5734, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(8192, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test137()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$hashcode(32);
      assertEquals((-606617892), int0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      
      int int1 = openHashSet0.size();
      assertFalse(int1 == int0);
      assertEquals(0, int1);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test138()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      assertNotNull(openHashSet0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      assertNotNull(classTag1);
      assertSame(classTag1, classTag0);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(2851, classTag1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      int int0 = openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size();
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(classTag1, classTag0);
      assertNotSame(openHashSet1, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(0, int0);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.size());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet0.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(4096, openHashSet1.capacity());
      assertEquals(44, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(2867, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(4095, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(4096, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test139()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      assertArrayEquals(new long[] {0L, 0L, 0L, 0L, 0L}, longArray0);
      assertEquals(5, longArray0.length);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(0, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      openHashSet0.add$mcJ$sp(1);
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet2.size());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      
      OpenHashSet<BoxedUnit> openHashSet3 = openHashSet0.union(openHashSet2);
      assertNotNull(openHashSet3);
      assertSame(openHashSet0, openHashSet3);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet3);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet0);
      assertSame(openHashSet2, openHashSet3);
      assertSame(openHashSet3, openHashSet0);
      assertSame(openHashSet3, openHashSet2);
      assertNotSame(openHashSet3, openHashSet1);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet2));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertFalse(openHashSet3.equals((Object)openHashSet1));
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(2, openHashSet0.capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1, openHashSet0.size());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet1.size());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(1, openHashSet2.size());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(Integer.MAX_VALUE, openHashSet3.POSITION_MASK());
      assertEquals(1, openHashSet3.size());
      assertFalse(openHashSet3.specInstance$());
      assertEquals(Integer.MIN_VALUE, openHashSet3.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet3.INVALID_POS());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet3.MAX_CAPACITY());
      assertEquals(2, openHashSet3.capacity());
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet3.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
  }

  @Test(timeout = 4000)
  public void test140()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      assertNotNull(openHashSet0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      assertNotNull(openHashSet1);
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      OpenHashSet<BoxedUnit> openHashSet2 = openHashSet0.union(openHashSet1);
      assertNotNull(openHashSet2);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertNotSame(openHashSet1, openHashSet2);
      assertNotSame(openHashSet1, openHashSet0);
      assertNotSame(openHashSet2, openHashSet1);
      assertSame(openHashSet2, openHashSet0);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertFalse(openHashSet1.equals((Object)openHashSet0));
      assertFalse(openHashSet2.equals((Object)openHashSet1));
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet1.size());
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet1.NONEXISTENCE_MASK());
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals((-1), openHashSet1.INVALID_POS());
      assertEquals(64, openHashSet1.capacity());
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertFalse(openHashSet1.specInstance$());
      assertEquals(1073741824, openHashSet1.MAX_CAPACITY());
      assertEquals(Integer.MAX_VALUE, openHashSet1.POSITION_MASK());
      assertEquals(2, openHashSet2.capacity());
      assertEquals(0, openHashSet2.size());
      assertEquals((-1), openHashSet2.INVALID_POS());
      assertEquals(Integer.MAX_VALUE, openHashSet2.POSITION_MASK());
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertFalse(openHashSet2.specInstance$());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet2.MAX_CAPACITY());
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(Integer.MIN_VALUE, openHashSet2.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(63, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(0.7, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(64, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(44, openHashSet1.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(0, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(2, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_capacity);
      assertEquals(0.7, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(1, openHashSet2.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      
      int int0 = openHashSet0.getPos$mcI$sp(0);
      assertNotSame(openHashSet0, openHashSet1);
      assertSame(openHashSet0, openHashSet2);
      assertFalse(openHashSet0.equals((Object)openHashSet1));
      assertEquals((-1), int0);
      assertEquals(Integer.MAX_VALUE, openHashSet0.POSITION_MASK());
      assertEquals(0, openHashSet0.size());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size());
      assertEquals(Integer.MIN_VALUE, openHashSet0.NONEXISTENCE_MASK());
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity());
      assertEquals((-1), openHashSet0.INVALID_POS());
      assertEquals(2, openHashSet0.capacity());
      assertFalse(openHashSet0.specInstance$());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold());
      assertEquals(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertEquals(0.7, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$loadFactor, 0.01);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold);
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask);
      assertEquals(2, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_capacity);
  }

  @Test(timeout = 4000)
  public void test141()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1962, classTag0);
      // Undeclared exception!
      try { 
        openHashSet0.add$mcJ$sp(1962);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test142()  throws Throwable  {
      int int0 = 25;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(25, classTag0);
      openHashSet0.getPos$mcI$sp(25);
      // Undeclared exception!
      try { 
        openHashSet0.add$mcJ$sp((-1));
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test143()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(2, classTag0);
      long[] longArray0 = new long[5];
      openHashSet0._data$mcJ$sp_$eq(longArray0);
      openHashSet0.add$mcJ$sp(1);
      boolean boolean0 = openHashSet0.contains$mcI$sp((-1195));
      assertEquals(1, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_size);
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void test144()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      // Undeclared exception!
      try { 
        openHashSet0.getValue$mcJ$sp(2968);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test145()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      int int0 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_growThreshold;
      // Undeclared exception!
      try { 
        openHashSet0.getValue(44);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test146()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      // Undeclared exception!
      try { 
        openHashSet1.add$mcI$sp(44);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test147()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
      // Undeclared exception!
      try { 
        openHashSet1.add$mcI$sp(64);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test148()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null, (Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(0, classTag0);
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      OpenHashSet<BoxedUnit> openHashSet1 = new OpenHashSet<BoxedUnit>(classTag1);
      openHashSet0.getPos$mcJ$sp(44);
      // Undeclared exception!
      try { 
        openHashSet1.getValue$mcJ$sp(1433);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("scala.runtime.ScalaRunTime$", e);
      }
  }

  @Test(timeout = 4000)
  public void test149()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(classTag0);
      int int0 = openHashSet0.getPos$mcJ$sp(44);
      assertEquals(63, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$_mask());
      assertEquals(1073741824, openHashSet0.MAX_CAPACITY());
      assertEquals((-1), int0);
  }

  @Test(timeout = 4000)
  public void test150()  throws Throwable  {
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>((ClassTag<BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test151()  throws Throwable  {
      int int0 = 3849;
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>(3849, (ClassTag<BoxedUnit>) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.spark.util.collection.OpenHashSet", e);
      }
  }

  @Test(timeout = 4000)
  public void test152()  throws Throwable  {
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>(1249, (-2326.957361938), (ClassTag<BoxedUnit>) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Load factor must be greater than 0.0
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test153()  throws Throwable  {
      int int0 = 0;
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      doReturn((Object) null).when(classTag0).newArray(anyInt());
      OpenHashSet<BoxedUnit> openHashSet0 = new OpenHashSet<BoxedUnit>(1083, classTag0);
      ClassTag<BoxedUnit> classTag1 = openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1;
      OpenHashSet<BoxedUnit> openHashSet1 = null;
      try {
        openHashSet1 = new OpenHashSet<BoxedUnit>(32, 0, openHashSet0.org$apache$spark$util$collection$OpenHashSet$$evidence$1);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Load factor must be greater than 0.0
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test154()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>((-32768), (-32768), classTag0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Invalid initial capacity
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test155()  throws Throwable  {
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>((-1), (ClassTag<BoxedUnit>) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Invalid initial capacity
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test156()  throws Throwable  {
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>((-128), (-128), (ClassTag<BoxedUnit>) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Invalid initial capacity
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test157()  throws Throwable  {
      int int0 = 1825;
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>(1825, 1825, (ClassTag<BoxedUnit>) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Load factor must be less than 1.0
         //
         verifyException("scala.Predef$", e);
      }
  }

  @Test(timeout = 4000)
  public void test158()  throws Throwable  {
      ClassTag<BoxedUnit> classTag0 = (ClassTag<BoxedUnit>) mock(ClassTag.class, new ViolatedAssumptionAnswer());
      OpenHashSet<BoxedUnit> openHashSet0 = null;
      try {
        openHashSet0 = new OpenHashSet<BoxedUnit>(1073741824, 1073741824, classTag0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // requirement failed: Load factor must be less than 1.0
         //
         verifyException("scala.Predef$", e);
      }
  }
}
