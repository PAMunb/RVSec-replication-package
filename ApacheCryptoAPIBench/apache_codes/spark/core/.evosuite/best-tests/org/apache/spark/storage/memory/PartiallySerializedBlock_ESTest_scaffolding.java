/**
 * Scaffolding file used to store all the setups needed to run 
 * tests automatically generated by EvoSuite
 * Thu Apr 21 23:22:45 GMT 2022
 */

package org.apache.spark.storage.memory;

import org.evosuite.runtime.annotation.EvoSuiteClassExclude;
import org.junit.BeforeClass;
import org.junit.Before;
import org.junit.After;
import org.junit.AfterClass;
import org.evosuite.runtime.sandbox.Sandbox;
import org.evosuite.runtime.sandbox.Sandbox.SandboxMode;

import static org.evosuite.shaded.org.mockito.Mockito.*;
@EvoSuiteClassExclude
public class PartiallySerializedBlock_ESTest_scaffolding {

  @org.junit.Rule
  public org.evosuite.runtime.vnet.NonFunctionalRequirementRule nfr = new org.evosuite.runtime.vnet.NonFunctionalRequirementRule();

  private static final java.util.Properties defaultProperties = (java.util.Properties) java.lang.System.getProperties().clone(); 

  private org.evosuite.runtime.thread.ThreadStopper threadStopper =  new org.evosuite.runtime.thread.ThreadStopper (org.evosuite.runtime.thread.KillSwitchHandler.getInstance(), 3000);


  @BeforeClass
  public static void initEvoSuiteFramework() { 
    org.evosuite.runtime.RuntimeSettings.className = "org.apache.spark.storage.memory.PartiallySerializedBlock"; 
    org.evosuite.runtime.GuiSupport.initialize(); 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfThreads = 100; 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfIterationsPerLoop = 10000; 
    org.evosuite.runtime.RuntimeSettings.mockSystemIn = true; 
    org.evosuite.runtime.RuntimeSettings.sandboxMode = org.evosuite.runtime.sandbox.Sandbox.SandboxMode.RECOMMENDED; 
    org.evosuite.runtime.sandbox.Sandbox.initializeSecurityManagerForSUT(); 
    org.evosuite.runtime.classhandling.JDKClassResetter.init();
    setSystemProperties();
    initializeClasses();
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    try { initMocksToAvoidTimeoutsInTheTests(); } catch(ClassNotFoundException e) {} 
  } 

  @AfterClass
  public static void clearEvoSuiteFramework(){ 
    Sandbox.resetDefaultSecurityManager(); 
    java.lang.System.setProperties((java.util.Properties) defaultProperties.clone()); 
  } 

  @Before
  public void initTestCase(){ 
    threadStopper.storeCurrentThreads();
    threadStopper.startRecordingTime();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().initHandler(); 
    org.evosuite.runtime.sandbox.Sandbox.goingToExecuteSUTCode(); 
    setSystemProperties(); 
    org.evosuite.runtime.GuiSupport.setHeadless(); 
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    org.evosuite.runtime.agent.InstrumentingAgent.activate(); 
  } 

  @After
  public void doneWithTestCase(){ 
    threadStopper.killAndJoinClientThreads();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().safeExecuteAddedHooks(); 
    org.evosuite.runtime.classhandling.JDKClassResetter.reset(); 
    resetClasses(); 
    org.evosuite.runtime.sandbox.Sandbox.doneWithExecutingSUTCode(); 
    org.evosuite.runtime.agent.InstrumentingAgent.deactivate(); 
    org.evosuite.runtime.GuiSupport.restoreHeadlessMode(); 
  } 

  public static void setSystemProperties() {
 
    java.lang.System.setProperties((java.util.Properties) defaultProperties.clone()); 
  }

  private static void initializeClasses() {
    org.evosuite.runtime.classhandling.ClassStateSupport.initializeClasses(PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader() ,
      "scala.collection.Seq$",
      "scala.math.Equiv",
      "scala.collection.mutable.Iterable$class",
      "scala.Function1$class",
      "scala.reflect.ManifestFactory$ClassTypeManifest",
      "scala.collection.generic.Shrinkable",
      "scala.collection.mutable.Seq$class",
      "scala.collection.LinearSeqOptimized",
      "org.apache.spark.storage.TempShuffleBlockId",
      "scala.collection.Iterator$class",
      "scala.collection.generic.IndexedSeqFactory",
      "scala.collection.AbstractMap",
      "scala.collection.immutable.IndexedSeq",
      "scala.collection.immutable.StringLike",
      "scala.collection.Map",
      "scala.collection.SeqLike$PermutationsItr",
      "scala.reflect.Manifest",
      "scala.collection.mutable.HashTable",
      "scala.collection.IndexedSeqLike$Elements",
      "com.google.common.io.ByteSink",
      "scala.Predef$StringAdd",
      "scala.collection.mutable.IndexedSeqLike",
      "scala.collection.mutable.Buffer",
      "scala.Product$class",
      "scala.collection.generic.FilterMonadic",
      "scala.runtime.NonLocalReturnControl",
      "org.apache.spark.serializer.TestJavaSerializerImpl$SerializationStreamImpl",
      "scala.collection.Iterator$JoinIterator",
      "scala.collection.mutable.Cloneable",
      "scala.collection.generic.GenTraversableFactory",
      "scala.Predef$RichException$",
      "scala.collection.SeqViewLike",
      "scala.collection.GenIterableLike",
      "scala.Equals",
      "scala.Predef$Triple$",
      "scala.collection.GenIterable$class",
      "scala.collection.generic.GenericSetTemplate",
      "scala.collection.mutable.StringBuilder",
      "scala.collection.generic.GenericTraversableTemplate",
      "scala.math.Ordering",
      "scala.Mutable",
      "scala.collection.GenSet",
      "com.google.common.io.ByteArrayDataInput",
      "org.apache.spark.serializer.JavaSerializationStream",
      "scala.collection.GenTraversable",
      "scala.collection.GenSeq",
      "org.apache.spark.TaskContextImpl",
      "org.apache.spark.serializer.KryoSerializationStream",
      "scala.collection.GenSeqLike",
      "org.apache.spark.internal.Logging",
      "org.apache.spark.storage.RDDBlockId",
      "io.netty.util.ReferenceCounted",
      "org.apache.spark.storage.memory.ValuesHolder",
      "scala.collection.immutable.Vector",
      "scala.collection.mutable.Seq",
      "scala.collection.SeqLike",
      "scala.collection.LinearSeq",
      "com.google.common.base.Preconditions",
      "org.apache.spark.TaskContext$",
      "scala.collection.TraversableView",
      "scala.collection.GenSeq$",
      "org.apache.spark.storage.TestBlockId",
      "scala.Predef$$eq$colon$eq$",
      "org.apache.spark.storage.memory.MemoryStore",
      "scala.collection.LinearSeqLike",
      "scala.collection.mutable.SeqLike",
      "scala.reflect.ClassTypeManifest",
      "scala.util.Left",
      "com.google.common.io.ByteArrayDataOutput",
      "scala.collection.SeqLike$CombinationsItr",
      "scala.collection.immutable.Nil$",
      "scala.Predef$$eq$colon$eq",
      "scala.Predef$$less$colon$less",
      "scala.PartialFunction",
      "org.apache.spark.memory.MemoryManager",
      "scala.collection.generic.GenericTraversableTemplate$class",
      "scala.reflect.ManifestFactory$SingletonTypeManifest",
      "org.apache.spark.serializer.SerializerManager",
      "org.apache.spark.memory.MemoryMode",
      "scala.collection.Seq$class",
      "scala.collection.IndexedSeqLike$class",
      "scala.collection.TraversableOnce",
      "scala.Tuple2",
      "scala.collection.mutable.IndexedSeqLike$class",
      "scala.Predef$any2stringadd",
      "scala.Predef$ArrowAssoc",
      "scala.runtime.TraitSetter",
      "scala.collection.IterableView",
      "scala.collection.BufferedIterator",
      "scala.runtime.AbstractFunction1",
      "scala.collection.immutable.Seq",
      "org.apache.spark.serializer.TestJavaSerializerImpl$DeserializationStreamImpl",
      "scala.collection.mutable.Iterable",
      "scala.Predef$SeqCharSequence",
      "scala.collection.immutable.Set",
      "org.apache.spark.storage.memory.PartiallySerializedBlock$$anonfun$8",
      "org.apache.spark.storage.ShuffleIndexBlockId",
      "scala.collection.mutable.IndexedSeq$class",
      "scala.collection.mutable.IndexedSeqView",
      "scala.collection.IndexedSeq$",
      "scala.collection.IndexedSeqLike",
      "scala.collection.mutable.IndexedSeqOptimized",
      "scala.collection.mutable.MapLike",
      "scala.collection.GenTraversableLike",
      "scala.Predef",
      "org.apache.spark.storage.TempLocalBlockId",
      "scala.Option$",
      "scala.Product2",
      "org.apache.spark.util.io.ChunkedByteBuffer",
      "scala.math.Numeric",
      "scala.Predef$Pair$",
      "scala.collection.mutable.HashMap",
      "scala.collection.GenIterable$",
      "scala.util.control.NoStackTrace",
      "scala.Predef$DummyImplicit$",
      "scala.util.Right",
      "org.apache.spark.util.io.ChunkedByteBufferInputStream",
      "scala.Predef$StringFormat",
      "scala.collection.generic.TraversableFactory",
      "org.apache.spark.storage.StreamBlockId",
      "scala.collection.mutable.IndexedSeq",
      "scala.PartialFunction$class",
      "scala.runtime.BoxedUnit",
      "scala.Option",
      "scala.collection.SeqLike$$anon$1",
      "scala.collection.generic.Subtractable",
      "org.apache.spark.storage.memory.PartiallySerializedBlock",
      "org.apache.spark.storage.ShuffleDataBlockId",
      "org.apache.spark.serializer.Serializer",
      "scala.collection.IndexedSeq$class",
      "scala.collection.mutable.Traversable",
      "scala.collection.mutable.AbstractMap",
      "com.google.common.io.ByteStreams$1",
      "scala.collection.Parallelizable",
      "scala.Serializable",
      "scala.reflect.ScalaSignature",
      "org.apache.spark.serializer.TestJavaSerializerImpl",
      "scala.Predef$ArrowAssoc$",
      "scala.util.matching.Regex",
      "scala.collection.immutable.Stream$Cons",
      "org.apache.spark.annotation.Private",
      "scala.collection.mutable.BufferLike",
      "com.google.common.io.ByteStreams$6",
      "scala.collection.AbstractSeq",
      "com.google.common.io.ByteStreams$7",
      "scala.collection.Iterable$",
      "org.apache.spark.storage.BlockInfoManager",
      "org.apache.spark.storage.BlockId",
      "scala.collection.immutable.List",
      "scala.collection.TraversableLike$class",
      "scala.collection.Seq",
      "scala.collection.Set",
      "scala.collection.generic.GenericCompanion",
      "scala.collection.mutable.SeqLike$class",
      "scala.collection.immutable.VectorPointer",
      "scala.reflect.ManifestFactory",
      "scala.collection.immutable.LinearSeq",
      "scala.util.control.ControlThrowable",
      "scala.math.PartialOrdering",
      "scala.collection.mutable.ArrayLike",
      "scala.collection.MapLike",
      "com.google.common.io.ByteStreams",
      "scala.collection.GenTraversable$",
      "scala.collection.IndexedSeqOptimized$class",
      "scala.collection.mutable.Builder",
      "scala.collection.immutable.Stream$Empty$",
      "scala.collection.Traversable$class",
      "scala.reflect.ClassTag",
      "com.google.common.io.ByteProcessor",
      "scala.collection.mutable.Iterable$",
      "scala.Function0",
      "scala.Function1",
      "scala.Function2",
      "scala.reflect.ManifestFactory$PhantomManifest",
      "scala.Predef$DummyImplicit",
      "org.apache.spark.storage.memory.RedirectableOutputStream",
      "org.apache.spark.storage.memory.BlockEvictionHandler",
      "scala.collection.GenMapLike",
      "scala.collection.ViewMkString",
      "scala.collection.GenMap",
      "org.apache.spark.storage.TaskResultBlockId",
      "com.google.common.io.ByteSource",
      "scala.util.Either",
      "scala.collection.Parallelizable$class",
      "scala.collection.mutable.WrappedArray",
      "scala.collection.generic.GenericSeqCompanion",
      "scala.math.Ordered$class",
      "scala.collection.SeqView",
      "scala.collection.SeqLike$class",
      "org.apache.spark.TaskContext",
      "org.apache.spark.SparkConf",
      "scala.collection.mutable.ResizableArray",
      "scala.collection.mutable.Builder$class",
      "org.apache.spark.serializer.SerializationStream",
      "scala.None$",
      "scala.collection.TraversableViewLike",
      "scala.collection.mutable.Map",
      "com.google.common.io.OutputSupplier",
      "scala.Predef$Ensuring$",
      "scala.collection.immutable.Stream",
      "org.apache.spark.storage.memory.PartiallySerializedBlock$$anonfun$8$$anonfun$apply$2",
      "scala.Product",
      "scala.collection.GenTraversable$class",
      "scala.collection.Iterator$ConcatIterator",
      "com.google.common.io.InputSupplier",
      "scala.collection.Iterator$GroupedIterator",
      "org.apache.spark.storage.memory.PartiallyUnrolledIterator",
      "scala.collection.immutable.Iterable",
      "scala.Predef$StringFormat$",
      "scala.Predef$RichException",
      "org.apache.spark.util.io.ChunkedByteBufferOutputStream",
      "scala.collection.mutable.HashTable$HashUtils",
      "scala.reflect.ClassManifestDeprecatedApis",
      "scala.collection.GenIterable",
      "scala.collection.script.Scriptable",
      "scala.collection.mutable.AbstractBuffer",
      "scala.collection.immutable.StringLike$class",
      "scala.collection.GenSeqLike$class",
      "scala.collection.generic.SeqFactory",
      "scala.Cloneable",
      "scala.collection.mutable.Cloneable$class",
      "scala.Predef$any2stringadd$",
      "scala.collection.SetLike$SubsetsItr",
      "scala.Some",
      "scala.MatchError",
      "scala.reflect.OptManifest",
      "scala.collection.generic.GenSeqFactory",
      "scala.collection.TraversableOnce$class",
      "com.google.common.io.ByteStreams$ByteArrayByteSource",
      "org.apache.spark.serializer.DeserializationStream",
      "scala.collection.GenSeq$class",
      "com.google.common.io.ByteStreams$LimitedInputStream",
      "scala.math.Ordered",
      "org.apache.spark.storage.ShuffleBlockId",
      "scala.collection.TraversableLike",
      "scala.collection.SetLike",
      "scala.collection.IterableLike",
      "scala.Predef$Ensuring",
      "scala.collection.immutable.Map",
      "scala.collection.generic.CanBuildFrom",
      "org.apache.spark.annotation.DeveloperApi",
      "scala.collection.GenSetLike",
      "scala.reflect.AnyValManifest",
      "scala.collection.IndexedSeq",
      "scala.collection.IterableViewLike",
      "scala.collection.mutable.Traversable$",
      "scala.collection.generic.HasNewBuilder",
      "scala.collection.GenTraversableOnce",
      "scala.collection.AbstractTraversable",
      "scala.collection.mutable.ArrayBuilder",
      "scala.collection.immutable.MapLike",
      "scala.collection.AbstractIterator",
      "scala.Immutable",
      "io.netty.buffer.ByteBuf",
      "scala.collection.AbstractIterable",
      "scala.collection.Traversable",
      "scala.collection.mutable.ArrayBuffer",
      "scala.collection.immutable.$colon$colon",
      "org.apache.spark.io.CompressionCodec",
      "scala.collection.immutable.Traversable",
      "scala.collection.generic.Growable$class",
      "scala.runtime.Nothing$",
      "scala.collection.Iterator",
      "scala.collection.IndexedSeqOptimized",
      "org.apache.spark.storage.memory.MemoryEntry",
      "scala.collection.mutable.Seq$",
      "scala.Predef$StringAdd$",
      "scala.collection.Traversable$",
      "scala.collection.Iterable",
      "org.apache.spark.serializer.KryoSerializer",
      "scala.collection.mutable.AbstractSeq",
      "scala.collection.mutable.IndexedSeq$",
      "scala.collection.generic.Clearable",
      "scala.collection.mutable.Traversable$class",
      "scala.collection.generic.Growable",
      "scala.collection.IterableLike$class",
      "scala.collection.CustomParallelizable",
      "scala.collection.Iterable$class",
      "org.apache.spark.storage.BroadcastBlockId"
    );
  } 
  private static void initMocksToAvoidTimeoutsInTheTests() throws ClassNotFoundException { 
    mock(Class.forName("java.io.OutputStream", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.serializer.SerializationStream", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.serializer.SerializerManager", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.storage.BlockId", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.storage.memory.MemoryStore", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.storage.memory.RedirectableOutputStream", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.util.io.ChunkedByteBuffer", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.util.io.ChunkedByteBufferOutputStream", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("scala.collection.Iterator", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("scala.reflect.ClassTag", false, PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()));
  }

  private static void resetClasses() {
    org.evosuite.runtime.classhandling.ClassResetter.getInstance().setClassLoader(PartiallySerializedBlock_ESTest_scaffolding.class.getClassLoader()); 

    org.evosuite.runtime.classhandling.ClassStateSupport.resetClasses(
      "org.apache.spark.storage.memory.PartiallySerializedBlock",
      "scala.runtime.AbstractFunction1",
      "org.apache.spark.storage.memory.PartiallySerializedBlock$$anonfun$8",
      "org.apache.spark.storage.memory.PartiallySerializedBlock$$anonfun$8$$anonfun$apply$2",
      "scala.runtime.BoxedUnit",
      "com.google.common.io.ByteStreams$1",
      "com.google.common.io.ByteStreams",
      "scala.Option$",
      "org.apache.spark.TaskContext$",
      "org.apache.spark.storage.memory.MemoryStore",
      "org.apache.spark.serializer.SerializerManager",
      "org.apache.spark.serializer.SerializationStream",
      "org.apache.spark.storage.memory.RedirectableOutputStream",
      "scala.Option",
      "scala.Product$class",
      "scala.None$",
      "scala.Function1$class",
      "org.apache.spark.storage.BlockId",
      "org.apache.spark.util.io.ChunkedByteBufferOutputStream",
      "org.apache.spark.util.io.ChunkedByteBuffer",
      "org.apache.spark.storage.memory.PartiallyUnrolledIterator",
      "scala.collection.TraversableOnce$class",
      "scala.collection.Iterator$class",
      "scala.collection.AbstractTraversable",
      "scala.collection.AbstractIterable",
      "scala.collection.AbstractSeq",
      "scala.collection.mutable.AbstractSeq",
      "scala.collection.mutable.StringBuilder",
      "scala.collection.Parallelizable$class",
      "scala.collection.TraversableLike$class",
      "scala.collection.generic.GenericTraversableTemplate$class",
      "scala.collection.GenTraversable$class",
      "scala.collection.Traversable$class",
      "scala.collection.GenIterable$class",
      "scala.collection.IterableLike$class",
      "scala.collection.Iterable$class",
      "scala.PartialFunction$class",
      "scala.collection.GenSeqLike$class",
      "scala.collection.GenSeq$class",
      "scala.collection.SeqLike$class",
      "scala.collection.Seq$class",
      "scala.collection.mutable.Traversable$class",
      "scala.collection.mutable.Iterable$class",
      "scala.collection.mutable.Cloneable$class",
      "scala.collection.mutable.SeqLike$class",
      "scala.collection.mutable.Seq$class",
      "scala.collection.IndexedSeqLike$class",
      "scala.collection.IndexedSeq$class",
      "scala.collection.mutable.IndexedSeqLike$class",
      "scala.collection.mutable.IndexedSeq$class",
      "scala.collection.IndexedSeqOptimized$class",
      "scala.math.Ordered$class",
      "scala.collection.immutable.StringLike$class",
      "scala.collection.generic.Growable$class",
      "scala.collection.mutable.Builder$class",
      "com.google.common.base.Preconditions"
    );
  }
}
