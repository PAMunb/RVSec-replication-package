/**
 * Scaffolding file used to store all the setups needed to run 
 * tests automatically generated by EvoSuite
 * Fri Apr 22 00:05:56 GMT 2022
 */

package org.apache.spark;

import org.evosuite.runtime.annotation.EvoSuiteClassExclude;
import org.junit.BeforeClass;
import org.junit.Before;
import org.junit.After;
import org.junit.AfterClass;
import org.evosuite.runtime.sandbox.Sandbox;
import org.evosuite.runtime.sandbox.Sandbox.SandboxMode;

import static org.evosuite.shaded.org.mockito.Mockito.*;
@EvoSuiteClassExclude
public class SparkFirehoseListener_ESTest_scaffolding {

  @org.junit.Rule
  public org.evosuite.runtime.vnet.NonFunctionalRequirementRule nfr = new org.evosuite.runtime.vnet.NonFunctionalRequirementRule();

  private static final java.util.Properties defaultProperties = (java.util.Properties) java.lang.System.getProperties().clone(); 

  private org.evosuite.runtime.thread.ThreadStopper threadStopper =  new org.evosuite.runtime.thread.ThreadStopper (org.evosuite.runtime.thread.KillSwitchHandler.getInstance(), 3000);


  @BeforeClass
  public static void initEvoSuiteFramework() { 
    org.evosuite.runtime.RuntimeSettings.className = "org.apache.spark.SparkFirehoseListener"; 
    org.evosuite.runtime.GuiSupport.initialize(); 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfThreads = 100; 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfIterationsPerLoop = 10000; 
    org.evosuite.runtime.RuntimeSettings.mockSystemIn = true; 
    org.evosuite.runtime.RuntimeSettings.sandboxMode = org.evosuite.runtime.sandbox.Sandbox.SandboxMode.RECOMMENDED; 
    org.evosuite.runtime.sandbox.Sandbox.initializeSecurityManagerForSUT(); 
    org.evosuite.runtime.classhandling.JDKClassResetter.init();
    setSystemProperties();
    initializeClasses();
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    try { initMocksToAvoidTimeoutsInTheTests(); } catch(ClassNotFoundException e) {} 
  } 

  @AfterClass
  public static void clearEvoSuiteFramework(){ 
    Sandbox.resetDefaultSecurityManager(); 
    java.lang.System.setProperties((java.util.Properties) defaultProperties.clone()); 
  } 

  @Before
  public void initTestCase(){ 
    threadStopper.storeCurrentThreads();
    threadStopper.startRecordingTime();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().initHandler(); 
    org.evosuite.runtime.sandbox.Sandbox.goingToExecuteSUTCode(); 
    setSystemProperties(); 
    org.evosuite.runtime.GuiSupport.setHeadless(); 
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    org.evosuite.runtime.agent.InstrumentingAgent.activate(); 
  } 

  @After
  public void doneWithTestCase(){ 
    threadStopper.killAndJoinClientThreads();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().safeExecuteAddedHooks(); 
    org.evosuite.runtime.classhandling.JDKClassResetter.reset(); 
    resetClasses(); 
    org.evosuite.runtime.sandbox.Sandbox.doneWithExecutingSUTCode(); 
    org.evosuite.runtime.agent.InstrumentingAgent.deactivate(); 
    org.evosuite.runtime.GuiSupport.restoreHeadlessMode(); 
  } 

  public static void setSystemProperties() {
 
    java.lang.System.setProperties((java.util.Properties) defaultProperties.clone()); 
  }

  private static void initializeClasses() {
    org.evosuite.runtime.classhandling.ClassStateSupport.initializeClasses(SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader() ,
      "org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate",
      "scala.collection.Parallelizable",
      "scala.Serializable",
      "org.apache.spark.scheduler.SparkListenerNodeBlacklistedForStage",
      "scala.reflect.ScalaSignature",
      "org.apache.spark.scheduler.AccumulableInfo",
      "org.apache.spark.scheduler.cluster.ExecutorInfo",
      "com.fasterxml.jackson.annotation.JacksonAnnotation",
      "org.apache.spark.scheduler.SparkListenerEnvironmentUpdate",
      "scala.collection.GenIterable",
      "org.apache.spark.SparkFirehoseListener",
      "org.apache.spark.scheduler.SparkListenerNodeUnblacklisted",
      "org.apache.spark.storage.BlockUpdatedInfo",
      "org.apache.spark.scheduler.SparkListenerTaskEnd",
      "org.apache.spark.scheduler.JobResult",
      "org.apache.spark.scheduler.SparkListenerApplicationEnd",
      "org.apache.spark.scheduler.SparkListenerTaskGettingResult",
      "scala.PartialFunction",
      "scala.collection.Map",
      "org.apache.spark.scheduler.SparkListenerBlockManagerAdded",
      "scala.collection.Seq",
      "scala.Tuple6",
      "org.apache.spark.executor.TaskMetrics",
      "scala.Tuple4",
      "scala.Tuple5",
      "scala.collection.TraversableOnce",
      "scala.Tuple2",
      "scala.Tuple3",
      "org.apache.spark.scheduler.SparkListenerNodeBlacklisted",
      "org.apache.spark.scheduler.SparkListenerInterface",
      "com.fasterxml.jackson.annotation.JsonTypeInfo$Id",
      "org.apache.spark.scheduler.SparkListenerLogStart",
      "com.fasterxml.jackson.annotation.JsonTypeInfo",
      "org.apache.spark.scheduler.SparkListenerExecutorAdded",
      "scala.collection.TraversableLike",
      "scala.collection.IterableLike",
      "scala.collection.MapLike",
      "org.apache.spark.scheduler.SparkListenerBlockUpdated",
      "org.apache.spark.annotation.DeveloperApi",
      "scala.collection.generic.FilterMonadic",
      "org.apache.spark.scheduler.SparkListenerApplicationStart",
      "org.apache.spark.scheduler.SparkListenerExecutorUnblacklisted",
      "org.apache.spark.scheduler.SparkListenerExecutorRemoved",
      "com.fasterxml.jackson.annotation.JsonTypeInfo$As",
      "scala.collection.GenIterableLike",
      "scala.Equals",
      "scala.Function1",
      "scala.collection.generic.HasNewBuilder",
      "org.apache.spark.scheduler.SparkListenerSpeculativeTaskSubmitted",
      "scala.collection.GenTraversableOnce",
      "scala.collection.GenTraversableLike",
      "scala.Product5",
      "org.apache.spark.scheduler.SparkListenerExecutorBlacklisted",
      "org.apache.spark.scheduler.StageInfo",
      "scala.collection.generic.GenericTraversableTemplate",
      "scala.Product6",
      "org.apache.spark.scheduler.TaskInfo",
      "scala.Product3",
      "scala.Product4",
      "scala.collection.GenMapLike",
      "scala.Product2",
      "org.apache.spark.TaskEndReason",
      "scala.collection.GenMap",
      "scala.collection.GenTraversable",
      "scala.collection.GenSeq",
      "org.apache.spark.scheduler.SparkListenerBlockManagerRemoved",
      "scala.collection.Traversable",
      "org.apache.spark.scheduler.SparkListenerJobEnd",
      "org.apache.spark.storage.BlockManagerId",
      "scala.collection.Iterator",
      "org.apache.spark.scheduler.SparkListenerJobStart",
      "scala.collection.GenSeqLike",
      "scala.collection.Iterable",
      "org.apache.spark.scheduler.SparkListenerStageSubmitted",
      "org.apache.spark.scheduler.SparkListenerExecutorBlacklistedForStage",
      "scala.Option",
      "org.apache.spark.scheduler.SparkListenerEvent",
      "scala.collection.generic.Subtractable",
      "com.fasterxml.jackson.annotation.JsonTypeInfo$None",
      "scala.collection.SeqLike",
      "org.apache.spark.scheduler.SparkListenerTaskStart",
      "scala.Product",
      "org.apache.spark.scheduler.SparkListenerStageCompleted",
      "org.apache.spark.scheduler.SparkListenerUnpersistRDD"
    );
  } 
  private static void initMocksToAvoidTimeoutsInTheTests() throws ClassNotFoundException { 
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerApplicationEnd", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerApplicationStart", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerBlockManagerAdded", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerBlockManagerRemoved", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerBlockUpdated", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerEnvironmentUpdate", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerEvent", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerExecutorAdded", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerExecutorBlacklisted", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerExecutorBlacklistedForStage", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerExecutorRemoved", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerExecutorUnblacklisted", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerJobEnd", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerJobStart", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerNodeBlacklisted", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerNodeBlacklistedForStage", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerNodeUnblacklisted", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerSpeculativeTaskSubmitted", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerStageCompleted", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerStageSubmitted", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerTaskEnd", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerTaskGettingResult", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerTaskStart", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.SparkListenerUnpersistRDD", false, SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()));
  }

  private static void resetClasses() {
    org.evosuite.runtime.classhandling.ClassResetter.getInstance().setClassLoader(SparkFirehoseListener_ESTest_scaffolding.class.getClassLoader()); 

    org.evosuite.runtime.classhandling.ClassStateSupport.resetClasses(
      "org.apache.spark.SparkFirehoseListener",
      "com.fasterxml.jackson.annotation.JsonTypeInfo$As",
      "com.fasterxml.jackson.annotation.JsonTypeInfo$Id",
      "org.apache.spark.scheduler.SparkListenerNodeUnblacklisted",
      "org.apache.spark.scheduler.SparkListenerStageCompleted",
      "org.apache.spark.scheduler.SparkListenerExecutorBlacklisted",
      "org.apache.spark.scheduler.SparkListenerTaskGettingResult",
      "org.apache.spark.scheduler.SparkListenerExecutorUnblacklisted",
      "org.apache.spark.scheduler.SparkListenerSpeculativeTaskSubmitted",
      "org.apache.spark.scheduler.SparkListenerExecutorBlacklistedForStage",
      "org.apache.spark.scheduler.SparkListenerBlockManagerRemoved",
      "org.apache.spark.scheduler.SparkListenerBlockManagerAdded",
      "org.apache.spark.scheduler.SparkListenerExecutorAdded",
      "org.apache.spark.scheduler.SparkListenerStageSubmitted",
      "org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate",
      "org.apache.spark.scheduler.SparkListenerApplicationEnd",
      "org.apache.spark.scheduler.SparkListenerNodeBlacklistedForStage",
      "org.apache.spark.scheduler.SparkListenerTaskStart",
      "org.apache.spark.scheduler.SparkListenerEnvironmentUpdate",
      "org.apache.spark.scheduler.SparkListenerJobStart",
      "org.apache.spark.scheduler.SparkListenerJobEnd",
      "org.apache.spark.scheduler.SparkListenerExecutorRemoved",
      "org.apache.spark.scheduler.SparkListenerUnpersistRDD",
      "org.apache.spark.scheduler.SparkListenerTaskEnd",
      "org.apache.spark.scheduler.SparkListenerBlockUpdated",
      "org.apache.spark.scheduler.SparkListenerNodeBlacklisted",
      "org.apache.spark.scheduler.SparkListenerApplicationStart"
    );
  }
}
