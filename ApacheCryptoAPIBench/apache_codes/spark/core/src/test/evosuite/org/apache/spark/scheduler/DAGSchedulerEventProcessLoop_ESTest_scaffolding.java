/**
 * Scaffolding file used to store all the setups needed to run 
 * tests automatically generated by EvoSuite
 * Thu Apr 21 22:19:12 GMT 2022
 */

package org.apache.spark.scheduler;

import org.evosuite.runtime.annotation.EvoSuiteClassExclude;
import org.junit.BeforeClass;
import org.junit.Before;
import org.junit.After;
import org.junit.AfterClass;
import org.evosuite.runtime.sandbox.Sandbox;
import org.evosuite.runtime.sandbox.Sandbox.SandboxMode;

import static org.evosuite.shaded.org.mockito.Mockito.*;
@EvoSuiteClassExclude
public class DAGSchedulerEventProcessLoop_ESTest_scaffolding {

  @org.junit.Rule
  public org.evosuite.runtime.vnet.NonFunctionalRequirementRule nfr = new org.evosuite.runtime.vnet.NonFunctionalRequirementRule();

  private static final java.util.Properties defaultProperties = (java.util.Properties) java.lang.System.getProperties().clone(); 

  private org.evosuite.runtime.thread.ThreadStopper threadStopper =  new org.evosuite.runtime.thread.ThreadStopper (org.evosuite.runtime.thread.KillSwitchHandler.getInstance(), 3000);


  @BeforeClass
  public static void initEvoSuiteFramework() { 
    org.evosuite.runtime.RuntimeSettings.className = "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop"; 
    org.evosuite.runtime.GuiSupport.initialize(); 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfThreads = 100; 
    org.evosuite.runtime.RuntimeSettings.maxNumberOfIterationsPerLoop = 10000; 
    org.evosuite.runtime.RuntimeSettings.mockSystemIn = true; 
    org.evosuite.runtime.RuntimeSettings.sandboxMode = org.evosuite.runtime.sandbox.Sandbox.SandboxMode.RECOMMENDED; 
    org.evosuite.runtime.sandbox.Sandbox.initializeSecurityManagerForSUT(); 
    org.evosuite.runtime.classhandling.JDKClassResetter.init();
    setSystemProperties();
    initializeClasses();
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    try { initMocksToAvoidTimeoutsInTheTests(); } catch(ClassNotFoundException e) {} 
  } 

  @AfterClass
  public static void clearEvoSuiteFramework(){ 
    Sandbox.resetDefaultSecurityManager(); 
    java.lang.System.setProperties((java.util.Properties) defaultProperties.clone()); 
  } 

  @Before
  public void initTestCase(){ 
    threadStopper.storeCurrentThreads();
    threadStopper.startRecordingTime();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().initHandler(); 
    org.evosuite.runtime.sandbox.Sandbox.goingToExecuteSUTCode(); 
    setSystemProperties(); 
    org.evosuite.runtime.GuiSupport.setHeadless(); 
    org.evosuite.runtime.Runtime.getInstance().resetRuntime(); 
    org.evosuite.runtime.agent.InstrumentingAgent.activate(); 
  } 

  @After
  public void doneWithTestCase(){ 
    threadStopper.killAndJoinClientThreads();
    org.evosuite.runtime.jvm.ShutdownHookHandler.getInstance().safeExecuteAddedHooks(); 
    org.evosuite.runtime.classhandling.JDKClassResetter.reset(); 
    resetClasses(); 
    org.evosuite.runtime.sandbox.Sandbox.doneWithExecutingSUTCode(); 
    org.evosuite.runtime.agent.InstrumentingAgent.deactivate(); 
    org.evosuite.runtime.GuiSupport.restoreHeadlessMode(); 
  } 

  public static void setSystemProperties() {
 
    java.lang.System.setProperties((java.util.Properties) defaultProperties.clone()); 
    java.lang.System.setProperty("file.encoding", "UTF-8"); 
    java.lang.System.setProperty("java.awt.headless", "true"); 
    java.lang.System.setProperty("java.io.tmpdir", "/tmp"); 
    java.lang.System.setProperty("user.dir", "/home/pedro/projects/RVSec-replication-package/ApacheCryptoAPIBench/apache_codes/spark/core"); 
    java.lang.System.setProperty("user.home", "/home/pedro"); 
    java.lang.System.setProperty("user.language", "en"); 
    java.lang.System.setProperty("user.name", "pedro"); 
    java.lang.System.setProperty("user.timezone", ""); 
    java.lang.System.setProperty("log4j.configuration", "SUT.log4j.properties"); 
  }

  private static void initializeClasses() {
    org.evosuite.runtime.classhandling.ClassStateSupport.initializeClasses(DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader() ,
      "scala.collection.mutable.FlatHashTable$HashUtils",
      "scala.collection.Seq$",
      "scala.math.Equiv",
      "scala.collection.mutable.Iterable$class",
      "org.apache.hadoop.fs.FileSystem",
      "org.apache.log4j.helpers.PatternConverter",
      "scala.Product2$mcDJ$sp",
      "org.apache.spark.rpc.RpcEndpointRef",
      "com.codahale.metrics.MetricSet",
      "org.apache.log4j.AppenderSkeleton",
      "scala.Function1$class",
      "scala.Enumeration$Value",
      "scala.Function0$mcZ$sp$class",
      "org.apache.spark.scheduler.CompletionEvent",
      "scala.sys.SystemProperties$",
      "scala.reflect.Manifest$class",
      "org.apache.hadoop.conf.Configuration",
      "scala.math.BigInt$",
      "scala.collection.mutable.ArrayOps",
      "org.apache.spark.scheduler.ResubmitFailedStages$",
      "scala.collection.AbstractMap",
      "scala.util.matching.UnanchoredRegex",
      "scala.util.Either$",
      "org.apache.spark.scheduler.StageCancelled",
      "scala.Product2$class",
      "org.apache.spark.SparkContext",
      "org.apache.commons.lang3.JavaVersion",
      "scala.reflect.Manifest",
      "org.apache.spark.SparkContext$$anon$2",
      "scala.StringContext",
      "scala.collection.convert.Wrappers",
      "scala.Tuple2$mcII$sp",
      "org.apache.log4j.spi.Filter",
      "scala.reflect.ManifestFactory$$anon$2",
      "org.apache.spark.util.Clock",
      "scala.reflect.ManifestFactory$$anon$3",
      "scala.collection.immutable.HashMap$Merger",
      "org.apache.log4j.config.PropertySetter",
      "scala.reflect.ManifestFactory$$anon$4",
      "scala.collection.mutable.SetLike",
      "scala.collection.mutable.WrappedArray$ofChar",
      "scala.reflect.ManifestFactory$$anon$5",
      "scala.collection.mutable.Buffer",
      "scala.reflect.ManifestFactory$$anon$1",
      "scala.Enumeration",
      "scala.runtime.ScalaRunTime$",
      "scala.collection.SeqViewLike",
      "org.apache.spark.scheduler.DAGSchedulerSource",
      "scala.util.Success",
      "scala.collection.GenIterable$class",
      "scala.collection.LinearSeqLike$class",
      "scala.reflect.ManifestFactory$$anon$6",
      "scala.Tuple2$mcIJ$sp",
      "scala.reflect.ManifestFactory$$anon$7",
      "scala.reflect.ManifestFactory$$anon$8",
      "org.apache.spark.status.AppStatusStore",
      "scala.reflect.ManifestFactory$$anon$9",
      "org.apache.log4j.Hierarchy",
      "org.apache.spark.AccumulatorParam",
      "scala.collection.generic.GenericTraversableTemplate",
      "scala.collection.CustomParallelizable$class",
      "scala.Tuple2$mcZC$sp",
      "scala.math.Ordering",
      "org.json4s.JsonAST$JValue",
      "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop$$anonfun$onError$1",
      "scala.collection.MapLike$class",
      "scala.collection.generic.GenSetFactory",
      "scala.collection.GenSet$",
      "org.apache.spark.ui.ConsoleProgressBar",
      "org.apache.log4j.spi.OptionHandler",
      "scala.collection.generic.Subtractable$class",
      "scala.collection.GenSeqLike",
      "org.apache.spark.MapOutputStatistics",
      "scala.math.package$",
      "scala.collection.generic.Shrinkable$class",
      "org.apache.spark.scheduler.SparkListenerEvent",
      "scala.collection.mutable.Set",
      "org.apache.spark.rpc.RpcEndpoint",
      "org.apache.spark.util.LongAccumulator",
      "scala.collection.immutable.Vector",
      "scala.collection.convert.Decorators$AsScala",
      "scala.collection.mutable.Seq",
      "scala.collection.LinearSeq",
      "org.apache.spark.scheduler.EventLoggingListener",
      "org.apache.log4j.helpers.OptionConverter",
      "org.apache.log4j.helpers.FormattingInfo",
      "scala.collection.convert.WrapAsScala$class",
      "org.apache.spark.MapOutputTracker",
      "scala.collection.convert.Wrappers$MutableSeqWrapper$",
      "org.apache.spark.scheduler.GettingResultEvent",
      "scala.collection.immutable.Map$",
      "scala.collection.TraversableView",
      "scala.collection.GenSeq$",
      "scala.collection.immutable.HashMap$HashTrieMap",
      "org.apache.spark.util.Utils$$anonfun$getContextOrSparkClassLoader$1",
      "scala.collection.LinearSeqLike",
      "scala.Function0$mcV$sp",
      "scala.util.control.Breaks$TryBlock",
      "com.codahale.metrics.Counting",
      "scala.collection.generic.SetFactory",
      "scala.Enumeration$Val",
      "scala.Tuple2$mcCJ$sp",
      "scala.collection.convert.DecorateAsJava",
      "scala.math.Fractional$",
      "org.apache.spark.scheduler.JobSubmitted",
      "scala.collection.immutable.HashMap$HashMap1",
      "scala.collection.mutable.HashTable$HashUtils$class",
      "scala.util.Left",
      "org.apache.log4j.helpers.PatternParser",
      "org.apache.spark.scheduler.DAGScheduler",
      "scala.collection.convert.Wrappers$JMapWrapperLike$$anon$2",
      "scala.collection.immutable.HashMap$$anon$2",
      "scala.collection.GenSet$class",
      "org.apache.log4j.Category",
      "org.apache.spark.ShuffleDependency",
      "scala.collection.mutable.ArrayLike$class",
      "scala.collection.convert.Wrappers$JListWrapper$",
      "scala.Predef$$less$colon$less",
      "scala.collection.generic.GenericTraversableTemplate$class",
      "scala.collection.Set$",
      "scala.collection.Seq$class",
      "scala.collection.IndexedSeqLike$class",
      "scala.collection.TraversableOnce",
      "scala.Function0$mcV$sp$class",
      "scala.runtime.TraitSetter",
      "org.apache.spark.util.Utils$$anon$5",
      "org.apache.spark.util.Utils$$anon$6",
      "org.apache.log4j.ConsoleAppender",
      "scala.collection.convert.DecorateAsScala$class",
      "scala.runtime.AbstractFunction0",
      "org.apache.spark.util.Utils$$anon$1",
      "scala.runtime.AbstractFunction1",
      "scala.collection.immutable.HashMap$HashMapCollision1",
      "org.apache.spark.util.Utils$$anon$2",
      "scala.runtime.AbstractFunction2",
      "org.apache.spark.util.Utils$$anon$3",
      "scala.collection.mutable.Iterable",
      "org.apache.spark.rdd.RDD",
      "scala.math.Integral",
      "org.apache.spark.util.SparkUncaughtExceptionHandler$",
      "org.apache.spark.partial.PartialResult",
      "scala.StringContext$",
      "scala.concurrent.duration.Duration$Infinite",
      "scala.collection.mutable.IndexedSeqOptimized",
      "scala.collection.mutable.MapLike",
      "scala.Predef$ArrayCharSequence",
      "scala.collection.convert.Wrappers$JEnumerationWrapper$",
      "org.apache.spark.scheduler.JobGroupCancelled",
      "org.apache.log4j.helpers.PatternParser$NamedPatternConverter",
      "scala.Tuple2$mcZZ$sp",
      "scala.Option$",
      "org.apache.spark.scheduler.TaskLocation",
      "scala.collection.convert.Decorators",
      "scala.collection.convert.Wrappers$MutableSetWrapper$",
      "scala.collection.JavaConverters$",
      "scala.math.Numeric",
      "scala.sys.BooleanProp$BooleanPropImpl",
      "scala.collection.convert.Wrappers$SeqWrapper$",
      "org.apache.spark.SparkEnv",
      "scala.collection.GenIterable$",
      "scala.util.control.NoStackTrace",
      "com.codahale.metrics.Clock",
      "scala.util.PropertiesTrait$$anonfun$4",
      "scala.util.PropertiesTrait$$anonfun$3",
      "scala.util.PropertiesTrait$$anonfun$2",
      "scala.util.PropertiesTrait$$anonfun$1",
      "scala.PartialFunction$class",
      "scala.Product2$mcDI$sp",
      "scala.collection.mutable.ArrayBuilder$ofShort",
      "scala.collection.Parallel",
      "org.json4s.JsonAST$JObject",
      "org.apache.log4j.spi.AppenderAttachable",
      "org.apache.log4j.helpers.PatternParser$DatePatternConverter",
      "scala.Tuple2$mcZD$sp",
      "scala.collection.immutable.HashMap$$anonfun$1",
      "scala.collection.SeqLike$$anon$1",
      "scala.collection.generic.Subtractable",
      "org.apache.spark.scheduler.ExecutorLossReason",
      "scala.Tuple2$mcCI$sp",
      "scala.collection.TraversableOnce$BufferedCanBuildFrom",
      "scala.collection.convert.Decorators$AsJavaCollection",
      "org.apache.spark.scheduler.MapStageSubmitted",
      "scala.collection.mutable.ArrayBuilder$ofLong",
      "scala.collection.immutable.Stream$ConsWrapper",
      "org.apache.log4j.config.PropertySetterException",
      "scala.runtime.AbstractFunction0$mcV$sp",
      "scala.util.Try",
      "scala.sys.BooleanProp$$anonfun$keyExists$1",
      "scala.collection.Parallelizable",
      "scala.Tuple2$mcCC$sp",
      "scala.Serializable",
      "scala.collection.mutable.HashTable$",
      "scala.collection.immutable.IndexedSeq$",
      "org.apache.spark.SparkStatusTracker",
      "scala.collection.immutable.Stream$cons$",
      "com.codahale.metrics.Reservoir",
      "org.apache.spark.internal.Logging$class",
      "org.apache.spark.util.Utils$",
      "scala.concurrent.Awaitable",
      "scala.collection.immutable.Stream$Cons",
      "scala.Tuple2$mcDZ$sp",
      "scala.util.Random",
      "scala.collection.mutable.BufferLike",
      "scala.math.Numeric$",
      "org.apache.spark.MapOutputTrackerMaster",
      "scala.collection.generic.GenericSetTemplate$class",
      "scala.collection.Iterable$",
      "org.apache.spark.broadcast.Broadcast",
      "scala.collection.immutable.LinearSeq$",
      "scala.collection.mutable.LazyBuilder",
      "scala.collection.immutable.List",
      "scala.collection.TraversableLike$class",
      "scala.collection.generic.GenericCompanion",
      "scala.collection.mutable.SeqLike$class",
      "org.apache.spark.util.ThreadStackTrace",
      "org.apache.spark.scheduler.SparkListenerInterface",
      "scala.collection.generic.ImmutableMapFactory",
      "scala.collection.generic.GenTraversableFactory$$anon$1",
      "scala.concurrent.duration.Duration",
      "scala.collection.mutable.HashEntry$class",
      "scala.math.PartialOrdering",
      "scala.reflect.ClassTag$class",
      "scala.collection.MapLike",
      "scala.collection.GenTraversable$",
      "com.codahale.metrics.Sampling",
      "com.codahale.metrics.Timer",
      "scala.Product2$mcII$sp",
      "org.apache.log4j.WriterAppender",
      "scala.collection.mutable.Builder",
      "scala.collection.Traversable$class",
      "scala.collection.immutable.Stream$Empty$",
      "scala.math.ScalaNumericConversions",
      "scala.collection.immutable.StringOps",
      "scala.math.ScalaNumber",
      "org.apache.spark.scheduler.JobCancelled",
      "scala.reflect.ClassTag",
      "scala.collection.mutable.Iterable$",
      "scala.collection.immutable.Range$",
      "scala.collection.immutable.IndexedSeq$class",
      "scala.collection.mutable.WrappedArray$ofFloat",
      "scala.Product2$mcJJ$sp",
      "scala.reflect.ManifestFactory$PhantomManifest",
      "org.apache.log4j.helpers.Loader",
      "scala.collection.convert.Wrappers$MutableBufferWrapper$",
      "scala.math.BigInt",
      "scala.collection.mutable.Buffer$",
      "scala.Tuple2$mcDD$sp",
      "scala.collection.GenMapLike",
      "scala.collection.ViewMkString",
      "scala.collection.GenMap",
      "org.apache.spark.scheduler.Task",
      "org.apache.spark.network.sasl.SecretKeyHolder",
      "scala.collection.SeqView",
      "com.codahale.metrics.MetricRegistry",
      "org.apache.spark.FutureAction",
      "scala.collection.mutable.ArrayBuilder$ofRef",
      "org.apache.hadoop.mapreduce.InputFormat",
      "org.apache.hadoop.fs.HasEnhancedByteBufferAccess",
      "scala.collection.mutable.Builder$class",
      "scala.LowPriorityImplicits",
      "org.apache.spark.util.SparkUncaughtExceptionHandler",
      "scala.sys.BooleanProp",
      "scala.collection.mutable.WrappedArray$ofLong",
      "scala.collection.immutable.Stream",
      "scala.collection.immutable.Stream$",
      "scala.Product",
      "scala.collection.GenTraversable$class",
      "scala.runtime.AbstractFunction0$mcZ$sp",
      "scala.collection.convert.Wrappers$JIteratorWrapper$",
      "org.apache.spark.Accumulator",
      "scala.Specializable",
      "scala.collection.concurrent.Map",
      "scala.package$$anon$1",
      "scala.collection.immutable.Iterable",
      "scala.collection.generic.MapFactory",
      "org.apache.spark.internal.config.ConfigEntry",
      "scala.collection.mutable.HashTable$HashUtils",
      "scala.util.PropertiesTrait$class",
      "scala.collection.SetLike$class",
      "org.apache.spark.ui.SparkUI",
      "scala.collection.GenIterable",
      "org.apache.hadoop.mapred.InputFormat",
      "scala.collection.GenSeqLike$class",
      "scala.collection.mutable.WrappedArray$ofDouble",
      "org.apache.hadoop.fs.Path",
      "scala.collection.mutable.BufferLike$class",
      "scala.collection.mutable.Cloneable$class",
      "scala.collection.mutable.DefaultEntry",
      "org.apache.hadoop.conf.Configurable",
      "scala.util.Left$",
      "scala.math.BigDecimal",
      "org.apache.spark.scheduler.Stage",
      "scala.Some",
      "scala.MatchError",
      "scala.collection.mutable.ArrayBuilder$ofDouble",
      "com.google.common.base.Function",
      "scala.collection.generic.GenSeqFactory",
      "scala.collection.immutable.Traversable$",
      "scala.collection.mutable.ArrayBuilder$ofChar",
      "scala.runtime.Null$",
      "scala.Product2$mcJI$sp",
      "scala.StringContext$$anonfun$s$1",
      "scala.sys.Prop",
      "scala.Tuple2$mcDC$sp",
      "scala.reflect.ClassManifestDeprecatedApis$class",
      "org.apache.spark.ContextCleaner",
      "scala.math.LowPriorityOrderingImplicits",
      "scala.collection.SetLike",
      "scala.collection.immutable.Range$Inclusive",
      "org.apache.spark.scheduler.ShuffleMapStage",
      "scala.Tuple2$mcJJ$sp",
      "org.apache.spark.util.AccumulatorV2",
      "scala.reflect.NoManifest$",
      "org.apache.spark.internal.Logging$",
      "scala.collection.GenSetLike",
      "scala.collection.IndexedSeq",
      "org.apache.hadoop.fs.HasFileDescriptor",
      "scala.collection.mutable.Traversable$",
      "scala.math.ScalaNumericAnyConversions",
      "scala.collection.mutable.ArrayBuilder$ofInt",
      "org.apache.log4j.PropertyConfigurator",
      "scala.collection.immutable.AbstractMap",
      "scala.collection.mutable.WrappedArray$",
      "scala.collection.immutable.MapLike",
      "scala.Immutable",
      "scala.sys.package$",
      "scala.math.Ordered$",
      "scala.Predef$",
      "org.apache.spark.TaskEndReason",
      "org.apache.spark.scheduler.OutputCommitCoordinator",
      "scala.Tuple2$mcJI$sp",
      "scala.collection.immutable.Range",
      "scala.sys.ShutdownHookThread",
      "scala.collection.Traversable",
      "com.codahale.metrics.Timer$Context",
      "scala.collection.immutable.Map$class",
      "scala.util.control.NoStackTrace$class",
      "org.apache.spark.scheduler.AllJobsCancelled$",
      "scala.collection.mutable.HashSet",
      "org.apache.log4j.SortedKeyEnumeration",
      "scala.collection.IndexedSeqOptimized",
      "scala.collection.mutable.Seq$",
      "scala.collection.Traversable$",
      "scala.collection.convert.Decorators$",
      "scala.collection.immutable.LinearSeq$class",
      "scala.collection.TraversableLike$WithFilter",
      "org.apache.spark.util.EventLoop$$anon$1",
      "scala.collection.mutable.ResizableArray$",
      "scala.collection.mutable.Traversable$class",
      "scala.collection.generic.Growable",
      "scala.collection.immutable.StringOps$",
      "scala.collection.CustomParallelizable",
      "scala.math.BigDecimal$",
      "org.apache.log4j.spi.LoggerRepository",
      "org.apache.log4j.PatternLayout",
      "scala.collection.convert.Wrappers$MapWrapper",
      "scala.collection.Iterator$$anon$2",
      "scala.collection.Iterator$$anon$24",
      "scala.FallbackArrayBuilding",
      "scala.collection.convert.Wrappers$class",
      "org.apache.hadoop.io.Writable",
      "org.apache.spark.scheduler.AccumulableInfo",
      "scala.Tuple2$mcID$sp",
      "scala.collection.mutable.WrappedArray$ofInt",
      "scala.Function0$mcZ$sp",
      "scala.collection.GenSetLike$class",
      "scala.NotImplementedError",
      "scala.reflect.ManifestFactory$ClassTypeManifest",
      "scala.collection.generic.Shrinkable",
      "scala.collection.mutable.Seq$class",
      "scala.collection.LinearSeqOptimized",
      "org.apache.hadoop.fs.CanUnbuffer",
      "scala.collection.immutable.Stream$StreamBuilder",
      "org.apache.spark.scheduler.BeginEvent",
      "scala.collection.Iterator$class",
      "org.apache.log4j.Level",
      "org.apache.log4j.helpers.DateTimeDateFormat",
      "scala.collection.generic.IndexedSeqFactory",
      "org.apache.log4j.helpers.QuietWriter",
      "scala.collection.immutable.IndexedSeq",
      "org.apache.log4j.ConsoleAppender$SystemOutStream",
      "scala.reflect.ManifestFactory$$anon$11",
      "org.apache.spark.scheduler.JobWaiter",
      "scala.reflect.ManifestFactory$$anon$12",
      "scala.compat.Platform$",
      "scala.collection.immutable.Seq$",
      "scala.reflect.ManifestFactory$$anon$10",
      "scala.collection.immutable.StringLike",
      "scala.collection.Map",
      "com.codahale.metrics.Metric",
      "org.apache.log4j.helpers.ISO8601DateFormat",
      "scala.collection.mutable.HashTable",
      "scala.reflect.ManifestFactory$$anon$13",
      "scala.reflect.ManifestFactory$$anon$14",
      "scala.collection.IndexedSeqLike$Elements",
      "scala.collection.convert.DecorateAsScala$$anonfun$mapAsScalaMapConverter$1",
      "scala.collection.mutable.IndexedSeqLike",
      "org.apache.hadoop.fs.CanSetReadahead",
      "scala.Option$WithFilter",
      "org.apache.log4j.helpers.PatternParser$BasicPatternConverter",
      "org.apache.spark.SecurityManager",
      "scala.Product$class",
      "scala.math.LowPriorityOrderingImplicits$class",
      "org.apache.log4j.Layout",
      "scala.reflect.ManifestFactory$",
      "scala.collection.immutable.HashMap$EmptyHashMap$",
      "scala.collection.generic.FilterMonadic",
      "scala.runtime.NonLocalReturnControl",
      "scala.collection.mutable.Cloneable",
      "org.apache.spark.serializer.SerializerInstance",
      "scala.collection.generic.GenTraversableFactory",
      "scala.sys.SystemProperties$$anonfun$contains$1",
      "scala.collection.GenIterableLike",
      "scala.collection.LinearSeq$",
      "scala.Equals",
      "scala.collection.generic.GenericSetTemplate",
      "scala.collection.generic.MutableMapFactory",
      "scala.reflect.ClassManifestFactory$",
      "scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1",
      "scala.collection.mutable.StringBuilder",
      "scala.Mutable",
      "scala.Tuple2$mcIZ$sp",
      "scala.collection.immutable.Set$class",
      "org.apache.log4j.helpers.PatternParser$CategoryPatternConverter",
      "scala.collection.GenSet",
      "org.apache.hadoop.fs.CanSetDropBehind",
      "scala.collection.immutable.Vector$",
      "scala.collection.convert.Wrappers$JPropertiesWrapper$",
      "scala.collection.GenTraversable",
      "scala.collection.GenSeq",
      "org.apache.spark.WritableConverter",
      "scala.collection.convert.Wrappers$JCollectionWrapper$",
      "org.apache.log4j.helpers.NullEnumeration",
      "org.apache.spark.ExecutorAllocationManager",
      "org.apache.spark.util.Utils$Lock",
      "org.apache.log4j.spi.DefaultRepositorySelector",
      "scala.collection.immutable.Iterable$",
      "org.apache.commons.lang3.SystemUtils",
      "scala.collection.immutable.WrappedString",
      "org.apache.spark.internal.Logging",
      "scala.collection.mutable.ArrayBuilder$ofByte",
      "scala.Function2$class",
      "scala.collection.generic.Sizing",
      "scala.util.control.Breaks",
      "org.apache.spark.scheduler.SchedulerBackend",
      "org.apache.spark.scheduler.WorkerRemoved",
      "scala.collection.SeqLike",
      "scala.Predef$$anon$2",
      "scala.Predef$$anon$3",
      "scala.collection.immutable.Set$EmptySet$",
      "scala.collection.mutable.WrappedArray$ofUnit",
      "scala.Predef$$anon$1",
      "org.apache.spark.Accumulable",
      "scala.sys.PropImpl",
      "scala.Tuple2$mcCZ$sp",
      "org.apache.spark.scheduler.ExecutorAdded",
      "scala.collection.immutable.MapLike$class",
      "org.apache.log4j.or.ObjectRenderer",
      "scala.sys.SystemProperties$$anonfun$get$1",
      "com.codahale.metrics.Timer$1",
      "scala.Tuple2$mcZI$sp",
      "org.apache.hadoop.fs.Seekable",
      "org.apache.log4j.helpers.PatternParser$ClassNamePatternConverter",
      "scala.collection.Iterator$",
      "scala.collection.mutable.SeqLike",
      "scala.sys.BooleanProp$",
      "scala.util.hashing.package$",
      "scala.collection.convert.Wrappers$JMapWrapperLike$class",
      "org.apache.spark.scheduler.JobResult",
      "scala.collection.immutable.Iterable$class",
      "scala.collection.immutable.Seq$class",
      "scala.collection.generic.GenTraversableFactory$GenericCanBuildFrom",
      "scala.collection.immutable.Nil$",
      "scala.Predef$$eq$colon$eq",
      "scala.PartialFunction",
      "scala.Function0$class",
      "scala.collection.convert.DecorateAsScala",
      "scala.collection.mutable.WrappedArray$ofRef",
      "scala.Tuple4",
      "scala.Tuple2",
      "org.apache.spark.AccumulableParam",
      "scala.collection.convert.Wrappers$",
      "scala.collection.mutable.IndexedSeqLike$class",
      "scala.collection.immutable.Map$EmptyMap$",
      "scala.Tuple3",
      "com.codahale.metrics.Snapshot",
      "com.google.common.cache.CacheLoader",
      "scala.util.control.BreakControl",
      "scala.util.control.NoStackTrace$",
      "org.apache.spark.scheduler.TaskSet",
      "scala.collection.IterableView",
      "org.apache.spark.storage.StorageStatus",
      "org.apache.log4j.spi.LoggerFactory",
      "scala.collection.parallel.Combiner",
      "org.apache.log4j.spi.Configurator",
      "scala.collection.BufferedIterator",
      "scala.collection.immutable.Seq",
      "scala.collection.mutable.ResizableArray$class",
      "scala.Predef$SeqCharSequence",
      "scala.collection.immutable.Set",
      "scala.package$",
      "scala.collection.convert.Wrappers$JMapWrapper",
      "scala.collection.mutable.IndexedSeq$class",
      "scala.collection.convert.Wrappers$JIterableWrapper$",
      "scala.collection.mutable.IndexedSeqView",
      "scala.collection.IndexedSeq$",
      "scala.collection.IndexedSeqLike",
      "org.apache.spark.internal.config.OptionalConfigEntry",
      "scala.collection.immutable.Set$",
      "org.apache.spark.scheduler.LiveListenerBus",
      "scala.collection.GenTraversableLike",
      "scala.collection.mutable.WrappedArray$ofBoolean",
      "org.apache.spark.storage.BlockManagerMaster",
      "scala.Product2$mcDD$sp",
      "scala.sys.SystemProperties",
      "scala.util.PropertiesTrait$$anonfun$scalaProps$2",
      "scala.collection.immutable.Set$Set4",
      "scala.collection.mutable.WrappedArray$ofShort",
      "scala.collection.LinearSeq$class",
      "scala.Product3",
      "scala.Product4",
      "scala.Product2",
      "scala.collection.convert.WrapAsScala$",
      "scala.collection.$plus$colon$",
      "scala.collection.Set$class",
      "org.apache.spark.util.EventLoop",
      "scala.collection.immutable.Set$Set1",
      "scala.Product2$mcIJ$sp",
      "scala.collection.mutable.HashMap",
      "scala.collection.immutable.Set$Set3",
      "scala.collection.$colon$plus$",
      "scala.collection.immutable.Set$Set2",
      "scala.util.Right",
      "scala.Tuple2$mcCD$sp",
      "org.apache.spark.scheduler.ActiveJob",
      "scala.concurrent.Future",
      "scala.collection.generic.TraversableFactory",
      "scala.collection.mutable.IndexedSeq",
      "scala.runtime.BoxedUnit",
      "org.apache.spark.util.CollectionAccumulator",
      "scala.Option",
      "org.apache.spark.status.api.v1.UIRoot",
      "org.apache.log4j.helpers.PatternParser$MDCPatternConverter",
      "scala.util.PropertiesTrait$$anonfun$scalaProps$1",
      "org.apache.hadoop.mapred.JobConf",
      "scala.collection.immutable.Map$Map3",
      "scala.collection.immutable.Map$Map2",
      "scala.collection.immutable.Map$Map1",
      "scala.collection.convert.Wrappers$MutableMapWrapper",
      "org.apache.log4j.Priority",
      "scala.collection.IndexedSeq$class",
      "org.apache.spark.Dependency",
      "scala.collection.mutable.Traversable",
      "scala.collection.mutable.AbstractMap",
      "scala.collection.immutable.Map$Map4",
      "org.apache.spark.SimpleFutureAction",
      "org.apache.spark.scheduler.ExecutorLost",
      "org.apache.spark.SparkDriverExecutionException",
      "org.apache.log4j.LogManager",
      "com.google.common.cache.Cache",
      "org.apache.spark.scheduler.SpeculativeTaskSubmitted",
      "scala.collection.generic.BitOperations$Int$class",
      "com.google.common.cache.LoadingCache",
      "scala.collection.immutable.$colon$colon$",
      "scala.reflect.ScalaSignature",
      "scala.collection.mutable.Map$",
      "org.apache.log4j.DefaultCategoryFactory",
      "org.apache.log4j.or.RendererMap",
      "scala.collection.convert.Wrappers$DictionaryWrapper$",
      "scala.math.LowPriorityEquiv",
      "scala.util.matching.Regex",
      "org.apache.log4j.ConsoleAppender$SystemErrStream",
      "scala.collection.Map$class",
      "scala.collection.AbstractSet",
      "scala.reflect.package$",
      "org.apache.spark.scheduler.Schedulable",
      "scala.collection.AbstractSeq",
      "scala.Tuple2$mcDJ$sp",
      "org.apache.hadoop.fs.FSDataInputStream",
      "scala.Product2$mcID$sp",
      "scala.runtime.BoxesRunTime",
      "scala.collection.mutable.StringBuilder$",
      "scala.collection.convert.Wrappers$JDictionaryWrapper$",
      "org.apache.spark.storage.RDDInfo",
      "scala.util.Properties$",
      "scala.collection.Seq",
      "org.apache.spark.scheduler.ResultStage",
      "scala.collection.mutable.Buffer$class",
      "scala.collection.Set",
      "scala.collection.mutable.ArrayStack",
      "scala.collection.generic.GenMapFactory$MapCanBuildFrom",
      "scala.collection.immutable.VectorPointer",
      "scala.Tuple2$mcZJ$sp",
      "scala.collection.immutable.LinearSeq",
      "org.apache.hadoop.fs.ByteBufferReadable",
      "scala.util.control.ControlThrowable",
      "org.apache.log4j.helpers.PatternParser$LocationPatternConverter",
      "scala.collection.convert.Decorators$class",
      "scala.collection.mutable.ArrayBuilder$ofFloat",
      "org.apache.log4j.CategoryKey",
      "scala.collection.mutable.ArrayLike",
      "scala.collection.IndexedSeqOptimized$class",
      "scala.collection.immutable.VectorPointer$class",
      "scala.collection.generic.ImmutableSetFactory",
      "scala.collection.BufferedIterator$class",
      "org.apache.log4j.helpers.OnlyOnceErrorHandler",
      "scala.collection.immutable.Stream$$hash$colon$colon$",
      "scala.collection.immutable.Stream$StreamWithFilter",
      "scala.Function0",
      "scala.Function1",
      "scala.Function2",
      "scala.collection.immutable.HashMap$$anon$2$$anon$3",
      "scala.Function3",
      "scala.Function4",
      "scala.collection.convert.Decorators$AsJavaEnumeration",
      "scala.Function5",
      "scala.collection.convert.Wrappers$MutableMapWrapper$",
      "scala.collection.convert.Decorators$AsJavaDictionary",
      "org.apache.log4j.ProvisionNode",
      "scala.StringContext$InvalidEscapeException",
      "scala.collection.convert.Wrappers$JSetWrapper$",
      "org.apache.spark.scheduler.TaskInfo",
      "scala.collection.mutable.HashEntry",
      "org.apache.spark.partial.ApproximateEvaluator",
      "org.apache.spark.metrics.source.Source",
      "scala.util.Either",
      "scala.collection.Parallelizable$class",
      "scala.Tuple2$mcJC$sp",
      "org.apache.spark.util.DoubleAccumulator",
      "scala.collection.mutable.WrappedArray",
      "scala.collection.generic.GenericSeqCompanion",
      "org.apache.log4j.helpers.PatternParser$LiteralPatternConverter",
      "org.apache.spark.storage.BlockManagerId",
      "scala.collection.convert.Wrappers$JMapWrapperLike",
      "scala.math.Ordered$class",
      "scala.collection.SeqLike$class",
      "org.apache.log4j.spi.RootLogger",
      "org.apache.spark.TaskContext",
      "org.apache.spark.SparkConf",
      "org.apache.log4j.spi.ErrorHandler",
      "scala.collection.mutable.ResizableArray",
      "scala.None$",
      "scala.collection.convert.Wrappers$IterableWrapper$",
      "org.apache.log4j.spi.RendererSupport",
      "scala.collection.TraversableViewLike",
      "scala.collection.mutable.Map",
      "scala.util.Right$",
      "scala.math.LowPriorityEquiv$class",
      "scala.util.Failure",
      "scala.Tuple2$mcDI$sp",
      "org.apache.log4j.helpers.AppenderAttachableImpl",
      "scala.collection.IndexedSeq$$anon$1",
      "scala.collection.mutable.WrappedArray$ofByte",
      "scala.collection.immutable.List$$anon$1",
      "scala.collection.mutable.AbstractIterable",
      "org.apache.log4j.helpers.AbsoluteTimeDateFormat",
      "scala.collection.mutable.ArrayBuilder$ofUnit",
      "scala.Product2$mcJD$sp",
      "org.apache.spark.input.PortableDataStream",
      "scala.reflect.ClassManifestDeprecatedApis",
      "org.apache.log4j.Logger",
      "scala.collection.immutable.List$",
      "scala.collection.script.Scriptable",
      "org.apache.hadoop.conf.Configured",
      "scala.collection.mutable.AbstractBuffer",
      "scala.collection.mutable.MapBuilder",
      "scala.collection.immutable.StringLike$class",
      "scala.collection.generic.IsTraversableLike",
      "com.codahale.metrics.Metered",
      "scala.collection.generic.SeqFactory",
      "scala.Cloneable",
      "org.apache.log4j.helpers.LogLog",
      "org.apache.spark.scheduler.TaskSetFailed",
      "scala.collection.mutable.MapLike$class",
      "scala.Tuple2$mcJZ$sp",
      "scala.math.Integral$",
      "scala.reflect.OptManifest",
      "scala.collection.TraversableOnce$class",
      "org.apache.spark.scheduler.SparkListener",
      "scala.collection.mutable.FlatHashTable",
      "scala.DeprecatedPredef$class",
      "scala.collection.GenSeq$class",
      "org.apache.log4j.spi.RepositorySelector",
      "scala.math.Ordered",
      "scala.collection.mutable.HashTable$class",
      "scala.collection.mutable.ArrayBuilder$ofBoolean",
      "scala.UninitializedError",
      "org.apache.spark.ui.WebUI",
      "scala.collection.TraversableLike",
      "scala.collection.IterableLike",
      "scala.collection.immutable.Map",
      "scala.collection.convert.WrapAsScala",
      "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop",
      "scala.collection.generic.CanBuildFrom",
      "scala.Array$",
      "org.apache.log4j.or.DefaultRenderer",
      "org.apache.spark.annotation.DeveloperApi",
      "scala.collection.convert.Decorators$AsJava",
      "scala.reflect.AnyValManifest",
      "scala.collection.convert.Wrappers$JMapWrapper$",
      "scala.collection.IterableViewLike",
      "scala.collection.convert.Wrappers$JConcurrentMapWrapper$",
      "scala.collection.generic.BitOperations$Int",
      "org.apache.spark.util.CallSite",
      "org.json4s.Diff$Diffable",
      "org.apache.log4j.spi.ThrowableRendererSupport",
      "scala.collection.generic.HasNewBuilder",
      "scala.collection.GenTraversableOnce",
      "scala.collection.mutable.Map$class",
      "scala.collection.mutable.ArrayBuffer$",
      "scala.collection.AbstractTraversable",
      "scala.collection.mutable.ArrayBuilder",
      "scala.collection.immutable.HashMap$",
      "scala.collection.AbstractIterator",
      "org.apache.log4j.Appender",
      "scala.runtime.VolatileByteRef",
      "scala.collection.convert.Wrappers$IteratorWrapper$",
      "org.apache.spark.scheduler.TaskScheduler",
      "scala.collection.AbstractIterable",
      "org.apache.hadoop.fs.PositionedReadable",
      "org.apache.spark.scheduler.JobListener",
      "scala.collection.immutable.Traversable$class",
      "scala.DeprecatedPredef",
      "scala.util.PropertiesTrait",
      "org.apache.spark.SparkException",
      "org.apache.spark.scheduler.DAGSchedulerEvent",
      "scala.collection.convert.DecorateAsJava$class",
      "scala.collection.mutable.ArrayBuffer",
      "scala.collection.immutable.$colon$colon",
      "scala.collection.immutable.Traversable",
      "scala.collection.GenMapLike$class",
      "scala.collection.generic.Growable$class",
      "scala.runtime.Nothing$",
      "org.apache.spark.rdd.EmptyRDD",
      "scala.collection.Iterator",
      "org.apache.log4j.spi.LoggingEvent",
      "scala.collection.Iterable",
      "scala.collection.mutable.AbstractSet",
      "scala.Tuple2$mcIC$sp",
      "scala.collection.mutable.AbstractSeq",
      "scala.collection.mutable.IndexedSeq$",
      "scala.collection.generic.Clearable",
      "scala.collection.generic.GenMapFactory",
      "scala.math.Equiv$",
      "scala.util.PropertiesTrait$$anonfun$scalaPropOrElse$1",
      "scala.collection.IterableLike$class",
      "scala.collection.LinearSeqOptimized$class",
      "org.apache.commons.lang3.math.NumberUtils",
      "scala.collection.Iterable$class",
      "scala.runtime.ObjectRef",
      "scala.collection.immutable.HashMap",
      "scala.math.Ordering$",
      "scala.Tuple2$mcJD$sp"
    );
  } 
  private static void initMocksToAvoidTimeoutsInTheTests() throws ClassNotFoundException { 
    mock(Class.forName("com.codahale.metrics.Timer", false, DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("com.codahale.metrics.Timer$Context", false, DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("java.lang.Throwable", false, DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.SparkContext", false, DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.DAGScheduler", false, DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.DAGSchedulerEvent", false, DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader()));
    mock(Class.forName("org.apache.spark.scheduler.DAGSchedulerSource", false, DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader()));
  }

  private static void resetClasses() {
    org.evosuite.runtime.classhandling.ClassResetter.getInstance().setClassLoader(DAGSchedulerEventProcessLoop_ESTest_scaffolding.class.getClassLoader()); 

    org.evosuite.runtime.classhandling.ClassStateSupport.resetClasses(
      "org.apache.spark.util.EventLoop",
      "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop",
      "scala.runtime.AbstractFunction0",
      "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop$$anonfun$onError$1",
      "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop$$anonfun$onError$2",
      "scala.runtime.BoxedUnit",
      "scala.Product$class",
      "org.apache.spark.scheduler.AllJobsCancelled$",
      "org.apache.spark.scheduler.ResubmitFailedStages$",
      "org.apache.spark.scheduler.DAGScheduler",
      "org.apache.spark.internal.Logging$class",
      "org.apache.spark.util.EventLoop$$anon$1",
      "org.apache.spark.scheduler.DAGSchedulerSource",
      "scala.Function0$class",
      "org.apache.spark.util.SparkUncaughtExceptionHandler",
      "org.apache.spark.util.SparkUncaughtExceptionHandler$",
      "scala.sys.package$",
      "scala.collection.generic.GenMapFactory",
      "scala.collection.generic.MapFactory",
      "scala.collection.generic.ImmutableMapFactory",
      "scala.collection.immutable.Map$",
      "scala.collection.convert.DecorateAsJava$class",
      "scala.collection.convert.DecorateAsScala$class",
      "scala.collection.JavaConverters$",
      "scala.collection.convert.Decorators$AsScala",
      "scala.collection.convert.Decorators$class",
      "scala.collection.convert.Decorators$",
      "scala.collection.convert.DecorateAsScala$$anonfun$mapAsScalaMapConverter$1",
      "scala.collection.convert.WrapAsScala$class",
      "scala.collection.convert.WrapAsScala$",
      "scala.collection.AbstractTraversable",
      "scala.collection.AbstractIterable",
      "scala.collection.AbstractMap",
      "scala.collection.mutable.AbstractMap",
      "scala.collection.convert.Wrappers$JMapWrapper",
      "scala.collection.convert.Wrappers$class",
      "scala.collection.convert.Wrappers$",
      "scala.collection.TraversableOnce$class",
      "scala.collection.Parallelizable$class",
      "scala.collection.TraversableLike$class",
      "scala.collection.generic.GenericTraversableTemplate$class",
      "scala.collection.GenTraversable$class",
      "scala.collection.Traversable$class",
      "scala.collection.GenIterable$class",
      "scala.collection.IterableLike$class",
      "scala.collection.Iterable$class",
      "scala.collection.GenMapLike$class",
      "scala.Function1$class",
      "scala.PartialFunction$class",
      "scala.collection.generic.Subtractable$class",
      "scala.collection.MapLike$class",
      "scala.collection.Map$class",
      "scala.collection.mutable.Traversable$class",
      "scala.collection.mutable.Iterable$class",
      "scala.collection.generic.Growable$class",
      "scala.collection.mutable.Builder$class",
      "scala.collection.generic.Shrinkable$class",
      "scala.collection.mutable.Cloneable$class",
      "scala.collection.mutable.MapLike$class",
      "scala.collection.mutable.Map$class",
      "scala.collection.convert.Wrappers$JMapWrapperLike$class",
      "scala.collection.AbstractSeq",
      "scala.collection.mutable.AbstractSeq",
      "scala.collection.mutable.AbstractBuffer",
      "scala.collection.mutable.ArrayBuffer",
      "scala.collection.GenSeqLike$class",
      "scala.collection.GenSeq$class",
      "scala.collection.SeqLike$class",
      "scala.collection.Seq$class",
      "scala.collection.mutable.SeqLike$class",
      "scala.collection.mutable.Seq$class",
      "scala.collection.mutable.BufferLike$class",
      "scala.collection.mutable.Buffer$class",
      "scala.collection.IndexedSeqLike$class",
      "scala.collection.mutable.IndexedSeqLike$class",
      "scala.collection.IndexedSeqOptimized$class",
      "scala.collection.IndexedSeq$class",
      "scala.collection.mutable.IndexedSeq$class",
      "scala.collection.mutable.ResizableArray$class",
      "scala.math.package$",
      "scala.collection.CustomParallelizable$class",
      "scala.runtime.AbstractFunction1",
      "scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1",
      "scala.collection.AbstractIterator",
      "scala.collection.convert.Wrappers$JMapWrapperLike$$anon$2",
      "scala.collection.Iterator$class",
      "scala.Tuple2",
      "scala.Product2$class",
      "scala.collection.mutable.MapBuilder",
      "scala.collection.immutable.AbstractMap",
      "scala.collection.immutable.Traversable$class",
      "scala.collection.immutable.Iterable$class",
      "scala.collection.immutable.MapLike$class",
      "scala.collection.immutable.Map$class",
      "scala.collection.immutable.Map$EmptyMap$",
      "scala.collection.immutable.Map$Map1",
      "scala.collection.immutable.Map$Map2",
      "scala.collection.immutable.Map$Map3",
      "scala.collection.immutable.Map$Map4",
      "scala.collection.immutable.HashMap",
      "scala.LowPriorityImplicits",
      "scala.DeprecatedPredef$class",
      "scala.package$$anon$1",
      "scala.collection.generic.GenericCompanion",
      "scala.collection.generic.GenTraversableFactory",
      "scala.collection.generic.GenTraversableFactory$GenericCanBuildFrom",
      "scala.collection.generic.GenTraversableFactory$$anon$1",
      "scala.util.control.Breaks",
      "scala.util.control.BreakControl",
      "scala.util.control.NoStackTrace$class",
      "scala.sys.SystemProperties$",
      "scala.sys.BooleanProp$",
      "scala.sys.PropImpl",
      "scala.sys.BooleanProp$BooleanPropImpl",
      "scala.sys.BooleanProp$$anonfun$keyExists$1",
      "scala.collection.generic.MutableMapFactory",
      "scala.collection.mutable.Map$",
      "scala.collection.immutable.List",
      "scala.collection.immutable.Seq$class",
      "scala.collection.LinearSeqLike$class",
      "scala.collection.LinearSeq$class",
      "scala.collection.immutable.LinearSeq$class",
      "scala.collection.LinearSeqOptimized$class",
      "scala.collection.immutable.Nil$",
      "scala.collection.mutable.HashMap",
      "scala.collection.mutable.HashTable$HashUtils$class",
      "scala.collection.mutable.HashTable$class",
      "scala.collection.mutable.HashTable$",
      "scala.runtime.ScalaRunTime$",
      "scala.util.hashing.package$",
      "scala.collection.mutable.DefaultEntry",
      "scala.collection.mutable.HashEntry$class",
      "scala.Option",
      "scala.None$",
      "scala.sys.SystemProperties",
      "scala.runtime.AbstractFunction0$mcZ$sp",
      "scala.sys.SystemProperties$$anonfun$contains$1",
      "scala.Function0$mcZ$sp$class",
      "scala.Some",
      "scala.sys.SystemProperties$$anonfun$get$1",
      "scala.Option$",
      "scala.runtime.BoxesRunTime",
      "scala.util.control.NoStackTrace$",
      "scala.collection.Traversable$",
      "scala.collection.Iterable$",
      "scala.collection.generic.GenSeqFactory",
      "scala.collection.generic.SeqFactory",
      "scala.collection.Seq$",
      "scala.collection.generic.IndexedSeqFactory",
      "scala.collection.IndexedSeq$$anon$1",
      "scala.collection.IndexedSeq$",
      "scala.collection.Iterator$$anon$2",
      "scala.collection.Iterator$",
      "scala.collection.immutable.List$$anon$1",
      "scala.collection.immutable.List$",
      "scala.collection.immutable.$colon$colon$",
      "scala.collection.$plus$colon$",
      "scala.collection.$colon$plus$",
      "scala.collection.immutable.Stream$",
      "scala.collection.immutable.Stream$$hash$colon$colon$",
      "scala.collection.immutable.Vector",
      "scala.collection.immutable.IndexedSeq$class",
      "scala.collection.immutable.VectorPointer$class",
      "scala.collection.immutable.Vector$",
      "scala.collection.mutable.StringBuilder$",
      "scala.collection.immutable.Range$",
      "scala.math.BigDecimal$",
      "scala.math.BigInt$",
      "scala.math.LowPriorityEquiv$class",
      "scala.math.Equiv$",
      "scala.math.Fractional$",
      "scala.math.Integral$",
      "scala.math.Numeric$",
      "scala.math.Ordered$",
      "scala.math.LowPriorityOrderingImplicits$class",
      "scala.math.Ordering$",
      "scala.util.Either$",
      "scala.util.Left$",
      "scala.util.Right$",
      "scala.package$",
      "scala.collection.generic.GenSetFactory",
      "scala.collection.generic.SetFactory",
      "scala.collection.generic.ImmutableSetFactory",
      "scala.collection.immutable.Set$",
      "scala.reflect.AnyValManifest",
      "scala.reflect.ManifestFactory$$anon$6",
      "scala.reflect.ClassManifestDeprecatedApis$class",
      "scala.reflect.ClassTag$class",
      "scala.reflect.Manifest$class",
      "scala.reflect.ManifestFactory$$anon$7",
      "scala.reflect.ManifestFactory$$anon$8",
      "scala.reflect.ManifestFactory$$anon$9",
      "scala.reflect.ManifestFactory$$anon$10",
      "scala.reflect.ManifestFactory$$anon$11",
      "scala.reflect.ManifestFactory$$anon$12",
      "scala.reflect.ManifestFactory$$anon$13",
      "scala.reflect.ManifestFactory$$anon$14",
      "scala.reflect.ManifestFactory$ClassTypeManifest",
      "scala.reflect.ManifestFactory$PhantomManifest",
      "scala.reflect.ManifestFactory$$anon$1",
      "scala.reflect.ManifestFactory$$anon$2",
      "scala.reflect.ManifestFactory$$anon$3",
      "scala.reflect.ManifestFactory$$anon$4",
      "scala.reflect.ManifestFactory$$anon$5",
      "scala.reflect.ManifestFactory$",
      "scala.reflect.ClassManifestFactory$",
      "scala.reflect.package$",
      "scala.reflect.NoManifest$",
      "scala.Predef$$anon$3",
      "scala.Predef$$less$colon$less",
      "scala.Predef$$anon$1",
      "scala.Predef$$eq$colon$eq",
      "scala.Predef$$anon$2",
      "scala.Predef$",
      "scala.collection.mutable.WrappedArray",
      "scala.collection.mutable.WrappedArray$ofRef",
      "scala.collection.mutable.ArrayLike$class",
      "scala.collection.immutable.HashMap$HashMap1",
      "scala.collection.generic.BitOperations$Int$class",
      "scala.runtime.AbstractFunction2",
      "scala.collection.immutable.HashMap$$anonfun$1",
      "scala.Function2$class",
      "scala.collection.immutable.HashMap$Merger",
      "scala.collection.immutable.HashMap$$anon$2",
      "scala.collection.immutable.HashMap$$anon$2$$anon$3",
      "scala.collection.immutable.HashMap$",
      "scala.collection.immutable.HashMap$HashTrieMap",
      "scala.collection.generic.GenMapFactory$MapCanBuildFrom",
      "scala.collection.immutable.HashMap$EmptyHashMap$",
      "scala.FallbackArrayBuilding",
      "scala.Array$",
      "scala.util.PropertiesTrait$class",
      "scala.collection.mutable.StringBuilder",
      "scala.math.Ordered$class",
      "scala.collection.immutable.StringLike$class",
      "scala.runtime.AbstractFunction0$mcV$sp",
      "scala.util.PropertiesTrait$$anonfun$scalaProps$1",
      "scala.Function0$mcV$sp$class",
      "scala.util.PropertiesTrait$$anonfun$scalaProps$2",
      "scala.util.PropertiesTrait$$anonfun$1",
      "scala.Option$WithFilter",
      "scala.util.PropertiesTrait$$anonfun$2",
      "scala.util.PropertiesTrait$$anonfun$3",
      "scala.util.PropertiesTrait$$anonfun$4",
      "scala.util.PropertiesTrait$$anonfun$scalaPropOrElse$1",
      "scala.util.Properties$",
      "scala.compat.Platform$",
      "org.apache.commons.lang3.math.NumberUtils",
      "org.apache.commons.lang3.JavaVersion",
      "org.apache.commons.lang3.SystemUtils",
      "scala.collection.immutable.StringOps",
      "scala.util.matching.Regex",
      "scala.collection.immutable.StringOps$",
      "scala.collection.AbstractSet",
      "scala.collection.GenSetLike$class",
      "scala.collection.generic.GenericSetTemplate$class",
      "scala.collection.GenSet$class",
      "scala.collection.SetLike$class",
      "scala.collection.Set$class",
      "scala.collection.immutable.Set$class",
      "scala.collection.immutable.Set$EmptySet$",
      "org.apache.spark.util.Utils$",
      "org.apache.spark.util.Utils$$anonfun$getContextOrSparkClassLoader$1",
      "org.apache.spark.internal.Logging$",
      "org.apache.log4j.Hierarchy",
      "org.apache.log4j.Category",
      "org.apache.log4j.Logger",
      "org.apache.log4j.spi.RootLogger",
      "org.apache.log4j.Priority",
      "org.apache.log4j.Level",
      "org.apache.log4j.or.DefaultRenderer",
      "org.apache.log4j.or.RendererMap",
      "org.apache.log4j.DefaultCategoryFactory",
      "org.apache.log4j.spi.DefaultRepositorySelector",
      "org.apache.log4j.helpers.OptionConverter",
      "org.apache.log4j.helpers.Loader",
      "org.apache.log4j.helpers.LogLog",
      "org.apache.log4j.PropertyConfigurator",
      "org.apache.log4j.LogManager",
      "org.apache.log4j.helpers.NullEnumeration",
      "org.apache.log4j.AppenderSkeleton",
      "org.apache.log4j.WriterAppender",
      "org.apache.log4j.ConsoleAppender",
      "org.apache.log4j.helpers.OnlyOnceErrorHandler",
      "org.apache.log4j.Layout",
      "org.apache.log4j.PatternLayout",
      "org.apache.log4j.helpers.PatternParser",
      "org.apache.log4j.helpers.FormattingInfo",
      "org.apache.log4j.helpers.PatternConverter",
      "org.apache.log4j.helpers.PatternParser$BasicPatternConverter",
      "org.apache.log4j.helpers.PatternParser$LiteralPatternConverter",
      "org.apache.log4j.config.PropertySetter",
      "org.apache.log4j.helpers.PatternParser$DatePatternConverter",
      "org.apache.log4j.helpers.PatternParser$NamedPatternConverter",
      "org.apache.log4j.helpers.PatternParser$CategoryPatternConverter",
      "org.apache.log4j.helpers.QuietWriter",
      "org.apache.log4j.SortedKeyEnumeration",
      "org.apache.log4j.helpers.AppenderAttachableImpl",
      "org.apache.log4j.CategoryKey",
      "org.apache.log4j.ProvisionNode",
      "scala.StringContext",
      "scala.collection.mutable.WrappedArray$",
      "scala.StringContext$$anonfun$s$1",
      "scala.collection.IndexedSeqLike$Elements",
      "scala.collection.BufferedIterator$class",
      "scala.StringContext$",
      "com.codahale.metrics.Timer",
      "org.apache.spark.SparkContext",
      "scala.MatchError",
      "com.codahale.metrics.Timer$Context"
    );
  }
}
