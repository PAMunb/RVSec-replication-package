<?xml version="1.0" encoding="utf-8"?>
<BugCollection sequence='0' release='' analysisTimestamp='1650027306962' version='4.6.0' timestamp='1650027303654'><Project projectName='Spark Project Core'><Jar>/pedro/desenvolvimento/workspaces/workspaces-doutorado/workspace-rv/RVSec-replication-package/ApacheCryptoAPIBench/apache_codes/spark/core/target/scala-2.11/classes</Jar><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/twitter/chill_2.11/0.8.4/chill_2.11-0.8.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/esotericsoftware/kryo-shaded/3.0.3/kryo-shaded-3.0.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/twitter/chill-java/0.8.4/chill-java-0.8.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-client/2.6.5/hadoop-client-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-common/2.6.5/hadoop-common-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-auth/2.6.5/hadoop-auth-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/curator/curator-client/2.6.0/curator-client-2.6.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.6.5/hadoop-hdfs-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.6.5/hadoop-mapreduce-client-app-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.6.5/hadoop-mapreduce-client-common-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.6.5/hadoop-yarn-client-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.6.5/hadoop-yarn-server-common-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.6.5/hadoop-mapreduce-client-shuffle-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.6.5/hadoop-yarn-api-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.6.5/hadoop-mapreduce-client-core-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.6.5/hadoop-yarn-common-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.6.5/hadoop-mapreduce-client-jobclient-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/hadoop/hadoop-annotations/2.6.5/hadoop-annotations-2.6.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/spark/spark-launcher_2.11/2.4.0-SNAPSHOT/spark-launcher_2.11-2.4.0-SNAPSHOT.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/spark/spark-kvstore_2.11/2.4.0-SNAPSHOT/spark-kvstore_2.11-2.4.0-SNAPSHOT.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.6.7/jackson-core-2.6.7.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.6.7/jackson-annotations-2.6.7.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/spark/spark-network-common_2.11/2.4.0-SNAPSHOT/spark-network-common_2.11-2.4.0-SNAPSHOT.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/spark/spark-network-shuffle_2.11/2.4.0-SNAPSHOT/spark-network-shuffle_2.11-2.4.0-SNAPSHOT.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/spark/spark-unsafe_2.11/2.4.0-SNAPSHOT/spark-unsafe_2.11-2.4.0-SNAPSHOT.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/net/java/dev/jets3t/jets3t/0.9.4/jets3t-0.9.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/httpcomponents/httpcore/4.4.8/httpcore-4.4.8.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/httpcomponents/httpclient/4.5.4/httpclient-4.5.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-codec/commons-codec/1.10/commons-codec-1.10.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.58/bcprov-jdk15on-1.58.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.1/java-xmlbuilder-1.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/curator/curator-framework/2.6.0/curator-framework-2.6.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-plus/9.3.20.v20170531/jetty-plus-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-webapp/9.3.20.v20170531/jetty-webapp-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-xml/9.3.20.v20170531/jetty-xml-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-jndi/9.3.20.v20170531/jetty-jndi-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-security/9.3.20.v20170531/jetty-security-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-util/9.3.20.v20170531/jetty-util-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-server/9.3.20.v20170531/jetty-server-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-io/9.3.20.v20170531/jetty-io-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-http/9.3.20.v20170531/jetty-http-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-continuation/9.3.20.v20170531/jetty-continuation-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-servlet/9.3.20.v20170531/jetty-servlet-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-proxy/9.3.20.v20170531/jetty-proxy-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-client/9.3.20.v20170531/jetty-client-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/eclipse/jetty/jetty-servlets/9.3.20.v20170531/jetty-servlets-9.3.20.v20170531.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/slf4j/slf4j-log4j12/1.7.16/slf4j-log4j12-1.7.16.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/json4s/json4s-jackson_2.11/3.5.3/json4s-jackson_2.11-3.5.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/json4s/json4s-core_2.11/3.5.3/json4s-core_2.11-3.5.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/json4s/json4s-ast_2.11/3.5.3/json4s-ast_2.11-3.5.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/json4s/json4s-scalap_2.11/3.5.3/json4s-scalap_2.11-3.5.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/io/netty/netty-all/4.1.17.Final/netty-all-4.1.17.Final.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/io/netty/netty/3.9.9.Final/netty-3.9.9.Final.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.5/metrics-core-3.1.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.5/metrics-jvm-3.1.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.5/metrics-json-3.1.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.6.7.1/jackson-databind-2.6.7.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.11/2.6.7.1/jackson-module-scala_2.11-2.6.7.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/scala-lang/scala-reflect/2.11.8/scala-reflect-2.11.8.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/fasterxml/jackson/module/jackson-module-paranamer/2.7.9/jackson-module-paranamer-2.7.9.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/net/sf/py4j/py4j/0.10.6/py4j-0.10.6.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/spark/spark-tags_2.11/2.4.0-SNAPSHOT/spark-tags_2.11-2.4.0-SNAPSHOT.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/spark-project/hive/hive-exec/1.2.1.spark2/hive-exec-1.2.1.spark2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/twitter/parquet-hadoop-bundle/1.6.0/parquet-hadoop-bundle-1.6.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/log4j/apache-log4j-extras/1.2.17/apache-log4j-extras-1.2.17.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/jodd/jodd-core/3.5.2/jodd-core-3.5.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/datanucleus/datanucleus-core/3.2.10/datanucleus-core-3.2.10.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/calcite/calcite-avatica/1.2.0-incubating/calcite-avatica-1.2.0-incubating.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/spark-project/hive/hive-metastore/1.2.1.spark2/hive-metastore-1.2.1.spark2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.6/datanucleus-api-jdo-3.2.6.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.9/datanucleus-rdbms-3.2.9.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/thrift/libthrift/0.9.3/libthrift-0.9.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar</AuxClasspathEntry><AuxClasspathEntry>/home/pedro/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.5/scala-xml_2.11-1.0.5.jar</AuxClasspathEntry><Plugin id='com.h3xstream.findsecbugs' enabled='true'></Plugin><Plugin id='com.mebigfatguy.fbcontrib' enabled='true'></Plugin><SrcDir>/pedro/desenvolvimento/workspaces/workspaces-doutorado/workspace-rv/RVSec-replication-package/ApacheCryptoAPIBench/apache_codes/spark/core/src/main/java</SrcDir><SrcDir>/pedro/desenvolvimento/workspaces/workspaces-doutorado/workspace-rv/RVSec-replication-package/ApacheCryptoAPIBench/apache_codes/spark/core/src/main/scala</SrcDir><WrkDir>/pedro/desenvolvimento/workspaces/workspaces-doutorado/workspace-rv/RVSec-replication-package/ApacheCryptoAPIBench/apache_codes/spark/core/target</WrkDir></Project><BugInstance instanceOccurrenceNum='0' instanceHash='7e25dcb55a03355d16fc7e1d4f1e4ef2' cweid='502' rank='10' abbrev='SECOBDES' category='SECURITY' priority='1' type='OBJECT_DESERIALIZATION' instanceOccurrenceMax='0'><ShortMessage>Object deserialization is used in {1}</ShortMessage><LongMessage>Object deserialization is used in org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2.apply()</LongMessage><Class classname='org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2' primary='true'><SourceLine classname='org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2' start='819' end='819' sourcepath='org/apache/spark/MapOutputTracker.scala' sourcefile='MapOutputTracker.scala'><Message>At MapOutputTracker.scala:[line 819]</Message></SourceLine><Message>In class org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2</Message></Class><Method isStatic='false' classname='org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2' signature='()Ljava/lang/Object;' name='apply' primary='true'><SourceLine endBytecode='49' classname='org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2' start='819' end='819' sourcepath='org/apache/spark/MapOutputTracker.scala' sourcefile='MapOutputTracker.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2.apply()</Message></Method><SourceLine endBytecode='4' classname='org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2' start='819' end='819' sourcepath='org/apache/spark/MapOutputTracker.scala' sourcefile='MapOutputTracker.scala' startBytecode='4' primary='true'><Message>At MapOutputTracker.scala:[line 819]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6df149b89a9b3accae7637450b4192e7' cweid='502' rank='10' abbrev='SECOBDES' category='SECURITY' priority='1' type='OBJECT_DESERIALIZATION' instanceOccurrenceMax='1'><ShortMessage>Object deserialization is used in {1}</ShortMessage><LongMessage>Object deserialization is used in org.apache.spark.RangePartitioner$$anonfun$readObject$1.apply$mcV$sp()</LongMessage><Class classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' primary='true'><SourceLine classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' start='269' end='279' sourcepath='org/apache/spark/Partitioner.scala' sourcefile='Partitioner.scala'><Message>At Partitioner.scala:[lines 269-279]</Message></SourceLine><Message>In class org.apache.spark.RangePartitioner$$anonfun$readObject$1</Message></Class><Method isStatic='false' classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' signature='()V' name='apply$mcV$sp' primary='true'><SourceLine endBytecode='232' classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' start='270' end='269' sourcepath='org/apache/spark/Partitioner.scala' sourcefile='Partitioner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.RangePartitioner$$anonfun$readObject$1.apply$mcV$sp()</Message></Method><SourceLine endBytecode='55' classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' start='275' end='275' sourcepath='org/apache/spark/Partitioner.scala' sourcefile='Partitioner.scala' startBytecode='55' primary='true'><Message>At Partitioner.scala:[line 275]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='6df149b89a9b3accae7637450b4192e7' cweid='502' rank='10' abbrev='SECOBDES' category='SECURITY' priority='1' type='OBJECT_DESERIALIZATION' instanceOccurrenceMax='1'><ShortMessage>Object deserialization is used in {1}</ShortMessage><LongMessage>Object deserialization is used in org.apache.spark.RangePartitioner$$anonfun$readObject$1.apply$mcV$sp()</LongMessage><Class classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' primary='true'><SourceLine classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' start='269' end='279' sourcepath='org/apache/spark/Partitioner.scala' sourcefile='Partitioner.scala'><Message>At Partitioner.scala:[lines 269-279]</Message></SourceLine><Message>In class org.apache.spark.RangePartitioner$$anonfun$readObject$1</Message></Class><Method isStatic='false' classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' signature='()V' name='apply$mcV$sp' primary='true'><SourceLine endBytecode='232' classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' start='270' end='269' sourcepath='org/apache/spark/Partitioner.scala' sourcefile='Partitioner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.RangePartitioner$$anonfun$readObject$1.apply$mcV$sp()</Message></Method><SourceLine endBytecode='72' classname='org.apache.spark.RangePartitioner$$anonfun$readObject$1' start='276' end='276' sourcepath='org/apache/spark/Partitioner.scala' sourcefile='Partitioner.scala' startBytecode='72' primary='true'><Message>At Partitioner.scala:[line 276]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a5c877b3001f9d87f6a6666633109128' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SSLOptions$$anonfun$12' primary='true'><SourceLine classname='org.apache.spark.SSLOptions$$anonfun$12' start='192' end='192' sourcepath='org/apache/spark/SSLOptions.scala' sourcefile='SSLOptions.scala'><Message>At SSLOptions.scala:[line 192]</Message></SourceLine><Message>In class org.apache.spark.SSLOptions$$anonfun$12</Message></Class><Method isStatic='false' classname='org.apache.spark.SSLOptions$$anonfun$12' signature='(Ljava/lang/String;)Ljava/io/File;' name='apply' primary='true'><SourceLine endBytecode='60' classname='org.apache.spark.SSLOptions$$anonfun$12' start='192' end='192' sourcepath='org/apache/spark/SSLOptions.scala' sourcefile='SSLOptions.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SSLOptions$$anonfun$12.apply(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.SSLOptions$$anonfun$12' start='192' end='192' sourcepath='org/apache/spark/SSLOptions.scala' sourcefile='SSLOptions.scala' startBytecode='5' primary='true'><Message>At SSLOptions.scala:[line 192]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SSLOptions$$anonfun$12.apply(Ljava/lang/String;)Ljava/io/File; parameter 0'><Message>Unknown source org/apache/spark/SSLOptions$$anonfun$12.apply(Ljava/lang/String;)Ljava/io/File; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.SSLOptions$$anonfun$12' start='192' end='192' sourcepath='org/apache/spark/SSLOptions.scala' sourcefile='SSLOptions.scala' startBytecode='5'><Message>At SSLOptions.scala:[line 192]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ae5d691a88c5fa46dd59e1eaf47f35a2' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SSLOptions$$anonfun$6' primary='true'><SourceLine classname='org.apache.spark.SSLOptions$$anonfun$6' start='177' end='177' sourcepath='org/apache/spark/SSLOptions.scala' sourcefile='SSLOptions.scala'><Message>At SSLOptions.scala:[line 177]</Message></SourceLine><Message>In class org.apache.spark.SSLOptions$$anonfun$6</Message></Class><Method isStatic='false' classname='org.apache.spark.SSLOptions$$anonfun$6' signature='(Ljava/lang/String;)Ljava/io/File;' name='apply' primary='true'><SourceLine endBytecode='60' classname='org.apache.spark.SSLOptions$$anonfun$6' start='177' end='177' sourcepath='org/apache/spark/SSLOptions.scala' sourcefile='SSLOptions.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SSLOptions$$anonfun$6.apply(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.SSLOptions$$anonfun$6' start='177' end='177' sourcepath='org/apache/spark/SSLOptions.scala' sourcefile='SSLOptions.scala' startBytecode='5' primary='true'><Message>At SSLOptions.scala:[line 177]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SSLOptions$$anonfun$6.apply(Ljava/lang/String;)Ljava/io/File; parameter 0'><Message>Unknown source org/apache/spark/SSLOptions$$anonfun$6.apply(Ljava/lang/String;)Ljava/io/File; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.SSLOptions$$anonfun$6' start='177' end='177' sourcepath='org/apache/spark/SSLOptions.scala' sourcefile='SSLOptions.scala' startBytecode='5'><Message>At SSLOptions.scala:[line 177]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='50cc0a99ef0226a6529ce322654ea91a' cweid='295' rank='12' abbrev='SECWTM' category='SECURITY' priority='2' type='WEAK_TRUST_MANAGER' instanceOccurrenceMax='0'><ShortMessage>TrustManager that accept any certificates</ShortMessage><LongMessage>TrustManager that accept any certificates makes communication vulnerable to a MITM attack</LongMessage><Class classname='org.apache.spark.SecurityManager$$anon$1' primary='true'><SourceLine classname='org.apache.spark.SecurityManager$$anon$1' start='280' end='285' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala'><Message>At SecurityManager.scala:[lines 280-285]</Message></SourceLine><Message>In class org.apache.spark.SecurityManager$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.SecurityManager$$anon$1' signature='([Ljava/security/cert/X509Certificate;Ljava/lang/String;)V' name='checkClientTrusted' primary='true'><SourceLine endBytecode='62' classname='org.apache.spark.SecurityManager$$anon$1' start='283' end='283' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SecurityManager$$anon$1.checkClientTrusted(X509Certificate[], String)</Message></Method><SourceLine synthetic='true' endBytecode='62' classname='org.apache.spark.SecurityManager$$anon$1' start='283' end='283' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala' startBytecode='0'><Message>At SecurityManager.scala:[line 283]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6af9ee048b22b92b58ca1e4a13cebe52' cweid='295' rank='12' abbrev='SECWTM' category='SECURITY' priority='2' type='WEAK_TRUST_MANAGER' instanceOccurrenceMax='0'><ShortMessage>TrustManager that accept any certificates</ShortMessage><LongMessage>TrustManager that accept any certificates makes communication vulnerable to a MITM attack</LongMessage><Class classname='org.apache.spark.SecurityManager$$anon$1' primary='true'><SourceLine classname='org.apache.spark.SecurityManager$$anon$1' start='280' end='285' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala'><Message>At SecurityManager.scala:[lines 280-285]</Message></SourceLine><Message>In class org.apache.spark.SecurityManager$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.SecurityManager$$anon$1' signature='([Ljava/security/cert/X509Certificate;Ljava/lang/String;)V' name='checkServerTrusted' primary='true'><SourceLine endBytecode='62' classname='org.apache.spark.SecurityManager$$anon$1' start='285' end='285' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SecurityManager$$anon$1.checkServerTrusted(X509Certificate[], String)</Message></Method><SourceLine synthetic='true' endBytecode='62' classname='org.apache.spark.SecurityManager$$anon$1' start='285' end='285' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala' startBytecode='0'><Message>At SecurityManager.scala:[line 285]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fa86555641e7e5772b06d2e9d99bece9' cweid='295' rank='12' abbrev='SECWTM' category='SECURITY' priority='2' type='WEAK_TRUST_MANAGER' instanceOccurrenceMax='0'><ShortMessage>TrustManager that accept any certificates</ShortMessage><LongMessage>TrustManager that accept any certificates makes communication vulnerable to a MITM attack</LongMessage><Class classname='org.apache.spark.SecurityManager$$anon$1' primary='true'><SourceLine classname='org.apache.spark.SecurityManager$$anon$1' start='280' end='285' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala'><Message>At SecurityManager.scala:[lines 280-285]</Message></SourceLine><Message>In class org.apache.spark.SecurityManager$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.SecurityManager$$anon$1' signature='()[Ljava/security/cert/X509Certificate;' name='getAcceptedIssuers' primary='true'><SourceLine endBytecode='43' classname='org.apache.spark.SecurityManager$$anon$1' start='281' end='281' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SecurityManager$$anon$1.getAcceptedIssuers()</Message></Method><SourceLine synthetic='true' endBytecode='43' classname='org.apache.spark.SecurityManager$$anon$1' start='281' end='281' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala' startBytecode='0'><Message>At SecurityManager.scala:[line 281]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e360a5b78e78c3cf3d30f2d002b608' cweid='295' rank='12' abbrev='SECWHV' category='SECURITY' priority='2' type='WEAK_HOSTNAME_VERIFIER' instanceOccurrenceMax='0'><ShortMessage>HostnameVerifier that accept any signed certificates</ShortMessage><LongMessage>HostnameVerifier that accept any signed certificates makes communication vulnerable to a MITM attack</LongMessage><Class classname='org.apache.spark.SecurityManager$$anon$2' primary='true'><SourceLine classname='org.apache.spark.SecurityManager$$anon$2' start='295' end='296' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala'><Message>At SecurityManager.scala:[lines 295-296]</Message></SourceLine><Message>In class org.apache.spark.SecurityManager$$anon$2</Message></Class><Method isStatic='false' classname='org.apache.spark.SecurityManager$$anon$2' signature='(Ljava/lang/String;Ljavax/net/ssl/SSLSession;)Z' name='verify' primary='true'><SourceLine endBytecode='63' classname='org.apache.spark.SecurityManager$$anon$2' start='296' end='296' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SecurityManager$$anon$2.verify(String, SSLSession)</Message></Method><SourceLine synthetic='true' endBytecode='63' classname='org.apache.spark.SecurityManager$$anon$2' start='296' end='296' sourcepath='org/apache/spark/SecurityManager.scala' sourcefile='SecurityManager.scala' startBytecode='0'><Message>At SecurityManager.scala:[line 296]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dc58f5adb81aad04f6cd293d33b1ebf4' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkContext' primary='true'><SourceLine classname='org.apache.spark.SparkContext' start='72' end='2401' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala'><Message>At SparkContext.scala:[lines 72-2401]</Message></SourceLine><Message>In class org.apache.spark.SparkContext</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkContext' signature='(Ljava/lang/String;Z)V' name='addFile' primary='true'><SourceLine endBytecode='1025' classname='org.apache.spark.SparkContext' start='1518' end='1517' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkContext.addFile(String, boolean)</Message></Method><SourceLine endBytecode='59' classname='org.apache.spark.SparkContext' start='1520' end='1520' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='59' primary='true'><Message>At SparkContext.scala:[line 1520]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkContext.addFile(Ljava/lang/String;Z)V parameter 1'><Message>Unknown source org/apache/spark/SparkContext.addFile(Ljava/lang/String;Z)V parameter 1</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='3' classname='org.apache.spark.SparkContext' start='1498' end='1498' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='3'><Message>At SparkContext.scala:[line 1498]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.java.JavaSparkContext' start='673' end='673' sourcepath='org/apache/spark/api/java/JavaSparkContext.scala' sourcefile='JavaSparkContext.scala' startBytecode='5'><Message>At JavaSparkContext.scala:[line 673]</Message></SourceLine><SourceLine endBytecode='6' classname='org.apache.spark.api.java.JavaSparkContext' start='686' end='686' sourcepath='org/apache/spark/api/java/JavaSparkContext.scala' sourcefile='JavaSparkContext.scala' startBytecode='6'><Message>At JavaSparkContext.scala:[line 686]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2077a60cfb4e7c46facf2eca28efc53' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkContext' primary='true'><SourceLine classname='org.apache.spark.SparkContext' start='72' end='2401' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala'><Message>At SparkContext.scala:[lines 72-2401]</Message></SourceLine><Message>In class org.apache.spark.SparkContext</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkContext' signature='(Ljava/lang/String;Z)V' name='addFile' primary='true'><SourceLine endBytecode='1025' classname='org.apache.spark.SparkContext' start='1518' end='1517' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkContext.addFile(String, boolean)</Message></Method><SourceLine endBytecode='423' classname='org.apache.spark.SparkContext' start='1543' end='1543' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='423' primary='true'><Message>At SparkContext.scala:[line 1543]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/hadoop/fs/Path.toUri()Ljava/net/URI;'><Message>Unknown source org/apache/hadoop/fs/Path.toUri()Ljava/net/URI;</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><SourceLine endBytecode='420' classname='org.apache.spark.SparkContext' start='1543' end='1543' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='420'><Message>At SparkContext.scala:[line 1543]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='482f1bbccb3222c0e906a8e971430e24' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkContext' primary='true'><SourceLine classname='org.apache.spark.SparkContext' start='72' end='2401' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala'><Message>At SparkContext.scala:[lines 72-2401]</Message></SourceLine><Message>In class org.apache.spark.SparkContext</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkContext' signature='(Ljava/lang/String;Z)V' name='addFile' primary='true'><SourceLine endBytecode='1025' classname='org.apache.spark.SparkContext' start='1518' end='1517' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkContext.addFile(String, boolean)</Message></Method><SourceLine endBytecode='499' classname='org.apache.spark.SparkContext' start='1552' end='1552' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='499' primary='true'><Message>At SparkContext.scala:[line 1552]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkFiles$.getRootDirectory()Ljava/lang/String;'><Message>Unknown source org/apache/spark/SparkFiles$.getRootDirectory()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String><SourceLine endBytecode='496' classname='org.apache.spark.SparkContext' start='1552' end='1552' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='496'><Message>At SparkContext.scala:[line 1552]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d9a4f94331cacde4349f1cfa47d93381' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkContext' primary='true'><SourceLine classname='org.apache.spark.SparkContext' start='72' end='2401' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala'><Message>At SparkContext.scala:[lines 72-2401]</Message></SourceLine><Message>In class org.apache.spark.SparkContext</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkContext' signature='(Ljava/lang/String;)V' name='addJar' primary='true'><SourceLine endBytecode='423' classname='org.apache.spark.SparkContext' start='1821' end='1821' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkContext.addJar(String)</Message></Method><SourceLine endBytecode='35' classname='org.apache.spark.SparkContext' start='1826' end='1826' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='35' primary='true'><Message>At SparkContext.scala:[line 1826]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkContext.addJar(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/SparkContext.addJar(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.api.java.JavaSparkContext' start='695' end='695' sourcepath='org/apache/spark/api/java/JavaSparkContext.scala' sourcefile='JavaSparkContext.scala' startBytecode='5'><Message>At JavaSparkContext.scala:[line 695]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$5' start='140' end='140' sourcepath='org/apache/spark/api/r/RRDD.scala' sourcefile='RRDD.scala' startBytecode='5'><Message>At RRDD.scala:[line 140]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$5' start='141' end='141' sourcepath='org/apache/spark/api/r/RRDD.scala' sourcefile='RRDD.scala' startBytecode='5'><Message>At RRDD.scala:[line 141]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e7943e9f3bcdcad16c7422db53c414d9' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkContext' primary='true'><SourceLine classname='org.apache.spark.SparkContext' start='72' end='2401' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala'><Message>At SparkContext.scala:[lines 72-2401]</Message></SourceLine><Message>In class org.apache.spark.SparkContext</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkContext' signature='(Ljava/lang/String;)V' name='addJar' primary='true'><SourceLine endBytecode='423' classname='org.apache.spark.SparkContext' start='1821' end='1821' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkContext.addJar(String)</Message></Method><SourceLine endBytecode='81' classname='org.apache.spark.SparkContext' start='1835' end='1835' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='81' primary='true'><Message>At SparkContext.scala:[line 1835]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getRawPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getRawPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='org/apache/spark/SparkContext.addJar(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/SparkContext.addJar(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='50' classname='org.apache.spark.SparkContext' start='1828' end='1828' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='50'><Message>At SparkContext.scala:[line 1828]</Message></SourceLine><SourceLine endBytecode='78' classname='org.apache.spark.SparkContext' start='1835' end='1835' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='78'><Message>At SparkContext.scala:[line 1835]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.java.JavaSparkContext' start='695' end='695' sourcepath='org/apache/spark/api/java/JavaSparkContext.scala' sourcefile='JavaSparkContext.scala' startBytecode='5'><Message>At JavaSparkContext.scala:[line 695]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$5' start='140' end='140' sourcepath='org/apache/spark/api/r/RRDD.scala' sourcefile='RRDD.scala' startBytecode='5'><Message>At RRDD.scala:[line 140]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$5' start='141' end='141' sourcepath='org/apache/spark/api/r/RRDD.scala' sourcefile='RRDD.scala' startBytecode='5'><Message>At RRDD.scala:[line 141]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f37543a850f662397e0b7c714c868c9e' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkContext' primary='true'><SourceLine classname='org.apache.spark.SparkContext' start='72' end='2401' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala'><Message>At SparkContext.scala:[lines 72-2401]</Message></SourceLine><Message>In class org.apache.spark.SparkContext</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkContext' signature='(Ljava/lang/String;)V' name='addJar' primary='true'><SourceLine endBytecode='423' classname='org.apache.spark.SparkContext' start='1821' end='1821' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkContext.addJar(String)</Message></Method><SourceLine endBytecode='113' classname='org.apache.spark.SparkContext' start='1837' end='1837' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='113' primary='true'><Message>At SparkContext.scala:[line 1837]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='org/apache/spark/SparkContext.addJar(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/SparkContext.addJar(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='50' classname='org.apache.spark.SparkContext' start='1828' end='1828' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='50'><Message>At SparkContext.scala:[line 1828]</Message></SourceLine><SourceLine endBytecode='110' classname='org.apache.spark.SparkContext' start='1837' end='1837' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='110'><Message>At SparkContext.scala:[line 1837]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.java.JavaSparkContext' start='695' end='695' sourcepath='org/apache/spark/api/java/JavaSparkContext.scala' sourcefile='JavaSparkContext.scala' startBytecode='5'><Message>At JavaSparkContext.scala:[line 695]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$5' start='140' end='140' sourcepath='org/apache/spark/api/r/RRDD.scala' sourcefile='RRDD.scala' startBytecode='5'><Message>At RRDD.scala:[line 140]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$5' start='141' end='141' sourcepath='org/apache/spark/api/r/RRDD.scala' sourcefile='RRDD.scala' startBytecode='5'><Message>At RRDD.scala:[line 141]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8251a82f8e6c66e192e61e72c94ac8c2' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkContext$$anonfun$10' primary='true'><SourceLine classname='org.apache.spark.SparkContext$$anonfun$10' start='427' end='429' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala'><Message>At SparkContext.scala:[lines 427-429]</Message></SourceLine><Message>In class org.apache.spark.SparkContext$$anonfun$10</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkContext$$anonfun$10' signature='(Ljava/lang/String;)Lorg/apache/spark/SparkConf;' name='apply' primary='true'><SourceLine endBytecode='108' classname='org.apache.spark.SparkContext$$anonfun$10' start='428' end='429' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkContext$$anonfun$10.apply(String)</Message></Method><SourceLine endBytecode='20' classname='org.apache.spark.SparkContext$$anonfun$10' start='428' end='428' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='20' primary='true'><Message>At SparkContext.scala:[line 428]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkContext$$anonfun$10.apply(Ljava/lang/String;)Lorg/apache/spark/SparkConf; parameter 0'><Message>Unknown source org/apache/spark/SparkContext$$anonfun$10.apply(Ljava/lang/String;)Lorg/apache/spark/SparkConf; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.SparkContext$$anonfun$10' start='427' end='427' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='5'><Message>At SparkContext.scala:[line 427]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e5e10c9b81b444800f83746379b33e35' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkEnv' primary='true'><SourceLine classname='org.apache.spark.SparkEnv' start='57' end='133' sourcepath='org/apache/spark/SparkEnv.scala' sourcefile='SparkEnv.scala'><Message>At SparkEnv.scala:[lines 57-133]</Message></SourceLine><Message>In class org.apache.spark.SparkEnv</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkEnv' signature='()V' name='stop' primary='true'><SourceLine endBytecode='382' classname='org.apache.spark.SparkEnv' start='84' end='84' sourcepath='org/apache/spark/SparkEnv.scala' sourcefile='SparkEnv.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkEnv.stop()</Message></Method><SourceLine endBytecode='133' classname='org.apache.spark.SparkEnv' start='103' end='103' sourcepath='org/apache/spark/SparkEnv.scala' sourcefile='SparkEnv.scala' startBytecode='133' primary='true'><Message>At SparkEnv.scala:[line 103]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Some.x()Ljava/lang/Object;'><Message>Unknown source scala/Some.x()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='eec68213fb83e048e62c47dd77db3738' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.SparkFiles$' primary='true'><SourceLine classname='org.apache.spark.SparkFiles$' start='31' end='39' sourcepath='org/apache/spark/SparkFiles.scala' sourcefile='SparkFiles.scala'><Message>At SparkFiles.scala:[lines 31-39]</Message></SourceLine><Message>In class org.apache.spark.SparkFiles$</Message></Class><Method isStatic='false' classname='org.apache.spark.SparkFiles$' signature='(Ljava/lang/String;)Ljava/lang/String;' name='get' primary='true'><SourceLine endBytecode='67' classname='org.apache.spark.SparkFiles$' start='31' end='31' sourcepath='org/apache/spark/SparkFiles.scala' sourcefile='SparkFiles.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.SparkFiles$.get(String)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.SparkFiles$' start='31' end='31' sourcepath='org/apache/spark/SparkFiles.scala' sourcefile='SparkFiles.scala' startBytecode='9' primary='true'><Message>At SparkFiles.scala:[line 31]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkFiles$.get(Ljava/lang/String;)Ljava/lang/String; parameter 0'><Message>Unknown source org/apache/spark/SparkFiles$.get(Ljava/lang/String;)Ljava/lang/String; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='4' classname='org.apache.spark.SparkFiles' sourcepath='org/apache/spark/SparkFiles.scala' sourcefile='SparkFiles.scala' startBytecode='4'><Message>In SparkFiles.scala</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f44705c1da7c6376dd6a7da5574fd815' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.TestUtils$' primary='true'><SourceLine classname='org.apache.spark.TestUtils$' start='60' end='265' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 60-265]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$' signature='(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/TestUtils$JavaSourceFromString;Lscala/collection/Seq;)Ljava/io/File;' name='createCompiledClass' primary='true'><SourceLine endBytecode='428' classname='org.apache.spark.TestUtils$' start='133' end='154' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$.createCompiledClass(String, File, TestUtils$JavaSourceFromString, Seq)</Message></Method><SourceLine endBytecode='164' classname='org.apache.spark.TestUtils$' start='145' end='145' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='164' primary='true'><Message>At TestUtils.scala:[line 145]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/TestUtils$.createCompiledClass(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/TestUtils$JavaSourceFromString;Lscala/collection/Seq;)Ljava/io/File; parameter 3'><Message>Unknown source org/apache/spark/TestUtils$.createCompiledClass(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/TestUtils$JavaSourceFromString;Lscala/collection/Seq;)Ljava/io/File; parameter 3</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='7' classname='org.apache.spark.TestUtils' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='7'><Message>In TestUtils.scala</Message></SourceLine><SourceLine endBytecode='144' classname='org.apache.spark.TestUtils$' start='144' end='144' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='144'><Message>At TestUtils.scala:[line 144]</Message></SourceLine><SourceLine endBytecode='52' classname='org.apache.spark.TestUtils$' start='166' end='166' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='52'><Message>At TestUtils.scala:[line 166]</Message></SourceLine><SourceLine endBytecode='79' classname='org.apache.spark.TestUtils$' start='167' end='167' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='79'><Message>At TestUtils.scala:[line 167]</Message></SourceLine><SourceLine endBytecode='97' classname='org.apache.spark.TestUtils$' start='168' end='168' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='97'><Message>At TestUtils.scala:[line 168]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7619225e81856ee1556d4f2faff6c3bd' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.TestUtils$' primary='true'><SourceLine classname='org.apache.spark.TestUtils$' start='60' end='265' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 60-265]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$' signature='(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/TestUtils$JavaSourceFromString;Lscala/collection/Seq;)Ljava/io/File;' name='createCompiledClass' primary='true'><SourceLine endBytecode='428' classname='org.apache.spark.TestUtils$' start='133' end='154' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$.createCompiledClass(String, File, TestUtils$JavaSourceFromString, Seq)</Message></Method><SourceLine endBytecode='196' classname='org.apache.spark.TestUtils$' start='147' end='147' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='196' primary='true'><Message>At TestUtils.scala:[line 147]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/TestUtils$.createCompiledClass(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/TestUtils$JavaSourceFromString;Lscala/collection/Seq;)Ljava/io/File; parameter 3'><Message>Unknown source org/apache/spark/TestUtils$.createCompiledClass(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/TestUtils$JavaSourceFromString;Lscala/collection/Seq;)Ljava/io/File; parameter 3</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='7' classname='org.apache.spark.TestUtils' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='7'><Message>In TestUtils.scala</Message></SourceLine><SourceLine endBytecode='144' classname='org.apache.spark.TestUtils$' start='144' end='144' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='144'><Message>At TestUtils.scala:[line 144]</Message></SourceLine><SourceLine endBytecode='52' classname='org.apache.spark.TestUtils$' start='166' end='166' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='52'><Message>At TestUtils.scala:[line 166]</Message></SourceLine><SourceLine endBytecode='79' classname='org.apache.spark.TestUtils$' start='167' end='167' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='79'><Message>At TestUtils.scala:[line 167]</Message></SourceLine><SourceLine endBytecode='97' classname='org.apache.spark.TestUtils$' start='168' end='168' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='97'><Message>At TestUtils.scala:[line 168]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e7c72c069bf7ad379b8eee831729596d' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.TestUtils$' primary='true'><SourceLine classname='org.apache.spark.TestUtils$' start='60' end='265' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 60-265]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$' signature='(Lscala/collection/Seq;Ljava/lang/String;Lscala/collection/Seq;Lscala/collection/Seq;)Ljava/net/URL;' name='createJarWithClasses' primary='true'><SourceLine endBytecode='304' classname='org.apache.spark.TestUtils$' start='63' end='71' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$.createJarWithClasses(Seq, String, Seq, Seq)</Message></Method><SourceLine endBytecode='133' classname='org.apache.spark.TestUtils$' start='70' end='70' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='133' primary='true'><Message>At TestUtils.scala:[line 70]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9b49aea5fde65d6dfd811f42c97b1f2e' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.TestUtils$' primary='true'><SourceLine classname='org.apache.spark.TestUtils$' start='60' end='265' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 60-265]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$' signature='(Lscala/collection/immutable/Map;Ljava/io/File;)Ljava/net/URL;' name='createJarWithFiles' primary='true'><SourceLine endBytecode='189' classname='org.apache.spark.TestUtils$' start='79' end='88' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$.createJarWithFiles(Map, File)</Message></Method><SourceLine endBytecode='26' classname='org.apache.spark.TestUtils$' start='80' end='80' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='26' primary='true'><Message>At TestUtils.scala:[line 80]</Message></SourceLine><String role='Sink method' value='java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;'><Message>Sink method java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b3248a557ec7fff64a75029cca2b4421' rank='12' abbrev='SECSSL' category='SECURITY' priority='2' type='SSL_CONTEXT' instanceOccurrenceMax='0'><ShortMessage>Weak SSLContext</ShortMessage><LongMessage>SSLContext needs to be compatible with TLS 1.2</LongMessage><Class classname='org.apache.spark.TestUtils$' primary='true'><SourceLine classname='org.apache.spark.TestUtils$' start='60' end='265' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 60-265]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$' signature='(Ljava/net/URL;Ljava/lang/String;Lscala/collection/Seq;)I' name='httpResponseCode' primary='true'><SourceLine endBytecode='326' classname='org.apache.spark.TestUtils$' start='207' end='231' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$.httpResponseCode(URL, String, Seq)</Message></Method><SourceLine endBytecode='41' classname='org.apache.spark.TestUtils$' start='213' end='213' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='41' primary='true'><Message>At TestUtils.scala:[line 213]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='41b7b4f6e5c99309738617389760d0d8' cweid='918' rank='12' abbrev='SECSSSRFUC' category='SECURITY' priority='2' type='URLCONNECTION_SSRF_FD' instanceOccurrenceMax='0'><ShortMessage>URLConnection Server-Side Request Forgery (SSRF) and File Disclosure</ShortMessage><LongMessage>This web server request could be used by an attacker to expose internal services and filesystem.</LongMessage><Class classname='org.apache.spark.TestUtils$' primary='true'><SourceLine classname='org.apache.spark.TestUtils$' start='60' end='265' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 60-265]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$' signature='(Ljava/net/URL;Ljava/lang/String;Lscala/collection/Seq;)I' name='httpResponseCode' primary='true'><SourceLine endBytecode='326' classname='org.apache.spark.TestUtils$' start='207' end='231' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$.httpResponseCode(URL, String, Seq)</Message></Method><SourceLine endBytecode='1' classname='org.apache.spark.TestUtils$' start='207' end='207' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='1' primary='true'><Message>At TestUtils.scala:[line 207]</Message></SourceLine><String role='Sink method' value='java/net/URL.openConnection()Ljava/net/URLConnection;'><Message>Sink method java/net/URL.openConnection()Ljava/net/URLConnection;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/TestUtils$.httpResponseCode(Ljava/net/URL;Ljava/lang/String;Lscala/collection/Seq;)I parameter 2'><Message>Unknown source org/apache/spark/TestUtils$.httpResponseCode(Ljava/net/URL;Ljava/lang/String;Lscala/collection/Seq;)I parameter 2</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='6' classname='org.apache.spark.TestUtils' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='6'><Message>In TestUtils.scala</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='28e91d0ff70db1ec4b6fc103b71a87c2' cweid='295' rank='12' abbrev='SECWTM' category='SECURITY' priority='2' type='WEAK_TRUST_MANAGER' instanceOccurrenceMax='0'><ShortMessage>TrustManager that accept any certificates</ShortMessage><LongMessage>TrustManager that accept any certificates makes communication vulnerable to a MITM attack</LongMessage><Class classname='org.apache.spark.TestUtils$$anon$1' primary='true'><SourceLine classname='org.apache.spark.TestUtils$$anon$1' start='214' end='217' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 214-217]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$$anon$1' signature='([Ljava/security/cert/X509Certificate;Ljava/lang/String;)V' name='checkClientTrusted' primary='true'><SourceLine endBytecode='62' classname='org.apache.spark.TestUtils$$anon$1' start='216' end='216' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$$anon$1.checkClientTrusted(X509Certificate[], String)</Message></Method><SourceLine synthetic='true' endBytecode='62' classname='org.apache.spark.TestUtils$$anon$1' start='216' end='216' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'><Message>At TestUtils.scala:[line 216]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9c2661ab660b53017c4f377cb1d210f4' cweid='295' rank='12' abbrev='SECWTM' category='SECURITY' priority='2' type='WEAK_TRUST_MANAGER' instanceOccurrenceMax='0'><ShortMessage>TrustManager that accept any certificates</ShortMessage><LongMessage>TrustManager that accept any certificates makes communication vulnerable to a MITM attack</LongMessage><Class classname='org.apache.spark.TestUtils$$anon$1' primary='true'><SourceLine classname='org.apache.spark.TestUtils$$anon$1' start='214' end='217' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 214-217]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$$anon$1' signature='([Ljava/security/cert/X509Certificate;Ljava/lang/String;)V' name='checkServerTrusted' primary='true'><SourceLine endBytecode='62' classname='org.apache.spark.TestUtils$$anon$1' start='217' end='217' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$$anon$1.checkServerTrusted(X509Certificate[], String)</Message></Method><SourceLine synthetic='true' endBytecode='62' classname='org.apache.spark.TestUtils$$anon$1' start='217' end='217' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'><Message>At TestUtils.scala:[line 217]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77ac8a17f923ef55dfecb0e0f024872e' cweid='295' rank='12' abbrev='SECWTM' category='SECURITY' priority='2' type='WEAK_TRUST_MANAGER' instanceOccurrenceMax='0'><ShortMessage>TrustManager that accept any certificates</ShortMessage><LongMessage>TrustManager that accept any certificates makes communication vulnerable to a MITM attack</LongMessage><Class classname='org.apache.spark.TestUtils$$anon$1' primary='true'><SourceLine classname='org.apache.spark.TestUtils$$anon$1' start='214' end='217' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 214-217]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$$anon$1' signature='()[Ljava/security/cert/X509Certificate;' name='getAcceptedIssuers' primary='true'><SourceLine endBytecode='43' classname='org.apache.spark.TestUtils$$anon$1' start='215' end='215' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$$anon$1.getAcceptedIssuers()</Message></Method><SourceLine synthetic='true' endBytecode='43' classname='org.apache.spark.TestUtils$$anon$1' start='215' end='215' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'><Message>At TestUtils.scala:[line 215]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6af6bceac07af5028f83f99849aa062d' cweid='295' rank='12' abbrev='SECWHV' category='SECURITY' priority='2' type='WEAK_HOSTNAME_VERIFIER' instanceOccurrenceMax='0'><ShortMessage>HostnameVerifier that accept any signed certificates</ShortMessage><LongMessage>HostnameVerifier that accept any signed certificates makes communication vulnerable to a MITM attack</LongMessage><Class classname='org.apache.spark.TestUtils$$anon$2' primary='true'><SourceLine classname='org.apache.spark.TestUtils$$anon$2' start='219' end='220' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[lines 219-220]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$$anon$2</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$$anon$2' signature='(Ljava/lang/String;Ljavax/net/ssl/SSLSession;)Z' name='verify' primary='true'><SourceLine endBytecode='63' classname='org.apache.spark.TestUtils$$anon$2' start='220' end='220' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$$anon$2.verify(String, SSLSession)</Message></Method><SourceLine synthetic='true' endBytecode='63' classname='org.apache.spark.TestUtils$$anon$2' start='220' end='220' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'><Message>At TestUtils.scala:[line 220]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4ca1535db0651cff241a723cb40aced' cweid='78' rank='12' abbrev='SECSCI' category='SECURITY' priority='2' type='SCALA_COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection (Scala)</ShortMessage><LongMessage>The command execution could be vulnerable to injection</LongMessage><Class classname='org.apache.spark.TestUtils$$anonfun$1' primary='true'><SourceLine classname='org.apache.spark.TestUtils$$anonfun$1' start='196' end='196' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala'><Message>At TestUtils.scala:[line 196]</Message></SourceLine><Message>In class org.apache.spark.TestUtils$$anonfun$1</Message></Class><Method isStatic='false' classname='org.apache.spark.TestUtils$$anonfun$1' signature='()I' name='apply$mcI$sp' primary='true'><SourceLine endBytecode='76' classname='org.apache.spark.TestUtils$$anonfun$1' start='196' end='196' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.TestUtils$$anonfun$1.apply$mcI$sp()</Message></Method><SourceLine endBytecode='7' classname='org.apache.spark.TestUtils$$anonfun$1' start='196' end='196' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='7' primary='true'><Message>At TestUtils.scala:[line 196]</Message></SourceLine><String role='Sink method' value='scala/sys/process/Process$.apply(Ljava/lang/String;)Lscala/sys/process/ProcessBuilder;'><Message>Sink method scala/sys/process/Process$.apply(Ljava/lang/String;)Lscala/sys/process/ProcessBuilder;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/TestUtils$$anonfun$1.command$1'><Message>Unknown source org/apache/spark/TestUtils$$anonfun$1.command$1</Message></String><SourceLine endBytecode='4' classname='org.apache.spark.TestUtils$$anonfun$1' start='196' end='196' sourcepath='org/apache/spark/TestUtils.scala' sourcefile='TestUtils.scala' startBytecode='4'><Message>At TestUtils.scala:[line 196]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4fa05b52a6b0b2eea0b04e61ae247390' cweid='319' rank='12' abbrev='SECUS' category='SECURITY' priority='2' type='UNENCRYPTED_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Socket</ShortMessage><LongMessage>Unencrypted socket to org.apache.spark.api.python.PythonAccumulatorV2 (instead of SSLSocket)</LongMessage><Class classname='org.apache.spark.api.python.PythonAccumulatorV2' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonAccumulatorV2' start='572' end='619' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala'><Message>At PythonRDD.scala:[lines 572-619]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonAccumulatorV2</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonAccumulatorV2' signature='()Ljava/net/Socket;' name='openSocket' primary='true'><SourceLine endBytecode='100' classname='org.apache.spark.api.python.PythonAccumulatorV2' start='588' end='591' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonAccumulatorV2.openSocket()</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.api.python.PythonAccumulatorV2' start='589' end='589' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='30' primary='true'><Message>At PythonRDD.scala:[line 589]</Message></SourceLine><String value='remote host'><Message>Value remote host</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='508c07c998c75b15bd4121340b43c873' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.api.python.PythonBroadcast' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonBroadcast' start='630' end='672' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala'><Message>At PythonRDD.scala:[lines 630-672]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonBroadcast</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonBroadcast' signature='()V' name='finalize' primary='true'><SourceLine endBytecode='134' classname='org.apache.spark.api.python.PythonBroadcast' start='664' end='672' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonBroadcast.finalize()</Message></Method><SourceLine endBytecode='18' classname='org.apache.spark.api.python.PythonBroadcast' start='665' end='665' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='18' primary='true'><Message>At PythonRDD.scala:[line 665]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonBroadcast.path'><Message>Unknown source org/apache/spark/api/python/PythonBroadcast.path</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonBroadcast.path()Ljava/lang/String;'><Message>Unknown source org/apache/spark/api/python/PythonBroadcast.path()Ljava/lang/String;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.api.python.PythonBroadcast' start='630' end='630' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='1'><Message>At PythonRDD.scala:[line 630]</Message></SourceLine><SourceLine endBytecode='15' classname='org.apache.spark.api.python.PythonBroadcast' start='665' end='665' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='15'><Message>At PythonRDD.scala:[line 665]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='42cb254d13142d00be13309c377d291a' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' start='648' end='656' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala'><Message>At PythonRDD.scala:[lines 648-656]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' signature='()J' name='apply$mcJ$sp' primary='true'><SourceLine endBytecode='179' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' start='649' end='655' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1.apply$mcJ$sp()</Message></Method><SourceLine endBytecode='19' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' start='649' end='649' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='19' primary='true'><Message>At PythonRDD.scala:[line 649]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.getLocalDir(Lorg/apache/spark/SparkConf;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.getLocalDir(Lorg/apache/spark/SparkConf;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String><SourceLine endBytecode='16' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' start='649' end='649' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='16'><Message>At PythonRDD.scala:[line 649]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7fde9b87134d4ffe763650f26c980a29' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' start='648' end='656' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala'><Message>At PythonRDD.scala:[lines 648-656]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' signature='()J' name='apply$mcJ$sp' primary='true'><SourceLine endBytecode='179' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' start='649' end='655' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1.apply$mcJ$sp()</Message></Method><SourceLine endBytecode='28' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' start='650' end='650' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='28' primary='true'><Message>At PythonRDD.scala:[line 650]</Message></SourceLine><String role='Sink method' value='java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;'><Message>Sink method java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><SourceLine endBytecode='19' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1' start='649' end='649' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='19'><Message>At PythonRDD.scala:[line 649]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d5928f5adf657b52cfb29ef67e6e7fa' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1' start='636' end='641' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala'><Message>At PythonRDD.scala:[lines 636-641]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1' signature='()J' name='apply$mcJ$sp' primary='true'><SourceLine endBytecode='148' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1' start='637' end='641' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1.apply$mcJ$sp()</Message></Method><SourceLine endBytecode='15' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1' start='637' end='637' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='15' primary='true'><Message>At PythonRDD.scala:[line 637]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonBroadcast.path'><Message>Unknown source org/apache/spark/api/python/PythonBroadcast.path</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonBroadcast.path()Ljava/lang/String;'><Message>Unknown source org/apache/spark/api/python/PythonBroadcast.path()Ljava/lang/String;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.api.python.PythonBroadcast' start='630' end='630' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='1'><Message>At PythonRDD.scala:[line 630]</Message></SourceLine><SourceLine endBytecode='12' classname='org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1' start='637' end='637' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='12'><Message>At PythonRDD.scala:[line 637]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d9ce543122dd619e5ff442bb7773bcc6' cweid='319' rank='12' abbrev='SECUS' category='SECURITY' priority='2' type='UNENCRYPTED_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Socket</ShortMessage><LongMessage>Unencrypted socket to org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1 (instead of SSLSocket)</LongMessage><Class classname='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1' start='37' end='64' sourcepath='org/apache/spark/api/python/PythonGatewayServer.scala' sourcefile='PythonGatewayServer.scala'><Message>At PythonGatewayServer.scala:[lines 37-64]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1' signature='()V' name='apply$mcV$sp' primary='true'><SourceLine endBytecode='408' classname='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1' start='39' end='64' sourcepath='org/apache/spark/api/python/PythonGatewayServer.scala' sourcefile='PythonGatewayServer.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1.apply$mcV$sp()</Message></Method><SourceLine endBytecode='135' classname='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1' start='53' end='53' sourcepath='org/apache/spark/api/python/PythonGatewayServer.scala' sourcefile='PythonGatewayServer.scala' startBytecode='135' primary='true'><Message>At PythonGatewayServer.scala:[line 53]</Message></SourceLine><String value='remote host'><Message>Value remote host</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fdef8348d7df913be1501612c603ae74' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.api.python.PythonRDD$' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonRDD$' start='105' end='558' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala'><Message>At PythonRDD.scala:[lines 105-558]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonRDD$</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonRDD$' signature='(Lorg/apache/spark/api/java/JavaSparkContext;Ljava/lang/String;I)Lorg/apache/spark/api/java/JavaRDD;' name='readRDDFromFile' primary='true'><SourceLine endBytecode='362' classname='org.apache.spark.api.python.PythonRDD$' start='162' end='177' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonRDD$.readRDDFromFile(JavaSparkContext, String, int)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.api.python.PythonRDD$' start='162' end='162' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='9' primary='true'><Message>At PythonRDD.scala:[line 162]</Message></SourceLine><String role='Sink method' value='java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonRDD$.readRDDFromFile(Lorg/apache/spark/api/java/JavaSparkContext;Ljava/lang/String;I)Lorg/apache/spark/api/java/JavaRDD; parameter 1'><Message>Unknown source org/apache/spark/api/python/PythonRDD$.readRDDFromFile(Lorg/apache/spark/api/java/JavaSparkContext;Ljava/lang/String;I)Lorg/apache/spark/api/java/JavaRDD; parameter 1</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='6' classname='org.apache.spark.api.python.PythonRDD' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='6'><Message>In PythonRDD.scala</Message></SourceLine><SourceLine endBytecode='6' classname='org.apache.spark.api.r.RRDD' sourcepath='org/apache/spark/api/r/RRDD.scala' sourcefile='RRDD.scala' startBytecode='6'><Message>In RRDD.scala</Message></SourceLine><SourceLine endBytecode='6' classname='org.apache.spark.api.r.RRDD$' start='163' end='163' sourcepath='org/apache/spark/api/r/RRDD.scala' sourcefile='RRDD.scala' startBytecode='6'><Message>At RRDD.scala:[line 163]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='18423453578632353f24bf0eb9960c37' cweid='319' rank='12' abbrev='SECUSS' category='SECURITY' priority='2' type='UNENCRYPTED_SERVER_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Server Socket</ShortMessage><LongMessage>Unencrypted server socket (instead of SSLServerSocket)</LongMessage><Class classname='org.apache.spark.api.python.PythonRDD$' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonRDD$' start='105' end='558' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala'><Message>At PythonRDD.scala:[lines 105-558]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonRDD$</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonRDD$' signature='(Lscala/collection/Iterator;Ljava/lang/String;)I' name='serveIterator' primary='true'><SourceLine endBytecode='128' classname='org.apache.spark.api.python.PythonRDD$' start='389' end='413' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonRDD$.serveIterator(Iterator, String)</Message></Method><SourceLine endBytecode='12' classname='org.apache.spark.api.python.PythonRDD$' start='389' end='389' sourcepath='org/apache/spark/api/python/PythonRDD.scala' sourcefile='PythonRDD.scala' startBytecode='12' primary='true'><Message>At PythonRDD.scala:[line 389]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='26ae89d0318555611fd72880475d6006' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.api.python.PythonWorkerFactory' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonWorkerFactory' start='32' end='331' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala'><Message>At PythonWorkerFactory.scala:[lines 32-331]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonWorkerFactory</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonWorkerFactory' signature='()Ljava/net/Socket;' name='createSimpleWorker' primary='true'><SourceLine endBytecode='592' classname='org.apache.spark.api.python.PythonWorkerFactory' start='137' end='170' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker()</Message></Method><SourceLine endBytecode='89' classname='org.apache.spark.api.python.PythonWorkerFactory' start='142' end='142' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='89' primary='true'><Message>At PythonWorkerFactory.scala:[line 142]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/util/Arrays.asList([Ljava/lang/Object;)Ljava/util/List;'><Message>Unknown source java/util/Arrays.asList([Ljava/lang/Object;)Ljava/util/List;</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonWorkerFactory.org$apache$spark$api$python$PythonWorkerFactory$$pythonExec'><Message>Unknown source org/apache/spark/api/python/PythonWorkerFactory.org$apache$spark$api$python$PythonWorkerFactory$$pythonExec</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonWorkerFactory.workerModule'><Message>Unknown source org/apache/spark/api/python/PythonWorkerFactory.workerModule</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonWorkerFactory.workerModule()Ljava/lang/String;'><Message>Unknown source org/apache/spark/api/python/PythonWorkerFactory.workerModule()Ljava/lang/String;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.api.python.PythonWorkerFactory' start='62' end='62' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='1'><Message>At PythonWorkerFactory.scala:[line 62]</Message></SourceLine><SourceLine endBytecode='79' classname='org.apache.spark.api.python.PythonWorkerFactory' start='142' end='142' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='79'><Message>At PythonWorkerFactory.scala:[line 142]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='64589894380eb24edaa97fb756e8411a' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.api.python.PythonWorkerFactory' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonWorkerFactory' start='32' end='331' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala'><Message>At PythonWorkerFactory.scala:[lines 32-331]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonWorkerFactory</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonWorkerFactory' signature='()V' name='startDaemon' primary='true'><SourceLine endBytecode='652' classname='org.apache.spark.api.python.PythonWorkerFactory' start='179' end='221' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonWorkerFactory.startDaemon()</Message></Method><SourceLine endBytecode='40' classname='org.apache.spark.api.python.PythonWorkerFactory' start='185' end='185' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='40' primary='true'><Message>At PythonWorkerFactory.scala:[line 185]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonWorkerFactory.daemonModule'><Message>Unknown source org/apache/spark/api/python/PythonWorkerFactory.daemonModule</Message></String><String role='Unknown source' value='java/util/Arrays.asList([Ljava/lang/Object;)Ljava/util/List;'><Message>Unknown source java/util/Arrays.asList([Ljava/lang/Object;)Ljava/util/List;</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonWorkerFactory.org$apache$spark$api$python$PythonWorkerFactory$$pythonExec'><Message>Unknown source org/apache/spark/api/python/PythonWorkerFactory.org$apache$spark$api$python$PythonWorkerFactory$$pythonExec</Message></String><String role='Unknown source' value='org/apache/spark/api/python/PythonWorkerFactory.daemonModule()Ljava/lang/String;'><Message>Unknown source org/apache/spark/api/python/PythonWorkerFactory.daemonModule()Ljava/lang/String;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.api.python.PythonWorkerFactory' start='53' end='53' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='1'><Message>At PythonWorkerFactory.scala:[line 53]</Message></SourceLine><SourceLine endBytecode='18' classname='org.apache.spark.api.python.PythonWorkerFactory' start='185' end='185' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='18'><Message>At PythonWorkerFactory.scala:[line 185]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b94dba89661aaf80e793e5137b9c1404' cweid='319' rank='12' abbrev='SECUSS' category='SECURITY' priority='2' type='UNENCRYPTED_SERVER_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Server Socket</ShortMessage><LongMessage>Unencrypted server socket (instead of SSLServerSocket)</LongMessage><Class classname='org.apache.spark.api.python.PythonWorkerFactory' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonWorkerFactory' start='32' end='331' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala'><Message>At PythonWorkerFactory.scala:[lines 32-331]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonWorkerFactory</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonWorkerFactory' signature='()Ljava/net/Socket;' name='createSimpleWorker' primary='true'><SourceLine endBytecode='592' classname='org.apache.spark.api.python.PythonWorkerFactory' start='137' end='170' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker()</Message></Method><SourceLine endBytecode='52' classname='org.apache.spark.api.python.PythonWorkerFactory' start='139' end='139' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='52' primary='true'><Message>At PythonWorkerFactory.scala:[line 139]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='854e882a7912d4cfe7e93747fc790811' cweid='319' rank='12' abbrev='SECUS' category='SECURITY' priority='2' type='UNENCRYPTED_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Socket</ShortMessage><LongMessage>Unencrypted socket to org.apache.spark.api.python.PythonWorkerFactory (instead of SSLSocket)</LongMessage><Class classname='org.apache.spark.api.python.PythonWorkerFactory' primary='true'><SourceLine classname='org.apache.spark.api.python.PythonWorkerFactory' start='32' end='331' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala'><Message>At PythonWorkerFactory.scala:[lines 32-331]</Message></SourceLine><Message>In class org.apache.spark.api.python.PythonWorkerFactory</Message></Class><Method isStatic='false' classname='org.apache.spark.api.python.PythonWorkerFactory' signature='()Ljava/net/Socket;' name='createSocket$1' primary='true'><SourceLine endBytecode='178' classname='org.apache.spark.api.python.PythonWorkerFactory' start='106' end='112' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.python.PythonWorkerFactory.createSocket$1()</Message></Method><SourceLine endBytecode='12' classname='org.apache.spark.api.python.PythonWorkerFactory' start='106' end='106' sourcepath='org/apache/spark/api/python/PythonWorkerFactory.scala' sourcefile='PythonWorkerFactory.scala' startBytecode='12' primary='true'><Message>At PythonWorkerFactory.scala:[line 106]</Message></SourceLine><String value='remote host'><Message>Value remote host</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6eb38c1dd426bc66c6e4dd78a159a954' cweid='22' rank='10' abbrev='SECPTI' category='SECURITY' priority='1' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.api.r.RBackend$' primary='true'><SourceLine classname='org.apache.spark.api.r.RBackend$' start='105' end='166' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala'><Message>At RBackend.scala:[lines 105-166]</Message></SourceLine><Message>In class org.apache.spark.api.r.RBackend$</Message></Class><Method isStatic='false' classname='org.apache.spark.api.r.RBackend$' signature='([Ljava/lang/String;)V' name='main' primary='true'><SourceLine endBytecode='535' classname='org.apache.spark.api.r.RBackend$' start='109' end='166' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.r.RBackend$.main(String[])</Message></Method><SourceLine endBytecode='108' classname='org.apache.spark.api.r.RBackend$' start='130' end='130' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='108' primary='true'><Message>At RBackend.scala:[line 130]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/api/r/RBackend$.main([Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/api/r/RBackend$.main([Ljava/lang/String;)V parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='with tainted arguments detected'><Message>Method usage with tainted arguments detected</Message></String><SourceLine endBytecode='4' classname='org.apache.spark.api.r.RBackend' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='4'><Message>In RBackend.scala</Message></SourceLine><SourceLine endBytecode='105' classname='org.apache.spark.api.r.RBackend$' start='130' end='130' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='105'><Message>At RBackend.scala:[line 130]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bc60a653766c27b26f8741f18a035f7f' cweid='22' rank='10' abbrev='SECPTI' category='SECURITY' priority='1' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.api.r.RBackend$' primary='true'><SourceLine classname='org.apache.spark.api.r.RBackend$' start='105' end='166' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala'><Message>At RBackend.scala:[lines 105-166]</Message></SourceLine><Message>In class org.apache.spark.api.r.RBackend$</Message></Class><Method isStatic='false' classname='org.apache.spark.api.r.RBackend$' signature='([Ljava/lang/String;)V' name='main' primary='true'><SourceLine endBytecode='535' classname='org.apache.spark.api.r.RBackend$' start='109' end='166' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.r.RBackend$.main(String[])</Message></Method><SourceLine endBytecode='192' classname='org.apache.spark.api.r.RBackend$' start='137' end='137' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='192' primary='true'><Message>At RBackend.scala:[line 137]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/api/r/RBackend$.main([Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/api/r/RBackend$.main([Ljava/lang/String;)V parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='with tainted arguments detected'><Message>Method usage with tainted arguments detected</Message></String><SourceLine endBytecode='4' classname='org.apache.spark.api.r.RBackend' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='4'><Message>In RBackend.scala</Message></SourceLine><SourceLine endBytecode='102' classname='org.apache.spark.api.r.RBackend$' start='130' end='130' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='102'><Message>At RBackend.scala:[line 130]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f09c7e25b6cd2379e5eb6282575be64d' cweid='319' rank='12' abbrev='SECUSS' category='SECURITY' priority='2' type='UNENCRYPTED_SERVER_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Server Socket</ShortMessage><LongMessage>Unencrypted server socket (instead of SSLServerSocket)</LongMessage><Class classname='org.apache.spark.api.r.RBackend$' primary='true'><SourceLine classname='org.apache.spark.api.r.RBackend$' start='105' end='166' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala'><Message>At RBackend.scala:[lines 105-166]</Message></SourceLine><Message>In class org.apache.spark.api.r.RBackend$</Message></Class><Method isStatic='false' classname='org.apache.spark.api.r.RBackend$' signature='([Ljava/lang/String;)V' name='main' primary='true'><SourceLine endBytecode='535' classname='org.apache.spark.api.r.RBackend$' start='109' end='166' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.r.RBackend$.main(String[])</Message></Method><SourceLine endBytecode='43' classname='org.apache.spark.api.r.RBackend$' start='120' end='120' sourcepath='org/apache/spark/api/r/RBackend.scala' sourcefile='RBackend.scala' startBytecode='43' primary='true'><Message>At RBackend.scala:[line 120]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d86527f7381670d8b2372e6e8b76780' cweid='209' rank='15' abbrev='ERRMSG' category='SECURITY' priority='3' type='INFORMATION_EXPOSURE_THROUGH_AN_ERROR_MESSAGE' instanceOccurrenceMax='0'><ShortMessage>Information Exposure Through An Error Message</ShortMessage><LongMessage>Possible information exposure through an error message</LongMessage><Class classname='org.apache.spark.api.r.RBackendHandler' primary='true'><SourceLine classname='org.apache.spark.api.r.RBackendHandler' start='40' end='280' sourcepath='org/apache/spark/api/r/RBackendHandler.scala' sourcefile='RBackendHandler.scala'><Message>At RBackendHandler.scala:[lines 40-280]</Message></SourceLine><Message>In class org.apache.spark.api.r.RBackendHandler</Message></Class><Method isStatic='false' classname='org.apache.spark.api.r.RBackendHandler' signature='(Lio/netty/channel/ChannelHandlerContext;Ljava/lang/Throwable;)V' name='exceptionCaught' primary='true'><SourceLine endBytecode='151' classname='org.apache.spark.api.r.RBackendHandler' start='122' end='122' sourcepath='org/apache/spark/api/r/RBackendHandler.scala' sourcefile='RBackendHandler.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.r.RBackendHandler.exceptionCaught(ChannelHandlerContext, Throwable)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.api.r.RBackendHandler' start='128' end='128' sourcepath='org/apache/spark/api/r/RBackendHandler.scala' sourcefile='RBackendHandler.scala' startBytecode='30' primary='true'><Message>At RBackendHandler.scala:[line 128]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cba54ccd3daca8acbc8304bb2dc131' cweid='502' rank='15' abbrev='SECDESGAD' category='SECURITY' priority='3' type='DESERIALIZATION_GADGET' instanceOccurrenceMax='0'><ShortMessage>This class could be used as deserialization gadget</ShortMessage><LongMessage>This class could make application using serialization vulnerable</LongMessage><Class classname='org.apache.spark.api.r.RBackendHandler$$anonfun$1' primary='true'><SourceLine classname='org.apache.spark.api.r.RBackendHandler$$anonfun$1' start='152' end='152' sourcepath='org/apache/spark/api/r/RBackendHandler.scala' sourcefile='RBackendHandler.scala'><Message>At RBackendHandler.scala:[line 152]</Message></SourceLine><Message>In class org.apache.spark.api.r.RBackendHandler$$anonfun$1</Message></Class><SourceLine synthetic='true' classname='org.apache.spark.api.r.RBackendHandler$$anonfun$1' start='152' end='152' sourcepath='org/apache/spark/api/r/RBackendHandler.scala' sourcefile='RBackendHandler.scala'><Message>At RBackendHandler.scala:[line 152]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a2b5061f0f5aae01a80130ddfea972ca' cweid='502' rank='15' abbrev='SECDESGAD' category='SECURITY' priority='3' type='DESERIALIZATION_GADGET' instanceOccurrenceMax='0'><ShortMessage>This class could be used as deserialization gadget</ShortMessage><LongMessage>This class could make application using serialization vulnerable</LongMessage><Class classname='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$2' primary='true'><SourceLine classname='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$2' start='161' end='162' sourcepath='org/apache/spark/api/r/RBackendHandler.scala' sourcefile='RBackendHandler.scala'><Message>At RBackendHandler.scala:[lines 161-162]</Message></SourceLine><Message>In class org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$2</Message></Class><SourceLine synthetic='true' classname='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$2' start='161' end='162' sourcepath='org/apache/spark/api/r/RBackendHandler.scala' sourcefile='RBackendHandler.scala'><Message>At RBackendHandler.scala:[lines 161-162]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='22d7983a3b176f74b31647338244948e' cweid='319' rank='12' abbrev='SECUSS' category='SECURITY' priority='2' type='UNENCRYPTED_SERVER_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Server Socket</ShortMessage><LongMessage>Unencrypted server socket (instead of SSLServerSocket)</LongMessage><Class classname='org.apache.spark.api.r.RRunner' primary='true'><SourceLine classname='org.apache.spark.api.r.RRunner' start='35' end='270' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala'><Message>At RRunner.scala:[lines 35-270]</Message></SourceLine><Message>In class org.apache.spark.api.r.RRunner</Message></Class><Method isStatic='false' classname='org.apache.spark.api.r.RRunner' signature='(Lscala/collection/Iterator;I)Lscala/collection/Iterator;' name='compute' primary='true'><SourceLine endBytecode='372' classname='org.apache.spark.api.r.RRunner' start='61' end='108' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.r.RRunner.compute(Iterator, int)</Message></Method><SourceLine endBytecode='23' classname='org.apache.spark.api.r.RRunner' start='64' end='64' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='23' primary='true'><Message>At RRunner.scala:[line 64]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ad4059a402d26bad782b1c8905574420' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.api.r.RRunner$' primary='true'><SourceLine classname='org.apache.spark.api.r.RRunner$' start='41' end='394' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala'><Message>At RRunner.scala:[lines 41-394]</Message></SourceLine><Message>In class org.apache.spark.api.r.RRunner$</Message></Class><Method isStatic='false' classname='org.apache.spark.api.r.RRunner$' signature='(ILjava/lang/String;)Lorg/apache/spark/api/r/BufferedStreamThread;' name='createRProcess' primary='true'><SourceLine endBytecode='490' classname='org.apache.spark.api.r.RRunner$' start='332' end='355' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.r.RRunner$.createRProcess(int, String)</Message></Method><SourceLine endBytecode='121' classname='org.apache.spark.api.r.RRunner$' start='341' end='341' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='121' primary='true'><Message>At RRunner.scala:[line 341]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/util/Arrays.asList([Ljava/lang/Object;)Ljava/util/List;'><Message>Unknown source java/util/Arrays.asList([Ljava/lang/Object;)Ljava/util/List;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/api/r/RRunner$.createRProcess(ILjava/lang/String;)Lorg/apache/spark/api/r/BufferedStreamThread; parameter 0'><Message>Unknown source org/apache/spark/api/r/RRunner$.createRProcess(ILjava/lang/String;)Lorg/apache/spark/api/r/BufferedStreamThread; parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkConf.get(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/SparkConf.get(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/Seq.apply(I)Ljava/lang/Object;'><Message>Unknown source scala/collection/Seq.apply(I)Ljava/lang/Object;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String><SourceLine endBytecode='25' classname='org.apache.spark.api.r.RRunner$' start='334' end='334' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='25'><Message>At RRunner.scala:[line 334]</Message></SourceLine><SourceLine endBytecode='80' classname='org.apache.spark.api.r.RRunner$' start='340' end='340' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='80'><Message>At RRunner.scala:[line 340]</Message></SourceLine><SourceLine endBytecode='118' classname='org.apache.spark.api.r.RRunner$' start='341' end='341' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='118'><Message>At RRunner.scala:[line 341]</Message></SourceLine><SourceLine endBytecode='69' classname='org.apache.spark.api.r.RRunner$' start='369' end='369' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='69'><Message>At RRunner.scala:[line 369]</Message></SourceLine><SourceLine endBytecode='144' classname='org.apache.spark.api.r.RRunner$' start='391' end='391' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='144'><Message>At RRunner.scala:[line 391]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6693e00ae848c9c7d9841d06d970ad77' cweid='319' rank='12' abbrev='SECUSS' category='SECURITY' priority='2' type='UNENCRYPTED_SERVER_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Server Socket</ShortMessage><LongMessage>Unencrypted server socket (instead of SSLServerSocket)</LongMessage><Class classname='org.apache.spark.api.r.RRunner$' primary='true'><SourceLine classname='org.apache.spark.api.r.RRunner$' start='41' end='394' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala'><Message>At RRunner.scala:[lines 41-394]</Message></SourceLine><Message>In class org.apache.spark.api.r.RRunner$</Message></Class><Method isStatic='false' classname='org.apache.spark.api.r.RRunner$' signature='(I)Lorg/apache/spark/api/r/BufferedStreamThread;' name='createRWorker' primary='true'><SourceLine endBytecode='354' classname='org.apache.spark.api.r.RRunner$' start='362' end='364' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.r.RRunner$.createRWorker(int)</Message></Method><SourceLine endBytecode='51' classname='org.apache.spark.api.r.RRunner$' start='367' end='367' sourcepath='org/apache/spark/api/r/RRunner.scala' sourcefile='RRunner.scala' startBytecode='51' primary='true'><Message>At RRunner.scala:[line 367]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4c2a7d9175c7924669a843b13c0082c1' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.api.r.RUtils$$anonfun$isSparkRInstalled$1' primary='true'><SourceLine classname='org.apache.spark.api.r.RUtils$$anonfun$isSparkRInstalled$1' start='44' end='45' sourcepath='org/apache/spark/api/r/RUtils.scala' sourcefile='RUtils.scala'><Message>At RUtils.scala:[lines 44-45]</Message></SourceLine><Message>In class org.apache.spark.api.r.RUtils$$anonfun$isSparkRInstalled$1</Message></Class><Method isStatic='false' classname='org.apache.spark.api.r.RUtils$$anonfun$isSparkRInstalled$1' signature='(Ljava/lang/String;)Z' name='apply' primary='true'><SourceLine endBytecode='101' classname='org.apache.spark.api.r.RUtils$$anonfun$isSparkRInstalled$1' start='45' end='45' sourcepath='org/apache/spark/api/r/RUtils.scala' sourcefile='RUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.api.r.RUtils$$anonfun$isSparkRInstalled$1.apply(String)</Message></Method><SourceLine endBytecode='43' classname='org.apache.spark.api.r.RUtils$$anonfun$isSparkRInstalled$1' start='45' end='45' sourcepath='org/apache/spark/api/r/RUtils.scala' sourcefile='RUtils.scala' startBytecode='43' primary='true'><Message>At RUtils.scala:[line 45]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/TraversableOnce.mkString(Ljava/lang/String;)Ljava/lang/String;'><Message>Unknown source scala/collection/TraversableOnce.mkString(Ljava/lang/String;)Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='544b6f6f958f4561e929d949b64b642d' cweid='209' rank='15' abbrev='ERRMSG' category='SECURITY' priority='3' type='INFORMATION_EXPOSURE_THROUGH_AN_ERROR_MESSAGE' instanceOccurrenceMax='0'><ShortMessage>Information Exposure Through An Error Message</ShortMessage><LongMessage>Possible information exposure through an error message</LongMessage><Class classname='org.apache.spark.deploy.ClientEndpoint' primary='true'><SourceLine classname='org.apache.spark.deploy.ClientEndpoint' start='40' end='205' sourcepath='org/apache/spark/deploy/Client.scala' sourcefile='Client.scala'><Message>At Client.scala:[lines 40-205]</Message></SourceLine><Message>In class org.apache.spark.deploy.ClientEndpoint</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.ClientEndpoint' signature='(Ljava/lang/Throwable;)V' name='onError' primary='true'><SourceLine endBytecode='80' classname='org.apache.spark.deploy.ClientEndpoint' start='199' end='201' sourcepath='org/apache/spark/deploy/Client.scala' sourcefile='Client.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.ClientEndpoint.onError(Throwable)</Message></Method><SourceLine endBytecode='13' classname='org.apache.spark.deploy.ClientEndpoint' start='200' end='200' sourcepath='org/apache/spark/deploy/Client.scala' sourcefile='Client.scala' startBytecode='13' primary='true'><Message>At Client.scala:[line 200]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='af94239cdac3334d3d8e4fadc78653bb' cweid='209' rank='15' abbrev='ERRMSG' category='SECURITY' priority='3' type='INFORMATION_EXPOSURE_THROUGH_AN_ERROR_MESSAGE' instanceOccurrenceMax='0'><ShortMessage>Information Exposure Through An Error Message</ShortMessage><LongMessage>Possible information exposure through an error message</LongMessage><Class classname='org.apache.spark.deploy.ClientEndpoint' primary='true'><SourceLine classname='org.apache.spark.deploy.ClientEndpoint' start='40' end='205' sourcepath='org/apache/spark/deploy/Client.scala' sourcefile='Client.scala'><Message>At Client.scala:[lines 40-205]</Message></SourceLine><Message>In class org.apache.spark.deploy.ClientEndpoint</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.ClientEndpoint' signature='(Ljava/lang/String;)V' name='pollAndReportStatus' primary='true'><SourceLine endBytecode='663' classname='org.apache.spark.deploy.ClientEndpoint' start='122' end='119' sourcepath='org/apache/spark/deploy/Client.scala' sourcefile='Client.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.ClientEndpoint.pollAndReportStatus(String)</Message></Method><SourceLine endBytecode='312' classname='org.apache.spark.deploy.ClientEndpoint' start='139' end='139' sourcepath='org/apache/spark/deploy/Client.scala' sourcefile='Client.scala' startBytecode='312' primary='true'><Message>At Client.scala:[line 139]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f8e946d568e93617e82c6481b4eabc4a' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.DependencyUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.DependencyUtils$' start='36' end='152' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala'><Message>At DependencyUtils.scala:[lines 36-152]</Message></SourceLine><Message>In class org.apache.spark.deploy.DependencyUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.DependencyUtils$' signature='(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/SparkConf;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/spark/SecurityManager;)Ljava/lang/String;' name='downloadFile' primary='true'><SourceLine endBytecode='525' classname='org.apache.spark.deploy.DependencyUtils$' start='119' end='122' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.DependencyUtils$.downloadFile(String, File, SparkConf, Configuration, SecurityManager)</Message></Method><SourceLine endBytecode='161' classname='org.apache.spark.deploy.DependencyUtils$' start='127' end='127' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='161' primary='true'><Message>At DependencyUtils.scala:[line 127]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/DependencyUtils$.downloadFile(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/SparkConf;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/spark/SecurityManager;)Ljava/lang/String; parameter 4'><Message>Unknown source org/apache/spark/deploy/DependencyUtils$.downloadFile(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/SparkConf;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/spark/SecurityManager;)Ljava/lang/String; parameter 4</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='java/net/URI.getHost()Ljava/lang/String;'><Message>Unknown source java/net/URI.getHost()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.getScheme()Ljava/lang/String;'><Message>Unknown source java/net/URI.getScheme()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Unknown source' value='java/io/File.toURI()Ljava/net/URI;'><Message>Unknown source java/io/File.toURI()Ljava/net/URI;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI;'><Message>Unknown source org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI;</Message></String><String role='Unknown source' value='java/net/URI.getFragment()Ljava/lang/String;'><Message>Unknown source java/net/URI.getFragment()Ljava/lang/String;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='9' classname='org.apache.spark.deploy.DependencyUtils' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='9'><Message>In DependencyUtils.scala</Message></SourceLine><SourceLine endBytecode='26' classname='org.apache.spark.deploy.DependencyUtils$' start='120' end='120' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='26'><Message>At DependencyUtils.scala:[line 120]</Message></SourceLine><SourceLine endBytecode='158' classname='org.apache.spark.deploy.DependencyUtils$' start='127' end='127' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='158'><Message>At DependencyUtils.scala:[line 127]</Message></SourceLine><SourceLine endBytecode='135' classname='org.apache.spark.deploy.SparkSubmit$' start='434' end='434' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='135'><Message>At SparkSubmit.scala:[line 434]</Message></SourceLine><SourceLine endBytecode='46' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13$$anonfun$apply$3' start='448' end='448' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='46'><Message>At SparkSubmit.scala:[line 448]</Message></SourceLine><SourceLine endBytecode='34' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7' start='401' end='401' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='34'><Message>At SparkSubmit.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2034' end='2034' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2034]</Message></SourceLine><SourceLine endBytecode='65' classname='org.apache.spark.util.Utils$' start='2042' end='2042' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='65'><Message>At Utils.scala:[line 2042]</Message></SourceLine><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$' start='2043' end='2043' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='62'><Message>At Utils.scala:[line 2043]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ddf520ea604d9b159367e753973d5de' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.DependencyUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.DependencyUtils$' start='36' end='152' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala'><Message>At DependencyUtils.scala:[lines 36-152]</Message></SourceLine><Message>In class org.apache.spark.deploy.DependencyUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.DependencyUtils$' signature='(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/SparkConf;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/spark/SecurityManager;)Ljava/lang/String;' name='downloadFile' primary='true'><SourceLine endBytecode='525' classname='org.apache.spark.deploy.DependencyUtils$' start='119' end='122' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.DependencyUtils$.downloadFile(String, File, SparkConf, Configuration, SecurityManager)</Message></Method><SourceLine endBytecode='176' classname='org.apache.spark.deploy.DependencyUtils$' start='128' end='128' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='176' primary='true'><Message>At DependencyUtils.scala:[line 128]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getName()Ljava/lang/String;'><Message>Unknown source java/io/File.getName()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bf5cf9be41653f7585f17acf0f7d261a' cweid='78' rank='12' abbrev='SECSCI' category='SECURITY' priority='2' type='SCALA_COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection (Scala)</ShortMessage><LongMessage>The command execution could be vulnerable to injection</LongMessage><Class classname='org.apache.spark.deploy.Docker$' primary='true'><SourceLine classname='org.apache.spark.deploy.Docker$' start='434' end='450' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala'><Message>At FaultToleranceTest.scala:[lines 434-450]</Message></SourceLine><Message>In class org.apache.spark.deploy.Docker$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.Docker$' signature='(Lorg/apache/spark/deploy/DockerId;)V' name='kill' primary='true'><SourceLine endBytecode='99' classname='org.apache.spark.deploy.Docker$' start='444' end='444' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.Docker$.kill(DockerId)</Message></Method><SourceLine endBytecode='38' classname='org.apache.spark.deploy.Docker$' start='444' end='444' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='38' primary='true'><Message>At FaultToleranceTest.scala:[line 444]</Message></SourceLine><String role='Sink method' value='scala/sys/process/package$.stringToProcess(Ljava/lang/String;)Lscala/sys/process/ProcessBuilder;'><Message>Sink method scala/sys/process/package$.stringToProcess(Ljava/lang/String;)Lscala/sys/process/ProcessBuilder;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cd0660489615660111471f61c91d6d6' cweid='78' rank='12' abbrev='SECSCI' category='SECURITY' priority='2' type='SCALA_COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection (Scala)</ShortMessage><LongMessage>The command execution could be vulnerable to injection</LongMessage><Class classname='org.apache.spark.deploy.Docker$' primary='true'><SourceLine classname='org.apache.spark.deploy.Docker$' start='434' end='450' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala'><Message>At FaultToleranceTest.scala:[lines 434-450]</Message></SourceLine><Message>In class org.apache.spark.deploy.Docker$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.Docker$' signature='(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Lscala/sys/process/ProcessBuilder;' name='makeRunCmd' primary='true'><SourceLine endBytecode='260' classname='org.apache.spark.deploy.Docker$' start='436' end='440' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.Docker$.makeRunCmd(String, String, String)</Message></Method><SourceLine endBytecode='113' classname='org.apache.spark.deploy.Docker$' start='440' end='440' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='113' primary='true'><Message>At FaultToleranceTest.scala:[line 440]</Message></SourceLine><String role='Sink method' value='scala/sys/process/package$.stringToProcess(Ljava/lang/String;)Lscala/sys/process/ProcessBuilder;'><Message>Sink method scala/sys/process/package$.stringToProcess(Ljava/lang/String;)Lscala/sys/process/ProcessBuilder;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8c331b147d36765ba20f78f6de2f555c' cweid='209' rank='15' abbrev='ERRMSG' category='SECURITY' priority='3' type='INFORMATION_EXPOSURE_THROUGH_AN_ERROR_MESSAGE' instanceOccurrenceMax='0'><ShortMessage>Information Exposure Through An Error Message</ShortMessage><LongMessage>Possible information exposure through an error message</LongMessage><Class classname='org.apache.spark.deploy.FaultToleranceTest$$anonfun$8' primary='true'><SourceLine classname='org.apache.spark.deploy.FaultToleranceTest$$anonfun$8' start='254' end='262' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala'><Message>At FaultToleranceTest.scala:[lines 254-262]</Message></SourceLine><Message>In class org.apache.spark.deploy.FaultToleranceTest$$anonfun$8</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.FaultToleranceTest$$anonfun$8' signature='()Z' name='apply$mcZ$sp' primary='true'><SourceLine endBytecode='357' classname='org.apache.spark.deploy.FaultToleranceTest$$anonfun$8' start='255' end='254' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.FaultToleranceTest$$anonfun$8.apply$mcZ$sp()</Message></Method><SourceLine endBytecode='142' classname='org.apache.spark.deploy.FaultToleranceTest$$anonfun$8' start='261' end='261' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='142' primary='true'><Message>At FaultToleranceTest.scala:[line 261]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f4f36f45ba4c98dd349891e1efe177bd' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.deploy.PythonRunner$' primary='true'><SourceLine classname='org.apache.spark.deploy.PythonRunner$' start='38' end='148' sourcepath='org/apache/spark/deploy/PythonRunner.scala' sourcefile='PythonRunner.scala'><Message>At PythonRunner.scala:[lines 38-148]</Message></SourceLine><Message>In class org.apache.spark.deploy.PythonRunner$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.PythonRunner$' signature='([Ljava/lang/String;)V' name='main' primary='true'><SourceLine endBytecode='983' classname='org.apache.spark.deploy.PythonRunner$' start='38' end='100' sourcepath='org/apache/spark/deploy/PythonRunner.scala' sourcefile='PythonRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.PythonRunner$.main(String[])</Message></Method><SourceLine endBytecode='322' classname='org.apache.spark.deploy.PythonRunner$' start='79' end='79' sourcepath='org/apache/spark/deploy/PythonRunner.scala' sourcefile='PythonRunner.scala' startBytecode='322' primary='true'><Message>At PythonRunner.scala:[line 79]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/convert/Decorators$AsJava.asJava()Ljava/lang/Object;'><Message>Unknown source scala/collection/convert/Decorators$AsJava.asJava()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='545d821a71da1751c73afbaef2292c90' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.PythonRunner$$anonfun$6' primary='true'><SourceLine classname='org.apache.spark.deploy.PythonRunner$$anonfun$6' start='117' end='117' sourcepath='org/apache/spark/deploy/PythonRunner.scala' sourcefile='PythonRunner.scala'><Message>At PythonRunner.scala:[line 117]</Message></SourceLine><Message>In class org.apache.spark.deploy.PythonRunner$$anonfun$6</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.PythonRunner$$anonfun$6' signature='()Ljava/net/URI;' name='apply' primary='true'><SourceLine endBytecode='56' classname='org.apache.spark.deploy.PythonRunner$$anonfun$6' start='117' end='117' sourcepath='org/apache/spark/deploy/PythonRunner.scala' sourcefile='PythonRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.PythonRunner$$anonfun$6.apply()</Message></Method><SourceLine endBytecode='8' classname='org.apache.spark.deploy.PythonRunner$$anonfun$6' start='117' end='117' sourcepath='org/apache/spark/deploy/PythonRunner.scala' sourcefile='PythonRunner.scala' startBytecode='8' primary='true'><Message>At PythonRunner.scala:[line 117]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/PythonRunner$$anonfun$6.path$1'><Message>Unknown source org/apache/spark/deploy/PythonRunner$$anonfun$6.path$1</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.PythonRunner$$anonfun$6' start='117' end='117' sourcepath='org/apache/spark/deploy/PythonRunner.scala' sourcefile='PythonRunner.scala' startBytecode='5'><Message>At PythonRunner.scala:[line 117]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6b55ad9d910dad53f9d0b6e98e01cae0' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.deploy.RPackageUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.RPackageUtils$' start='33' end='258' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala'><Message>At RPackageUtils.scala:[lines 33-258]</Message></SourceLine><Message>In class org.apache.spark.deploy.RPackageUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.RPackageUtils$' signature='(Ljava/io/File;Ljava/io/PrintStream;ZLjava/lang/String;)Z' name='org$apache$spark$deploy$RPackageUtils$$rPackageBuilder' primary='true'><SourceLine endBytecode='676' classname='org.apache.spark.deploy.RPackageUtils$' start='112' end='110' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.RPackageUtils$.org$apache$spark$deploy$RPackageUtils$$rPackageBuilder(File, PrintStream, boolean, String)</Message></Method><SourceLine endBytecode='176' classname='org.apache.spark.deploy.RPackageUtils$' start='118' end='118' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='176' primary='true'><Message>At RPackageUtils.scala:[line 118]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/convert/Decorators$AsJava.asJava()Ljava/lang/Object;'><Message>Unknown source scala/collection/convert/Decorators$AsJava.asJava()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d62420c7e2308c9400b26a2d7b8dfcfc' cweid='209' rank='12' abbrev='ERRMSG' category='SECURITY' priority='2' type='INFORMATION_EXPOSURE_THROUGH_AN_ERROR_MESSAGE' instanceOccurrenceMax='0'><ShortMessage>Information Exposure Through An Error Message</ShortMessage><LongMessage>Possible information exposure through an error message</LongMessage><Class classname='org.apache.spark.deploy.RPackageUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.RPackageUtils$' start='33' end='258' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala'><Message>At RPackageUtils.scala:[lines 33-258]</Message></SourceLine><Message>In class org.apache.spark.deploy.RPackageUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.RPackageUtils$' signature='(Ljava/lang/String;Ljava/io/PrintStream;Ljava/util/logging/Level;Ljava/lang/Throwable;)V' name='org$apache$spark$deploy$RPackageUtils$$print' primary='true'><SourceLine endBytecode='448' classname='org.apache.spark.deploy.RPackageUtils$' start='73' end='73' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.RPackageUtils$.org$apache$spark$deploy$RPackageUtils$$print(String, PrintStream, Level, Throwable)</Message></Method><SourceLine endBytecode='186' classname='org.apache.spark.deploy.RPackageUtils$' start='78' end='78' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='186' primary='true'><Message>At RPackageUtils.scala:[line 78]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7352b0f04c54c830aa65abb2505fd08c' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='1'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.RPackageUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.RPackageUtils$' start='33' end='258' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala'><Message>At RPackageUtils.scala:[lines 33-258]</Message></SourceLine><Message>In class org.apache.spark.deploy.RPackageUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.RPackageUtils$' signature='(Ljava/util/jar/JarFile;Ljava/io/PrintStream;Z)Ljava/io/File;' name='org$apache$spark$deploy$RPackageUtils$$extractRFolder' primary='true'><SourceLine endBytecode='696' classname='org.apache.spark.deploy.RPackageUtils$' start='143' end='168' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.RPackageUtils$.org$apache$spark$deploy$RPackageUtils$$extractRFolder(JarFile, PrintStream, boolean)</Message></Method><SourceLine endBytecode='89' classname='org.apache.spark.deploy.RPackageUtils$' start='151' end='151' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='89' primary='true'><Message>At RPackageUtils.scala:[line 151]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/util/jar/JarEntry.getName()Ljava/lang/String;'><Message>Unknown source java/util/jar/JarEntry.getName()Ljava/lang/String;</Message></String><SourceLine endBytecode='68' classname='org.apache.spark.deploy.RPackageUtils$' start='149' end='149' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='68'><Message>At RPackageUtils.scala:[line 149]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='7352b0f04c54c830aa65abb2505fd08c' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='1'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.RPackageUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.RPackageUtils$' start='33' end='258' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala'><Message>At RPackageUtils.scala:[lines 33-258]</Message></SourceLine><Message>In class org.apache.spark.deploy.RPackageUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.RPackageUtils$' signature='(Ljava/util/jar/JarFile;Ljava/io/PrintStream;Z)Ljava/io/File;' name='org$apache$spark$deploy$RPackageUtils$$extractRFolder' primary='true'><SourceLine endBytecode='696' classname='org.apache.spark.deploy.RPackageUtils$' start='143' end='168' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.RPackageUtils$.org$apache$spark$deploy$RPackageUtils$$extractRFolder(JarFile, PrintStream, boolean)</Message></Method><SourceLine endBytecode='188' classname='org.apache.spark.deploy.RPackageUtils$' start='158' end='158' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='188' primary='true'><Message>At RPackageUtils.scala:[line 158]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/util/jar/JarEntry.getName()Ljava/lang/String;'><Message>Unknown source java/util/jar/JarEntry.getName()Ljava/lang/String;</Message></String><SourceLine endBytecode='68' classname='org.apache.spark.deploy.RPackageUtils$' start='149' end='149' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='68'><Message>At RPackageUtils.scala:[line 149]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec7d4ae57ccade7a3e6a6ff6c672f992' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.RPackageUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.RPackageUtils$' start='33' end='258' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala'><Message>At RPackageUtils.scala:[lines 33-258]</Message></SourceLine><Message>In class org.apache.spark.deploy.RPackageUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.RPackageUtils$' signature='(Ljava/io/File;Ljava/lang/String;)Ljava/io/File;' name='zipRLibraries' primary='true'><SourceLine endBytecode='295' classname='org.apache.spark.deploy.RPackageUtils$' start='233' end='256' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.RPackageUtils$.zipRLibraries(File, String)</Message></Method><SourceLine endBytecode='40' classname='org.apache.spark.deploy.RPackageUtils$' start='235' end='235' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='40' primary='true'><Message>At RPackageUtils.scala:[line 235]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/RPackageUtils$.zipRLibraries(Ljava/io/File;Ljava/lang/String;)Ljava/io/File; parameter 0'><Message>Unknown source org/apache/spark/deploy/RPackageUtils$.zipRLibraries(Ljava/io/File;Ljava/lang/String;)Ljava/io/File; parameter 0</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.SparkSubmit$' start='92' end='92' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='1'><Message>At SparkSubmit.scala:[line 92]</Message></SourceLine><SourceLine endBytecode='2751' classname='org.apache.spark.deploy.SparkSubmit$' start='499' end='499' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2751'><Message>At SparkSubmit.scala:[line 499]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='76955f3a7191c446ad803ddd376a3547' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/net/URI;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' primary='true'><SourceLine classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='178' end='209' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala'><Message>At RPackageUtils.scala:[lines 178-209]</Message></SourceLine><Message>In class org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='247' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='179' end='178' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1.apply(String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='179' end='179' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='11' primary='true'><Message>At RPackageUtils.scala:[line 179]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/net/URI;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/net/URI;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='java/net/URI.getHost()Ljava/lang/String;'><Message>Unknown source java/net/URI.getHost()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.getScheme()Ljava/lang/String;'><Message>Unknown source java/net/URI.getScheme()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Unknown source' value='java/io/File.toURI()Ljava/net/URI;'><Message>Unknown source java/io/File.toURI()Ljava/net/URI;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI;'><Message>Unknown source org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/RPackageUtils$$anonfun$checkAndBuildRPackage$1.apply(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/deploy/RPackageUtils$$anonfun$checkAndBuildRPackage$1.apply(Ljava/lang/String;)V parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getFragment()Ljava/lang/String;'><Message>Unknown source java/net/URI.getFragment()Ljava/lang/String;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='178' end='178' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='5'><Message>At RPackageUtils.scala:[line 178]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='179' end='179' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='8'><Message>At RPackageUtils.scala:[line 179]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2034' end='2034' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2034]</Message></SourceLine><SourceLine endBytecode='65' classname='org.apache.spark.util.Utils$' start='2042' end='2042' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='65'><Message>At Utils.scala:[line 2042]</Message></SourceLine><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$' start='2043' end='2043' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='62'><Message>At Utils.scala:[line 2043]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6c3ffccf688ab810a673a46c9f664b00' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.deploy.RRunner$' primary='true'><SourceLine classname='org.apache.spark.deploy.RRunner$' start='36' end='114' sourcepath='org/apache/spark/deploy/RRunner.scala' sourcefile='RRunner.scala'><Message>At RRunner.scala:[lines 36-114]</Message></SourceLine><Message>In class org.apache.spark.deploy.RRunner$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.RRunner$' signature='([Ljava/lang/String;)V' name='main' primary='true'><SourceLine endBytecode='1318' classname='org.apache.spark.deploy.RRunner$' start='37' end='101' sourcepath='org/apache/spark/deploy/RRunner.scala' sourcefile='RRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.RRunner$.main(String[])</Message></Method><SourceLine endBytecode='403' classname='org.apache.spark.deploy.RRunner$' start='85' end='85' sourcepath='org/apache/spark/deploy/RRunner.scala' sourcefile='RRunner.scala' startBytecode='403' primary='true'><Message>At RRunner.scala:[line 85]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/convert/Decorators$AsJava.asJava()Ljava/lang/Object;'><Message>Unknown source scala/collection/convert/Decorators$AsJava.asJava()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2396c7d3d5af553979ac650ca7da562f' cweid='22' rank='10' abbrev='SECPTI' category='SECURITY' priority='1' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.RRunner$' primary='true'><SourceLine classname='org.apache.spark.deploy.RRunner$' start='36' end='114' sourcepath='org/apache/spark/deploy/RRunner.scala' sourcefile='RRunner.scala'><Message>At RRunner.scala:[lines 36-114]</Message></SourceLine><Message>In class org.apache.spark.deploy.RRunner$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.RRunner$' signature='([Ljava/lang/String;)V' name='main' primary='true'><SourceLine endBytecode='1318' classname='org.apache.spark.deploy.RRunner$' start='37' end='101' sourcepath='org/apache/spark/deploy/RRunner.scala' sourcefile='RRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.RRunner$.main(String[])</Message></Method><SourceLine endBytecode='242' classname='org.apache.spark.deploy.RRunner$' start='60' end='60' sourcepath='org/apache/spark/deploy/RRunner.scala' sourcefile='RRunner.scala' startBytecode='242' primary='true'><Message>At RRunner.scala:[line 60]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/RRunner$.main([Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/deploy/RRunner$.main([Ljava/lang/String;)V parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/PythonRunner$.formatPath(Ljava/lang/String;Z)Ljava/lang/String; parameter 1'><Message>Unknown source org/apache/spark/deploy/PythonRunner$.formatPath(Ljava/lang/String;Z)Ljava/lang/String; parameter 1</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.stripPrefix(Ljava/lang/String;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.stripPrefix(Ljava/lang/String;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/util/Try.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/util/Try.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/PythonRunner$.formatPath(Ljava/lang/String;Z)Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/PythonRunner$.formatPath(Ljava/lang/String;Z)Ljava/lang/String;</Message></String><String role='Method usage' value='with tainted arguments detected'><Message>Method usage with tainted arguments detected</Message></String><SourceLine endBytecode='190' classname='org.apache.spark.deploy.PythonRunner$' start='120' end='120' sourcepath='org/apache/spark/deploy/PythonRunner.scala' sourcefile='PythonRunner.scala' startBytecode='190'><Message>At PythonRunner.scala:[line 120]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.RRunner' sourcepath='org/apache/spark/deploy/RRunner.scala' sourcefile='RRunner.scala' startBytecode='4'><Message>In RRunner.scala</Message></SourceLine><SourceLine endBytecode='12' classname='org.apache.spark.deploy.RRunner$' start='37' end='37' sourcepath='org/apache/spark/deploy/RRunner.scala' sourcefile='RRunner.scala' startBytecode='12'><Message>At RRunner.scala:[line 37]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e74ee9d50d796437d95db5a78b07d359' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkDocker$' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkDocker$' start='398' end='430' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala'><Message>At FaultToleranceTest.scala:[lines 398-430]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkDocker$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkDocker$' signature='(Lscala/sys/process/ProcessBuilder;)Lscala/Tuple3;' name='startNode' primary='true'><SourceLine endBytecode='247' classname='org.apache.spark.deploy.SparkDocker$' start='410' end='426' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkDocker$.startNode(ProcessBuilder)</Message></Method><SourceLine endBytecode='29' classname='org.apache.spark.deploy.SparkDocker$' start='411' end='411' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='29' primary='true'><Message>At FaultToleranceTest.scala:[line 411]</Message></SourceLine><String role='Sink method' value='java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;'><Message>Sink method java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getCanonicalFile()Ljava/io/File;'><Message>Unknown source java/io/File.getCanonicalFile()Ljava/io/File;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.createTempDir(Ljava/lang/String;Ljava/lang/String;)Ljava/io/File;'><Message>Unknown source org/apache/spark/util/Utils$.createTempDir(Ljava/lang/String;Ljava/lang/String;)Ljava/io/File;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.createDirectory(Ljava/lang/String;Ljava/lang/String;)Ljava/io/File;'><Message>Unknown source org/apache/spark/util/Utils$.createDirectory(Ljava/lang/String;Ljava/lang/String;)Ljava/io/File;</Message></String><SourceLine endBytecode='26' classname='org.apache.spark.deploy.SparkDocker$' start='411' end='411' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='26'><Message>At FaultToleranceTest.scala:[line 411]</Message></SourceLine><SourceLine endBytecode='3' classname='org.apache.spark.util.Utils$' start='316' end='316' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='3'><Message>At Utils.scala:[line 316]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a1a274905892d14644981dd806f54853' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkHadoopUtil' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkHadoopUtil' start='50' end='417' sourcepath='org/apache/spark/deploy/SparkHadoopUtil.scala' sourcefile='SparkHadoopUtil.scala'><Message>At SparkHadoopUtil.scala:[lines 50-417]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkHadoopUtil</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkHadoopUtil' signature='(Ljava/lang/String;Ljava/lang/String;)V' name='loginUserFromKeytab' primary='true'><SourceLine endBytecode='177' classname='org.apache.spark.deploy.SparkHadoopUtil' start='131' end='132' sourcepath='org/apache/spark/deploy/SparkHadoopUtil.scala' sourcefile='SparkHadoopUtil.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkHadoopUtil.loginUserFromKeytab(String, String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.deploy.SparkHadoopUtil' start='131' end='131' sourcepath='org/apache/spark/deploy/SparkHadoopUtil.scala' sourcefile='SparkHadoopUtil.scala' startBytecode='5' primary='true'><Message>At SparkHadoopUtil.scala:[line 131]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkHadoopUtil.loginUserFromKeytab(Ljava/lang/String;Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/deploy/SparkHadoopUtil.loginUserFromKeytab(Ljava/lang/String;Ljava/lang/String;)V parameter 0</Message></String><SourceLine endBytecode='32' classname='org.apache.spark.deploy.history.HistoryServer$' start='322' end='322' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='32'><Message>At HistoryServer.scala:[line 322]</Message></SourceLine><SourceLine endBytecode='44' classname='org.apache.spark.deploy.history.HistoryServer$' start='323' end='323' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='44'><Message>At HistoryServer.scala:[line 323]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b80ad205947611cd635e094219cc540' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmit$' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmit$' start='70' end='961' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 70-961]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmit$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmit$' signature='(Ljava/lang/String;Lorg/apache/spark/util/MutableURLClassLoader;)V' name='addJarToClasspath' primary='true'><SourceLine endBytecode='375' classname='org.apache.spark.deploy.SparkSubmit$' start='893' end='892' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmit$.addJarToClasspath(String, MutableURLClassLoader)</Message></Method><SourceLine endBytecode='64' classname='org.apache.spark.deploy.SparkSubmit$' start='896' end='896' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='64' primary='true'><Message>At SparkSubmit.scala:[line 896]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='java/net/URI.getHost()Ljava/lang/String;'><Message>Unknown source java/net/URI.getHost()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.getScheme()Ljava/lang/String;'><Message>Unknown source java/net/URI.getScheme()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Unknown source' value='java/io/File.toURI()Ljava/net/URI;'><Message>Unknown source java/io/File.toURI()Ljava/net/URI;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkSubmit$.addJarToClasspath(Ljava/lang/String;Lorg/apache/spark/util/MutableURLClassLoader;)V parameter 1'><Message>Unknown source org/apache/spark/deploy/SparkSubmit$.addJarToClasspath(Ljava/lang/String;Lorg/apache/spark/util/MutableURLClassLoader;)V parameter 1</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI;'><Message>Unknown source org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI;</Message></String><String role='Unknown source' value='java/net/URI.getFragment()Ljava/lang/String;'><Message>Unknown source java/net/URI.getFragment()Ljava/lang/String;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$addJarsToClassPath$1' start='73' end='73' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='5'><Message>At DependencyUtils.scala:[line 73]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$addJarsToClassPath$1' start='74' end='74' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='8'><Message>At DependencyUtils.scala:[line 74]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.SparkSubmit$' start='893' end='893' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='4'><Message>At SparkSubmit.scala:[line 893]</Message></SourceLine><SourceLine endBytecode='61' classname='org.apache.spark.deploy.SparkSubmit$' start='896' end='896' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='61'><Message>At SparkSubmit.scala:[line 896]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2034' end='2034' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2034]</Message></SourceLine><SourceLine endBytecode='65' classname='org.apache.spark.util.Utils$' start='2042' end='2042' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='65'><Message>At Utils.scala:[line 2042]</Message></SourceLine><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$' start='2043' end='2043' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='62'><Message>At Utils.scala:[line 2043]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d29481e78da5ef637c6c17b2d27b3961' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmit$' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmit$' start='70' end='961' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 70-961]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmit$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmit$' signature='(Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/hadoop/conf/Configuration;Ljava/io/File;Lscala/runtime/ObjectRef;Lscala/collection/Seq;Lscala/runtime/VolatileByteRef;)Ljava/lang/String;' name='org$apache$spark$deploy$SparkSubmit$$downloadResource$1' primary='true'><SourceLine endBytecode='367' classname='org.apache.spark.deploy.SparkSubmit$' start='426' end='427' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$downloadResource$1(String, SparkConf, Configuration, File, ObjectRef, Seq, VolatileByteRef)</Message></Method><SourceLine endBytecode='94' classname='org.apache.spark.deploy.SparkSubmit$' start='430' end='430' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='94' primary='true'><Message>At SparkSubmit.scala:[line 430]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/hadoop/fs/Path.getName()Ljava/lang/String;'><Message>Unknown source org/apache/hadoop/fs/Path.getName()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9fcccfd284dfa148eb6f2bd9b50d6ee5' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmit$' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmit$' start='70' end='961' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 70-961]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmit$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmit$' signature='(Lorg/apache/spark/deploy/SparkSubmitArguments;Lscala/Option;)Lscala/Tuple4;' name='prepareSubmitEnvironment' primary='true'><SourceLine endBytecode='13623' classname='org.apache.spark.deploy.SparkSubmit$' start='393' end='781' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmitArguments, Option)</Message></Method><SourceLine endBytecode='1668' classname='org.apache.spark.deploy.SparkSubmit$' start='375' end='375' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='1668' primary='true'><Message>At SparkSubmit.scala:[line 375]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkSubmitArguments.keytab()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/SparkSubmitArguments.keytab()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkSubmitArguments.keytab'><Message>Unknown source org/apache/spark/deploy/SparkSubmitArguments.keytab</Message></String><SourceLine endBytecode='1665' classname='org.apache.spark.deploy.SparkSubmit$' start='375' end='375' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='1665'><Message>At SparkSubmit.scala:[line 375]</Message></SourceLine><SourceLine endBytecode='1' classname='org.apache.spark.deploy.SparkSubmitArguments' start='75' end='75' sourcepath='org/apache/spark/deploy/SparkSubmitArguments.scala' sourcefile='SparkSubmitArguments.scala' startBytecode='1'><Message>At SparkSubmitArguments.scala:[line 75]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='81c287edf94fd35b07c8241a05ef911a' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmit$' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmit$' start='70' end='961' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 70-961]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmit$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmit$' signature='(Lorg/apache/spark/deploy/SparkSubmitArguments;Lscala/Option;)Lscala/Tuple4;' name='prepareSubmitEnvironment' primary='true'><SourceLine endBytecode='13623' classname='org.apache.spark.deploy.SparkSubmit$' start='393' end='781' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmitArguments, Option)</Message></Method><SourceLine endBytecode='2576' classname='org.apache.spark.deploy.SparkSubmit$' start='486' end='486' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2576' primary='true'><Message>At SparkSubmit.scala:[line 486]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkSubmit$.SPARKR_PACKAGE_ARCHIVE()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/SparkSubmit$.SPARKR_PACKAGE_ARCHIVE()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkSubmit$.SPARKR_PACKAGE_ARCHIVE'><Message>Unknown source org/apache/spark/deploy/SparkSubmit$.SPARKR_PACKAGE_ARCHIVE</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.SparkSubmit$' start='91' end='91' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='1'><Message>At SparkSubmit.scala:[line 91]</Message></SourceLine><SourceLine endBytecode='2573' classname='org.apache.spark.deploy.SparkSubmit$' start='486' end='486' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2573'><Message>At SparkSubmit.scala:[line 486]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9d92ad8ebe77fd7a6526793de454c939' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmit$' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmit$' start='70' end='961' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 70-961]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmit$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmit$' signature='(Lorg/apache/spark/deploy/SparkSubmitArguments;Lscala/Option;)Lscala/Tuple4;' name='prepareSubmitEnvironment' primary='true'><SourceLine endBytecode='13623' classname='org.apache.spark.deploy.SparkSubmit$' start='393' end='781' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmitArguments, Option)</Message></Method><SourceLine endBytecode='2744' classname='org.apache.spark.deploy.SparkSubmit$' start='499' end='499' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2744' primary='true'><Message>At SparkSubmit.scala:[line 499]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Option.get()Ljava/lang/Object;'><Message>Unknown source scala/Option.get()Ljava/lang/Object;</Message></String><String role='Unknown source' value='org/apache/spark/api/r/RUtils$.rPackages'><Message>Unknown source org/apache/spark/api/r/RUtils$.rPackages</Message></String><String role='Unknown source' value='org/apache/spark/api/r/RUtils$.rPackages()Lscala/Option;'><Message>Unknown source org/apache/spark/api/r/RUtils$.rPackages()Lscala/Option;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.api.r.RUtils$' start='28' end='28' sourcepath='org/apache/spark/api/r/RUtils.scala' sourcefile='RUtils.scala' startBytecode='1'><Message>At RUtils.scala:[line 28]</Message></SourceLine><SourceLine endBytecode='2735' classname='org.apache.spark.deploy.SparkSubmit$' start='499' end='499' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2735'><Message>At SparkSubmit.scala:[line 499]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a8b070b25b2f943d4992ea673dfd957f' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmitUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmitUtils$' start='970' end='1301' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 970-1301]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmitUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmitUtils$' signature='(Ljava/lang/String;Lscala/Option;Lscala/Option;)Lorg/apache/ivy/core/settings/IvySettings;' name='loadIvySettings' primary='true'><SourceLine endBytecode='381' classname='org.apache.spark.deploy.SparkSubmitUtils$' start='1146' end='1150' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmitUtils$.loadIvySettings(String, Option, Option)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.deploy.SparkSubmitUtils$' start='1146' end='1146' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='5' primary='true'><Message>At SparkSubmit.scala:[line 1146]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkSubmitUtils$.loadIvySettings(Ljava/lang/String;Lscala/Option;Lscala/Option;)Lorg/apache/ivy/core/settings/IvySettings; parameter 2'><Message>Unknown source org/apache/spark/deploy/SparkSubmitUtils$.loadIvySettings(Ljava/lang/String;Lscala/Option;Lscala/Option;)Lorg/apache/ivy/core/settings/IvySettings; parameter 2</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$1' start='43' end='43' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='5'><Message>At DependencyUtils.scala:[line 43]</Message></SourceLine><SourceLine endBytecode='24' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$1' start='44' end='44' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='24'><Message>At DependencyUtils.scala:[line 44]</Message></SourceLine><SourceLine endBytecode='6' classname='org.apache.spark.deploy.SparkSubmitUtils' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='6'><Message>In SparkSubmit.scala</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b3e64b3b5d8d60a61850310671ffb660' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmitUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmitUtils$' start='970' end='1301' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 970-1301]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmitUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmitUtils$' signature='(Ljava/lang/String;Lorg/apache/ivy/core/settings/IvySettings;Lscala/collection/Seq;Z)Ljava/lang/String;' name='resolveMavenCoordinates' primary='true'><SourceLine endBytecode='1087' classname='org.apache.spark.deploy.SparkSubmitUtils$' start='1213' end='1279' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(String, IvySettings, Seq, boolean)</Message></Method><SourceLine endBytecode='348' classname='org.apache.spark.deploy.SparkSubmitUtils$' start='1254' end='1254' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='348' primary='true'><Message>At SparkSubmit.scala:[line 1254]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='345' classname='org.apache.spark.deploy.SparkSubmitUtils$' start='1255' end='1255' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='345'><Message>At SparkSubmit.scala:[line 1255]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fef270a662fbd9c1bc282cff45ac3d9' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' start='1163' end='1165' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 1163-1165]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='88' classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' start='1164' end='1165' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2.apply(String)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' start='1164' end='1164' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='9' primary='true'><Message>At SparkSubmit.scala:[line 1164]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkSubmitUtils$$anonfun$processIvyPathArg$2.apply(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/deploy/SparkSubmitUtils$$anonfun$processIvyPathArg$2.apply(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' start='1163' end='1163' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='5'><Message>At SparkSubmit.scala:[line 1163]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2d191cf8c664c1f3776c2a5c840a1a32' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' primary='true'><SourceLine classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' start='1163' end='1165' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala'><Message>At SparkSubmit.scala:[lines 1163-1165]</Message></SourceLine><Message>In class org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='88' classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' start='1164' end='1165' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2.apply(String)</Message></Method><SourceLine endBytecode='26' classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' start='1165' end='1165' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='26' primary='true'><Message>At SparkSubmit.scala:[line 1165]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='org/apache/spark/deploy/SparkSubmitUtils$$anonfun$processIvyPathArg$2.apply(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/deploy/SparkSubmitUtils$$anonfun$processIvyPathArg$2.apply(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2' start='1163' end='1163' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='5'><Message>At SparkSubmit.scala:[line 1163]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c0ea656518c13f9b740feba0e07a19c2' cweid='918' rank='12' abbrev='SECSSSRFUC' category='SECURITY' priority='2' type='URLCONNECTION_SSRF_FD' instanceOccurrenceMax='0'><ShortMessage>URLConnection Server-Side Request Forgery (SSRF) and File Disclosure</ShortMessage><LongMessage>This web server request could be used by an attacker to expose internal services and filesystem.</LongMessage><Class classname='org.apache.spark.deploy.TestMasterInfo' primary='true'><SourceLine classname='org.apache.spark.deploy.TestMasterInfo' start='340' end='380' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala'><Message>At FaultToleranceTest.scala:[lines 340-380]</Message></SourceLine><Message>In class org.apache.spark.deploy.TestMasterInfo</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.TestMasterInfo' signature='()V' name='readState' primary='true'><SourceLine endBytecode='448' classname='org.apache.spark.deploy.TestMasterInfo' start='352' end='351' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.TestMasterInfo.readState()</Message></Method><SourceLine endBytecode='46' classname='org.apache.spark.deploy.TestMasterInfo' start='353' end='353' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='46' primary='true'><Message>At FaultToleranceTest.scala:[line 353]</Message></SourceLine><String role='Sink method' value='java/net/URL.openStream()Ljava/io/InputStream;'><Message>Sink method java/net/URL.openStream()Ljava/io/InputStream;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URL.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URL.&lt;init&gt;(Ljava/lang/String;)V</Message></String><SourceLine endBytecode='43' classname='org.apache.spark.deploy.TestMasterInfo' start='353' end='353' sourcepath='org/apache/spark/deploy/FaultToleranceTest.scala' sourcefile='FaultToleranceTest.scala' startBytecode='43'><Message>At FaultToleranceTest.scala:[line 353]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c3d4e0632ed3c88bfdfebccce3e6230c' rank='15' abbrev='SECSSQ' category='SECURITY' priority='3' type='SERVLET_QUERY_STRING' instanceOccurrenceMax='0'><ShortMessage>Untrusted query string</ShortMessage><LongMessage>The query string can be any value</LongMessage><Class classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' primary='true'><SourceLine classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='369' end='420' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala'><Message>At ApplicationCache.scala:[lines 369-420]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.ApplicationCacheCheckFilter</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' signature='(Ljavax/servlet/ServletRequest;Ljavax/servlet/ServletResponse;Ljavax/servlet/FilterChain;)V' name='doFilter' primary='true'><SourceLine endBytecode='513' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='392' end='407' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.ApplicationCacheCheckFilter.doFilter(ServletRequest, ServletResponse, FilterChain)</Message></Method><SourceLine endBytecode='113' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='412' end='412' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala' startBytecode='113' primary='true'><Message>At ApplicationCache.scala:[line 412]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='df092faedf133e5e0d90c7ee97f0bebe' cweid='601' rank='12' abbrev='SECUR' category='SECURITY' priority='2' type='UNVALIDATED_REDIRECT' instanceOccurrenceMax='0'><ShortMessage>Unvalidated Redirect</ShortMessage><LongMessage>The following redirection could be used by an attacker to redirect users to a phishing website.</LongMessage><Class classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' primary='true'><SourceLine classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='369' end='420' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala'><Message>At ApplicationCache.scala:[lines 369-420]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.ApplicationCacheCheckFilter</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' signature='(Ljavax/servlet/ServletRequest;Ljavax/servlet/ServletResponse;Ljavax/servlet/FilterChain;)V' name='doFilter' primary='true'><SourceLine endBytecode='513' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='392' end='407' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.ApplicationCacheCheckFilter.doFilter(ServletRequest, ServletResponse, FilterChain)</Message></Method><SourceLine endBytecode='181' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='414' end='414' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala' startBytecode='181' primary='true'><Message>At ApplicationCache.scala:[line 414]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.sendRedirect(Ljava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.sendRedirect(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='javax/servlet/http/HttpServletResponse.encodeRedirectURL(Ljava/lang/String;)Ljava/lang/String;'><Message>Unknown source javax/servlet/http/HttpServletResponse.encodeRedirectURL(Ljava/lang/String;)Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d840fa54a03b9307a6ab9f85a832837b' rank='10' abbrev='SECURLR' category='SECURITY' priority='1' type='URL_REWRITING' instanceOccurrenceMax='0'><ShortMessage>URL rewriting method</ShortMessage><LongMessage>Method rewriting session ID into the URL</LongMessage><Class classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' primary='true'><SourceLine classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='369' end='420' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala'><Message>At ApplicationCache.scala:[lines 369-420]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.ApplicationCacheCheckFilter</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' signature='(Ljavax/servlet/ServletRequest;Ljavax/servlet/ServletResponse;Ljavax/servlet/FilterChain;)V' name='doFilter' primary='true'><SourceLine endBytecode='513' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='392' end='407' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.ApplicationCacheCheckFilter.doFilter(ServletRequest, ServletResponse, FilterChain)</Message></Method><SourceLine endBytecode='170' classname='org.apache.spark.deploy.history.ApplicationCacheCheckFilter' start='413' end='413' sourcepath='org/apache/spark/deploy/history/ApplicationCache.scala' sourcefile='ApplicationCache.scala' startBytecode='170' primary='true'><Message>At ApplicationCache.scala:[line 413]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cee7303c36950de9c2fa7b10b1e2fd26' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2' primary='true'><SourceLine classname='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2' start='127' end='127' sourcepath='org/apache/spark/deploy/history/FsHistoryProvider.scala' sourcefile='FsHistoryProvider.scala'><Message>At FsHistoryProvider.scala:[line 127]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2' signature='(Ljava/lang/String;)Ljava/io/File;' name='apply' primary='true'><SourceLine endBytecode='60' classname='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2' start='127' end='127' sourcepath='org/apache/spark/deploy/history/FsHistoryProvider.scala' sourcefile='FsHistoryProvider.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2.apply(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2' start='127' end='127' sourcepath='org/apache/spark/deploy/history/FsHistoryProvider.scala' sourcefile='FsHistoryProvider.scala' startBytecode='5' primary='true'><Message>At FsHistoryProvider.scala:[line 127]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$2.apply(Ljava/lang/String;)Ljava/io/File; parameter 0'><Message>Unknown source org/apache/spark/deploy/history/FsHistoryProvider$$anonfun$2.apply(Ljava/lang/String;)Ljava/io/File; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2' start='127' end='127' sourcepath='org/apache/spark/deploy/history/FsHistoryProvider.scala' sourcefile='FsHistoryProvider.scala' startBytecode='5'><Message>At FsHistoryProvider.scala:[line 127]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='abaab794197cf807847027e46f0fa57' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryPage' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryPage' start='27' end='99' sourcepath='org/apache/spark/deploy/history/HistoryPage.scala' sourcefile='HistoryPage.scala'><Message>At HistoryPage.scala:[lines 27-99]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='3410' classname='org.apache.spark.deploy.history.HistoryPage' start='32' end='91' sourcepath='org/apache/spark/deploy/history/HistoryPage.scala' sourcefile='HistoryPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='16' classname='org.apache.spark.deploy.history.HistoryPage' start='32' end='32' sourcepath='org/apache/spark/deploy/history/HistoryPage.scala' sourcefile='HistoryPage.scala' startBytecode='16' primary='true'><Message>At HistoryPage.scala:[line 32]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='17870ce4c02cbf19b11eb8437fdb2e00' rank='15' abbrev='SECSSQ' category='SECURITY' priority='3' type='SERVLET_QUERY_STRING' instanceOccurrenceMax='0'><ShortMessage>Untrusted query string</ShortMessage><LongMessage>The query string can be any value</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='70' end='106' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala'><Message>At HistoryServer.scala:[lines 70-106]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryServer$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doGet' primary='true'><SourceLine endBytecode='601' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='74' end='93' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryServer$$anon$1.doGet(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='186' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='100' end='100' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='186' primary='true'><Message>At HistoryServer.scala:[line 100]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fb07d3c3e36c2203765b3a9758764ef9' cweid='601' rank='12' abbrev='SECUR' category='SECURITY' priority='2' type='UNVALIDATED_REDIRECT' instanceOccurrenceMax='0'><ShortMessage>Unvalidated Redirect</ShortMessage><LongMessage>The following redirection could be used by an attacker to redirect users to a phishing website.</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='70' end='106' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala'><Message>At HistoryServer.scala:[lines 70-106]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryServer$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doGet' primary='true'><SourceLine endBytecode='601' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='74' end='93' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryServer$$anon$1.doGet(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='233' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='101' end='101' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='233' primary='true'><Message>At HistoryServer.scala:[line 101]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.sendRedirect(Ljava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.sendRedirect(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='javax/servlet/http/HttpServletResponse.encodeRedirectURL(Ljava/lang/String;)Ljava/lang/String;'><Message>Unknown source javax/servlet/http/HttpServletResponse.encodeRedirectURL(Ljava/lang/String;)Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cd3a5aa1371a25dbeabf390a901ebbe' rank='10' abbrev='SECURLR' category='SECURITY' priority='1' type='URL_REWRITING' instanceOccurrenceMax='0'><ShortMessage>URL rewriting method</ShortMessage><LongMessage>Method rewriting session ID into the URL</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='70' end='106' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala'><Message>At HistoryServer.scala:[lines 70-106]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryServer$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doGet' primary='true'><SourceLine endBytecode='601' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='74' end='93' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryServer$$anon$1.doGet(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='228' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='101' end='101' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='228' primary='true'><Message>At HistoryServer.scala:[line 101]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='653c4cde04bc6cf18af6decfbf53137e' cweid='79' rank='12' abbrev='SECXSS2' category='SECURITY' priority='2' type='XSS_SERVLET' instanceOccurrenceMax='0'><ShortMessage>Potential XSS in Servlet</ShortMessage><LongMessage>This use of javax/servlet/http/HttpServletResponse.sendError(ILjava/lang/String;)V could be vulnerable to XSS in the Servlet</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='70' end='106' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala'><Message>At HistoryServer.scala:[lines 70-106]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryServer$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doGet' primary='true'><SourceLine endBytecode='601' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='74' end='93' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryServer$$anon$1.doGet(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='94' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='76' end='76' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='94' primary='true'><Message>At HistoryServer.scala:[line 76]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.sendError(ILjava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.sendError(ILjava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='91' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1' start='77' end='77' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='91'><Message>At HistoryServer.scala:[line 77]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='992d3372afd5352997e676e007fbe115' cweid='79' rank='12' abbrev='SECXSS2' category='SECURITY' priority='2' type='XSS_SERVLET' instanceOccurrenceMax='0'><ShortMessage>Potential XSS in Servlet</ShortMessage><LongMessage>This use of java/io/PrintWriter.write(Ljava/lang/String;)V could be vulnerable to XSS in the Servlet</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2' start='90' end='91' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala'><Message>At HistoryServer.scala:[lines 90-91]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2' signature='(Lscala/xml/Node;)V' name='apply' primary='true'><SourceLine endBytecode='68' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2' start='91' end='91' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2.apply(Node)</Message></Method><SourceLine endBytecode='13' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2' start='91' end='91' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='13' primary='true'><Message>At HistoryServer.scala:[line 91]</Message></SourceLine><String role='Sink method' value='java/io/PrintWriter.write(Ljava/lang/String;)V'><Message>Sink method java/io/PrintWriter.write(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/xml/Node.toString()Ljava/lang/String;'><Message>Unknown source scala/xml/Node.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/history/HistoryServer$$anon$1$$anonfun$doGet$2.apply(Lscala/xml/Node;)V parameter 0'><Message>Unknown source org/apache/spark/deploy/history/HistoryServer$$anon$1$$anonfun$doGet$2.apply(Lscala/xml/Node;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2' start='90' end='90' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='5'><Message>At HistoryServer.scala:[line 90]</Message></SourceLine><SourceLine endBytecode='10' classname='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2' start='91' end='91' sourcepath='org/apache/spark/deploy/history/HistoryServer.scala' sourcefile='HistoryServer.scala' startBytecode='10'><Message>At HistoryServer.scala:[line 91]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2b88170e781211afb395f4a45a04154' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryServerDiskManager' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryServerDiskManager' start='49' end='268' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala'><Message>At HistoryServerDiskManager.scala:[lines 49-268]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryServerDiskManager</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryServerDiskManager' signature='(Ljava/lang/String;Lscala/Option;)Ljava/io/File;' name='org$apache$spark$deploy$history$HistoryServerDiskManager$$appStorePath' primary='true'><SourceLine endBytecode='135' classname='org.apache.spark.deploy.history.HistoryServerDiskManager' start='241' end='242' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryServerDiskManager.org$apache$spark$deploy$history$HistoryServerDiskManager$$appStorePath(String, Option)</Message></Method><SourceLine endBytecode='56' classname='org.apache.spark.deploy.history.HistoryServerDiskManager' start='242' end='242' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='56' primary='true'><Message>At HistoryServerDiskManager.scala:[line 242]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/history/HistoryServerDiskManager.org$apache$spark$deploy$history$HistoryServerDiskManager$$appStorePath(Ljava/lang/String;Lscala/Option;)Ljava/io/File; parameter 1'><Message>Unknown source org/apache/spark/deploy/history/HistoryServerDiskManager.org$apache$spark$deploy$history$HistoryServerDiskManager$$appStorePath(Ljava/lang/String;Lscala/Option;)Ljava/io/File; parameter 1</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='267' classname='org.apache.spark.deploy.history.FsHistoryProvider' start='313' end='313' sourcepath='org/apache/spark/deploy/history/FsHistoryProvider.scala' sourcefile='FsHistoryProvider.scala' startBytecode='267'><Message>At FsHistoryProvider.scala:[line 313]</Message></SourceLine><SourceLine endBytecode='33' classname='org.apache.spark.deploy.history.FsHistoryProvider' start='824' end='824' sourcepath='org/apache/spark/deploy/history/FsHistoryProvider.scala' sourcefile='FsHistoryProvider.scala' startBytecode='33'><Message>At FsHistoryProvider.scala:[line 824]</Message></SourceLine><SourceLine endBytecode='172' classname='org.apache.spark.deploy.history.FsHistoryProvider' start='846' end='846' sourcepath='org/apache/spark/deploy/history/FsHistoryProvider.scala' sourcefile='FsHistoryProvider.scala' startBytecode='172'><Message>At FsHistoryProvider.scala:[line 846]</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.deploy.history.HistoryServerDiskManager' start='130' end='130' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='11'><Message>At HistoryServerDiskManager.scala:[line 130]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.deploy.history.HistoryServerDiskManager' start='241' end='241' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='8'><Message>At HistoryServerDiskManager.scala:[line 241]</Message></SourceLine><SourceLine endBytecode='3' classname='org.apache.spark.deploy.history.HistoryServerDiskManager' start='246' end='246' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='3'><Message>At HistoryServerDiskManager.scala:[line 246]</Message></SourceLine><SourceLine endBytecode='12' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$release$1' start='159' end='159' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='12'><Message>At HistoryServerDiskManager.scala:[line 159]</Message></SourceLine><SourceLine endBytecode='6' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$Lease' start='277' end='277' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='6'><Message>At HistoryServerDiskManager.scala:[line 277]</Message></SourceLine><SourceLine endBytecode='38' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$Lease' start='280' end='280' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='38'><Message>At HistoryServerDiskManager.scala:[line 280]</Message></SourceLine><SourceLine endBytecode='259' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$Lease' start='304' end='304' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='259'><Message>At HistoryServerDiskManager.scala:[line 304]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='22a57671c58c53a2e8dbd3f554600eef' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1' start='81' end='82' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala'><Message>At HistoryServerDiskManager.scala:[lines 81-82]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1' signature='(Lorg/apache/spark/deploy/history/ApplicationStoreInfo;)Z' name='apply' primary='true'><SourceLine endBytecode='85' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1' start='82' end='82' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1.apply(ApplicationStoreInfo)</Message></Method><SourceLine endBytecode='8' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1' start='82' end='82' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='8' primary='true'><Message>At HistoryServerDiskManager.scala:[line 82]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/history/ApplicationStoreInfo.path'><Message>Unknown source org/apache/spark/deploy/history/ApplicationStoreInfo.path</Message></String><String role='Unknown source' value='org/apache/spark/deploy/history/ApplicationStoreInfo.path()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/history/ApplicationStoreInfo.path()Ljava/lang/String;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.history.ApplicationStoreInfo' start='323' end='323' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='1'><Message>At HistoryServerDiskManager.scala:[line 323]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1' start='82' end='82' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='5'><Message>At HistoryServerDiskManager.scala:[line 82]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96d822c67441ed80f2e419031a0b77d3' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2' primary='true'><SourceLine classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2' start='225' end='229' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala'><Message>At HistoryServerDiskManager.scala:[lines 225-229]</Message></SourceLine><Message>In class org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2' signature='(Lorg/apache/spark/deploy/history/ApplicationStoreInfo;)J' name='apply' primary='true'><SourceLine endBytecode='115' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2' start='226' end='229' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2.apply(ApplicationStoreInfo)</Message></Method><SourceLine endBytecode='28' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2' start='227' end='227' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='28' primary='true'><Message>At HistoryServerDiskManager.scala:[line 227]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/history/ApplicationStoreInfo.path'><Message>Unknown source org/apache/spark/deploy/history/ApplicationStoreInfo.path</Message></String><String role='Unknown source' value='org/apache/spark/deploy/history/ApplicationStoreInfo.path()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/history/ApplicationStoreInfo.path()Ljava/lang/String;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.history.ApplicationStoreInfo' start='323' end='323' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='1'><Message>At HistoryServerDiskManager.scala:[line 323]</Message></SourceLine><SourceLine endBytecode='25' classname='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2' start='227' end='227' sourcepath='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' sourcefile='HistoryServerDiskManager.scala' startBytecode='25'><Message>At HistoryServerDiskManager.scala:[line 227]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d8030beec2ad3bba7412fe9787365405' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' primary='true'><SourceLine classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='36' end='84' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala'><Message>At FileSystemPersistenceEngine.scala:[lines 36-84]</Message></SourceLine><Message>In class org.apache.spark.deploy.master.FileSystemPersistenceEngine</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' signature='(Ljava/lang/String;Lorg/apache/spark/serializer/Serializer;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='104' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='37' end='41' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.deploy.master.FileSystemPersistenceEngine(String, Serializer)</Message></Method><SourceLine endBytecode='23' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='41' end='41' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='23' primary='true'><Message>At FileSystemPersistenceEngine.scala:[line 41]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.&lt;init&gt;(Ljava/lang/String;Lorg/apache/spark/serializer/Serializer;)V parameter 1'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.&lt;init&gt;(Ljava/lang/String;Lorg/apache/spark/serializer/Serializer;)V parameter 1</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.master.FileSystemRecoveryModeFactory' start='55' end='55' sourcepath='org/apache/spark/deploy/master/RecoveryModeFactory.scala' sourcefile='RecoveryModeFactory.scala' startBytecode='1'><Message>At RecoveryModeFactory.scala:[line 55]</Message></SourceLine><SourceLine endBytecode='24' classname='org.apache.spark.deploy.master.FileSystemRecoveryModeFactory' start='59' end='59' sourcepath='org/apache/spark/deploy/master/RecoveryModeFactory.scala' sourcefile='RecoveryModeFactory.scala' startBytecode='24'><Message>At RecoveryModeFactory.scala:[line 59]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36742329891ad1de82eb5b4ed7402ec6' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' primary='true'><SourceLine classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='36' end='84' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala'><Message>At FileSystemPersistenceEngine.scala:[lines 36-84]</Message></SourceLine><Message>In class org.apache.spark.deploy.master.FileSystemPersistenceEngine</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' signature='(Ljava/lang/String;Ljava/lang/Object;)V' name='persist' primary='true'><SourceLine endBytecode='101' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='44' end='44' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.master.FileSystemPersistenceEngine.persist(String, Object)</Message></Method><SourceLine endBytecode='32' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='44' end='44' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='32' primary='true'><Message>At FileSystemPersistenceEngine.scala:[line 44]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.persist(Ljava/lang/String;Ljava/lang/Object;)V parameter 1'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.persist(Ljava/lang/String;Ljava/lang/Object;)V parameter 1</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='37' end='37' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='1'><Message>At FileSystemPersistenceEngine.scala:[line 37]</Message></SourceLine><SourceLine endBytecode='26' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='44' end='44' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='26'><Message>At FileSystemPersistenceEngine.scala:[line 44]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='edcfd31d65f6d5c5febac333cf0fb626' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' primary='true'><SourceLine classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='36' end='84' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala'><Message>At FileSystemPersistenceEngine.scala:[lines 36-84]</Message></SourceLine><Message>In class org.apache.spark.deploy.master.FileSystemPersistenceEngine</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' signature='(Ljava/lang/String;Lscala/reflect/ClassTag;)Lscala/collection/Seq;' name='read' primary='true'><SourceLine endBytecode='156' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='55' end='56' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.master.FileSystemPersistenceEngine.read(String, ClassTag)</Message></Method><SourceLine endBytecode='11' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='55' end='55' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='11' primary='true'><Message>At FileSystemPersistenceEngine.scala:[line 55]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir()Ljava/lang/String;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='37' end='37' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='1'><Message>At FileSystemPersistenceEngine.scala:[line 37]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='55' end='55' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='8'><Message>At FileSystemPersistenceEngine.scala:[line 55]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='524b64c587eca55d9d9879b7bcf14a4f' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' primary='true'><SourceLine classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='36' end='84' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala'><Message>At FileSystemPersistenceEngine.scala:[lines 36-84]</Message></SourceLine><Message>In class org.apache.spark.deploy.master.FileSystemPersistenceEngine</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' signature='(Ljava/lang/String;)V' name='unpersist' primary='true'><SourceLine endBytecode='143' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='48' end='47' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.master.FileSystemPersistenceEngine.unpersist(String)</Message></Method><SourceLine endBytecode='31' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='48' end='48' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='31' primary='true'><Message>At FileSystemPersistenceEngine.scala:[line 48]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.dir()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/master/FileSystemPersistenceEngine.unpersist(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/deploy/master/FileSystemPersistenceEngine.unpersist(Ljava/lang/String;)V parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='37' end='37' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='1'><Message>At FileSystemPersistenceEngine.scala:[line 37]</Message></SourceLine><SourceLine endBytecode='25' classname='org.apache.spark.deploy.master.FileSystemPersistenceEngine' start='48' end='48' sourcepath='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' sourcefile='FileSystemPersistenceEngine.scala' startBytecode='25'><Message>At FileSystemPersistenceEngine.scala:[line 48]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8f79f7525341144857ba996ea74c0e6f' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.master.ui.ApplicationPage' primary='true'><SourceLine classname='org.apache.spark.deploy.master.ui.ApplicationPage' start='30' end='149' sourcepath='org/apache/spark/deploy/master/ui/ApplicationPage.scala' sourcefile='ApplicationPage.scala'><Message>At ApplicationPage.scala:[lines 30-149]</Message></SourceLine><Message>In class org.apache.spark.deploy.master.ui.ApplicationPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.master.ui.ApplicationPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='6464' classname='org.apache.spark.deploy.master.ui.ApplicationPage' start='37' end='130' sourcepath='org/apache/spark/deploy/master/ui/ApplicationPage.scala' sourcefile='ApplicationPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.master.ui.ApplicationPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='6' classname='org.apache.spark.deploy.master.ui.ApplicationPage' start='37' end='37' sourcepath='org/apache/spark/deploy/master/ui/ApplicationPage.scala' sourcefile='ApplicationPage.scala' startBytecode='6' primary='true'><Message>At ApplicationPage.scala:[line 37]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d4c95e50efddd5991ce5ec5a3f2e0606' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='1'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.master.ui.MasterPage' primary='true'><SourceLine classname='org.apache.spark.deploy.master.ui.MasterPage' start='32' end='317' sourcepath='org/apache/spark/deploy/master/ui/MasterPage.scala' sourcefile='MasterPage.scala'><Message>At MasterPage.scala:[lines 32-317]</Message></SourceLine><Message>In class org.apache.spark.deploy.master.ui.MasterPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.master.ui.MasterPage' signature='(Ljavax/servlet/http/HttpServletRequest;Lscala/Function1;)V' name='handleKillRequest' primary='true'><SourceLine endBytecode='281' classname='org.apache.spark.deploy.master.ui.MasterPage' start='58' end='58' sourcepath='org/apache/spark/deploy/master/ui/MasterPage.scala' sourcefile='MasterPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.master.ui.MasterPage.handleKillRequest(HttpServletRequest, Function1)</Message></Method><SourceLine endBytecode='48' classname='org.apache.spark.deploy.master.ui.MasterPage' start='62' end='62' sourcepath='org/apache/spark/deploy/master/ui/MasterPage.scala' sourcefile='MasterPage.scala' startBytecode='48' primary='true'><Message>At MasterPage.scala:[line 62]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='d4c95e50efddd5991ce5ec5a3f2e0606' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='1'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.master.ui.MasterPage' primary='true'><SourceLine classname='org.apache.spark.deploy.master.ui.MasterPage' start='32' end='317' sourcepath='org/apache/spark/deploy/master/ui/MasterPage.scala' sourcefile='MasterPage.scala'><Message>At MasterPage.scala:[lines 32-317]</Message></SourceLine><Message>In class org.apache.spark.deploy.master.ui.MasterPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.master.ui.MasterPage' signature='(Ljavax/servlet/http/HttpServletRequest;Lscala/Function1;)V' name='handleKillRequest' primary='true'><SourceLine endBytecode='281' classname='org.apache.spark.deploy.master.ui.MasterPage' start='58' end='58' sourcepath='org/apache/spark/deploy/master/ui/MasterPage.scala' sourcefile='MasterPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.master.ui.MasterPage.handleKillRequest(HttpServletRequest, Function1)</Message></Method><SourceLine endBytecode='92' classname='org.apache.spark.deploy.master.ui.MasterPage' start='63' end='63' sourcepath='org/apache/spark/deploy/master/ui/MasterPage.scala' sourcefile='MasterPage.scala' startBytecode='92' primary='true'><Message>At MasterPage.scala:[line 63]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5ca8ab89cfe14c11897a206b81827dff' cweid='79' rank='12' abbrev='SECXSS2' category='SECURITY' priority='2' type='XSS_SERVLET' instanceOccurrenceMax='0'><ShortMessage>Potential XSS in Servlet</ShortMessage><LongMessage>This use of java/io/PrintWriter.write(Ljava/lang/String;)V could be vulnerable to XSS in the Servlet</LongMessage><Class classname='org.apache.spark.deploy.rest.RestServlet' primary='true'><SourceLine classname='org.apache.spark.deploy.rest.RestServlet' start='124' end='200' sourcepath='org/apache/spark/deploy/rest/RestSubmissionServer.scala' sourcefile='RestSubmissionServer.scala'><Message>At RestSubmissionServer.scala:[lines 124-200]</Message></SourceLine><Message>In class org.apache.spark.deploy.rest.RestServlet</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.rest.RestServlet' signature='(Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse;Ljavax/servlet/http/HttpServletResponse;)V' name='sendResponse' primary='true'><SourceLine endBytecode='120' classname='org.apache.spark.deploy.rest.RestServlet' start='133' end='136' sourcepath='org/apache/spark/deploy/rest/RestSubmissionServer.scala' sourcefile='RestSubmissionServer.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.rest.RestServlet.sendResponse(SubmitRestProtocolResponse, HttpServletResponse)</Message></Method><SourceLine endBytecode='33' classname='org.apache.spark.deploy.rest.RestServlet' start='136' end='136' sourcepath='org/apache/spark/deploy/rest/RestSubmissionServer.scala' sourcefile='RestSubmissionServer.scala' startBytecode='33' primary='true'><Message>At RestSubmissionServer.scala:[line 136]</Message></SourceLine><String role='Sink method' value='java/io/PrintWriter.write(Ljava/lang/String;)V'><Message>Sink method java/io/PrintWriter.write(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/rest/SubmitRestProtocolResponse.toJson()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/rest/SubmitRestProtocolResponse.toJson()Ljava/lang/String;</Message></String><String role='Unknown source' value='com/fasterxml/jackson/databind/ObjectMapper.writeValueAsString(Ljava/lang/Object;)Ljava/lang/String;'><Message>Unknown source com/fasterxml/jackson/databind/ObjectMapper.writeValueAsString(Ljava/lang/Object;)Ljava/lang/String;</Message></String><SourceLine endBytecode='30' classname='org.apache.spark.deploy.rest.RestServlet' start='136' end='136' sourcepath='org/apache/spark/deploy/rest/RestSubmissionServer.scala' sourcefile='RestSubmissionServer.scala' startBytecode='30'><Message>At RestSubmissionServer.scala:[line 136]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a167e25fecbd9f03d35fd2d0ed0b0845' cweid='918' rank='12' abbrev='SECSSSRFUC' category='SECURITY' priority='2' type='URLCONNECTION_SSRF_FD' instanceOccurrenceMax='0'><ShortMessage>URLConnection Server-Side Request Forgery (SSRF) and File Disclosure</ShortMessage><LongMessage>This web server request could be used by an attacker to expose internal services and filesystem.</LongMessage><Class classname='org.apache.spark.deploy.rest.RestSubmissionClient' primary='true'><SourceLine classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='61' end='392' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala'><Message>At RestSubmissionClient.scala:[lines 61-392]</Message></SourceLine><Message>In class org.apache.spark.deploy.rest.RestSubmissionClient</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.rest.RestSubmissionClient' signature='(Ljava/net/URL;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse;' name='org$apache$spark$deploy$rest$RestSubmissionClient$$get' primary='true'><SourceLine endBytecode='107' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='192' end='195' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.rest.RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$get(URL)</Message></Method><SourceLine endBytecode='14' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='193' end='193' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='14' primary='true'><Message>At RestSubmissionClient.scala:[line 193]</Message></SourceLine><String role='Sink method' value='java/net/URL.openConnection()Ljava/net/URLConnection;'><Message>Sink method java/net/URL.openConnection()Ljava/net/URLConnection;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/rest/RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$get(Ljava/net/URL;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse; parameter 0'><Message>Unknown source org/apache/spark/deploy/rest/RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$get(Ljava/net/URL;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse; parameter 0</Message></String><SourceLine endBytecode='66' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='292' end='292' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='66'><Message>At RestSubmissionClient.scala:[line 292]</Message></SourceLine><SourceLine endBytecode='17' classname='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$requestSubmissionStatus$3' start='150' end='150' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='17'><Message>At RestSubmissionClient.scala:[line 150]</Message></SourceLine><SourceLine endBytecode='30' classname='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$requestSubmissionStatus$3' start='152' end='152' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='30'><Message>At RestSubmissionClient.scala:[line 152]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d8a4d18b18d90073b4e3f20d2b6591f2' cweid='918' rank='12' abbrev='SECSSSRFUC' category='SECURITY' priority='2' type='URLCONNECTION_SSRF_FD' instanceOccurrenceMax='0'><ShortMessage>URLConnection Server-Side Request Forgery (SSRF) and File Disclosure</ShortMessage><LongMessage>This web server request could be used by an attacker to expose internal services and filesystem.</LongMessage><Class classname='org.apache.spark.deploy.rest.RestSubmissionClient' primary='true'><SourceLine classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='61' end='392' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala'><Message>At RestSubmissionClient.scala:[lines 61-392]</Message></SourceLine><Message>In class org.apache.spark.deploy.rest.RestSubmissionClient</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.rest.RestSubmissionClient' signature='(Ljava/net/URL;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse;' name='org$apache$spark$deploy$rest$RestSubmissionClient$$post' primary='true'><SourceLine endBytecode='107' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='200' end='203' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.rest.RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$post(URL)</Message></Method><SourceLine endBytecode='14' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='201' end='201' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='14' primary='true'><Message>At RestSubmissionClient.scala:[line 201]</Message></SourceLine><String role='Sink method' value='java/net/URL.openConnection()Ljava/net/URLConnection;'><Message>Sink method java/net/URL.openConnection()Ljava/net/URLConnection;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/rest/RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$post(Ljava/net/URL;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse; parameter 0'><Message>Unknown source org/apache/spark/deploy/rest/RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$post(Ljava/net/URL;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse; parameter 0</Message></String><SourceLine endBytecode='66' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='286' end='286' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='66'><Message>At RestSubmissionClient.scala:[line 286]</Message></SourceLine><SourceLine endBytecode='17' classname='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$killSubmission$3' start='118' end='118' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='17'><Message>At RestSubmissionClient.scala:[line 118]</Message></SourceLine><SourceLine endBytecode='30' classname='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$killSubmission$3' start='120' end='120' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='30'><Message>At RestSubmissionClient.scala:[line 120]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='985ef8b56097173f0246b2fe863c25a8' cweid='918' rank='12' abbrev='SECSSSRFUC' category='SECURITY' priority='2' type='URLCONNECTION_SSRF_FD' instanceOccurrenceMax='0'><ShortMessage>URLConnection Server-Side Request Forgery (SSRF) and File Disclosure</ShortMessage><LongMessage>This web server request could be used by an attacker to expose internal services and filesystem.</LongMessage><Class classname='org.apache.spark.deploy.rest.RestSubmissionClient' primary='true'><SourceLine classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='61' end='392' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala'><Message>At RestSubmissionClient.scala:[lines 61-392]</Message></SourceLine><Message>In class org.apache.spark.deploy.rest.RestSubmissionClient</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.rest.RestSubmissionClient' signature='(Ljava/net/URL;Ljava/lang/String;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse;' name='org$apache$spark$deploy$rest$RestSubmissionClient$$postJson' primary='true'><SourceLine endBytecode='295' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='208' end='223' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.rest.RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$postJson(URL, String)</Message></Method><SourceLine endBytecode='15' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='209' end='209' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='15' primary='true'><Message>At RestSubmissionClient.scala:[line 209]</Message></SourceLine><String role='Sink method' value='java/net/URL.openConnection()Ljava/net/URLConnection;'><Message>Sink method java/net/URL.openConnection()Ljava/net/URLConnection;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/rest/RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$postJson(Ljava/net/URL;Ljava/lang/String;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse; parameter 1'><Message>Unknown source org/apache/spark/deploy/rest/RestSubmissionClient.org$apache$spark$deploy$rest$RestSubmissionClient$$postJson(Ljava/net/URL;Ljava/lang/String;)Lorg/apache/spark/deploy/rest/SubmitRestProtocolResponse; parameter 1</Message></String><SourceLine endBytecode='59' classname='org.apache.spark.deploy.rest.RestSubmissionClient' start='280' end='280' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='59'><Message>At RestSubmissionClient.scala:[line 280]</Message></SourceLine><SourceLine endBytecode='13' classname='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$createSubmission$3' start='88' end='88' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='13'><Message>At RestSubmissionClient.scala:[line 88]</Message></SourceLine><SourceLine endBytecode='33' classname='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$createSubmission$3' start='90' end='90' sourcepath='org/apache/spark/deploy/rest/RestSubmissionClient.scala' sourcefile='RestSubmissionClient.scala' startBytecode='33'><Message>At RestSubmissionClient.scala:[line 90]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6c254fa1f2262528e400150710f2b570' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;([Ljava/lang/String;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.deploy.worker.CommandUtils$' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.CommandUtils$' start='35' end='118' sourcepath='org/apache/spark/deploy/worker/CommandUtils.scala' sourcefile='CommandUtils.scala'><Message>At CommandUtils.scala:[lines 35-118]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.CommandUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.CommandUtils$' signature='(Lorg/apache/spark/deploy/Command;Lorg/apache/spark/SecurityManager;ILjava/lang/String;Lscala/Function1;Lscala/collection/Seq;Lscala/collection/Map;)Ljava/lang/ProcessBuilder;' name='buildProcessBuilder' primary='true'><SourceLine endBytecode='272' classname='org.apache.spark.deploy.worker.CommandUtils$' start='49' end='57' sourcepath='org/apache/spark/deploy/worker/CommandUtils.scala' sourcefile='CommandUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.CommandUtils$.buildProcessBuilder(Command, SecurityManager, int, String, Function1, Seq, Map)</Message></Method><SourceLine endBytecode='47' classname='org.apache.spark.deploy.worker.CommandUtils$' start='52' end='52' sourcepath='org/apache/spark/deploy/worker/CommandUtils.scala' sourcefile='CommandUtils.scala' startBytecode='47' primary='true'><Message>At CommandUtils.scala:[line 52]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;([Ljava/lang/String;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;([Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/Seq.toArray(Lscala/reflect/ClassTag;)Ljava/lang/Object;'><Message>Unknown source scala/collection/Seq.toArray(Lscala/reflect/ClassTag;)Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6e4b663f271c37c46a0d03754966def7' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.DriverRunner' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.DriverRunner' start='41' end='237' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala'><Message>At DriverRunner.scala:[lines 41-237]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.DriverRunner</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.DriverRunner' signature='()Ljava/io/File;' name='createWorkingDirectory' primary='true'><SourceLine endBytecode='137' classname='org.apache.spark.deploy.worker.DriverRunner' start='139' end='141' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.DriverRunner.createWorkingDirectory()</Message></Method><SourceLine endBytecode='12' classname='org.apache.spark.deploy.worker.DriverRunner' start='139' end='139' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='12' primary='true'><Message>At DriverRunner.scala:[line 139]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/worker/DriverRunner.driverId()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/worker/DriverRunner.driverId()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/worker/DriverRunner.driverId'><Message>Unknown source org/apache/spark/deploy/worker/DriverRunner.driverId</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.worker.DriverRunner' start='43' end='43' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='1'><Message>At DriverRunner.scala:[line 43]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.deploy.worker.DriverRunner' start='139' end='139' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='9'><Message>At DriverRunner.scala:[line 139]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31078a4d6eb2dcfe9f8188f4c68e1604' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.DriverRunner' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.DriverRunner' start='41' end='237' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala'><Message>At DriverRunner.scala:[lines 41-237]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.DriverRunner</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.DriverRunner' signature='(Ljava/io/File;)Ljava/lang/String;' name='downloadUserJar' primary='true'><SourceLine endBytecode='347' classname='org.apache.spark.deploy.worker.DriverRunner' start='151' end='164' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.DriverRunner.downloadUserJar(File)</Message></Method><SourceLine endBytecode='47' classname='org.apache.spark.deploy.worker.DriverRunner' start='152' end='152' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='47' primary='true'><Message>At DriverRunner.scala:[line 152]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/ArrayOps.last()Ljava/lang/Object;'><Message>Unknown source scala/collection/mutable/ArrayOps.last()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='79f9368def48b7749b63c7c089f46040' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.DriverWrapper$' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.DriverWrapper$' start='34' end='98' sourcepath='org/apache/spark/deploy/worker/DriverWrapper.scala' sourcefile='DriverWrapper.scala'><Message>At DriverWrapper.scala:[lines 34-98]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.DriverWrapper$</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.DriverWrapper$' signature='([Ljava/lang/String;)V' name='main' primary='true'><SourceLine endBytecode='854' classname='org.apache.spark.deploy.worker.DriverWrapper$' start='36' end='36' sourcepath='org/apache/spark/deploy/worker/DriverWrapper.scala' sourcefile='DriverWrapper.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.DriverWrapper$.main(String[])</Message></Method><SourceLine endBytecode='252' classname='org.apache.spark.deploy.worker.DriverWrapper$' start='52' end='52' sourcepath='org/apache/spark/deploy/worker/DriverWrapper.scala' sourcefile='DriverWrapper.scala' startBytecode='252' primary='true'><Message>At DriverWrapper.scala:[line 52]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/immutable/$colon$colon.head()Ljava/lang/Object;'><Message>Unknown source scala/collection/immutable/$colon$colon.head()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cd0b091b6c55ae18c94f5ce8e0ad3dc2' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.Worker' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.Worker' start='43' end='740' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala'><Message>At Worker.scala:[lines 43-740]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.Worker</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.Worker' signature='(Lorg/apache/spark/rpc/RpcEnv;III[Lorg/apache/spark/rpc/RpcAddress;Ljava/lang/String;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='1481' classname='org.apache.spark.deploy.worker.Worker' start='44' end='172' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.deploy.worker.Worker(RpcEnv, int, int, int, RpcAddress[], String, String, SparkConf, SecurityManager)</Message></Method><SourceLine endBytecode='454' classname='org.apache.spark.deploy.worker.Worker' start='126' end='126' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='454' primary='true'><Message>At Worker.scala:[line 126]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/sys/SystemProperties.apply(Ljava/lang/Object;)Ljava/lang/Object;'><Message>Unknown source scala/sys/SystemProperties.apply(Ljava/lang/Object;)Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6336828f33fe422fff0f7d6a6177d991' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.Worker' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.Worker' start='43' end='740' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala'><Message>At Worker.scala:[lines 43-740]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.Worker</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.Worker' signature='(Lorg/apache/spark/rpc/RpcEnv;III[Lorg/apache/spark/rpc/RpcAddress;Ljava/lang/String;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='1481' classname='org.apache.spark.deploy.worker.Worker' start='44' end='172' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.deploy.worker.Worker(RpcEnv, int, int, int, RpcAddress[], String, String, SparkConf, SecurityManager)</Message></Method><SourceLine endBytecode='492' classname='org.apache.spark.deploy.worker.Worker' start='128' end='128' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='492' primary='true'><Message>At Worker.scala:[line 128]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='533c7cbfbc5815ad1af80c889f009c94' cweid='330' rank='12' abbrev='SECPRS' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM_SCALA' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator (Scala)</ShortMessage><LongMessage>This Scala random generator (scala.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.deploy.worker.Worker' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.Worker' start='43' end='740' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala'><Message>At Worker.scala:[lines 43-740]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.Worker</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.Worker' signature='(Lorg/apache/spark/rpc/RpcEnv;III[Lorg/apache/spark/rpc/RpcAddress;Ljava/lang/String;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='1481' classname='org.apache.spark.deploy.worker.Worker' start='44' end='172' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.deploy.worker.Worker(RpcEnv, int, int, int, RpcAddress[], String, String, SparkConf, SecurityManager)</Message></Method><SourceLine endBytecode='198' classname='org.apache.spark.deploy.worker.Worker' start='84' end='84' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='198' primary='true'><Message>At Worker.scala:[line 84]</Message></SourceLine><String value='scala.util.Random'><Message>Value scala.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='623cd677396e026c1dd6967bb085c5d7' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1' start='178' end='178' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala'><Message>At Worker.scala:[line 178]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1' signature='(Ljava/lang/String;)Ljava/io/File;' name='apply' primary='true'><SourceLine endBytecode='60' classname='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1' start='178' end='178' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1.apply(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1' start='178' end='178' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='5' primary='true'><Message>At Worker.scala:[line 178]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/worker/Worker$$anonfun$createWorkDir$1.apply(Ljava/lang/String;)Ljava/io/File; parameter 0'><Message>Unknown source org/apache/spark/deploy/worker/Worker$$anonfun$createWorkDir$1.apply(Ljava/lang/String;)Ljava/io/File; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1' start='178' end='178' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='5'><Message>At Worker.scala:[line 178]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5576af69497fadc3d95f50ed1c56d1c7' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10' start='631' end='632' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala'><Message>At Worker.scala:[lines 631-632]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='66' classname='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10' start='632' end='632' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10.apply(String)</Message></Method><SourceLine endBytecode='8' classname='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10' start='632' end='632' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='8' primary='true'><Message>At Worker.scala:[line 632]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10.apply(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/deploy/worker/Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10.apply(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10' start='631' end='631' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='5'><Message>At Worker.scala:[line 631]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f0548b927ce2bdc200a5f2d48599ecbf' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1' start='433' end='599' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala'><Message>At Worker.scala:[lines 433-599]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.Worker$$anonfun$receive$1</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1' signature='(Ljava/lang/Object;Lscala/Function1;)Ljava/lang/Object;' name='applyOrElse' primary='true'><SourceLine endBytecode='3389' classname='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1' start='433' end='433' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.Worker$$anonfun$receive$1.applyOrElse(Object, Function1)</Message></Method><SourceLine endBytecode='592' classname='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1' start='487' end='487' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='592' primary='true'><Message>At Worker.scala:[line 487]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/DeployMessages$LaunchExecutor.appId'><Message>Unknown source org/apache/spark/deploy/DeployMessages$LaunchExecutor.appId</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/deploy/DeployMessages$LaunchExecutor.appId()Ljava/lang/String;'><Message>Unknown source org/apache/spark/deploy/DeployMessages$LaunchExecutor.appId()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.DeployMessages$LaunchExecutor' start='115' end='115' sourcepath='org/apache/spark/deploy/DeployMessage.scala' sourcefile='DeployMessage.scala' startBytecode='1'><Message>At DeployMessage.scala:[line 115]</Message></SourceLine><SourceLine endBytecode='466' classname='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1' start='479' end='479' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='466'><Message>At Worker.scala:[line 479]</Message></SourceLine><SourceLine endBytecode='578' classname='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1' start='487' end='487' sourcepath='org/apache/spark/deploy/worker/Worker.scala' sourcefile='Worker.scala' startBytecode='578'><Message>At Worker.scala:[line 487]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='277487cac581775762505df3a76f3a5e' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Lorg/apache/spark/deploy/worker/ui/WorkerWebUI;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='159' classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='34' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.deploy.worker.ui.LogPage(WorkerWebUI)</Message></Method><SourceLine endBytecode='37' classname='org.apache.spark.deploy.worker.ui.LogPage' start='32' end='32' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='37' primary='true'><Message>At LogPage.scala:[line 32]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.normalize()Ljava/net/URI;'><Message>Unknown source java/net/URI.normalize()Ljava/net/URI;</Message></String><String role='Unknown source' value='java/io/File.toURI()Ljava/net/URI;'><Message>Unknown source java/io/File.toURI()Ljava/net/URI;</Message></String><SourceLine endBytecode='34' classname='org.apache.spark.deploy.worker.ui.LogPage' start='32' end='32' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='34'><Message>At LogPage.scala:[line 32]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='490395fd66cfc7b1b6d4ab7caab85284' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljava/lang/String;Ljava/lang/String;Lscala/Option;I)Lscala/Tuple4;' name='getLog' primary='true'><SourceLine endBytecode='807' classname='org.apache.spark.deploy.worker.ui.LogPage' start='132' end='130' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.getLog(String, String, Option, int)</Message></Method><SourceLine endBytecode='18' classname='org.apache.spark.deploy.worker.ui.LogPage' start='137' end='137' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='18' primary='true'><Message>At LogPage.scala:[line 137]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/deploy/worker/ui/LogPage.getLog(Ljava/lang/String;Ljava/lang/String;Lscala/Option;I)Lscala/Tuple4; parameter 3'><Message>Unknown source org/apache/spark/deploy/worker/ui/LogPage.getLog(Ljava/lang/String;Ljava/lang/String;Lscala/Option;I)Lscala/Tuple4; parameter 3</Message></String><SourceLine endBytecode='339' classname='org.apache.spark.deploy.worker.ui.LogPage' start='49' end='49' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='339'><Message>At LogPage.scala:[line 49]</Message></SourceLine><SourceLine endBytecode='489' classname='org.apache.spark.deploy.worker.ui.LogPage' start='51' end='51' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='489'><Message>At LogPage.scala:[line 51]</Message></SourceLine><SourceLine endBytecode='507' classname='org.apache.spark.deploy.worker.ui.LogPage' start='56' end='56' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='507'><Message>At LogPage.scala:[line 56]</Message></SourceLine><SourceLine endBytecode='774' classname='org.apache.spark.deploy.worker.ui.LogPage' start='81' end='81' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='774'><Message>At LogPage.scala:[line 81]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='99f5ae78e568056b4dd784af00d48322' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljava/lang/String;Ljava/lang/String;Lscala/Option;I)Lscala/Tuple4;' name='getLog' primary='true'><SourceLine endBytecode='807' classname='org.apache.spark.deploy.worker.ui.LogPage' start='132' end='130' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.getLog(String, String, Option, int)</Message></Method><SourceLine endBytecode='38' classname='org.apache.spark.deploy.worker.ui.LogPage' start='138' end='138' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='38' primary='true'><Message>At LogPage.scala:[line 138]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.normalize()Ljava/net/URI;'><Message>Unknown source java/net/URI.normalize()Ljava/net/URI;</Message></String><String role='Unknown source' value='java/io/File.toURI()Ljava/net/URI;'><Message>Unknown source java/io/File.toURI()Ljava/net/URI;</Message></String><SourceLine endBytecode='24' classname='org.apache.spark.deploy.worker.ui.LogPage' start='137' end='137' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='24'><Message>At LogPage.scala:[line 137]</Message></SourceLine><SourceLine endBytecode='35' classname='org.apache.spark.deploy.worker.ui.LogPage' start='138' end='138' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='35'><Message>At LogPage.scala:[line 138]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3e7717d4f6fc4ead92615497d44c1397' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='3400' classname='org.apache.spark.deploy.worker.ui.LogPage' start='63' end='78' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.deploy.worker.ui.LogPage' start='63' end='63' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='9' primary='true'><Message>At LogPage.scala:[line 63]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='3e7717d4f6fc4ead92615497d44c1397' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='3400' classname='org.apache.spark.deploy.worker.ui.LogPage' start='63' end='78' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.deploy.worker.ui.LogPage' start='64' end='64' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='30' primary='true'><Message>At LogPage.scala:[line 64]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='2' instanceHash='3e7717d4f6fc4ead92615497d44c1397' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='3400' classname='org.apache.spark.deploy.worker.ui.LogPage' start='63' end='78' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='51' classname='org.apache.spark.deploy.worker.ui.LogPage' start='65' end='65' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='51' primary='true'><Message>At LogPage.scala:[line 65]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='3' instanceHash='3e7717d4f6fc4ead92615497d44c1397' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='3400' classname='org.apache.spark.deploy.worker.ui.LogPage' start='63' end='78' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='70' classname='org.apache.spark.deploy.worker.ui.LogPage' start='66' end='66' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='70' primary='true'><Message>At LogPage.scala:[line 66]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='4' instanceHash='3e7717d4f6fc4ead92615497d44c1397' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='3400' classname='org.apache.spark.deploy.worker.ui.LogPage' start='63' end='78' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='89' classname='org.apache.spark.deploy.worker.ui.LogPage' start='67' end='67' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='89' primary='true'><Message>At LogPage.scala:[line 67]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='5' instanceHash='3e7717d4f6fc4ead92615497d44c1397' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='3400' classname='org.apache.spark.deploy.worker.ui.LogPage' start='63' end='78' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='122' classname='org.apache.spark.deploy.worker.ui.LogPage' start='69' end='69' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='122' primary='true'><Message>At LogPage.scala:[line 69]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='83bd2763f0bc32263e14b92abdb0625b' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Ljava/lang/String;' name='renderLog' primary='true'><SourceLine endBytecode='1262' classname='org.apache.spark.deploy.worker.ui.LogPage' start='38' end='53' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.renderLog(HttpServletRequest)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.deploy.worker.ui.LogPage' start='38' end='38' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='9' primary='true'><Message>At LogPage.scala:[line 38]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='83bd2763f0bc32263e14b92abdb0625b' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Ljava/lang/String;' name='renderLog' primary='true'><SourceLine endBytecode='1262' classname='org.apache.spark.deploy.worker.ui.LogPage' start='38' end='53' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.renderLog(HttpServletRequest)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.deploy.worker.ui.LogPage' start='39' end='39' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='30' primary='true'><Message>At LogPage.scala:[line 39]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='2' instanceHash='83bd2763f0bc32263e14b92abdb0625b' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Ljava/lang/String;' name='renderLog' primary='true'><SourceLine endBytecode='1262' classname='org.apache.spark.deploy.worker.ui.LogPage' start='38' end='53' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.renderLog(HttpServletRequest)</Message></Method><SourceLine endBytecode='51' classname='org.apache.spark.deploy.worker.ui.LogPage' start='40' end='40' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='51' primary='true'><Message>At LogPage.scala:[line 40]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='3' instanceHash='83bd2763f0bc32263e14b92abdb0625b' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Ljava/lang/String;' name='renderLog' primary='true'><SourceLine endBytecode='1262' classname='org.apache.spark.deploy.worker.ui.LogPage' start='38' end='53' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.renderLog(HttpServletRequest)</Message></Method><SourceLine endBytecode='70' classname='org.apache.spark.deploy.worker.ui.LogPage' start='41' end='41' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='70' primary='true'><Message>At LogPage.scala:[line 41]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='4' instanceHash='83bd2763f0bc32263e14b92abdb0625b' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Ljava/lang/String;' name='renderLog' primary='true'><SourceLine endBytecode='1262' classname='org.apache.spark.deploy.worker.ui.LogPage' start='38' end='53' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.renderLog(HttpServletRequest)</Message></Method><SourceLine endBytecode='89' classname='org.apache.spark.deploy.worker.ui.LogPage' start='42' end='42' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='89' primary='true'><Message>At LogPage.scala:[line 42]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='5' instanceHash='83bd2763f0bc32263e14b92abdb0625b' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.deploy.worker.ui.LogPage' primary='true'><SourceLine classname='org.apache.spark.deploy.worker.ui.LogPage' start='30' end='167' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala'><Message>At LogPage.scala:[lines 30-167]</Message></SourceLine><Message>In class org.apache.spark.deploy.worker.ui.LogPage</Message></Class><Method isStatic='false' classname='org.apache.spark.deploy.worker.ui.LogPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Ljava/lang/String;' name='renderLog' primary='true'><SourceLine endBytecode='1262' classname='org.apache.spark.deploy.worker.ui.LogPage' start='38' end='53' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.deploy.worker.ui.LogPage.renderLog(HttpServletRequest)</Message></Method><SourceLine endBytecode='122' classname='org.apache.spark.deploy.worker.ui.LogPage' start='44' end='44' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='122' primary='true'><Message>At LogPage.scala:[line 44]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e8120c05949bea292cf93592791eefa0' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.executor.Executor$$anonfun$10' primary='true'><SourceLine classname='org.apache.spark.executor.Executor$$anonfun$10' start='696' end='697' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala'><Message>At Executor.scala:[lines 696-697]</Message></SourceLine><Message>In class org.apache.spark.executor.Executor$$anonfun$10</Message></Class><Method isStatic='false' classname='org.apache.spark.executor.Executor$$anonfun$10' signature='(Ljava/lang/String;)Ljava/net/URL;' name='apply' primary='true'><SourceLine endBytecode='88' classname='org.apache.spark.executor.Executor$$anonfun$10' start='697' end='697' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.executor.Executor$$anonfun$10.apply(String)</Message></Method><SourceLine endBytecode='27' classname='org.apache.spark.executor.Executor$$anonfun$10' start='697' end='697' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='27' primary='true'><Message>At Executor.scala:[line 697]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/ArrayOps.last()Ljava/lang/Object;'><Message>Unknown source scala/collection/mutable/ArrayOps.last()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5638cfc8ff224c8fc0048b73d42e4164' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' primary='true'><SourceLine classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' start='740' end='745' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala'><Message>At Executor.scala:[lines 740-745]</Message></SourceLine><Message>In class org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3</Message></Class><Method isStatic='false' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' signature='(Lscala/Tuple2;)V' name='apply' primary='true'><SourceLine endBytecode='324' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' start='740' end='740' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3.apply(Tuple2)</Message></Method><SourceLine endBytecode='52' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' start='743' end='743' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='52' primary='true'><Message>At Executor.scala:[line 743]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkFiles$.getRootDirectory()Ljava/lang/String;'><Message>Unknown source org/apache/spark/SparkFiles$.getRootDirectory()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String><SourceLine endBytecode='49' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' start='743' end='743' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='49'><Message>At Executor.scala:[line 743]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='76e62ada6368fa2714884ac1c3e3e0ac' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' primary='true'><SourceLine classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='747' end='762' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala'><Message>At Executor.scala:[lines 747-762]</Message></SourceLine><Message>In class org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5</Message></Class><Method isStatic='false' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' signature='(Lscala/Tuple2;)V' name='apply' primary='true'><SourceLine endBytecode='610' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='747' end='747' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Tuple2)</Message></Method><SourceLine endBytecode='135' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='755' end='755' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='135' primary='true'><Message>At Executor.scala:[line 755]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkFiles$.getRootDirectory()Ljava/lang/String;'><Message>Unknown source org/apache/spark/SparkFiles$.getRootDirectory()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String><SourceLine endBytecode='132' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='755' end='755' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='132'><Message>At Executor.scala:[line 755]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4fc4f696f8378a226d2e9ebd7e8528f4' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' primary='true'><SourceLine classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='747' end='762' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala'><Message>At Executor.scala:[lines 747-762]</Message></SourceLine><Message>In class org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5</Message></Class><Method isStatic='false' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' signature='(Lscala/Tuple2;)V' name='apply' primary='true'><SourceLine endBytecode='610' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='747' end='747' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5.apply(Tuple2)</Message></Method><SourceLine endBytecode='219' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='759' end='759' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='219' primary='true'><Message>At Executor.scala:[line 759]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/ArrayOps.last()Ljava/lang/Object;'><Message>Unknown source scala/collection/mutable/ArrayOps.last()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dbe4cb55dba1ad1ab865a8fe19b47bfb' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;)V' name='logDebug' primary='true'><SourceLine endBytecode='95' classname='org.apache.spark.internal.Logging$class' start='58' end='58' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logDebug(Logging, Function0)</Message></Method><SourceLine endBytecode='29' classname='org.apache.spark.internal.Logging$class' start='58' end='58' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='29' primary='true'><Message>At Logging.scala:[line 58]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e3aa157ad00132a605f488d2077db41d' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;Ljava/lang/Throwable;)V' name='logDebug' primary='true'><SourceLine endBytecode='106' classname='org.apache.spark.internal.Logging$class' start='79' end='79' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logDebug(Logging, Function0, Throwable)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.internal.Logging$class' start='79' end='79' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='30' primary='true'><Message>At Logging.scala:[line 79]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5865a0c0ad42401c7407bb31e3ab6d39' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;)V' name='logError' primary='true'><SourceLine endBytecode='95' classname='org.apache.spark.internal.Logging$class' start='70' end='70' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logError(Logging, Function0)</Message></Method><SourceLine endBytecode='29' classname='org.apache.spark.internal.Logging$class' start='70' end='70' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='29' primary='true'><Message>At Logging.scala:[line 70]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9936c1f849c669765e24b283ba59473a' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;Ljava/lang/Throwable;)V' name='logError' primary='true'><SourceLine endBytecode='106' classname='org.apache.spark.internal.Logging$class' start='91' end='91' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logError(Logging, Function0, Throwable)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.internal.Logging$class' start='91' end='91' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='30' primary='true'><Message>At Logging.scala:[line 91]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ef052db9ff74b578cf28a867a067e43e' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.info(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;)V' name='logInfo' primary='true'><SourceLine endBytecode='95' classname='org.apache.spark.internal.Logging$class' start='54' end='54' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logInfo(Logging, Function0)</Message></Method><SourceLine endBytecode='29' classname='org.apache.spark.internal.Logging$class' start='54' end='54' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='29' primary='true'><Message>At Logging.scala:[line 54]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.info(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.info(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9125fe2076f95ba2118a8d0a31b83eb2' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.info(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;Ljava/lang/Throwable;)V' name='logInfo' primary='true'><SourceLine endBytecode='106' classname='org.apache.spark.internal.Logging$class' start='75' end='75' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logInfo(Logging, Function0, Throwable)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.internal.Logging$class' start='75' end='75' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='30' primary='true'><Message>At Logging.scala:[line 75]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.info(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.info(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8d3b505d1dc261bb1dabd84d8dabd6cd' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.trace(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;)V' name='logTrace' primary='true'><SourceLine endBytecode='95' classname='org.apache.spark.internal.Logging$class' start='62' end='62' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logTrace(Logging, Function0)</Message></Method><SourceLine endBytecode='29' classname='org.apache.spark.internal.Logging$class' start='62' end='62' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='29' primary='true'><Message>At Logging.scala:[line 62]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.trace(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.trace(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d2cf0e87bbb59c2257e2d8a1a9c90326' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.trace(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;Ljava/lang/Throwable;)V' name='logTrace' primary='true'><SourceLine endBytecode='106' classname='org.apache.spark.internal.Logging$class' start='83' end='83' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logTrace(Logging, Function0, Throwable)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.internal.Logging$class' start='83' end='83' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='30' primary='true'><Message>At Logging.scala:[line 83]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.trace(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.trace(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='43a8b5d8bd2f937d4d530a0eec7ae98' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.warn(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;)V' name='logWarning' primary='true'><SourceLine endBytecode='95' classname='org.apache.spark.internal.Logging$class' start='66' end='66' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logWarning(Logging, Function0)</Message></Method><SourceLine endBytecode='29' classname='org.apache.spark.internal.Logging$class' start='66' end='66' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='29' primary='true'><Message>At Logging.scala:[line 66]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.warn(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.warn(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4ea4174097cde08a3da3fcca61c5b3b9' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.warn(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.internal.Logging$class' primary='true'><SourceLine classname='org.apache.spark.internal.Logging$class' start='35' end='161' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala'><Message>At Logging.scala:[lines 35-161]</Message></SourceLine><Message>In class org.apache.spark.internal.Logging$class</Message></Class><Method isStatic='true' classname='org.apache.spark.internal.Logging$class' signature='(Lorg/apache/spark/internal/Logging;Lscala/Function0;Ljava/lang/Throwable;)V' name='logWarning' primary='true'><SourceLine endBytecode='106' classname='org.apache.spark.internal.Logging$class' start='87' end='87' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.internal.Logging$class.logWarning(Logging, Function0, Throwable)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.internal.Logging$class' start='87' end='87' sourcepath='org/apache/spark/internal/Logging.scala' sourcefile='Logging.scala' startBytecode='30' primary='true'><Message>At Logging.scala:[line 87]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.warn(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.warn(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='scala/Function0.apply()Ljava/lang/Object;'><Message>Unknown source scala/Function0.apply()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f9232ff48e8507c0e4b88e9b5c31834f' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.warn(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.io.ReadAheadInputStream' primary='true'><SourceLine classname='org.apache.spark.io.ReadAheadInputStream' start='42' end='410' sourcepath='org/apache/spark/io/ReadAheadInputStream.java' sourcefile='ReadAheadInputStream.java'><Message>At ReadAheadInputStream.java:[lines 42-410]</Message></SourceLine><Message>In class org.apache.spark.io.ReadAheadInputStream</Message></Class><Method isStatic='false' classname='org.apache.spark.io.ReadAheadInputStream' signature='()V' name='closeUnderlyingInputStreamIfNecessary' primary='true'><SourceLine endBytecode='234' classname='org.apache.spark.io.ReadAheadInputStream' start='202' end='220' sourcepath='org/apache/spark/io/ReadAheadInputStream.java' sourcefile='ReadAheadInputStream.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.io.ReadAheadInputStream.closeUnderlyingInputStreamIfNecessary()</Message></Method><SourceLine endBytecode='73' classname='org.apache.spark.io.ReadAheadInputStream' start='217' end='217' sourcepath='org/apache/spark/io/ReadAheadInputStream.java' sourcefile='ReadAheadInputStream.java' startBytecode='73' primary='true'><Message>At ReadAheadInputStream.java:[line 217]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.warn(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.warn(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='java/io/IOException.getMessage()Ljava/lang/String;'><Message>Unknown source java/io/IOException.getMessage()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bfec2af83611e25113faec4a4de8e833' cweid='319' rank='12' abbrev='SECUS' category='SECURITY' priority='2' type='UNENCRYPTED_SOCKET' instanceOccurrenceMax='0'><ShortMessage>Unencrypted Socket</ShortMessage><LongMessage>Unencrypted socket to org.apache.spark.launcher.LauncherBackend (instead of SSLSocket)</LongMessage><Class classname='org.apache.spark.launcher.LauncherBackend' primary='true'><SourceLine classname='org.apache.spark.launcher.LauncherBackend' start='34' end='128' sourcepath='org/apache/spark/launcher/LauncherBackend.scala' sourcefile='LauncherBackend.scala'><Message>At LauncherBackend.scala:[lines 34-128]</Message></SourceLine><Message>In class org.apache.spark.launcher.LauncherBackend</Message></Class><Method isStatic='false' classname='org.apache.spark.launcher.LauncherBackend' signature='()V' name='connect' primary='true'><SourceLine endBytecode='383' classname='org.apache.spark.launcher.LauncherBackend' start='42' end='41' sourcepath='org/apache/spark/launcher/LauncherBackend.scala' sourcefile='LauncherBackend.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.launcher.LauncherBackend.connect()</Message></Method><SourceLine endBytecode='118' classname='org.apache.spark.launcher.LauncherBackend' start='48' end='48' sourcepath='org/apache/spark/launcher/LauncherBackend.scala' sourcefile='LauncherBackend.scala' startBytecode='118' primary='true'><Message>At LauncherBackend.scala:[line 48]</Message></SourceLine><String value='remote host'><Message>Value remote host</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d5f7dc9e1a84e373c0dcd2f48313130a' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='acquireExecutionMemory' primary='true'><SourceLine endBytecode='1395' classname='org.apache.spark.memory.TaskMemoryManager' start='139' end='224' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='323' classname='org.apache.spark.memory.TaskMemoryManager' start='182' end='182' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='323' primary='true'><Message>At TaskMemoryManager.java:[line 182]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/util/TreeMap.ceilingEntry(Ljava/lang/Object;)Ljava/util/Map$Entry;'><Message>Unknown source java/util/TreeMap.ceilingEntry(Ljava/lang/Object;)Ljava/util/Map$Entry;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='java/util/Map$Entry.getValue()Ljava/lang/Object;'><Message>Unknown source java/util/Map$Entry.getValue()Ljava/lang/Object;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='java/util/TreeMap.lastEntry()Ljava/util/Map$Entry;'><Message>Unknown source java/util/TreeMap.lastEntry()Ljava/util/Map$Entry;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0</Message></String><String role='Unknown source' value='scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;'><Message>Unknown source scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;</Message></String><String role='Unknown source' value='scala/math/BigDecimal.toString()Ljava/lang/String;'><Message>Unknown source scala/math/BigDecimal.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='214' classname='org.apache.spark.memory.TaskMemoryManager' start='174' end='174' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='214'><Message>At TaskMemoryManager.java:[line 174]</Message></SourceLine><SourceLine endBytecode='235' classname='org.apache.spark.memory.TaskMemoryManager' start='175' end='175' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='235'><Message>At TaskMemoryManager.java:[line 175]</Message></SourceLine><SourceLine endBytecode='275' classname='org.apache.spark.memory.TaskMemoryManager' start='180' end='180' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='275'><Message>At TaskMemoryManager.java:[line 180]</Message></SourceLine><SourceLine endBytecode='310' classname='org.apache.spark.memory.TaskMemoryManager' start='183' end='183' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='310'><Message>At TaskMemoryManager.java:[line 183]</Message></SourceLine><SourceLine endBytecode='497' classname='org.apache.spark.memory.TaskMemoryManager' start='204' end='204' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='497'><Message>At TaskMemoryManager.java:[line 204]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.memory.TaskMemoryManager' start='283' end='283' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='63'><Message>At TaskMemoryManager.java:[line 283]</Message></SourceLine><SourceLine endBytecode='221' classname='org.apache.spark.memory.TaskMemoryManager' start='310' end='310' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='221'><Message>At TaskMemoryManager.java:[line 310]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$' start='1168' end='1168' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>At Utils.scala:[line 1168]</Message></SourceLine><SourceLine endBytecode='86' classname='org.apache.spark.util.Utils$' start='1180' end='1180' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='86'><Message>At Utils.scala:[line 1180]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c0672cb5b1a80f32d25c38947b38e93d' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='acquireExecutionMemory' primary='true'><SourceLine endBytecode='1395' classname='org.apache.spark.memory.TaskMemoryManager' start='139' end='224' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='390' classname='org.apache.spark.memory.TaskMemoryManager' start='191' end='191' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='390' primary='true'><Message>At TaskMemoryManager.java:[line 191]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='java/util/TreeMap.ceilingEntry(Ljava/lang/Object;)Ljava/util/Map$Entry;'><Message>Unknown source java/util/TreeMap.ceilingEntry(Ljava/lang/Object;)Ljava/util/Map$Entry;</Message></String><String role='Unknown source' value='java/util/Map$Entry.getValue()Ljava/lang/Object;'><Message>Unknown source java/util/Map$Entry.getValue()Ljava/lang/Object;</Message></String><String role='Unknown source' value='java/util/TreeMap.lastEntry()Ljava/util/Map$Entry;'><Message>Unknown source java/util/TreeMap.lastEntry()Ljava/util/Map$Entry;</Message></String><SourceLine endBytecode='214' classname='org.apache.spark.memory.TaskMemoryManager' start='174' end='174' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='214'><Message>At TaskMemoryManager.java:[line 174]</Message></SourceLine><SourceLine endBytecode='235' classname='org.apache.spark.memory.TaskMemoryManager' start='175' end='175' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='235'><Message>At TaskMemoryManager.java:[line 175]</Message></SourceLine><SourceLine endBytecode='382' classname='org.apache.spark.memory.TaskMemoryManager' start='191' end='191' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='382'><Message>At TaskMemoryManager.java:[line 191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='c0672cb5b1a80f32d25c38947b38e93d' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='acquireExecutionMemory' primary='true'><SourceLine endBytecode='1395' classname='org.apache.spark.memory.TaskMemoryManager' start='139' end='224' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='435' classname='org.apache.spark.memory.TaskMemoryManager' start='194' end='194' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='435' primary='true'><Message>At TaskMemoryManager.java:[line 194]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='java/util/TreeMap.ceilingEntry(Ljava/lang/Object;)Ljava/util/Map$Entry;'><Message>Unknown source java/util/TreeMap.ceilingEntry(Ljava/lang/Object;)Ljava/util/Map$Entry;</Message></String><String role='Unknown source' value='java/util/Map$Entry.getValue()Ljava/lang/Object;'><Message>Unknown source java/util/Map$Entry.getValue()Ljava/lang/Object;</Message></String><String role='Unknown source' value='java/util/TreeMap.lastEntry()Ljava/util/Map$Entry;'><Message>Unknown source java/util/TreeMap.lastEntry()Ljava/util/Map$Entry;</Message></String><SourceLine endBytecode='214' classname='org.apache.spark.memory.TaskMemoryManager' start='174' end='174' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='214'><Message>At TaskMemoryManager.java:[line 174]</Message></SourceLine><SourceLine endBytecode='235' classname='org.apache.spark.memory.TaskMemoryManager' start='175' end='175' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='235'><Message>At TaskMemoryManager.java:[line 175]</Message></SourceLine><SourceLine endBytecode='430' classname='org.apache.spark.memory.TaskMemoryManager' start='194' end='194' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='430'><Message>At TaskMemoryManager.java:[line 194]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c3afa45805baca13857f1884e13b556d' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='acquireExecutionMemory' primary='true'><SourceLine endBytecode='1395' classname='org.apache.spark.memory.TaskMemoryManager' start='139' end='224' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='540' classname='org.apache.spark.memory.TaskMemoryManager' start='206' end='206' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='540' primary='true'><Message>At TaskMemoryManager.java:[line 206]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;'><Message>Unknown source scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal.toString()Ljava/lang/String;'><Message>Unknown source scala/math/BigDecimal.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='275' classname='org.apache.spark.memory.TaskMemoryManager' start='180' end='180' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='275'><Message>At TaskMemoryManager.java:[line 180]</Message></SourceLine><SourceLine endBytecode='497' classname='org.apache.spark.memory.TaskMemoryManager' start='204' end='204' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='497'><Message>At TaskMemoryManager.java:[line 204]</Message></SourceLine><SourceLine endBytecode='532' classname='org.apache.spark.memory.TaskMemoryManager' start='207' end='207' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='532'><Message>At TaskMemoryManager.java:[line 207]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.memory.TaskMemoryManager' start='283' end='283' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='63'><Message>At TaskMemoryManager.java:[line 283]</Message></SourceLine><SourceLine endBytecode='221' classname='org.apache.spark.memory.TaskMemoryManager' start='310' end='310' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='221'><Message>At TaskMemoryManager.java:[line 310]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$' start='1168' end='1168' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>At Utils.scala:[line 1168]</Message></SourceLine><SourceLine endBytecode='86' classname='org.apache.spark.util.Utils$' start='1180' end='1180' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='86'><Message>At Utils.scala:[line 1180]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='be7e0e2722bcd1ad72ffeb13ea6917a6' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='acquireExecutionMemory' primary='true'><SourceLine endBytecode='1395' classname='org.apache.spark.memory.TaskMemoryManager' start='139' end='224' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='596' classname='org.apache.spark.memory.TaskMemoryManager' start='212' end='212' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='596' primary='true'><Message>At TaskMemoryManager.java:[line 212]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='275' classname='org.apache.spark.memory.TaskMemoryManager' start='180' end='180' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='275'><Message>At TaskMemoryManager.java:[line 180]</Message></SourceLine><SourceLine endBytecode='497' classname='org.apache.spark.memory.TaskMemoryManager' start='204' end='204' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='497'><Message>At TaskMemoryManager.java:[line 204]</Message></SourceLine><SourceLine endBytecode='588' classname='org.apache.spark.memory.TaskMemoryManager' start='212' end='212' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='588'><Message>At TaskMemoryManager.java:[line 212]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.memory.TaskMemoryManager' start='283' end='283' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='63'><Message>At TaskMemoryManager.java:[line 283]</Message></SourceLine><SourceLine endBytecode='221' classname='org.apache.spark.memory.TaskMemoryManager' start='310' end='310' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='221'><Message>At TaskMemoryManager.java:[line 310]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='be7e0e2722bcd1ad72ffeb13ea6917a6' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='acquireExecutionMemory' primary='true'><SourceLine endBytecode='1395' classname='org.apache.spark.memory.TaskMemoryManager' start='139' end='224' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='640' classname='org.apache.spark.memory.TaskMemoryManager' start='215' end='215' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='640' primary='true'><Message>At TaskMemoryManager.java:[line 215]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Throwable;)V</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='275' classname='org.apache.spark.memory.TaskMemoryManager' start='180' end='180' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='275'><Message>At TaskMemoryManager.java:[line 180]</Message></SourceLine><SourceLine endBytecode='497' classname='org.apache.spark.memory.TaskMemoryManager' start='204' end='204' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='497'><Message>At TaskMemoryManager.java:[line 204]</Message></SourceLine><SourceLine endBytecode='632' classname='org.apache.spark.memory.TaskMemoryManager' start='215' end='215' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='632'><Message>At TaskMemoryManager.java:[line 215]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.memory.TaskMemoryManager' start='283' end='283' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='63'><Message>At TaskMemoryManager.java:[line 283]</Message></SourceLine><SourceLine endBytecode='221' classname='org.apache.spark.memory.TaskMemoryManager' start='310' end='310' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='221'><Message>At TaskMemoryManager.java:[line 310]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='c3afa45805baca13857f1884e13b556d' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='acquireExecutionMemory' primary='true'><SourceLine endBytecode='1395' classname='org.apache.spark.memory.TaskMemoryManager' start='139' end='224' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='725' classname='org.apache.spark.memory.TaskMemoryManager' start='222' end='222' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='725' primary='true'><Message>At TaskMemoryManager.java:[line 222]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.acquireExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)J parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;'><Message>Unknown source scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal.toString()Ljava/lang/String;'><Message>Unknown source scala/math/BigDecimal.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='275' classname='org.apache.spark.memory.TaskMemoryManager' start='180' end='180' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='275'><Message>At TaskMemoryManager.java:[line 180]</Message></SourceLine><SourceLine endBytecode='497' classname='org.apache.spark.memory.TaskMemoryManager' start='204' end='204' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='497'><Message>At TaskMemoryManager.java:[line 204]</Message></SourceLine><SourceLine endBytecode='717' classname='org.apache.spark.memory.TaskMemoryManager' start='222' end='222' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='717'><Message>At TaskMemoryManager.java:[line 222]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.memory.TaskMemoryManager' start='283' end='283' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='63'><Message>At TaskMemoryManager.java:[line 283]</Message></SourceLine><SourceLine endBytecode='221' classname='org.apache.spark.memory.TaskMemoryManager' start='310' end='310' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='221'><Message>At TaskMemoryManager.java:[line 310]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$' start='1168' end='1168' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>At Utils.scala:[line 1168]</Message></SourceLine><SourceLine endBytecode='86' classname='org.apache.spark.util.Utils$' start='1180' end='1180' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='86'><Message>At Utils.scala:[line 1180]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f633b4227b847dd4c49c001f8c003563' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='()J' name='cleanUpAllAllocatedMemory' primary='true'><SourceLine endBytecode='423' classname='org.apache.spark.memory.TaskMemoryManager' start='423' end='445' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.cleanUpAllAllocatedMemory()</Message></Method><SourceLine endBytecode='81' classname='org.apache.spark.memory.TaskMemoryManager' start='427' end='427' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='81' primary='true'><Message>At TaskMemoryManager.java:[line 427]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.consumers'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.consumers</Message></String><String role='Unknown source' value='java/util/HashSet.iterator()Ljava/util/Iterator;'><Message>Unknown source java/util/HashSet.iterator()Ljava/util/Iterator;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='java/util/Iterator.next()Ljava/lang/Object;'><Message>Unknown source java/util/Iterator.next()Ljava/lang/Object;</Message></String><String role='Unknown source' value='scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;'><Message>Unknown source scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;</Message></String><String role='Unknown source' value='scala/math/BigDecimal.toString()Ljava/lang/String;'><Message>Unknown source scala/math/BigDecimal.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='22' classname='org.apache.spark.memory.TaskMemoryManager' start='424' end='424' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='22'><Message>At TaskMemoryManager.java:[line 424]</Message></SourceLine><SourceLine endBytecode='71' classname='org.apache.spark.memory.TaskMemoryManager' start='427' end='427' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='71'><Message>At TaskMemoryManager.java:[line 427]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$' start='1168' end='1168' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>At Utils.scala:[line 1168]</Message></SourceLine><SourceLine endBytecode='86' classname='org.apache.spark.util.Utils$' start='1180' end='1180' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='86'><Message>At Utils.scala:[line 1180]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d111558e52d64492b4dfef3cd49bc71a' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='()J' name='cleanUpAllAllocatedMemory' primary='true'><SourceLine endBytecode='423' classname='org.apache.spark.memory.TaskMemoryManager' start='423' end='445' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.cleanUpAllAllocatedMemory()</Message></Method><SourceLine endBytecode='159' classname='org.apache.spark.memory.TaskMemoryManager' start='434' end='434' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='159' primary='true'><Message>At TaskMemoryManager.java:[line 434]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.pageTable'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.pageTable</Message></String><SourceLine endBytecode='97' classname='org.apache.spark.memory.TaskMemoryManager' start='432' end='432' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='97'><Message>At TaskMemoryManager.java:[line 432]</Message></SourceLine><SourceLine endBytecode='141' classname='org.apache.spark.memory.TaskMemoryManager' start='434' end='434' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='141'><Message>At TaskMemoryManager.java:[line 434]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96b21bea612e1674b7e705c05025d50b' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='(JLorg/apache/spark/memory/MemoryConsumer;)V' name='releaseExecutionMemory' primary='true'><SourceLine endBytecode='121' classname='org.apache.spark.memory.TaskMemoryManager' start='231' end='233' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.releaseExecutionMemory(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='30' classname='org.apache.spark.memory.TaskMemoryManager' start='231' end='231' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='30' primary='true'><Message>At TaskMemoryManager.java:[line 231]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;[Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;'><Message>Unknown source scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.releaseExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)V parameter 0'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.releaseExecutionMemory(JLorg/apache/spark/memory/MemoryConsumer;)V parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal.toString()Ljava/lang/String;'><Message>Unknown source scala/math/BigDecimal.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='275' classname='org.apache.spark.memory.TaskMemoryManager' start='180' end='180' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='275'><Message>At TaskMemoryManager.java:[line 180]</Message></SourceLine><SourceLine endBytecode='497' classname='org.apache.spark.memory.TaskMemoryManager' start='204' end='204' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='497'><Message>At TaskMemoryManager.java:[line 204]</Message></SourceLine><SourceLine endBytecode='22' classname='org.apache.spark.memory.TaskMemoryManager' start='231' end='231' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='22'><Message>At TaskMemoryManager.java:[line 231]</Message></SourceLine><SourceLine endBytecode='104' classname='org.apache.spark.memory.TaskMemoryManager' start='292' end='292' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='104'><Message>At TaskMemoryManager.java:[line 292]</Message></SourceLine><SourceLine endBytecode='221' classname='org.apache.spark.memory.TaskMemoryManager' start='310' end='310' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='221'><Message>At TaskMemoryManager.java:[line 310]</Message></SourceLine><SourceLine endBytecode='201' classname='org.apache.spark.memory.TaskMemoryManager' start='344' end='344' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='201'><Message>At TaskMemoryManager.java:[line 344]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$' start='1168' end='1168' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>At Utils.scala:[line 1168]</Message></SourceLine><SourceLine endBytecode='86' classname='org.apache.spark.util.Utils$' start='1180' end='1180' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='86'><Message>At Utils.scala:[line 1180]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c48c3a56939d8ed0184d91612ad7fa03' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.info(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.memory.TaskMemoryManager' primary='true'><SourceLine classname='org.apache.spark.memory.TaskMemoryManager' start='59' end='459' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java'><Message>At TaskMemoryManager.java:[lines 59-459]</Message></SourceLine><Message>In class org.apache.spark.memory.TaskMemoryManager</Message></Class><Method isStatic='false' classname='org.apache.spark.memory.TaskMemoryManager' signature='()V' name='showMemoryUsage' primary='true'><SourceLine endBytecode='422' classname='org.apache.spark.memory.TaskMemoryManager' start='239' end='258' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.memory.TaskMemoryManager.showMemoryUsage()</Message></Method><SourceLine endBytecode='122' classname='org.apache.spark.memory.TaskMemoryManager' start='246' end='246' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='122' primary='true'><Message>At TaskMemoryManager.java:[line 246]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.info(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.info(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/memory/TaskMemoryManager.consumers'><Message>Unknown source org/apache/spark/memory/TaskMemoryManager.consumers</Message></String><String role='Unknown source' value='java/util/HashSet.iterator()Ljava/util/Iterator;'><Message>Unknown source java/util/HashSet.iterator()Ljava/util/Iterator;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;'><Message>Unknown source scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;</Message></String><String role='Unknown source' value='java/util/Iterator.next()Ljava/lang/Object;'><Message>Unknown source java/util/Iterator.next()Ljava/lang/Object;</Message></String><String role='Unknown source' value='scala/math/BigDecimal.toString()Ljava/lang/String;'><Message>Unknown source scala/math/BigDecimal.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='57' classname='org.apache.spark.memory.TaskMemoryManager' start='242' end='242' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='57'><Message>At TaskMemoryManager.java:[line 242]</Message></SourceLine><SourceLine endBytecode='113' classname='org.apache.spark.memory.TaskMemoryManager' start='246' end='246' sourcepath='org/apache/spark/memory/TaskMemoryManager.java' sourcefile='TaskMemoryManager.java' startBytecode='113'><Message>At TaskMemoryManager.java:[line 246]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$' start='1168' end='1168' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>At Utils.scala:[line 1168]</Message></SourceLine><SourceLine endBytecode='86' classname='org.apache.spark.util.Utils$' start='1180' end='1180' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='86'><Message>At Utils.scala:[line 1180]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='99af8339eb76af169ab292fa3e0b6bb0' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.metrics.MetricsConfig' primary='true'><SourceLine classname='org.apache.spark.metrics.MetricsConfig' start='31' end='145' sourcepath='org/apache/spark/metrics/MetricsConfig.scala' sourcefile='MetricsConfig.scala'><Message>At MetricsConfig.scala:[lines 31-145]</Message></SourceLine><Message>In class org.apache.spark.metrics.MetricsConfig</Message></Class><Method isStatic='false' classname='org.apache.spark.metrics.MetricsConfig' signature='(Lscala/Option;)V' name='loadPropertiesFromFile' primary='true'><SourceLine endBytecode='390' classname='org.apache.spark.metrics.MetricsConfig' start='129' end='128' sourcepath='org/apache/spark/metrics/MetricsConfig.scala' sourcefile='MetricsConfig.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.metrics.MetricsConfig.loadPropertiesFromFile(Option)</Message></Method><SourceLine endBytecode='36' classname='org.apache.spark.metrics.MetricsConfig' start='132' end='132' sourcepath='org/apache/spark/metrics/MetricsConfig.scala' sourcefile='MetricsConfig.scala' startBytecode='36' primary='true'><Message>At MetricsConfig.scala:[line 132]</Message></SourceLine><String role='Sink method' value='java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Some.x()Ljava/lang/Object;'><Message>Unknown source scala/Some.x()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4e947778f6132a57e0954d11c51b5923' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.metrics.sink.CsvSink' primary='true'><SourceLine classname='org.apache.spark.metrics.sink.CsvSink' start='29' end='71' sourcepath='org/apache/spark/metrics/sink/CsvSink.scala' sourcefile='CsvSink.scala'><Message>At CsvSink.scala:[lines 29-71]</Message></SourceLine><Message>In class org.apache.spark.metrics.sink.CsvSink</Message></Class><Method isStatic='false' classname='org.apache.spark.metrics.sink.CsvSink' signature='(Ljava/util/Properties;Lcom/codahale/metrics/MetricRegistry;Lorg/apache/spark/SecurityManager;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='899' classname='org.apache.spark.metrics.sink.CsvSink' start='29' end='39' sourcepath='org/apache/spark/metrics/sink/CsvSink.scala' sourcefile='CsvSink.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.metrics.sink.CsvSink(Properties, MetricRegistry, SecurityManager)</Message></Method><SourceLine endBytecode='336' classname='org.apache.spark.metrics.sink.CsvSink' start='60' end='60' sourcepath='org/apache/spark/metrics/sink/CsvSink.scala' sourcefile='CsvSink.scala' startBytecode='336' primary='true'><Message>At CsvSink.scala:[line 60]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/metrics/sink/CsvSink.pollDir()Ljava/lang/String;'><Message>Unknown source org/apache/spark/metrics/sink/CsvSink.pollDir()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/metrics/sink/CsvSink.pollDir'><Message>Unknown source org/apache/spark/metrics/sink/CsvSink.pollDir</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.metrics.sink.CsvSink' start='51' end='51' sourcepath='org/apache/spark/metrics/sink/CsvSink.scala' sourcefile='CsvSink.scala' startBytecode='1'><Message>At CsvSink.scala:[line 51]</Message></SourceLine><SourceLine endBytecode='333' classname='org.apache.spark.metrics.sink.CsvSink' start='60' end='60' sourcepath='org/apache/spark/metrics/sink/CsvSink.scala' sourcefile='CsvSink.scala' startBytecode='333'><Message>At CsvSink.scala:[line 60]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='56e3a5b6bf605f9fc4e4e340f4f4dcb7' cweid='330' rank='12' abbrev='SECPRS' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM_SCALA' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator (Scala)</ShortMessage><LongMessage>This Scala random generator (scala.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.rdd.DefaultPartitionCoalescer' primary='true'><SourceLine classname='org.apache.spark.rdd.DefaultPartitionCoalescer' start='157' end='396' sourcepath='org/apache/spark/rdd/CoalescedRDD.scala' sourcefile='CoalescedRDD.scala'><Message>At CoalescedRDD.scala:[lines 157-396]</Message></SourceLine><Message>In class org.apache.spark.rdd.DefaultPartitionCoalescer</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.DefaultPartitionCoalescer' signature='(D)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='152' classname='org.apache.spark.rdd.DefaultPartitionCoalescer' start='157' end='174' sourcepath='org/apache/spark/rdd/CoalescedRDD.scala' sourcefile='CoalescedRDD.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.rdd.DefaultPartitionCoalescer(double)</Message></Method><SourceLine endBytecode='17' classname='org.apache.spark.rdd.DefaultPartitionCoalescer' start='163' end='163' sourcepath='org/apache/spark/rdd/CoalescedRDD.scala' sourcefile='CoalescedRDD.scala' startBytecode='17' primary='true'><Message>At CoalescedRDD.scala:[line 163]</Message></SourceLine><String value='scala.util.Random'><Message>Value scala.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b35e2297a42a19a504f66f58c88fb2b3' cweid='89' rank='12' abbrev='SECSQLIJDBC' category='SECURITY' priority='2' type='SQL_INJECTION_JDBC' instanceOccurrenceMax='0'><ShortMessage>Potential JDBC Injection</ShortMessage><LongMessage>This use of java/sql/Connection.prepareStatement(Ljava/lang/String;II)Ljava/sql/PreparedStatement; can be vulnerable to SQL injection (with JDBC)</LongMessage><Class classname='org.apache.spark.rdd.JdbcRDD$$anon$1' primary='true'><SourceLine classname='org.apache.spark.rdd.JdbcRDD$$anon$1' start='78' end='133' sourcepath='org/apache/spark/rdd/JdbcRDD.scala' sourcefile='JdbcRDD.scala'><Message>At JdbcRDD.scala:[lines 78-133]</Message></SourceLine><Message>In class org.apache.spark.rdd.JdbcRDD$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.JdbcRDD$$anon$1' signature='(Lorg/apache/spark/rdd/JdbcRDD;Lorg/apache/spark/Partition;Lorg/apache/spark/TaskContext;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='338' classname='org.apache.spark.rdd.JdbcRDD$$anon$1' start='78' end='101' sourcepath='org/apache/spark/rdd/JdbcRDD.scala' sourcefile='JdbcRDD.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.rdd.JdbcRDD$$anon$1(JdbcRDD, Partition, TaskContext)</Message></Method><SourceLine endBytecode='67' classname='org.apache.spark.rdd.JdbcRDD$$anon$1' start='83' end='83' sourcepath='org/apache/spark/rdd/JdbcRDD.scala' sourcefile='JdbcRDD.scala' startBytecode='67' primary='true'><Message>At JdbcRDD.scala:[line 83]</Message></SourceLine><String role='Sink method' value='java/sql/Connection.prepareStatement(Ljava/lang/String;II)Ljava/sql/PreparedStatement;'><Message>Sink method java/sql/Connection.prepareStatement(Ljava/lang/String;II)Ljava/sql/PreparedStatement;</Message></String><String role='Sink parameter' value='2'><Message>Sink parameter 2</Message></String><String role='Unknown source' value='org/apache/spark/rdd/JdbcRDD.org$apache$spark$rdd$JdbcRDD$$sql'><Message>Unknown source org/apache/spark/rdd/JdbcRDD.org$apache$spark$rdd$JdbcRDD$$sql</Message></String><SourceLine endBytecode='58' classname='org.apache.spark.rdd.JdbcRDD$$anon$1' start='83' end='83' sourcepath='org/apache/spark/rdd/JdbcRDD.scala' sourcefile='JdbcRDD.scala' startBytecode='58'><Message>At JdbcRDD.scala:[line 83]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6d1453f3e87bca9dfc2ac6a903455b05' cweid='89' rank='15' abbrev='SQL' category='SECURITY' priority='3' type='SQL_PREPARED_STATEMENT_GENERATED_FROM_NONCONSTANT_STRING' instanceOccurrenceMax='0'><ShortMessage>A prepared statement is generated from a nonconstant String</ShortMessage><LongMessage>A prepared statement is generated from a nonconstant String in new org.apache.spark.rdd.JdbcRDD$$anon$1(JdbcRDD, Partition, TaskContext)</LongMessage><Class classname='org.apache.spark.rdd.JdbcRDD$$anon$1' primary='true'><SourceLine classname='org.apache.spark.rdd.JdbcRDD$$anon$1' start='78' end='133' sourcepath='org/apache/spark/rdd/JdbcRDD.scala' sourcefile='JdbcRDD.scala'><Message>At JdbcRDD.scala:[lines 78-133]</Message></SourceLine><Message>In class org.apache.spark.rdd.JdbcRDD$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.JdbcRDD$$anon$1' signature='(Lorg/apache/spark/rdd/JdbcRDD;Lorg/apache/spark/Partition;Lorg/apache/spark/TaskContext;)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='80' classname='org.apache.spark.rdd.JdbcRDD$$anon$1' start='78' end='101' sourcepath='org/apache/spark/rdd/JdbcRDD.scala' sourcefile='JdbcRDD.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.rdd.JdbcRDD$$anon$1(JdbcRDD, Partition, TaskContext)</Message></Method><SourceLine endBytecode='67' classname='org.apache.spark.rdd.JdbcRDD$$anon$1' start='83' end='83' sourcepath='org/apache/spark/rdd/JdbcRDD.scala' sourcefile='JdbcRDD.scala' startBytecode='67' primary='true'><Message>At JdbcRDD.scala:[line 83]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6cd4204bb0b94897b16114556774d596' cweid='330' rank='12' abbrev='SECPR' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator</ShortMessage><LongMessage>This random generator (java.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.rdd.PartitionwiseSampledRDD' primary='true'><SourceLine classname='org.apache.spark.rdd.PartitionwiseSampledRDD' start='47' end='68' sourcepath='org/apache/spark/rdd/PartitionwiseSampledRDD.scala' sourcefile='PartitionwiseSampledRDD.scala'><Message>At PartitionwiseSampledRDD.scala:[lines 47-68]</Message></SourceLine><Message>In class org.apache.spark.rdd.PartitionwiseSampledRDD</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.PartitionwiseSampledRDD' signature='()[Lorg/apache/spark/Partition;' name='getPartitions' primary='true'><SourceLine endBytecode='119' classname='org.apache.spark.rdd.PartitionwiseSampledRDD' start='57' end='58' sourcepath='org/apache/spark/rdd/PartitionwiseSampledRDD.scala' sourcefile='PartitionwiseSampledRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rdd.PartitionwiseSampledRDD.getPartitions()</Message></Method><SourceLine endBytecode='8' classname='org.apache.spark.rdd.PartitionwiseSampledRDD' start='57' end='57' sourcepath='org/apache/spark/rdd/PartitionwiseSampledRDD.scala' sourcefile='PartitionwiseSampledRDD.scala' startBytecode='8' primary='true'><Message>At PartitionwiseSampledRDD.scala:[line 57]</Message></SourceLine><String value='java.util.Random'><Message>Value java.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='263daa3c3c024beed8cbb9a4528afa44' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.rdd.PipedRDD' primary='true'><SourceLine classname='org.apache.spark.rdd.PipedRDD' start='43' end='163' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala'><Message>At PipedRDD.scala:[lines 43-163]</Message></SourceLine><Message>In class org.apache.spark.rdd.PipedRDD</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.PipedRDD' signature='(Lorg/apache/spark/Partition;Lorg/apache/spark/TaskContext;)Lscala/collection/Iterator;' name='compute' primary='true'><SourceLine endBytecode='736' classname='org.apache.spark.rdd.PipedRDD' start='67' end='163' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rdd.PipedRDD.compute(Partition, TaskContext)</Message></Method><SourceLine endBytecode='20' classname='org.apache.spark.rdd.PipedRDD' start='67' end='67' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='20' primary='true'><Message>At PipedRDD.scala:[line 67]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;(Ljava/util/List;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/convert/Decorators$AsJava.asJava()Ljava/lang/Object;'><Message>Unknown source scala/collection/convert/Decorators$AsJava.asJava()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8250b59fbf067a43c3d5377733ee3349' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1' primary='true'><SourceLine classname='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1' start='191' end='191' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala'><Message>At PipedRDD.scala:[line 191]</Message></SourceLine><Message>In class org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1' signature='()V' name='apply$mcV$sp' primary='true'><SourceLine endBytecode='62' classname='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1' start='191' end='191' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1.apply$mcV$sp()</Message></Method><SourceLine endBytecode='14' classname='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1' start='191' end='191' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='14' primary='true'><Message>At PipedRDD.scala:[line 191]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/rdd/PipedRDD$$anon$1.taskDirectory$1'><Message>Unknown source org/apache/spark/rdd/PipedRDD$$anon$1.taskDirectory$1</Message></String><SourceLine endBytecode='11' classname='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1' start='191' end='191' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='11'><Message>At PipedRDD.scala:[line 191]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b20f68a72dba3ea7568036f0249f01e0' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' primary='true'><SourceLine classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='98' end='101' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala'><Message>At PipedRDD.scala:[lines 98-101]</Message></SourceLine><Message>In class org.apache.spark.rdd.PipedRDD$$anonfun$compute$4</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='141' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='99' end='100' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rdd.PipedRDD$$anonfun$compute$4.apply(String)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='99' end='99' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='9' primary='true'><Message>At PipedRDD.scala:[line 99]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/rdd/PipedRDD$$anonfun$compute$4.apply(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/rdd/PipedRDD$$anonfun$compute$4.apply(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='98' end='98' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='5'><Message>At PipedRDD.scala:[line 98]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7efb9e18e9d3cc0617e8eb189276f2a4' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' primary='true'><SourceLine classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='98' end='101' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala'><Message>At PipedRDD.scala:[lines 98-101]</Message></SourceLine><Message>In class org.apache.spark.rdd.PipedRDD$$anonfun$compute$4</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='141' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='99' end='100' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rdd.PipedRDD$$anonfun$compute$4.apply(String)</Message></Method><SourceLine endBytecode='24' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='100' end='100' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='24' primary='true'><Message>At PipedRDD.scala:[line 100]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ec6d4240d10728fffc46ce1acae7391' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' primary='true'><SourceLine classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='98' end='101' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala'><Message>At PipedRDD.scala:[lines 98-101]</Message></SourceLine><Message>In class org.apache.spark.rdd.PipedRDD$$anonfun$compute$4</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='141' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='99' end='100' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rdd.PipedRDD$$anonfun$compute$4.apply(String)</Message></Method><SourceLine endBytecode='61' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='101' end='101' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='61' primary='true'><Message>At PipedRDD.scala:[line 101]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getName()Ljava/lang/String;'><Message>Unknown source java/io/File.getName()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/rdd/PipedRDD$$anonfun$compute$4.taskDirectory$1'><Message>Unknown source org/apache/spark/rdd/PipedRDD$$anonfun$compute$4.taskDirectory$1</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='48' classname='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4' start='101' end='101' sourcepath='org/apache/spark/rdd/PipedRDD.scala' sourcefile='PipedRDD.scala' startBytecode='48'><Message>At PipedRDD.scala:[line 101]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c164cc519221034579fd5683bbb8ac4d' cweid='330' rank='12' abbrev='SECPR' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator</ShortMessage><LongMessage>This random generator (java.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8' primary='true'><SourceLine classname='org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8' start='453' end='455' sourcepath='org/apache/spark/rdd/RDD.scala' sourcefile='RDD.scala'><Message>At RDD.scala:[lines 453-455]</Message></SourceLine><Message>In class org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8' signature='(ILscala/collection/Iterator;)Lscala/collection/Iterator;' name='apply' primary='true'><SourceLine endBytecode='120' classname='org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8' start='454' end='455' sourcepath='org/apache/spark/rdd/RDD.scala' sourcefile='RDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8.apply(int, Iterator)</Message></Method><SourceLine endBytecode='12' classname='org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8' start='454' end='454' sourcepath='org/apache/spark/rdd/RDD.scala' sourcefile='RDD.scala' startBytecode='12' primary='true'><Message>At RDD.scala:[line 454]</Message></SourceLine><String value='java.util.Random'><Message>Value java.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d831a31d71552a7e3fc3dfa213ce9d84' cweid='330' rank='12' abbrev='SECPR' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator</ShortMessage><LongMessage>This random generator (java.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.rdd.RDD$$anonfun$takeSample$1' primary='true'><SourceLine classname='org.apache.spark.rdd.RDD$$anonfun$takeSample$1' start='560' end='591' sourcepath='org/apache/spark/rdd/RDD.scala' sourcefile='RDD.scala'><Message>At RDD.scala:[lines 560-591]</Message></SourceLine><Message>In class org.apache.spark.rdd.RDD$$anonfun$takeSample$1</Message></Class><Method isStatic='false' classname='org.apache.spark.rdd.RDD$$anonfun$takeSample$1' signature='()Ljava/lang/Object;' name='apply' primary='true'><SourceLine endBytecode='606' classname='org.apache.spark.rdd.RDD$$anonfun$takeSample$1' start='561' end='560' sourcepath='org/apache/spark/rdd/RDD.scala' sourcefile='RDD.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rdd.RDD$$anonfun$takeSample$1.apply()</Message></Method><SourceLine endBytecode='135' classname='org.apache.spark.rdd.RDD$$anonfun$takeSample$1' start='575' end='575' sourcepath='org/apache/spark/rdd/RDD.scala' sourcefile='RDD.scala' startBytecode='135' primary='true'><Message>At RDD.scala:[line 575]</Message></SourceLine><String value='java.util.Random'><Message>Value java.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a7e96a3402a8ff2bef21f8732ca6ea65' cweid='502' rank='15' abbrev='SECDESGAD' category='SECURITY' priority='3' type='DESERIALIZATION_GADGET' instanceOccurrenceMax='0'><ShortMessage>This class could be used as deserialization gadget</ShortMessage><LongMessage>This class could make application using serialization vulnerable</LongMessage><Class classname='org.apache.spark.rpc.netty.NettyRpcEndpointRef' primary='true'><SourceLine classname='org.apache.spark.rpc.netty.NettyRpcEndpointRef' start='501' end='539' sourcepath='org/apache/spark/rpc/netty/NettyRpcEnv.scala' sourcefile='NettyRpcEnv.scala'><Message>At NettyRpcEnv.scala:[lines 501-539]</Message></SourceLine><Message>In class org.apache.spark.rpc.netty.NettyRpcEndpointRef</Message></Class><SourceLine synthetic='true' classname='org.apache.spark.rpc.netty.NettyRpcEndpointRef' start='501' end='539' sourcepath='org/apache/spark/rpc/netty/NettyRpcEnv.scala' sourcefile='NettyRpcEnv.scala'><Message>At NettyRpcEnv.scala:[lines 501-539]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3853a6fc33e5c41805a1a44219d69be3' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.rpc.netty.NettyStreamManager' primary='true'><SourceLine classname='org.apache.spark.rpc.netty.NettyStreamManager' start='39' end='88' sourcepath='org/apache/spark/rpc/netty/NettyStreamManager.scala' sourcefile='NettyStreamManager.scala'><Message>At NettyStreamManager.scala:[lines 39-88]</Message></SourceLine><Message>In class org.apache.spark.rpc.netty.NettyStreamManager</Message></Class><Method isStatic='false' classname='org.apache.spark.rpc.netty.NettyStreamManager' signature='(Ljava/lang/String;)Lorg/apache/spark/network/buffer/ManagedBuffer;' name='openStream' primary='true'><SourceLine endBytecode='729' classname='org.apache.spark.rpc.netty.NettyStreamManager' start='51' end='51' sourcepath='org/apache/spark/rpc/netty/NettyStreamManager.scala' sourcefile='NettyStreamManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.rpc.netty.NettyStreamManager.openStream(String)</Message></Method><SourceLine endBytecode='247' classname='org.apache.spark.rpc.netty.NettyStreamManager' start='58' end='58' sourcepath='org/apache/spark/rpc/netty/NettyStreamManager.scala' sourcefile='NettyStreamManager.scala' startBytecode='247' primary='true'><Message>At NettyStreamManager.scala:[line 58]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Tuple2._2()Ljava/lang/Object;'><Message>Unknown source scala/Tuple2._2()Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ae42ed41c734ff94d3816d2f0a44cc09' cweid='502' rank='10' abbrev='SECOBDES' category='SECURITY' priority='1' type='OBJECT_DESERIALIZATION' instanceOccurrenceMax='0'><ShortMessage>Object deserialization is used in {1}</ShortMessage><LongMessage>Object deserialization is used in org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2.apply(int)</LongMessage><Class classname='org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2' primary='true'><SourceLine classname='org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2' start='66' end='67' sourcepath='org/apache/spark/scheduler/TaskResult.scala' sourcefile='TaskResult.scala'><Message>At TaskResult.scala:[lines 66-67]</Message></SourceLine><Message>In class org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2</Message></Class><Method isStatic='false' classname='org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2' signature='(I)Lscala/collection/mutable/ArrayBuffer;' name='apply' primary='true'><SourceLine endBytecode='74' classname='org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2' start='67' end='67' sourcepath='org/apache/spark/scheduler/TaskResult.scala' sourcefile='TaskResult.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2.apply(int)</Message></Method><SourceLine endBytecode='11' classname='org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2' start='67' end='67' sourcepath='org/apache/spark/scheduler/TaskResult.scala' sourcefile='TaskResult.scala' startBytecode='11' primary='true'><Message>At TaskResult.scala:[line 67]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5d7f6589a21f1b064bfe14429f10e80' cweid='22' rank='12' abbrev='SECPTO' category='SECURITY' priority='2' type='PATH_TRAVERSAL_OUT' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file write)</ShortMessage><LongMessage>This API (java/io/FileOutputStream.&lt;init&gt;(Ljava/lang/String;)V) writes to a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.scheduler.EventLoggingListener' primary='true'><SourceLine classname='org.apache.spark.scheduler.EventLoggingListener' start='55' end='286' sourcepath='org/apache/spark/scheduler/EventLoggingListener.scala' sourcefile='EventLoggingListener.scala'><Message>At EventLoggingListener.scala:[lines 55-286]</Message></SourceLine><Message>In class org.apache.spark.scheduler.EventLoggingListener</Message></Class><Method isStatic='false' classname='org.apache.spark.scheduler.EventLoggingListener' signature='()V' name='start' primary='true'><SourceLine endBytecode='825' classname='org.apache.spark.scheduler.EventLoggingListener' start='100' end='135' sourcepath='org/apache/spark/scheduler/EventLoggingListener.scala' sourcefile='EventLoggingListener.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.scheduler.EventLoggingListener.start()</Message></Method><SourceLine endBytecode='197' classname='org.apache.spark.scheduler.EventLoggingListener' start='118' end='118' sourcepath='org/apache/spark/scheduler/EventLoggingListener.scala' sourcefile='EventLoggingListener.scala' startBytecode='197' primary='true'><Message>At EventLoggingListener.scala:[line 118]</Message></SourceLine><String role='Sink method' value='java/io/FileOutputStream.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/FileOutputStream.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/hadoop/fs/Path.toUri()Ljava/net/URI;'><Message>Unknown source org/apache/hadoop/fs/Path.toUri()Ljava/net/URI;</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><SourceLine endBytecode='194' classname='org.apache.spark.scheduler.EventLoggingListener' start='118' end='118' sourcepath='org/apache/spark/scheduler/EventLoggingListener.scala' sourcefile='EventLoggingListener.scala' startBytecode='194'><Message>At EventLoggingListener.scala:[line 118]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5b13a7db010a0a0bf7a340698f635480' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1' primary='true'><SourceLine classname='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1' start='76' end='79' sourcepath='org/apache/spark/scheduler/SchedulableBuilder.scala' sourcefile='SchedulableBuilder.scala'><Message>At SchedulableBuilder.scala:[lines 76-79]</Message></SourceLine><Message>In class org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1</Message></Class><Method isStatic='false' classname='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1' signature='(Ljava/lang/String;)Lscala/Some;' name='apply' primary='true'><SourceLine endBytecode='111' classname='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1' start='77' end='79' sourcepath='org/apache/spark/scheduler/SchedulableBuilder.scala' sourcefile='SchedulableBuilder.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1.apply(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1' start='77' end='77' sourcepath='org/apache/spark/scheduler/SchedulableBuilder.scala' sourcefile='SchedulableBuilder.scala' startBytecode='5' primary='true'><Message>At SchedulableBuilder.scala:[line 77]</Message></SourceLine><String role='Sink method' value='java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/FileInputStream.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/scheduler/FairSchedulableBuilder$$anonfun$buildPools$1.apply(Ljava/lang/String;)Lscala/Some; parameter 0'><Message>Unknown source org/apache/spark/scheduler/FairSchedulableBuilder$$anonfun$buildPools$1.apply(Ljava/lang/String;)Lscala/Some; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1' start='76' end='76' sourcepath='org/apache/spark/scheduler/SchedulableBuilder.scala' sourcefile='SchedulableBuilder.scala' startBytecode='5'><Message>At SchedulableBuilder.scala:[line 76]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='62f39c033a5b56f505db00553217932f' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3' primary='true'><SourceLine classname='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3' start='119' end='119' sourcepath='org/apache/spark/scheduler/local/LocalSchedulerBackend.scala' sourcefile='LocalSchedulerBackend.scala'><Message>At LocalSchedulerBackend.scala:[line 119]</Message></SourceLine><Message>In class org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3</Message></Class><Method isStatic='false' classname='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3' signature='(Ljava/lang/String;)Ljava/net/URL;' name='apply' primary='true'><SourceLine endBytecode='66' classname='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3' start='119' end='119' sourcepath='org/apache/spark/scheduler/local/LocalSchedulerBackend.scala' sourcefile='LocalSchedulerBackend.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3.apply(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3' start='119' end='119' sourcepath='org/apache/spark/scheduler/local/LocalSchedulerBackend.scala' sourcefile='LocalSchedulerBackend.scala' startBytecode='5' primary='true'><Message>At LocalSchedulerBackend.scala:[line 119]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/scheduler/local/LocalSchedulerBackend$$anonfun$getUserClasspath$3.apply(Ljava/lang/String;)Ljava/net/URL; parameter 0'><Message>Unknown source org/apache/spark/scheduler/local/LocalSchedulerBackend$$anonfun$getUserClasspath$3.apply(Ljava/lang/String;)Ljava/net/URL; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3' start='119' end='119' sourcepath='org/apache/spark/scheduler/local/LocalSchedulerBackend.scala' sourcefile='LocalSchedulerBackend.scala' startBytecode='5'><Message>At LocalSchedulerBackend.scala:[line 119]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='56dd8fa9d92ff3afeef9bb1692e2d29e' cweid='329' rank='12' abbrev='STAIV' category='SECURITY' priority='2' type='STATIC_IV' instanceOccurrenceMax='0'><ShortMessage>Static IV</ShortMessage><LongMessage>The initialization vector (IV) is not properly generated</LongMessage><Class classname='org.apache.spark.security.CryptoStreamUtils$' primary='true'><SourceLine classname='org.apache.spark.security.CryptoStreamUtils$' start='40' end='136' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala'><Message>At CryptoStreamUtils.scala:[lines 40-136]</Message></SourceLine><Message>In class org.apache.spark.security.CryptoStreamUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.security.CryptoStreamUtils$' signature='(Ljava/io/InputStream;Lorg/apache/spark/SparkConf;[B)Ljava/io/InputStream;' name='createCryptoInputStream' primary='true'><SourceLine endBytecode='169' classname='org.apache.spark.security.CryptoStreamUtils$' start='84' end='87' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.security.CryptoStreamUtils$.createCryptoInputStream(InputStream, SparkConf, byte[])</Message></Method><SourceLine endBytecode='51' classname='org.apache.spark.security.CryptoStreamUtils$' start='88' end='88' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala' startBytecode='51' primary='true'><Message>At CryptoStreamUtils.scala:[line 88]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c29e8a01856cc5c44d27d74272e0def1' cweid='329' rank='12' abbrev='STAIV' category='SECURITY' priority='2' type='STATIC_IV' instanceOccurrenceMax='0'><ShortMessage>Static IV</ShortMessage><LongMessage>The initialization vector (IV) is not properly generated</LongMessage><Class classname='org.apache.spark.security.CryptoStreamUtils$' primary='true'><SourceLine classname='org.apache.spark.security.CryptoStreamUtils$' start='40' end='136' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala'><Message>At CryptoStreamUtils.scala:[lines 40-136]</Message></SourceLine><Message>In class org.apache.spark.security.CryptoStreamUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.security.CryptoStreamUtils$' signature='(Ljava/io/OutputStream;Lorg/apache/spark/SparkConf;[B)Ljava/io/OutputStream;' name='createCryptoOutputStream' primary='true'><SourceLine endBytecode='172' classname='org.apache.spark.security.CryptoStreamUtils$' start='54' end='57' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.security.CryptoStreamUtils$.createCryptoOutputStream(OutputStream, SparkConf, byte[])</Message></Method><SourceLine endBytecode='54' classname='org.apache.spark.security.CryptoStreamUtils$' start='58' end='58' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala' startBytecode='54' primary='true'><Message>At CryptoStreamUtils.scala:[line 58]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4d37ce9d583c6c9b29a751c376aa9731' cweid='329' rank='12' abbrev='STAIV' category='SECURITY' priority='2' type='STATIC_IV' instanceOccurrenceMax='0'><ShortMessage>Static IV</ShortMessage><LongMessage>The initialization vector (IV) is not properly generated</LongMessage><Class classname='org.apache.spark.security.CryptoStreamUtils$' primary='true'><SourceLine classname='org.apache.spark.security.CryptoStreamUtils$' start='40' end='136' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala'><Message>At CryptoStreamUtils.scala:[lines 40-136]</Message></SourceLine><Message>In class org.apache.spark.security.CryptoStreamUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.security.CryptoStreamUtils$' signature='(Ljava/nio/channels/ReadableByteChannel;Lorg/apache/spark/SparkConf;[B)Ljava/nio/channels/ReadableByteChannel;' name='createReadableChannel' primary='true'><SourceLine endBytecode='190' classname='org.apache.spark.security.CryptoStreamUtils$' start='98' end='103' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.security.CryptoStreamUtils$.createReadableChannel(ReadableByteChannel, SparkConf, byte[])</Message></Method><SourceLine endBytecode='58' classname='org.apache.spark.security.CryptoStreamUtils$' start='104' end='104' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala' startBytecode='58' primary='true'><Message>At CryptoStreamUtils.scala:[line 104]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='506056eef3196244600e23d0f2fa7b37' cweid='329' rank='12' abbrev='STAIV' category='SECURITY' priority='2' type='STATIC_IV' instanceOccurrenceMax='0'><ShortMessage>Static IV</ShortMessage><LongMessage>The initialization vector (IV) is not properly generated</LongMessage><Class classname='org.apache.spark.security.CryptoStreamUtils$' primary='true'><SourceLine classname='org.apache.spark.security.CryptoStreamUtils$' start='40' end='136' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala'><Message>At CryptoStreamUtils.scala:[lines 40-136]</Message></SourceLine><Message>In class org.apache.spark.security.CryptoStreamUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.security.CryptoStreamUtils$' signature='(Ljava/nio/channels/WritableByteChannel;Lorg/apache/spark/SparkConf;[B)Ljava/nio/channels/WritableByteChannel;' name='createWritableChannel' primary='true'><SourceLine endBytecode='202' classname='org.apache.spark.security.CryptoStreamUtils$' start='68' end='73' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.security.CryptoStreamUtils$.createWritableChannel(WritableByteChannel, SparkConf, byte[])</Message></Method><SourceLine endBytecode='70' classname='org.apache.spark.security.CryptoStreamUtils$' start='74' end='74' sourcepath='org/apache/spark/security/CryptoStreamUtils.scala' sourcefile='CryptoStreamUtils.scala' startBytecode='70' primary='true'><Message>At CryptoStreamUtils.scala:[line 74]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6cbb57c81c87ec50c038c521d291ca6f' cweid='502' rank='10' abbrev='SECOBDES' category='SECURITY' priority='1' type='OBJECT_DESERIALIZATION' instanceOccurrenceMax='0'><ShortMessage>Object deserialization is used in {1}</ShortMessage><LongMessage>Object deserialization is used in org.apache.spark.serializer.JavaDeserializationStream.readObject(ClassTag)</LongMessage><Class classname='org.apache.spark.serializer.JavaDeserializationStream' primary='true'><SourceLine classname='org.apache.spark.serializer.JavaDeserializationStream' start='60' end='76' sourcepath='org/apache/spark/serializer/JavaSerializer.scala' sourcefile='JavaSerializer.scala'><Message>At JavaSerializer.scala:[lines 60-76]</Message></SourceLine><Message>In class org.apache.spark.serializer.JavaDeserializationStream</Message></Class><Method isStatic='false' classname='org.apache.spark.serializer.JavaDeserializationStream' signature='(Lscala/reflect/ClassTag;)Ljava/lang/Object;' name='readObject' primary='true'><SourceLine endBytecode='59' classname='org.apache.spark.serializer.JavaDeserializationStream' start='75' end='75' sourcepath='org/apache/spark/serializer/JavaSerializer.scala' sourcefile='JavaSerializer.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.serializer.JavaDeserializationStream.readObject(ClassTag)</Message></Method><SourceLine endBytecode='4' classname='org.apache.spark.serializer.JavaDeserializationStream' start='75' end='75' sourcepath='org/apache/spark/serializer/JavaSerializer.scala' sourcefile='JavaSerializer.scala' startBytecode='4' primary='true'><Message>At JavaSerializer.scala:[line 75]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='301490d3152320a336860e00fa220448' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' start='73' end='246' sourcepath='org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java' sourcefile='BypassMergeSortShuffleWriter.java'><Message>At BypassMergeSortShuffleWriter.java:[lines 73-246]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' signature='(Z)Lscala/Option;' name='stop' primary='true'><SourceLine endBytecode='334' classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' start='222' end='246' sourcepath='org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java' sourcefile='BypassMergeSortShuffleWriter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.stop(boolean)</Message></Method><SourceLine endBytecode='100' classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' start='239' end='239' sourcepath='org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java' sourcefile='BypassMergeSortShuffleWriter.java' startBytecode='100' primary='true'><Message>At BypassMergeSortShuffleWriter.java:[line 239]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c1d1f3907f933e157b734a5ba1edc16e' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' start='73' end='246' sourcepath='org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java' sourcefile='BypassMergeSortShuffleWriter.java'><Message>At BypassMergeSortShuffleWriter.java:[lines 73-246]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' signature='(Lscala/collection/Iterator;)V' name='write' primary='true'><SourceLine endBytecode='922' classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' start='124' end='171' sourcepath='org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java' sourcefile='BypassMergeSortShuffleWriter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(Iterator)</Message></Method><SourceLine endBytecode='424' classname='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter' start='167' end='167' sourcepath='org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java' sourcefile='BypassMergeSortShuffleWriter.java' startBytecode='424' primary='true'><Message>At BypassMergeSortShuffleWriter.java:[line 167]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='99a505fdea99c9d3f9db6a257633eeef' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' start='66' end='421' sourcepath='org/apache/spark/shuffle/sort/ShuffleExternalSorter.java' sourcefile='ShuffleExternalSorter.java'><Message>At ShuffleExternalSorter.java:[lines 66-421]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.ShuffleExternalSorter</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' signature='()V' name='cleanupResources' primary='true'><SourceLine endBytecode='194' classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' start='312' end='322' sourcepath='org/apache/spark/shuffle/sort/ShuffleExternalSorter.java' sourcefile='ShuffleExternalSorter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.ShuffleExternalSorter.cleanupResources()</Message></Method><SourceLine endBytecode='83' classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' start='319' end='319' sourcepath='org/apache/spark/shuffle/sort/ShuffleExternalSorter.java' sourcefile='ShuffleExternalSorter.java' startBytecode='83' primary='true'><Message>At ShuffleExternalSorter.java:[line 319]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getPath()Ljava/lang/String;'><Message>Unknown source java/io/File.getPath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b7e44b20c909cf773ed6aac554f61461' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.info(Ljava/lang/String;[Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' start='66' end='421' sourcepath='org/apache/spark/shuffle/sort/ShuffleExternalSorter.java' sourcefile='ShuffleExternalSorter.java'><Message>At ShuffleExternalSorter.java:[lines 66-421]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.ShuffleExternalSorter</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='spill' primary='true'><SourceLine endBytecode='313' classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' start='252' end='269' sourcepath='org/apache/spark/shuffle/sort/ShuffleExternalSorter.java' sourcefile='ShuffleExternalSorter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.ShuffleExternalSorter.spill(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='89' classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' start='256' end='256' sourcepath='org/apache/spark/shuffle/sort/ShuffleExternalSorter.java' sourcefile='ShuffleExternalSorter.java' startBytecode='89' primary='true'><Message>At ShuffleExternalSorter.java:[line 256]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.info(Ljava/lang/String;[Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.info(Ljava/lang/String;[Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;'><Message>Unknown source scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal.toString()Ljava/lang/String;'><Message>Unknown source scala/math/BigDecimal.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='51' classname='org.apache.spark.shuffle.sort.ShuffleExternalSorter' start='258' end='258' sourcepath='org/apache/spark/shuffle/sort/ShuffleExternalSorter.java' sourcefile='ShuffleExternalSorter.java' startBytecode='51'><Message>At ShuffleExternalSorter.java:[line 258]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$' start='1168' end='1168' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>At Utils.scala:[line 1168]</Message></SourceLine><SourceLine endBytecode='86' classname='org.apache.spark.util.Utils$' start='1180' end='1180' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='86'><Message>At Utils.scala:[line 1180]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ecf9fb50a87ccd2145b9be2b0f904c29' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.SortShuffleManager$' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='170' end='201' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala'><Message>At SortShuffleManager.scala:[lines 170-201]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.SortShuffleManager$</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' signature='(Lorg/apache/spark/ShuffleDependency;)Z' name='canUseSerializedShuffle' primary='true'><SourceLine endBytecode='600' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='185' end='184' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.SortShuffleManager$.canUseSerializedShuffle(ShuffleDependency)</Message></Method><SourceLine endBytecode='425' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='188' end='188' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='425' primary='true'><Message>At SortShuffleManager.scala:[line 188]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='422' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='188' end='188' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='422'><Message>At SortShuffleManager.scala:[line 188]</Message></SourceLine><SourceLine endBytecode='419' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='189' end='189' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='419'><Message>At SortShuffleManager.scala:[line 189]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b96a17e792a18d9d8d4d4b55d099235f' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.SortShuffleManager$' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='170' end='201' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala'><Message>At SortShuffleManager.scala:[lines 170-201]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.SortShuffleManager$</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' signature='(Lorg/apache/spark/ShuffleDependency;)Z' name='canUseSerializedShuffle' primary='true'><SourceLine endBytecode='600' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='185' end='184' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.SortShuffleManager$.canUseSerializedShuffle(ShuffleDependency)</Message></Method><SourceLine endBytecode='87' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='192' end='192' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='87' primary='true'><Message>At SortShuffleManager.scala:[line 192]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='84' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='193' end='193' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='84'><Message>At SortShuffleManager.scala:[line 193]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='ecf9fb50a87ccd2145b9be2b0f904c29' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.SortShuffleManager$' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='170' end='201' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala'><Message>At SortShuffleManager.scala:[lines 170-201]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.SortShuffleManager$</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' signature='(Lorg/apache/spark/ShuffleDependency;)Z' name='canUseSerializedShuffle' primary='true'><SourceLine endBytecode='600' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='185' end='184' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.SortShuffleManager$.canUseSerializedShuffle(ShuffleDependency)</Message></Method><SourceLine endBytecode='227' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='196' end='196' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='227' primary='true'><Message>At SortShuffleManager.scala:[line 196]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='224' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='196' end='196' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='224'><Message>At SortShuffleManager.scala:[line 196]</Message></SourceLine><SourceLine endBytecode='221' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='197' end='197' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='221'><Message>At SortShuffleManager.scala:[line 197]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='b96a17e792a18d9d8d4d4b55d099235f' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='1'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.debug(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.SortShuffleManager$' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='170' end='201' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala'><Message>At SortShuffleManager.scala:[lines 170-201]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.SortShuffleManager$</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' signature='(Lorg/apache/spark/ShuffleDependency;)Z' name='canUseSerializedShuffle' primary='true'><SourceLine endBytecode='600' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='185' end='184' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.SortShuffleManager$.canUseSerializedShuffle(ShuffleDependency)</Message></Method><SourceLine endBytecode='290' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='200' end='200' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='290' primary='true'><Message>At SortShuffleManager.scala:[line 200]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.debug(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.debug(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='287' classname='org.apache.spark.shuffle.sort.SortShuffleManager$' start='200' end='200' sourcepath='org/apache/spark/shuffle/sort/SortShuffleManager.scala' sourcefile='SortShuffleManager.scala' startBytecode='287'><Message>At SortShuffleManager.scala:[line 200]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='591acd23470edd5cb05c04dce6f835f' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='60' end='518' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java'><Message>At UnsafeShuffleWriter.java:[lines 60-518]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.UnsafeShuffleWriter</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' signature='()V' name='closeAndWriteOutput' primary='true'><SourceLine endBytecode='808' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='226' end='252' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.UnsafeShuffleWriter.closeAndWriteOutput()</Message></Method><SourceLine endBytecode='214' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='241' end='241' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java' startBytecode='214' primary='true'><Message>At UnsafeShuffleWriter.java:[line 241]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getPath()Ljava/lang/String;'><Message>Unknown source java/io/File.getPath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a445ac53c258c667e0115f97044f7b1e' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='60' end='518' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java'><Message>At UnsafeShuffleWriter.java:[lines 60-518]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.UnsafeShuffleWriter</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' signature='()V' name='closeAndWriteOutput' primary='true'><SourceLine endBytecode='808' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='226' end='252' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.UnsafeShuffleWriter.closeAndWriteOutput()</Message></Method><SourceLine endBytecode='308' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='248' end='248' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java' startBytecode='308' primary='true'><Message>At UnsafeShuffleWriter.java:[line 248]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='95bd68c395b30eb2c06ab291e17d0f3d' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' primary='true'><SourceLine classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='60' end='518' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java'><Message>At UnsafeShuffleWriter.java:[lines 60-518]</Message></SourceLine><Message>In class org.apache.spark.shuffle.sort.UnsafeShuffleWriter</Message></Class><Method isStatic='false' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' signature='([Lorg/apache/spark/shuffle/sort/SpillInfo;Ljava/io/File;)[J' name='mergeSpills' primary='true'><SourceLine endBytecode='635' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='284' end='340' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.shuffle.sort.UnsafeShuffleWriter.mergeSpills(SpillInfo[], File)</Message></Method><SourceLine endBytecode='261' classname='org.apache.spark.shuffle.sort.UnsafeShuffleWriter' start='338' end='338' sourcepath='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' sourcefile='UnsafeShuffleWriter.java' startBytecode='261' primary='true'><Message>At UnsafeShuffleWriter.java:[line 338]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getPath()Ljava/lang/String;'><Message>Unknown source java/io/File.getPath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e3454793d748c6a0fc22f26f4998cbb4' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.allExecutorList() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='()Lscala/collection/Seq;' name='allExecutorList' primary='true'><SourceLine endBytecode='57' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='56' end='56' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.allExecutorList()</Message></Method><SourceLine synthetic='true' endBytecode='57' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='56' end='56' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[line 56]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7629c61dce275b8830617c6ecc022c52' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.applicationAttempt() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='()Ljava/lang/Class;' name='applicationAttempt' primary='true'><SourceLine endBytecode='86' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='134' end='135' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.applicationAttempt()</Message></Method><SourceLine synthetic='true' endBytecode='86' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='134' end='135' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[lines 134-135]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e55b5a406ba005976b141223bd500ed4' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.environmentInfo() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='()Lorg/apache/spark/status/api/v1/ApplicationEnvironmentInfo;' name='environmentInfo' primary='true'><SourceLine endBytecode='57' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='78' end='78' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.environmentInfo()</Message></Method><SourceLine synthetic='true' endBytecode='57' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='78' end='78' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[line 78]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='8ad39c56daf64bf61cc51e7236a1b158' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.executorList() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='()Lscala/collection/Seq;' name='executorList' primary='true'><SourceLine endBytecode='57' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='52' end='52' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.executorList()</Message></Method><SourceLine synthetic='true' endBytecode='57' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='52' end='52' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[line 52]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ae14e88f5a1fd4146861d979c9cb71' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.getEventLogs() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='()Ljavax/ws/rs/core/Response;' name='getEventLogs' primary='true'><SourceLine endBytecode='627' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='88' end='83' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.getEventLogs()</Message></Method><SourceLine synthetic='true' endBytecode='627' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='88' end='83' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[lines 88-83]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f07f08acb3d53e0bdea3bba65e32147d' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.jobsList(List) is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='(Ljava/util/List;)Lscala/collection/Seq;' name='jobsList' primary='true'><SourceLine endBytecode='68' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='36' end='36' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.jobsList(List)</Message></Method><SourceLine synthetic='true' endBytecode='68' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='36' end='36' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[line 36]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2a05038245db230b2d3e473389256752' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.oneJob(int) is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='(I)Lorg/apache/spark/status/api/v1/JobData;' name='oneJob' primary='true'><SourceLine endBytecode='68' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='41' end='41' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.oneJob(int)</Message></Method><SourceLine synthetic='true' endBytecode='68' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='41' end='41' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[line 41]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fff3c59a9e995c702cd62ff0147b7680' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.rddData(int) is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='(I)Lorg/apache/spark/status/api/v1/RDDStorageInfo;' name='rddData' primary='true'><SourceLine endBytecode='68' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='67' end='67' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.rddData(int)</Message></Method><SourceLine synthetic='true' endBytecode='68' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='67' end='67' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[line 67]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='36dbae7acc95fa35db3978995ab9260c' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.rddList() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='()Lscala/collection/Seq;' name='rddList' primary='true'><SourceLine endBytecode='57' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='63' end='63' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.rddList()</Message></Method><SourceLine synthetic='true' endBytecode='57' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='63' end='63' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[line 63]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cbc67747476eec0485b1d85d174471af' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.AbstractApplicationResource.org.apache.spark.status.api.v1.AbstractApplicationResource.stages() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.AbstractApplicationResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='31' end='137' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala'><Message>At OneApplicationResource.scala:[lines 31-137]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.AbstractApplicationResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' signature='()Ljava/lang/Class;' name='stages' primary='true'><SourceLine endBytecode='44' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='59' end='59' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.AbstractApplicationResource.stages()</Message></Method><SourceLine synthetic='true' endBytecode='44' classname='org.apache.spark.status.api.v1.AbstractApplicationResource' start='59' end='59' sourcepath='org/apache/spark/status/api/v1/OneApplicationResource.scala' sourcefile='OneApplicationResource.scala' startBytecode='0'><Message>At OneApplicationResource.scala:[line 59]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fa34b1a1a5689bc72d2396093f40ad13' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.ApiRootResource.org.apache.spark.status.api.v1.ApiRootResource.application() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.ApiRootResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.ApiRootResource' start='44' end='53' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala'><Message>At ApiRootResource.scala:[lines 44-53]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.ApiRootResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.ApiRootResource' signature='()Ljava/lang/Class;' name='application' primary='true'><SourceLine endBytecode='44' classname='org.apache.spark.status.api.v1.ApiRootResource' start='50' end='50' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.ApiRootResource.application()</Message></Method><SourceLine synthetic='true' endBytecode='44' classname='org.apache.spark.status.api.v1.ApiRootResource' start='50' end='50' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala' startBytecode='0'><Message>At ApiRootResource.scala:[line 50]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aa3dfcead99c81220b5ce14bad560ab3' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.ApiRootResource.org.apache.spark.status.api.v1.ApiRootResource.applicationList() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.ApiRootResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.ApiRootResource' start='44' end='53' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala'><Message>At ApiRootResource.scala:[lines 44-53]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.ApiRootResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.ApiRootResource' signature='()Ljava/lang/Class;' name='applicationList' primary='true'><SourceLine endBytecode='44' classname='org.apache.spark.status.api.v1.ApiRootResource' start='47' end='47' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.ApiRootResource.applicationList()</Message></Method><SourceLine synthetic='true' endBytecode='44' classname='org.apache.spark.status.api.v1.ApiRootResource' start='47' end='47' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala' startBytecode='0'><Message>At ApiRootResource.scala:[line 47]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cf1c39d629677b53611ca55eca2f8ff8' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.ApiRootResource.org.apache.spark.status.api.v1.ApiRootResource.version() is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.ApiRootResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.ApiRootResource' start='44' end='53' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala'><Message>At ApiRootResource.scala:[lines 44-53]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.ApiRootResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.ApiRootResource' signature='()Lorg/apache/spark/status/api/v1/VersionInfo;' name='version' primary='true'><SourceLine endBytecode='55' classname='org.apache.spark.status.api.v1.ApiRootResource' start='53' end='53' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.ApiRootResource.version()</Message></Method><SourceLine synthetic='true' endBytecode='55' classname='org.apache.spark.status.api.v1.ApiRootResource' start='53' end='53' sourcepath='org/apache/spark/status/api/v1/ApiRootResource.scala' sourcefile='ApiRootResource.scala' startBytecode='0'><Message>At ApiRootResource.scala:[line 53]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='270d38a5ff12318837f840dd028e576' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.StagesResource.org.apache.spark.status.api.v1.StagesResource.oneAttemptData(int, int, boolean) is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.StagesResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.StagesResource' start='30' end='102' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala'><Message>At StagesResource.scala:[lines 30-102]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.StagesResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.StagesResource' signature='(IIZ)Lorg/apache/spark/status/api/v1/StageData;' name='oneAttemptData' primary='true'><SourceLine endBytecode='90' classname='org.apache.spark.status.api.v1.StagesResource' start='57' end='57' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.StagesResource.oneAttemptData(int, int, boolean)</Message></Method><SourceLine synthetic='true' endBytecode='90' classname='org.apache.spark.status.api.v1.StagesResource' start='57' end='57' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala' startBytecode='0'><Message>At StagesResource.scala:[line 57]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='819cddc649e571cd9ed044b00809d82' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.StagesResource.org.apache.spark.status.api.v1.StagesResource.stageData(int, boolean) is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.StagesResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.StagesResource' start='30' end='102' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala'><Message>At StagesResource.scala:[lines 30-102]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.StagesResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.StagesResource' signature='(IZ)Lscala/collection/Seq;' name='stageData' primary='true'><SourceLine endBytecode='79' classname='org.apache.spark.status.api.v1.StagesResource' start='42' end='42' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.StagesResource.stageData(int, boolean)</Message></Method><SourceLine synthetic='true' endBytecode='79' classname='org.apache.spark.status.api.v1.StagesResource' start='42' end='42' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala' startBytecode='0'><Message>At StagesResource.scala:[line 42]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bbd41ce57055c7fc5cc79b718b96d8b7' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.StagesResource.org.apache.spark.status.api.v1.StagesResource.taskList(int, int, int, int, TaskSorting) is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.StagesResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.StagesResource' start='30' end='102' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala'><Message>At StagesResource.scala:[lines 30-102]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.StagesResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.StagesResource' signature='(IIIILorg/apache/spark/status/api/v1/TaskSorting;)Lscala/collection/Seq;' name='taskList' primary='true'><SourceLine endBytecode='114' classname='org.apache.spark.status.api.v1.StagesResource' start='102' end='102' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.StagesResource.taskList(int, int, int, int, TaskSorting)</Message></Method><SourceLine synthetic='true' endBytecode='114' classname='org.apache.spark.status.api.v1.StagesResource' start='102' end='102' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala' startBytecode='0'><Message>At StagesResource.scala:[line 102]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='13dfd0f3b4de1c3344eaf044f1be4ed5' rank='15' abbrev='SECJRS' category='SECURITY' priority='3' type='JAXRS_ENDPOINT' instanceOccurrenceMax='0'><ShortMessage>Found JAX-RS REST endpoint</ShortMessage><LongMessage>org.apache.spark.status.api.v1.StagesResource.org.apache.spark.status.api.v1.StagesResource.taskSummary(int, int, String) is a REST Web Service endpoint</LongMessage><Class classname='org.apache.spark.status.api.v1.StagesResource' primary='true'><SourceLine classname='org.apache.spark.status.api.v1.StagesResource' start='30' end='102' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala'><Message>At StagesResource.scala:[lines 30-102]</Message></SourceLine><Message>In class org.apache.spark.status.api.v1.StagesResource</Message></Class><Method isStatic='false' classname='org.apache.spark.status.api.v1.StagesResource' signature='(IILjava/lang/String;)Lorg/apache/spark/status/api/v1/TaskMetricDistributions;' name='taskSummary' primary='true'><SourceLine endBytecode='90' classname='org.apache.spark.status.api.v1.StagesResource' start='80' end='80' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.status.api.v1.StagesResource.taskSummary(int, int, String)</Message></Method><SourceLine synthetic='true' endBytecode='90' classname='org.apache.spark.status.api.v1.StagesResource' start='80' end='80' sourcepath='org/apache/spark/status/api/v1/StagesResource.scala' sourcefile='StagesResource.scala' startBytecode='0'><Message>At StagesResource.scala:[line 80]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='454b8a887cf412c34ab9a6976a5c9af5' cweid='330' rank='12' abbrev='SECPRS' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM_SCALA' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator (Scala)</ShortMessage><LongMessage>This Scala random generator (scala.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.storage.BasicBlockReplicationPolicy' primary='true'><SourceLine classname='org.apache.spark.storage.BasicBlockReplicationPolicy' start='135' end='218' sourcepath='org/apache/spark/storage/BlockReplicationPolicy.scala' sourcefile='BlockReplicationPolicy.scala'><Message>At BlockReplicationPolicy.scala:[lines 135-218]</Message></SourceLine><Message>In class org.apache.spark.storage.BasicBlockReplicationPolicy</Message></Class><Method isStatic='false' classname='org.apache.spark.storage.BasicBlockReplicationPolicy' signature='(Lorg/apache/spark/storage/BlockManagerId;Lscala/collection/Seq;Lscala/collection/mutable/HashSet;Lorg/apache/spark/storage/BlockId;I)Lscala/collection/immutable/List;' name='prioritize' primary='true'><SourceLine endBytecode='1055' classname='org.apache.spark.storage.BasicBlockReplicationPolicy' start='161' end='186' sourcepath='org/apache/spark/storage/BlockReplicationPolicy.scala' sourcefile='BlockReplicationPolicy.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.storage.BasicBlockReplicationPolicy.prioritize(BlockManagerId, Seq, HashSet, BlockId, int)</Message></Method><SourceLine endBytecode='35' classname='org.apache.spark.storage.BasicBlockReplicationPolicy' start='164' end='164' sourcepath='org/apache/spark/storage/BlockReplicationPolicy.scala' sourcefile='BlockReplicationPolicy.scala' startBytecode='35' primary='true'><Message>At BlockReplicationPolicy.scala:[line 164]</Message></SourceLine><String value='scala.util.Random'><Message>Value scala.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7a39d9b91b89597831c9e779b298dad4' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup' primary='true'><SourceLine classname='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup' start='1588' end='1596' sourcepath='org/apache/spark/storage/BlockManager.scala' sourcefile='BlockManager.scala'><Message>At BlockManager.scala:[lines 1588-1596]</Message></SourceLine><Message>In class org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup</Message></Class><Method isStatic='false' classname='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup' signature='()V' name='cleanUp' primary='true'><SourceLine endBytecode='110' classname='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup' start='1593' end='1592' sourcepath='org/apache/spark/storage/BlockManager.scala' sourcefile='BlockManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup.cleanUp()</Message></Method><SourceLine endBytecode='23' classname='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup' start='1595' end='1595' sourcepath='org/apache/spark/storage/BlockManager.scala' sourcefile='BlockManager.scala' startBytecode='23' primary='true'><Message>At BlockManager.scala:[line 1595]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/storage/BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup.org$apache$spark$storage$BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup$$filePath'><Message>Unknown source org/apache/spark/storage/BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup.org$apache$spark$storage$BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup$$filePath</Message></String><String role='Unknown source' value='org/apache/spark/storage/BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup.org$apache$spark$storage$BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup$$filePath()Ljava/lang/String;'><Message>Unknown source org/apache/spark/storage/BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup.org$apache$spark$storage$BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup$$filePath()Ljava/lang/String;</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup' start='1590' end='1590' sourcepath='org/apache/spark/storage/BlockManager.scala' sourcefile='BlockManager.scala' startBytecode='1'><Message>At BlockManager.scala:[line 1590]</Message></SourceLine><SourceLine endBytecode='20' classname='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup' start='1595' end='1595' sourcepath='org/apache/spark/storage/BlockManager.scala' sourcefile='BlockManager.scala' startBytecode='20'><Message>At BlockManager.scala:[line 1595]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ed874f63a77bf0632ec34c6f2c02c084' cweid='330' rank='12' abbrev='SECPRS' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM_SCALA' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator (Scala)</ShortMessage><LongMessage>This Scala random generator (scala.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.storage.BlockManagerMasterEndpoint' primary='true'><SourceLine classname='org.apache.spark.storage.BlockManagerMasterEndpoint' start='41' end='473' sourcepath='org/apache/spark/storage/BlockManagerMasterEndpoint.scala' sourcefile='BlockManagerMasterEndpoint.scala'><Message>At BlockManagerMasterEndpoint.scala:[lines 41-473]</Message></SourceLine><Message>In class org.apache.spark.storage.BlockManagerMasterEndpoint</Message></Class><Method isStatic='false' classname='org.apache.spark.storage.BlockManagerMasterEndpoint' signature='(Lorg/apache/spark/storage/BlockManagerId;)V' name='org$apache$spark$storage$BlockManagerMasterEndpoint$$removeBlockManager' primary='true'><SourceLine endBytecode='494' classname='org.apache.spark.storage.BlockManagerMasterEndpoint' start='203' end='240' sourcepath='org/apache/spark/storage/BlockManagerMasterEndpoint.scala' sourcefile='BlockManagerMasterEndpoint.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$removeBlockManager(BlockManagerId)</Message></Method><SourceLine endBytecode='164' classname='org.apache.spark.storage.BlockManagerMasterEndpoint' start='228' end='228' sourcepath='org/apache/spark/storage/BlockManagerMasterEndpoint.scala' sourcefile='BlockManagerMasterEndpoint.scala' startBytecode='164' primary='true'><Message>At BlockManagerMasterEndpoint.scala:[line 228]</Message></SourceLine><String value='scala.util.Random'><Message>Value scala.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='780ce9f9f16c9084d0e4e575356cf5f5' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.storage.DiskBlockManager' primary='true'><SourceLine classname='org.apache.spark.storage.DiskBlockManager' start='35' end='174' sourcepath='org/apache/spark/storage/DiskBlockManager.scala' sourcefile='DiskBlockManager.scala'><Message>At DiskBlockManager.scala:[lines 35-174]</Message></SourceLine><Message>In class org.apache.spark.storage.DiskBlockManager</Message></Class><Method isStatic='false' classname='org.apache.spark.storage.DiskBlockManager' signature='(Ljava/lang/String;)Ljava/io/File;' name='getFile' primary='true'><SourceLine endBytecode='465' classname='org.apache.spark.storage.DiskBlockManager' start='58' end='63' sourcepath='org/apache/spark/storage/DiskBlockManager.scala' sourcefile='DiskBlockManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.storage.DiskBlockManager.getFile(String)</Message></Method><SourceLine endBytecode='102' classname='org.apache.spark.storage.DiskBlockManager' start='68' end='68' sourcepath='org/apache/spark/storage/DiskBlockManager.scala' sourcefile='DiskBlockManager.scala' startBytecode='102' primary='true'><Message>At DiskBlockManager.scala:[line 68]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.format(Lscala/collection/Seq;)Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='afc002fdbf45037dce6149499919c9cf' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.storage.DiskBlockManager' primary='true'><SourceLine classname='org.apache.spark.storage.DiskBlockManager' start='35' end='174' sourcepath='org/apache/spark/storage/DiskBlockManager.scala' sourcefile='DiskBlockManager.scala'><Message>At DiskBlockManager.scala:[lines 35-174]</Message></SourceLine><Message>In class org.apache.spark.storage.DiskBlockManager</Message></Class><Method isStatic='false' classname='org.apache.spark.storage.DiskBlockManager' signature='(Ljava/lang/String;)Ljava/io/File;' name='getFile' primary='true'><SourceLine endBytecode='465' classname='org.apache.spark.storage.DiskBlockManager' start='58' end='63' sourcepath='org/apache/spark/storage/DiskBlockManager.scala' sourcefile='DiskBlockManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.storage.DiskBlockManager.getFile(String)</Message></Method><SourceLine endBytecode='216' classname='org.apache.spark.storage.DiskBlockManager' start='77' end='77' sourcepath='org/apache/spark/storage/DiskBlockManager.scala' sourcefile='DiskBlockManager.scala' startBytecode='216' primary='true'><Message>At DiskBlockManager.scala:[line 77]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/storage/DiskBlockManager.getFile(Ljava/lang/String;)Ljava/io/File; parameter 0'><Message>Unknown source org/apache/spark/storage/DiskBlockManager.getFile(Ljava/lang/String;)Ljava/io/File; parameter 0</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.storage.DiskBlockManager' start='80' end='80' sourcepath='org/apache/spark/storage/DiskBlockManager.scala' sourcefile='DiskBlockManager.scala' startBytecode='5'><Message>At DiskBlockManager.scala:[line 80]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.storage.DiskBlockManager' start='84' end='84' sourcepath='org/apache/spark/storage/DiskBlockManager.scala' sourcefile='DiskBlockManager.scala' startBytecode='5'><Message>At DiskBlockManager.scala:[line 84]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.storage.DiskStore' start='100' end='100' sourcepath='org/apache/spark/storage/DiskStore.scala' sourcefile='DiskStore.scala' startBytecode='8'><Message>At DiskStore.scala:[line 100]</Message></SourceLine><SourceLine endBytecode='17' classname='org.apache.spark.storage.DiskStore' start='116' end='116' sourcepath='org/apache/spark/storage/DiskStore.scala' sourcefile='DiskStore.scala' startBytecode='17'><Message>At DiskStore.scala:[line 116]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.storage.DiskStore' start='129' end='129' sourcepath='org/apache/spark/storage/DiskStore.scala' sourcefile='DiskStore.scala' startBytecode='8'><Message>At DiskStore.scala:[line 129]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e522d2e20f8522fb73b21012ade74f44' cweid='330' rank='12' abbrev='SECPRS' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM_SCALA' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator (Scala)</ShortMessage><LongMessage>This Scala random generator (scala.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.storage.RandomBlockReplicationPolicy' primary='true'><SourceLine classname='org.apache.spark.storage.RandomBlockReplicationPolicy' start='97' end='130' sourcepath='org/apache/spark/storage/BlockReplicationPolicy.scala' sourcefile='BlockReplicationPolicy.scala'><Message>At BlockReplicationPolicy.scala:[lines 97-130]</Message></SourceLine><Message>In class org.apache.spark.storage.RandomBlockReplicationPolicy</Message></Class><Method isStatic='false' classname='org.apache.spark.storage.RandomBlockReplicationPolicy' signature='(Lorg/apache/spark/storage/BlockManagerId;Lscala/collection/Seq;Lscala/collection/mutable/HashSet;Lorg/apache/spark/storage/BlockId;I)Lscala/collection/immutable/List;' name='prioritize' primary='true'><SourceLine endBytecode='280' classname='org.apache.spark.storage.RandomBlockReplicationPolicy' start='119' end='130' sourcepath='org/apache/spark/storage/BlockReplicationPolicy.scala' sourcefile='BlockReplicationPolicy.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.storage.RandomBlockReplicationPolicy.prioritize(BlockManagerId, Seq, HashSet, BlockId, int)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.storage.RandomBlockReplicationPolicy' start='119' end='119' sourcepath='org/apache/spark/storage/BlockReplicationPolicy.scala' sourcefile='BlockReplicationPolicy.scala' startBytecode='9' primary='true'><Message>At BlockReplicationPolicy.scala:[line 119]</Message></SourceLine><String value='scala.util.Random'><Message>Value scala.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b46fec59ccc59825eac94a935d7e8108' rank='15' abbrev='SECFSM' category='SECURITY' priority='3' type='FORMAT_STRING_MANIPULATION' instanceOccurrenceMax='0'><ShortMessage>Format String Manipulation</ShortMessage><LongMessage>Format string argument allowing user controlled parameters</LongMessage><Class classname='org.apache.spark.ui.ConsoleProgressBar' primary='true'><SourceLine classname='org.apache.spark.ui.ConsoleProgressBar' start='32' end='130' sourcepath='org/apache/spark/ui/ConsoleProgressBar.scala' sourcefile='ConsoleProgressBar.scala'><Message>At ConsoleProgressBar.scala:[lines 32-130]</Message></SourceLine><Message>In class org.apache.spark.ui.ConsoleProgressBar</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.ConsoleProgressBar' signature='()V' name='clear' primary='true'><SourceLine endBytecode='145' classname='org.apache.spark.ui.ConsoleProgressBar' start='111' end='111' sourcepath='org/apache/spark/ui/ConsoleProgressBar.scala' sourcefile='ConsoleProgressBar.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.ConsoleProgressBar.clear()</Message></Method><SourceLine endBytecode='70' classname='org.apache.spark.ui.ConsoleProgressBar' start='112' end='112' sourcepath='org/apache/spark/ui/ConsoleProgressBar.scala' sourcefile='ConsoleProgressBar.scala' startBytecode='70' primary='true'><Message>At ConsoleProgressBar.scala:[line 112]</Message></SourceLine><String role='Sink method' value='java/io/PrintStream.printf(Ljava/lang/String;[Ljava/lang/Object;)Ljava/io/PrintStream;'><Message>Sink method java/io/PrintStream.printf(Ljava/lang/String;[Ljava/lang/Object;)Ljava/io/PrintStream;</Message></String><String role='Sink parameter' value='1'><Message>Sink parameter 1</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.$times(I)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.$times(I)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='50' classname='org.apache.spark.ui.ConsoleProgressBar' start='112' end='112' sourcepath='org/apache/spark/ui/ConsoleProgressBar.scala' sourcefile='ConsoleProgressBar.scala' startBytecode='50'><Message>At ConsoleProgressBar.scala:[line 112]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='ef7dd497eb4bad69bd8411530e81ffd0' rank='15' abbrev='SECSH' category='SECURITY' priority='3' type='SERVLET_HEADER' instanceOccurrenceMax='0'><ShortMessage>HTTP headers untrusted</ShortMessage><LongMessage>Request header can easily be altered by the client</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$' start='48' end='500' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 48-500]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$' signature='(Ljava/lang/String;Ljavax/servlet/http/HttpServletRequest;Ljava/net/URI;)Ljava/lang/String;' name='createProxyLocationHeader' primary='true'><SourceLine endBytecode='334' classname='org.apache.spark.ui.JettyUtils$' start='477' end='476' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$.createProxyLocationHeader(String, HttpServletRequest, URI)</Message></Method><SourceLine endBytecode='164' classname='org.apache.spark.ui.JettyUtils$' start='482' end='482' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='164' primary='true'><Message>At JettyUtils.scala:[line 482]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='861538b9922dc9d619efaf34ffa689e1' cweid='601' rank='12' abbrev='SECUR' category='SECURITY' priority='2' type='UNVALIDATED_REDIRECT' instanceOccurrenceMax='0'><ShortMessage>Unvalidated Redirect</ShortMessage><LongMessage>The following redirection could be used by an attacker to redirect users to a phishing website.</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$1' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$1' start='426' end='439' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 426-439]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$1' signature='(Ljava/lang/String;Lorg/eclipse/jetty/server/Request;Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='handle' primary='true'><SourceLine endBytecode='194' classname='org.apache.spark.ui.JettyUtils$$anon$1' start='432' end='439' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$1.handle(String, Request, HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='55' classname='org.apache.spark.ui.JettyUtils$$anon$1' start='438' end='438' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='55' primary='true'><Message>At JettyUtils.scala:[line 438]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.sendRedirect(Ljava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.sendRedirect(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='javax/servlet/http/HttpServletResponse.encodeRedirectURL(Ljava/lang/String;)Ljava/lang/String;'><Message>Unknown source javax/servlet/http/HttpServletResponse.encodeRedirectURL(Ljava/lang/String;)Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='96b5b569bcc2254ca002e5785bb64433' rank='10' abbrev='SECURLR' category='SECURITY' priority='1' type='URL_REWRITING' instanceOccurrenceMax='0'><ShortMessage>URL rewriting method</ShortMessage><LongMessage>Method rewriting session ID into the URL</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$1' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$1' start='426' end='439' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 426-439]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$1</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$1' signature='(Ljava/lang/String;Lorg/eclipse/jetty/server/Request;Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='handle' primary='true'><SourceLine endBytecode='194' classname='org.apache.spark.ui.JettyUtils$$anon$1' start='432' end='439' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$1.handle(String, Request, HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='50' classname='org.apache.spark.ui.JettyUtils$$anon$1' start='438' end='438' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='50' primary='true'><Message>At JettyUtils.scala:[line 438]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b937bceea780617d09ceb64de8450d29' cweid='176' rank='15' abbrev='SECUNI' category='SECURITY' priority='3' type='IMPROPER_UNICODE' instanceOccurrenceMax='0'><ShortMessage>Improper handling of Unicode transformations</ShortMessage><LongMessage>Improper handling of Unicode transformations such as case mapping and normalization.</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$2' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$2' start='206' end='249' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 206-249]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$2</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$2' signature='(Ljavax/servlet/http/HttpServletRequest;Lorg/eclipse/jetty/client/api/Response;Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String;' name='filterServerResponseHeader' primary='true'><SourceLine endBytecode='181' classname='org.apache.spark.ui.JettyUtils$$anon$2' start='241' end='248' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$2.filterServerResponseHeader(HttpServletRequest, Response, String, String)</Message></Method><SourceLine endBytecode='3' classname='org.apache.spark.ui.JettyUtils$$anon$2' start='241' end='241' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='3' primary='true'><Message>At JettyUtils.scala:[line 241]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5314edd14d78aee42597a22160291d85' rank='15' abbrev='SECSSQ' category='SECURITY' priority='3' type='SERVLET_QUERY_STRING' instanceOccurrenceMax='0'><ShortMessage>Untrusted query string</ShortMessage><LongMessage>The query string can be any value</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$1' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$1' start='223' end='223' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[line 223]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$1</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$1' signature='(Ljava/lang/String;)Ljava/net/URI;' name='apply' primary='true'><SourceLine endBytecode='76' classname='org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$1' start='223' end='223' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$1.apply(String)</Message></Method><SourceLine endBytecode='16' classname='org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$1' start='223' end='223' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='16' primary='true'><Message>At JettyUtils.scala:[line 223]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b91d4aeff81122a0733fcc7d5b71522b' cweid='113' rank='15' abbrev='SECHRS' category='SECURITY' priority='3' type='HTTP_RESPONSE_SPLITTING' instanceOccurrenceMax='0'><ShortMessage>Potential HTTP Response Splitting</ShortMessage><LongMessage>This use of javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V might be used to include CRLF characters into HTTP headers</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$3' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$3' start='84' end='118' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 84-118]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$3</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$3' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doGet' primary='true'><SourceLine endBytecode='578' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='87' end='86' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$3.doGet(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='101' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='92' end='92' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='101' primary='true'><Message>At JettyUtils.scala:[line 92]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/ui/JettyUtils$$anon$3.xFrameOptionsValue$1'><Message>Unknown source org/apache/spark/ui/JettyUtils$$anon$3.xFrameOptionsValue$1</Message></String><SourceLine endBytecode='98' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='92' end='92' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='98'><Message>At JettyUtils.scala:[line 92]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='31da65c0b3b2848e2ae594d4ae3e6aa3' cweid='113' rank='15' abbrev='SECHRS' category='SECURITY' priority='3' type='HTTP_RESPONSE_SPLITTING' instanceOccurrenceMax='0'><ShortMessage>Potential HTTP Response Splitting</ShortMessage><LongMessage>This use of javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V might be used to include CRLF characters into HTTP headers</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$3' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$3' start='84' end='118' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 84-118]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$3</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$3' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doGet' primary='true'><SourceLine endBytecode='578' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='87' end='86' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$3.doGet(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='125' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='93' end='93' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='125' primary='true'><Message>At JettyUtils.scala:[line 93]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/SparkConf.get(Lorg/apache/spark/internal/config/ConfigEntry;)Ljava/lang/Object;'><Message>Unknown source org/apache/spark/SparkConf.get(Lorg/apache/spark/internal/config/ConfigEntry;)Ljava/lang/Object;</Message></String><String role='Unknown source' value='org/apache/spark/internal/config/ConfigEntry.readFrom(Lorg/apache/spark/internal/config/ConfigReader;)Ljava/lang/Object;'><Message>Unknown source org/apache/spark/internal/config/ConfigEntry.readFrom(Lorg/apache/spark/internal/config/ConfigReader;)Ljava/lang/Object;</Message></String><SourceLine endBytecode='119' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='93' end='93' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='119'><Message>At JettyUtils.scala:[line 93]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3b13d337e7254bdea2e0b24d7ee8e804' cweid='79' rank='12' abbrev='SECXSS2' category='SECURITY' priority='2' type='XSS_SERVLET' instanceOccurrenceMax='0'><ShortMessage>Potential XSS in Servlet</ShortMessage><LongMessage>This use of java/io/PrintWriter.print(Ljava/lang/String;)V could be vulnerable to XSS in the Servlet</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$3' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$3' start='84' end='118' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 84-118]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$3</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$3' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doGet' primary='true'><SourceLine endBytecode='578' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='87' end='86' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$3.doGet(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='241' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='101' end='101' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='241' primary='true'><Message>At JettyUtils.scala:[line 101]</Message></SourceLine><String role='Sink method' value='java/io/PrintWriter.print(Ljava/lang/String;)V'><Message>Sink method java/io/PrintWriter.print(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Function1.apply(Ljava/lang/Object;)Ljava/lang/Object;'><Message>Unknown source scala/Function1.apply(Ljava/lang/Object;)Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a6b53beb639594836dd0bb713a26d01d' cweid='79' rank='12' abbrev='SECXSS2' category='SECURITY' priority='2' type='XSS_SERVLET' instanceOccurrenceMax='0'><ShortMessage>Potential XSS in Servlet</ShortMessage><LongMessage>This use of javax/servlet/http/HttpServletResponse.sendError(ILjava/lang/String;)V could be vulnerable to XSS in the Servlet</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$3' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$3' start='84' end='118' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 84-118]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$3</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$3' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doGet' primary='true'><SourceLine endBytecode='578' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='87' end='86' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$3.doGet(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='311' classname='org.apache.spark.ui.JettyUtils$$anon$3' start='110' end='110' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='311' primary='true'><Message>At JettyUtils.scala:[line 110]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.sendError(ILjava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.sendError(ILjava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/lang/IllegalArgumentException.getMessage()Ljava/lang/String;'><Message>Unknown source java/lang/IllegalArgumentException.getMessage()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c9bfca3187fd483fc618df5c58e204e' cweid='113' rank='15' abbrev='SECHRS' category='SECURITY' priority='3' type='HTTP_RESPONSE_SPLITTING' instanceOccurrenceMax='0'><ShortMessage>Potential HTTP Response Splitting</ShortMessage><LongMessage>This use of javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V might be used to include CRLF characters into HTTP headers</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1' start='99' end='99' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[line 99]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='64' classname='org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1' start='99' end='99' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1.apply(String)</Message></Method><SourceLine endBytecode='7' classname='org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1' start='99' end='99' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='7' primary='true'><Message>At JettyUtils.scala:[line 99]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.setHeader(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/ui/JettyUtils$$anon$3$$anonfun$doGet$1.apply(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/ui/JettyUtils$$anon$3$$anonfun$doGet$1.apply(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1' start='99' end='99' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='5'><Message>At JettyUtils.scala:[line 99]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='16903a697a6276b9797a6ed70d4db890' cweid='601' rank='10' abbrev='SECUR' category='SECURITY' priority='1' type='UNVALIDATED_REDIRECT' instanceOccurrenceMax='0'><ShortMessage>Unvalidated Redirect</ShortMessage><LongMessage>The following redirection could be used by an attacker to redirect users to a phishing website.</LongMessage><Class classname='org.apache.spark.ui.JettyUtils$$anon$4' primary='true'><SourceLine classname='org.apache.spark.ui.JettyUtils$$anon$4' start='158' end='181' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala'><Message>At JettyUtils.scala:[lines 158-181]</Message></SourceLine><Message>In class org.apache.spark.ui.JettyUtils$$anon$4</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.JettyUtils$$anon$4' signature='(Ljavax/servlet/http/HttpServletRequest;Ljavax/servlet/http/HttpServletResponse;)V' name='doRequest' primary='true'><SourceLine endBytecode='129' classname='org.apache.spark.ui.JettyUtils$$anon$4' start='174' end='177' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.JettyUtils$$anon$4.doRequest(HttpServletRequest, HttpServletResponse)</Message></Method><SourceLine endBytecode='44' classname='org.apache.spark.ui.JettyUtils$$anon$4' start='177' end='177' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='44' primary='true'><Message>At JettyUtils.scala:[line 177]</Message></SourceLine><String role='Sink method' value='javax/servlet/http/HttpServletResponse.sendRedirect(Ljava/lang/String;)V'><Message>Sink method javax/servlet/http/HttpServletResponse.sendRedirect(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Tainted source' value='java/net/URL.toString()Ljava/lang/String;'><Message>Tainted source java/net/URL.toString()Ljava/lang/String;</Message></String><String role='Tainted source' value='java/net/URL.&lt;init&gt;(Ljava/lang/String;)V'><Message>Tainted source java/net/URL.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Tainted source' value='java/lang/StringBuffer.toString()Ljava/lang/String;'><Message>Tainted source java/lang/StringBuffer.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/ui/JettyUtils$$anon$4.prefixedDestPath$1'><Message>Unknown source org/apache/spark/ui/JettyUtils$$anon$4.prefixedDestPath$1</Message></String><String role='Tainted source' value='javax/servlet/http/HttpServletRequest.getRequestURL()Ljava/lang/StringBuffer;'><Message>Tainted source javax/servlet/http/HttpServletRequest.getRequestURL()Ljava/lang/StringBuffer;</Message></String><String role='Tainted source' value='java/net/URL.&lt;init&gt;(Ljava/net/URL;Ljava/lang/String;)V'><Message>Tainted source java/net/URL.&lt;init&gt;(Ljava/net/URL;Ljava/lang/String;)V</Message></String><SourceLine endBytecode='32' classname='org.apache.spark.ui.JettyUtils$$anon$4' start='176' end='176' sourcepath='org/apache/spark/ui/JettyUtils.scala' sourcefile='JettyUtils.scala' startBytecode='32'><Message>At JettyUtils.scala:[line 176]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7ccbf5bee05fd10fdafc2e57af4af523' cweid='330' rank='12' abbrev='SECPRS' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM_SCALA' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator (Scala)</ShortMessage><LongMessage>This Scala random generator (scala.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.ui.UIWorkloadGenerator$' primary='true'><SourceLine classname='org.apache.spark.ui.UIWorkloadGenerator$' start='36' end='123' sourcepath='org/apache/spark/ui/UIWorkloadGenerator.scala' sourcefile='UIWorkloadGenerator.scala'><Message>At UIWorkloadGenerator.scala:[lines 36-123]</Message></SourceLine><Message>In class org.apache.spark.ui.UIWorkloadGenerator$</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.UIWorkloadGenerator$' signature='()F' name='org$apache$spark$ui$UIWorkloadGenerator$$nextFloat$1' primary='true'><SourceLine endBytecode='52' classname='org.apache.spark.ui.UIWorkloadGenerator$' start='66' end='66' sourcepath='org/apache/spark/ui/UIWorkloadGenerator.scala' sourcefile='UIWorkloadGenerator.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.UIWorkloadGenerator$.org$apache$spark$ui$UIWorkloadGenerator$$nextFloat$1()</Message></Method><SourceLine endBytecode='4' classname='org.apache.spark.ui.UIWorkloadGenerator$' start='66' end='66' sourcepath='org/apache/spark/ui/UIWorkloadGenerator.scala' sourcefile='UIWorkloadGenerator.scala' startBytecode='4' primary='true'><Message>At UIWorkloadGenerator.scala:[line 66]</Message></SourceLine><String value='scala.util.Random'><Message>Value scala.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a40b7e27bdf6f10a1ac068399b1ea1e2' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.exec.ExecutorThreadDumpPage' primary='true'><SourceLine classname='org.apache.spark.ui.exec.ExecutorThreadDumpPage' start='29' end='111' sourcepath='org/apache/spark/ui/exec/ExecutorThreadDumpPage.scala' sourcefile='ExecutorThreadDumpPage.scala'><Message>At ExecutorThreadDumpPage.scala:[lines 29-111]</Message></SourceLine><Message>In class org.apache.spark.ui.exec.ExecutorThreadDumpPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.exec.ExecutorThreadDumpPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='315' classname='org.apache.spark.ui.exec.ExecutorThreadDumpPage' start='35' end='111' sourcepath='org/apache/spark/ui/exec/ExecutorThreadDumpPage.scala' sourcefile='ExecutorThreadDumpPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.exec.ExecutorThreadDumpPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.ui.exec.ExecutorThreadDumpPage' start='35' end='35' sourcepath='org/apache/spark/ui/exec/ExecutorThreadDumpPage.scala' sourcefile='ExecutorThreadDumpPage.scala' startBytecode='9' primary='true'><Message>At ExecutorThreadDumpPage.scala:[line 35]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='64419a56a5ce7ef39565dfa3c189a5fe' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameterMap returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.AllJobsPage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.AllJobsPage' start='38' end='410' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala'><Message>At AllJobsPage.scala:[lines 38-410]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.AllJobsPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.AllJobsPage' signature='(Ljavax/servlet/http/HttpServletRequest;Ljava/lang/String;Ljava/lang/String;Lscala/collection/Seq;Z)Lscala/collection/Seq;' name='jobsTable' primary='true'><SourceLine endBytecode='1584' classname='org.apache.spark.ui.jobs.AllJobsPage' start='209' end='245' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.AllJobsPage.jobsTable(HttpServletRequest, String, String, Seq, boolean)</Message></Method><SourceLine endBytecode='4' classname='org.apache.spark.ui.jobs.AllJobsPage' start='209' end='209' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='4' primary='true'><Message>At AllJobsPage.scala:[line 209]</Message></SourceLine><String value='getParameterMap'><Message>Value getParameterMap</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cdac5f9f8a1a0c15f8fff0cc58b72955' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.AllJobsPage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.AllJobsPage' start='38' end='410' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala'><Message>At AllJobsPage.scala:[lines 38-410]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.AllJobsPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.AllJobsPage' signature='(Ljavax/servlet/http/HttpServletRequest;Ljava/lang/String;Ljava/lang/String;Lscala/collection/Seq;Z)Lscala/collection/Seq;' name='jobsTable' primary='true'><SourceLine endBytecode='1584' classname='org.apache.spark.ui.jobs.AllJobsPage' start='209' end='245' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.AllJobsPage.jobsTable(HttpServletRequest, String, String, Seq, boolean)</Message></Method><SourceLine endBytecode='141' classname='org.apache.spark.ui.jobs.AllJobsPage' start='217' end='217' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='141' primary='true'><Message>At AllJobsPage.scala:[line 217]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='cdac5f9f8a1a0c15f8fff0cc58b72955' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.AllJobsPage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.AllJobsPage' start='38' end='410' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala'><Message>At AllJobsPage.scala:[lines 38-410]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.AllJobsPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.AllJobsPage' signature='(Ljavax/servlet/http/HttpServletRequest;Ljava/lang/String;Ljava/lang/String;Lscala/collection/Seq;Z)Lscala/collection/Seq;' name='jobsTable' primary='true'><SourceLine endBytecode='1584' classname='org.apache.spark.ui.jobs.AllJobsPage' start='209' end='245' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.AllJobsPage.jobsTable(HttpServletRequest, String, String, Seq, boolean)</Message></Method><SourceLine endBytecode='175' classname='org.apache.spark.ui.jobs.AllJobsPage' start='218' end='218' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='175' primary='true'><Message>At AllJobsPage.scala:[line 218]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='2' instanceHash='cdac5f9f8a1a0c15f8fff0cc58b72955' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.AllJobsPage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.AllJobsPage' start='38' end='410' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala'><Message>At AllJobsPage.scala:[lines 38-410]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.AllJobsPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.AllJobsPage' signature='(Ljavax/servlet/http/HttpServletRequest;Ljava/lang/String;Ljava/lang/String;Lscala/collection/Seq;Z)Lscala/collection/Seq;' name='jobsTable' primary='true'><SourceLine endBytecode='1584' classname='org.apache.spark.ui.jobs.AllJobsPage' start='209' end='245' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.AllJobsPage.jobsTable(HttpServletRequest, String, String, Seq, boolean)</Message></Method><SourceLine endBytecode='209' classname='org.apache.spark.ui.jobs.AllJobsPage' start='219' end='219' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='209' primary='true'><Message>At AllJobsPage.scala:[line 219]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='3' instanceHash='cdac5f9f8a1a0c15f8fff0cc58b72955' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.AllJobsPage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.AllJobsPage' start='38' end='410' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala'><Message>At AllJobsPage.scala:[lines 38-410]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.AllJobsPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.AllJobsPage' signature='(Ljavax/servlet/http/HttpServletRequest;Ljava/lang/String;Ljava/lang/String;Lscala/collection/Seq;Z)Lscala/collection/Seq;' name='jobsTable' primary='true'><SourceLine endBytecode='1584' classname='org.apache.spark.ui.jobs.AllJobsPage' start='209' end='245' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.AllJobsPage.jobsTable(HttpServletRequest, String, String, Seq, boolean)</Message></Method><SourceLine endBytecode='243' classname='org.apache.spark.ui.jobs.AllJobsPage' start='220' end='220' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='243' primary='true'><Message>At AllJobsPage.scala:[line 220]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='4' instanceHash='cdac5f9f8a1a0c15f8fff0cc58b72955' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.AllJobsPage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.AllJobsPage' start='38' end='410' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala'><Message>At AllJobsPage.scala:[lines 38-410]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.AllJobsPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.AllJobsPage' signature='(Ljavax/servlet/http/HttpServletRequest;Ljava/lang/String;Ljava/lang/String;Lscala/collection/Seq;Z)Lscala/collection/Seq;' name='jobsTable' primary='true'><SourceLine endBytecode='1584' classname='org.apache.spark.ui.jobs.AllJobsPage' start='209' end='245' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.AllJobsPage.jobsTable(HttpServletRequest, String, String, Seq, boolean)</Message></Method><SourceLine endBytecode='277' classname='org.apache.spark.ui.jobs.AllJobsPage' start='221' end='221' sourcepath='org/apache/spark/ui/jobs/AllJobsPage.scala' sourcefile='AllJobsPage.scala' startBytecode='277' primary='true'><Message>At AllJobsPage.scala:[line 221]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e798ed3daf1b7025e8110945818d098d' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.JobPage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.JobPage' start='35' end='416' sourcepath='org/apache/spark/ui/jobs/JobPage.scala' sourcefile='JobPage.scala'><Message>At JobPage.scala:[lines 35-416]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.JobPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.JobPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='9477' classname='org.apache.spark.ui.jobs.JobPage' start='186' end='186' sourcepath='org/apache/spark/ui/jobs/JobPage.scala' sourcefile='JobPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.JobPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='14' classname='org.apache.spark.ui.jobs.JobPage' start='188' end='188' sourcepath='org/apache/spark/ui/jobs/JobPage.scala' sourcefile='JobPage.scala' startBytecode='14' primary='true'><Message>At JobPage.scala:[line 188]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c3d1cfa172b8497f84ea999ead8cbf' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.JobsTab' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.JobsTab' start='30' end='52' sourcepath='org/apache/spark/ui/jobs/JobsTab.scala' sourcefile='JobsTab.scala'><Message>At JobsTab.scala:[lines 30-52]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.JobsTab</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.JobsTab' signature='(Ljavax/servlet/http/HttpServletRequest;)V' name='handleKillRequest' primary='true'><SourceLine endBytecode='155' classname='org.apache.spark.ui.jobs.JobsTab' start='49' end='49' sourcepath='org/apache/spark/ui/jobs/JobsTab.scala' sourcefile='JobsTab.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.JobsTab.handleKillRequest(HttpServletRequest)</Message></Method><SourceLine endBytecode='35' classname='org.apache.spark.ui.jobs.JobsTab' start='51' end='51' sourcepath='org/apache/spark/ui/jobs/JobsTab.scala' sourcefile='JobsTab.scala' startBytecode='35' primary='true'><Message>At JobsTab.scala:[line 51]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c3b33ca364b6c5023397219f2f358d32' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.PoolPage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.PoolPage' start='29' end='68' sourcepath='org/apache/spark/ui/jobs/PoolPage.scala' sourcefile='PoolPage.scala'><Message>At PoolPage.scala:[lines 29-68]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.PoolPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.PoolPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='1291' classname='org.apache.spark.ui.jobs.PoolPage' start='33' end='68' sourcepath='org/apache/spark/ui/jobs/PoolPage.scala' sourcefile='PoolPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.PoolPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='9' classname='org.apache.spark.ui.jobs.PoolPage' start='33' end='33' sourcepath='org/apache/spark/ui/jobs/PoolPage.scala' sourcefile='PoolPage.scala' startBytecode='9' primary='true'><Message>At PoolPage.scala:[line 33]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='63ad320e85215db0396ca94313cb53c1' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='6'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StagePage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StagePage' start='37' end='669' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala'><Message>At StagePage.scala:[lines 37-669]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StagePage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StagePage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='14549' classname='org.apache.spark.ui.jobs.StagePage' start='82' end='82' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.StagePage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='14' classname='org.apache.spark.ui.jobs.StagePage' start='84' end='84' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='14' primary='true'><Message>At StagePage.scala:[line 84]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='63ad320e85215db0396ca94313cb53c1' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='6'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StagePage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StagePage' start='37' end='669' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala'><Message>At StagePage.scala:[lines 37-669]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StagePage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StagePage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='14549' classname='org.apache.spark.ui.jobs.StagePage' start='82' end='82' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.StagePage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='75' classname='org.apache.spark.ui.jobs.StagePage' start='87' end='87' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='75' primary='true'><Message>At StagePage.scala:[line 87]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='2' instanceHash='63ad320e85215db0396ca94313cb53c1' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='6'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StagePage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StagePage' start='37' end='669' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala'><Message>At StagePage.scala:[lines 37-669]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StagePage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StagePage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='14549' classname='org.apache.spark.ui.jobs.StagePage' start='82' end='82' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.StagePage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='136' classname='org.apache.spark.ui.jobs.StagePage' start='90' end='90' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='136' primary='true'><Message>At StagePage.scala:[line 90]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='3' instanceHash='63ad320e85215db0396ca94313cb53c1' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='6'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StagePage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StagePage' start='37' end='669' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala'><Message>At StagePage.scala:[lines 37-669]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StagePage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StagePage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='14549' classname='org.apache.spark.ui.jobs.StagePage' start='82' end='82' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.StagePage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='152' classname='org.apache.spark.ui.jobs.StagePage' start='91' end='91' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='152' primary='true'><Message>At StagePage.scala:[line 91]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='4' instanceHash='63ad320e85215db0396ca94313cb53c1' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='6'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StagePage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StagePage' start='37' end='669' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala'><Message>At StagePage.scala:[lines 37-669]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StagePage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StagePage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='14549' classname='org.apache.spark.ui.jobs.StagePage' start='82' end='82' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.StagePage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='168' classname='org.apache.spark.ui.jobs.StagePage' start='92' end='92' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='168' primary='true'><Message>At StagePage.scala:[line 92]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='5' instanceHash='63ad320e85215db0396ca94313cb53c1' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='6'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StagePage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StagePage' start='37' end='669' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala'><Message>At StagePage.scala:[lines 37-669]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StagePage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StagePage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='14549' classname='org.apache.spark.ui.jobs.StagePage' start='82' end='82' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.StagePage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='184' classname='org.apache.spark.ui.jobs.StagePage' start='93' end='93' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='184' primary='true'><Message>At StagePage.scala:[line 93]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='6' instanceHash='63ad320e85215db0396ca94313cb53c1' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='6'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StagePage' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StagePage' start='37' end='669' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala'><Message>At StagePage.scala:[lines 37-669]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StagePage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StagePage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='14549' classname='org.apache.spark.ui.jobs.StagePage' start='82' end='82' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.StagePage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='200' classname='org.apache.spark.ui.jobs.StagePage' start='94' end='94' sourcepath='org/apache/spark/ui/jobs/StagePage.scala' sourcefile='StagePage.scala' startBytecode='200' primary='true'><Message>At StagePage.scala:[line 94]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='bcc77fefa82522d1e800783631cbefdc' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameterMap returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StageTableBase' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='108' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala'><Message>At StageTable.scala:[lines 35-108]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StageTableBase</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StageTableBase' signature='(Lorg/apache/spark/status/AppStatusStore;Ljavax/servlet/http/HttpServletRequest;Lscala/collection/Seq;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ZZZ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='940' classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='80' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.ui.jobs.StageTableBase(AppStatusStore, HttpServletRequest, Seq, String, String, String, String, boolean, boolean, boolean)</Message></Method><SourceLine endBytecode='61' classname='org.apache.spark.ui.jobs.StageTableBase' start='46' end='46' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='61' primary='true'><Message>At StageTable.scala:[line 46]</Message></SourceLine><String value='getParameterMap'><Message>Value getParameterMap</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f67cab5a6656c3e671c91cc1aed756d0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StageTableBase' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='108' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala'><Message>At StageTable.scala:[lines 35-108]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StageTableBase</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StageTableBase' signature='(Lorg/apache/spark/status/AppStatusStore;Ljavax/servlet/http/HttpServletRequest;Lscala/collection/Seq;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ZZZ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='940' classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='80' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.ui.jobs.StageTableBase(AppStatusStore, HttpServletRequest, Seq, String, String, String, String, boolean, boolean, boolean)</Message></Method><SourceLine endBytecode='171' classname='org.apache.spark.ui.jobs.StageTableBase' start='50' end='50' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='171' primary='true'><Message>At StageTable.scala:[line 50]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='f67cab5a6656c3e671c91cc1aed756d0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StageTableBase' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='108' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala'><Message>At StageTable.scala:[lines 35-108]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StageTableBase</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StageTableBase' signature='(Lorg/apache/spark/status/AppStatusStore;Ljavax/servlet/http/HttpServletRequest;Lscala/collection/Seq;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ZZZ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='940' classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='80' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.ui.jobs.StageTableBase(AppStatusStore, HttpServletRequest, Seq, String, String, String, String, boolean, boolean, boolean)</Message></Method><SourceLine endBytecode='208' classname='org.apache.spark.ui.jobs.StageTableBase' start='51' end='51' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='208' primary='true'><Message>At StageTable.scala:[line 51]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='2' instanceHash='f67cab5a6656c3e671c91cc1aed756d0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StageTableBase' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='108' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala'><Message>At StageTable.scala:[lines 35-108]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StageTableBase</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StageTableBase' signature='(Lorg/apache/spark/status/AppStatusStore;Ljavax/servlet/http/HttpServletRequest;Lscala/collection/Seq;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ZZZ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='940' classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='80' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.ui.jobs.StageTableBase(AppStatusStore, HttpServletRequest, Seq, String, String, String, String, boolean, boolean, boolean)</Message></Method><SourceLine endBytecode='245' classname='org.apache.spark.ui.jobs.StageTableBase' start='52' end='52' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='245' primary='true'><Message>At StageTable.scala:[line 52]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='3' instanceHash='f67cab5a6656c3e671c91cc1aed756d0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StageTableBase' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='108' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala'><Message>At StageTable.scala:[lines 35-108]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StageTableBase</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StageTableBase' signature='(Lorg/apache/spark/status/AppStatusStore;Ljavax/servlet/http/HttpServletRequest;Lscala/collection/Seq;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ZZZ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='940' classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='80' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.ui.jobs.StageTableBase(AppStatusStore, HttpServletRequest, Seq, String, String, String, String, boolean, boolean, boolean)</Message></Method><SourceLine endBytecode='282' classname='org.apache.spark.ui.jobs.StageTableBase' start='53' end='53' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='282' primary='true'><Message>At StageTable.scala:[line 53]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='4' instanceHash='f67cab5a6656c3e671c91cc1aed756d0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='4'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StageTableBase' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='108' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala'><Message>At StageTable.scala:[lines 35-108]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StageTableBase</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StageTableBase' signature='(Lorg/apache/spark/status/AppStatusStore;Ljavax/servlet/http/HttpServletRequest;Lscala/collection/Seq;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ZZZ)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='940' classname='org.apache.spark.ui.jobs.StageTableBase' start='35' end='80' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.ui.jobs.StageTableBase(AppStatusStore, HttpServletRequest, Seq, String, String, String, String, boolean, boolean, boolean)</Message></Method><SourceLine endBytecode='319' classname='org.apache.spark.ui.jobs.StageTableBase' start='55' end='55' sourcepath='org/apache/spark/ui/jobs/StageTable.scala' sourcefile='StageTable.scala' startBytecode='319' primary='true'><Message>At StageTable.scala:[line 55]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d807bebe66ea20040cb7326ab85c98b4' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='0'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.jobs.StagesTab' primary='true'><SourceLine classname='org.apache.spark.ui.jobs.StagesTab' start='28' end='50' sourcepath='org/apache/spark/ui/jobs/StagesTab.scala' sourcefile='StagesTab.scala'><Message>At StagesTab.scala:[lines 28-50]</Message></SourceLine><Message>In class org.apache.spark.ui.jobs.StagesTab</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.jobs.StagesTab' signature='(Ljavax/servlet/http/HttpServletRequest;)V' name='handleKillRequest' primary='true'><SourceLine endBytecode='155' classname='org.apache.spark.ui.jobs.StagesTab' start='47' end='47' sourcepath='org/apache/spark/ui/jobs/StagesTab.scala' sourcefile='StagesTab.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.jobs.StagesTab.handleKillRequest(HttpServletRequest)</Message></Method><SourceLine endBytecode='35' classname='org.apache.spark.ui.jobs.StagesTab' start='49' end='49' sourcepath='org/apache/spark/ui/jobs/StagesTab.scala' sourcefile='StagesTab.scala' startBytecode='35' primary='true'><Message>At StagesTab.scala:[line 49]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3beba7d058fbebebd618475601c183b0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.storage.RDDPage' primary='true'><SourceLine classname='org.apache.spark.ui.storage.RDDPage' start='31' end='169' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala'><Message>At RDDPage.scala:[lines 31-169]</Message></SourceLine><Message>In class org.apache.spark.ui.storage.RDDPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.storage.RDDPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='4143' classname='org.apache.spark.ui.storage.RDDPage' start='35' end='73' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.storage.RDDPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='6' classname='org.apache.spark.ui.storage.RDDPage' start='35' end='35' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='6' primary='true'><Message>At RDDPage.scala:[line 35]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='3beba7d058fbebebd618475601c183b0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.storage.RDDPage' primary='true'><SourceLine classname='org.apache.spark.ui.storage.RDDPage' start='31' end='169' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala'><Message>At RDDPage.scala:[lines 31-169]</Message></SourceLine><Message>In class org.apache.spark.ui.storage.RDDPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.storage.RDDPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='4143' classname='org.apache.spark.ui.storage.RDDPage' start='35' end='73' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.storage.RDDPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='64' classname='org.apache.spark.ui.storage.RDDPage' start='38' end='38' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='64' primary='true'><Message>At RDDPage.scala:[line 38]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='2' instanceHash='3beba7d058fbebebd618475601c183b0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.storage.RDDPage' primary='true'><SourceLine classname='org.apache.spark.ui.storage.RDDPage' start='31' end='169' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala'><Message>At RDDPage.scala:[lines 31-169]</Message></SourceLine><Message>In class org.apache.spark.ui.storage.RDDPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.storage.RDDPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='4143' classname='org.apache.spark.ui.storage.RDDPage' start='35' end='73' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.storage.RDDPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='79' classname='org.apache.spark.ui.storage.RDDPage' start='39' end='39' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='79' primary='true'><Message>At RDDPage.scala:[line 39]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='3' instanceHash='3beba7d058fbebebd618475601c183b0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.storage.RDDPage' primary='true'><SourceLine classname='org.apache.spark.ui.storage.RDDPage' start='31' end='169' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala'><Message>At RDDPage.scala:[lines 31-169]</Message></SourceLine><Message>In class org.apache.spark.ui.storage.RDDPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.storage.RDDPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='4143' classname='org.apache.spark.ui.storage.RDDPage' start='35' end='73' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.storage.RDDPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='95' classname='org.apache.spark.ui.storage.RDDPage' start='40' end='40' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='95' primary='true'><Message>At RDDPage.scala:[line 40]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='4' instanceHash='3beba7d058fbebebd618475601c183b0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.storage.RDDPage' primary='true'><SourceLine classname='org.apache.spark.ui.storage.RDDPage' start='31' end='169' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala'><Message>At RDDPage.scala:[lines 31-169]</Message></SourceLine><Message>In class org.apache.spark.ui.storage.RDDPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.storage.RDDPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='4143' classname='org.apache.spark.ui.storage.RDDPage' start='35' end='73' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.storage.RDDPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='111' classname='org.apache.spark.ui.storage.RDDPage' start='41' end='41' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='111' primary='true'><Message>At RDDPage.scala:[line 41]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='5' instanceHash='3beba7d058fbebebd618475601c183b0' rank='15' abbrev='SECSP' category='SECURITY' priority='3' type='SERVLET_PARAMETER' instanceOccurrenceMax='5'><ShortMessage>Untrusted servlet parameter</ShortMessage><LongMessage>The method getParameter returns a String value that is controlled by the client</LongMessage><Class classname='org.apache.spark.ui.storage.RDDPage' primary='true'><SourceLine classname='org.apache.spark.ui.storage.RDDPage' start='31' end='169' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala'><Message>At RDDPage.scala:[lines 31-169]</Message></SourceLine><Message>In class org.apache.spark.ui.storage.RDDPage</Message></Class><Method isStatic='false' classname='org.apache.spark.ui.storage.RDDPage' signature='(Ljavax/servlet/http/HttpServletRequest;)Lscala/collection/Seq;' name='render' primary='true'><SourceLine endBytecode='4143' classname='org.apache.spark.ui.storage.RDDPage' start='35' end='73' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.ui.storage.RDDPage.render(HttpServletRequest)</Message></Method><SourceLine endBytecode='127' classname='org.apache.spark.ui.storage.RDDPage' start='42' end='42' sourcepath='org/apache/spark/ui/storage/RDDPage.scala' sourcefile='RDDPage.scala' startBytecode='127' primary='true'><Message>At RDDPage.scala:[line 42]</Message></SourceLine><String value='getParameter'><Message>Value getParameter</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='48c386f3482157e8fbd44ddd69cee121' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.unsafe.map.BytesToBytesMap' primary='true'><SourceLine classname='org.apache.spark.unsafe.map.BytesToBytesMap' start='66' end='930' sourcepath='org/apache/spark/unsafe/map/BytesToBytesMap.java' sourcefile='BytesToBytesMap.java'><Message>At BytesToBytesMap.java:[lines 66-930]</Message></SourceLine><Message>In class org.apache.spark.unsafe.map.BytesToBytesMap</Message></Class><Method isStatic='false' classname='org.apache.spark.unsafe.map.BytesToBytesMap' signature='()V' name='free' primary='true'><SourceLine endBytecode='325' classname='org.apache.spark.unsafe.map.BytesToBytesMap' start='801' end='822' sourcepath='org/apache/spark/unsafe/map/BytesToBytesMap.java' sourcefile='BytesToBytesMap.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.unsafe.map.BytesToBytesMap.free()</Message></Method><SourceLine endBytecode='140' classname='org.apache.spark.unsafe.map.BytesToBytesMap' start='818' end='818' sourcepath='org/apache/spark/unsafe/map/BytesToBytesMap.java' sourcefile='BytesToBytesMap.java' startBytecode='140' primary='true'><Message>At BytesToBytesMap.java:[line 818]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5e9c55ba7f398aa49400a7efebb02c4e' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.unsafe.map.BytesToBytesMap$MapIterator' primary='true'><SourceLine classname='org.apache.spark.unsafe.map.BytesToBytesMap$MapIterator' start='240' end='403' sourcepath='org/apache/spark/unsafe/map/BytesToBytesMap.java' sourcefile='BytesToBytesMap.java'><Message>At BytesToBytesMap.java:[lines 240-403]</Message></SourceLine><Message>In class org.apache.spark.unsafe.map.BytesToBytesMap$MapIterator</Message></Class><Method isStatic='false' classname='org.apache.spark.unsafe.map.BytesToBytesMap$MapIterator' signature='()V' name='handleFailedDelete' primary='true'><SourceLine endBytecode='127' classname='org.apache.spark.unsafe.map.BytesToBytesMap$MapIterator' start='399' end='403' sourcepath='org/apache/spark/unsafe/map/BytesToBytesMap.java' sourcefile='BytesToBytesMap.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.unsafe.map.BytesToBytesMap$MapIterator.handleFailedDelete()</Message></Method><SourceLine endBytecode='44' classname='org.apache.spark.unsafe.map.BytesToBytesMap$MapIterator' start='401' end='401' sourcepath='org/apache/spark/unsafe/map/BytesToBytesMap.java' sourcefile='BytesToBytesMap.java' startBytecode='44' primary='true'><Message>At BytesToBytesMap.java:[line 401]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='46a351921e9bb526203ee7254f52dbe6' cweid='176' rank='15' abbrev='SECUNI' category='SECURITY' priority='3' type='IMPROPER_UNICODE' instanceOccurrenceMax='0'><ShortMessage>Improper handling of Unicode transformations</ShortMessage><LongMessage>Improper handling of Unicode transformations such as case mapping and normalization.</LongMessage><Class classname='org.apache.spark.util.EnumUtil' primary='true'><SourceLine classname='org.apache.spark.util.EnumUtil' start='23' end='36' sourcepath='org/apache/spark/util/EnumUtil.java' sourcefile='EnumUtil.java'><Message>At EnumUtil.java:[lines 23-36]</Message></SourceLine><Message>In class org.apache.spark.util.EnumUtil</Message></Class><Method isStatic='true' classname='org.apache.spark.util.EnumUtil' signature='(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Enum;' name='parseIgnoreCase' primary='true'><SourceLine endBytecode='261' classname='org.apache.spark.util.EnumUtil' start='25' end='35' sourcepath='org/apache/spark/util/EnumUtil.java' sourcefile='EnumUtil.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.EnumUtil.parseIgnoreCase(Class, String)</Message></Method><SourceLine endBytecode='42' classname='org.apache.spark.util.EnumUtil' start='30' end='30' sourcepath='org/apache/spark/util/EnumUtil.java' sourcefile='EnumUtil.java' startBytecode='42' primary='true'><Message>At EnumUtil.java:[line 30]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='71bc8cad5aeaaabbc33ea683b56d0098' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3' primary='true'><SourceLine classname='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3' start='62' end='67' sourcepath='org/apache/spark/util/ShutdownHookManager.scala' sourcefile='ShutdownHookManager.scala'><Message>At ShutdownHookManager.scala:[lines 62-67]</Message></SourceLine><Message>In class org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3</Message></Class><Method isStatic='false' classname='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3' signature='(Ljava/lang/String;)V' name='apply' primary='true'><SourceLine endBytecode='138' classname='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3' start='64' end='63' sourcepath='org/apache/spark/util/ShutdownHookManager.scala' sourcefile='ShutdownHookManager.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(String)</Message></Method><SourceLine endBytecode='23' classname='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3' start='65' end='65' sourcepath='org/apache/spark/util/ShutdownHookManager.scala' sourcefile='ShutdownHookManager.scala' startBytecode='23' primary='true'><Message>At ShutdownHookManager.scala:[line 65]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(Ljava/lang/String;)V parameter 0'><Message>Unknown source org/apache/spark/util/ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(Ljava/lang/String;)V parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3' start='62' end='62' sourcepath='org/apache/spark/util/ShutdownHookManager.scala' sourcefile='ShutdownHookManager.scala' startBytecode='5'><Message>At ShutdownHookManager.scala:[line 62]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='7e79f247233d0bbc4c45e36224cd82ca' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1' primary='true'><SourceLine classname='org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1' start='42' end='44' sourcepath='org/apache/spark/util/SignalUtils.scala' sourcefile='SignalUtils.scala'><Message>At SignalUtils.scala:[lines 42-44]</Message></SourceLine><Message>In class org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1</Message></Class><Method isStatic='false' classname='org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1' signature='()Z' name='apply$mcZ$sp' primary='true'><SourceLine endBytecode='81' classname='org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1' start='43' end='44' sourcepath='org/apache/spark/util/SignalUtils.scala' sourcefile='SignalUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1.apply$mcZ$sp()</Message></Method><SourceLine endBytecode='29' classname='org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1' start='43' end='43' sourcepath='org/apache/spark/util/SignalUtils.scala' sourcefile='SignalUtils.scala' startBytecode='29' primary='true'><Message>At SignalUtils.scala:[line 43]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1.sig$1'><Message>Unknown source org/apache/spark/util/SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1.sig$1</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='26' classname='org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1' start='43' end='43' sourcepath='org/apache/spark/util/SignalUtils.scala' sourcefile='SignalUtils.scala' startBytecode='26'><Message>At SignalUtils.scala:[line 43]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dc9253f05842f2d2d16b7663e8bca4f9' cweid='330' rank='12' abbrev='SECPR' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator</ShortMessage><LongMessage>This random generator (java.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.util.SizeEstimator$' primary='true'><SourceLine classname='org.apache.spark.util.SizeEstimator$' start='57' end='388' sourcepath='org/apache/spark/util/SizeEstimator.scala' sourcefile='SizeEstimator.scala'><Message>At SizeEstimator.scala:[lines 57-388]</Message></SourceLine><Message>In class org.apache.spark.util.SizeEstimator$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.SizeEstimator$' signature='(Ljava/lang/Object;Ljava/lang/Class;Lorg/apache/spark/util/SizeEstimator$SearchState;)V' name='visitArray' primary='true'><SourceLine endBytecode='524' classname='org.apache.spark.util.SizeEstimator$' start='236' end='235' sourcepath='org/apache/spark/util/SizeEstimator.scala' sourcefile='SizeEstimator.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.SizeEstimator$.visitArray(Object, Class, SizeEstimator$SearchState)</Message></Method><SourceLine endBytecode='150' classname='org.apache.spark.util.SizeEstimator$' start='259' end='259' sourcepath='org/apache/spark/util/SizeEstimator.scala' sourcefile='SizeEstimator.scala' startBytecode='150' primary='true'><Message>At SizeEstimator.scala:[line 259]</Message></SourceLine><String value='java.util.Random'><Message>Value java.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dfbf4c91a4b65a7ff755c4dbb898b6e2' cweid='78' rank='12' abbrev='SECCI' category='SECURITY' priority='2' type='COMMAND_INJECTION' instanceOccurrenceMax='0'><ShortMessage>Potential Command Injection</ShortMessage><LongMessage>This usage of java/lang/ProcessBuilder.&lt;init&gt;([Ljava/lang/String;)V can be vulnerable to Command Injection</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Lscala/collection/Seq;Ljava/io/File;Lscala/collection/Map;Z)Ljava/lang/Process;' name='executeCommand' primary='true'><SourceLine endBytecode='310' classname='org.apache.spark.util.Utils$' start='1239' end='1250' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.executeCommand(Seq, File, Map, boolean)</Message></Method><SourceLine endBytecode='22' classname='org.apache.spark.util.Utils$' start='1239' end='1239' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='22' primary='true'><Message>At Utils.scala:[line 1239]</Message></SourceLine><String role='Sink method' value='java/lang/ProcessBuilder.&lt;init&gt;([Ljava/lang/String;)V'><Message>Sink method java/lang/ProcessBuilder.&lt;init&gt;([Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/Seq.toArray(Lscala/reflect/ClassTag;)Ljava/lang/Object;'><Message>Unknown source scala/collection/Seq.toArray(Lscala/reflect/ClassTag;)Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f52ba8f6512d3b3ee0e90c9543615c47' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.info(Ljava/lang/String;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Lorg/slf4j/Logger;)V' name='initDaemon' primary='true'><SourceLine endBytecode='121' classname='org.apache.spark.util.Utils$' start='2608' end='2609' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.initDaemon(Logger)</Message></Method><SourceLine endBytecode='53' classname='org.apache.spark.util.Utils$' start='2608' end='2608' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='53' primary='true'><Message>At Utils.scala:[line 2608]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.info(Ljava/lang/String;)V'><Message>Sink method org/slf4j/Logger.info(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='50' classname='org.apache.spark.util.Utils$' start='2608' end='2608' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='50'><Message>At Utils.scala:[line 2608]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9de15737f28ed16287d40296c31b57d5' cweid='209' rank='12' abbrev='ERRMSG' category='SECURITY' priority='2' type='INFORMATION_EXPOSURE_THROUGH_AN_ERROR_MESSAGE' instanceOccurrenceMax='0'><ShortMessage>Information Exposure Through An Error Message</ShortMessage><LongMessage>Possible information exposure through an error message</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/Throwable;)Ljava/lang/String;' name='exceptionString' primary='true'><SourceLine endBytecode='129' classname='org.apache.spark.util.Utils$' start='2145' end='2145' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.exceptionString(Throwable)</Message></Method><SourceLine endBytecode='27' classname='org.apache.spark.util.Utils$' start='2150' end='2150' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='27' primary='true'><Message>At Utils.scala:[line 2150]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5abbc722b519801f8c7e4a35f3ca1612' cweid='502' rank='10' abbrev='SECOBDES' category='SECURITY' priority='1' type='OBJECT_DESERIALIZATION' instanceOccurrenceMax='0'><ShortMessage>Object deserialization is used in {1}</ShortMessage><LongMessage>Object deserialization is used in org.apache.spark.util.Utils$.deserialize(byte[])</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='([B)Ljava/lang/Object;' name='deserialize' primary='true'><SourceLine endBytecode='102' classname='org.apache.spark.util.Utils$' start='151' end='153' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.deserialize(byte[])</Message></Method><SourceLine endBytecode='19' classname='org.apache.spark.util.Utils$' start='153' end='153' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='19' primary='true'><Message>At Utils.scala:[line 153]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='aa0408cad3ba2bd26d71890f0c17459b' cweid='502' rank='10' abbrev='SECOBDES' category='SECURITY' priority='1' type='OBJECT_DESERIALIZATION' instanceOccurrenceMax='0'><ShortMessage>Object deserialization is used in {1}</ShortMessage><LongMessage>Object deserialization is used in org.apache.spark.util.Utils$.deserialize(byte[], ClassLoader)</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='([BLjava/lang/ClassLoader;)Ljava/lang/Object;' name='deserialize' primary='true'><SourceLine endBytecode='115' classname='org.apache.spark.util.Utils$' start='158' end='166' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.deserialize(byte[], ClassLoader)</Message></Method><SourceLine endBytecode='22' classname='org.apache.spark.util.Utils$' start='166' end='166' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='22' primary='true'><Message>At Utils.scala:[line 166]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='4af30718a6cab1b3b5477ba2dd0642f4' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File;' name='doFetchFile' primary='true'><SourceLine endBytecode='1024' classname='org.apache.spark.util.Utils$' start='652' end='696' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.doFetchFile(String, File, String, SparkConf, SecurityManager, Configuration)</Message></Method><SourceLine endBytecode='6' classname='org.apache.spark.util.Utils$' start='652' end='652' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='6' primary='true'><Message>At Utils.scala:[line 652]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 3'><Message>Unknown source org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 3</Message></String><SourceLine endBytecode='220' classname='org.apache.spark.deploy.DependencyUtils$' start='131' end='131' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='220'><Message>At DependencyUtils.scala:[line 131]</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='61' classname='org.apache.spark.util.Utils$' start='432' end='432' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='61'><Message>At Utils.scala:[line 432]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.util.Utils$' start='456' end='456' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='9'><Message>At Utils.scala:[line 456]</Message></SourceLine><SourceLine endBytecode='112' classname='org.apache.spark.util.Utils$' start='460' end='460' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='112'><Message>At Utils.scala:[line 460]</Message></SourceLine><SourceLine endBytecode='277' classname='org.apache.spark.util.Utils$' start='472' end='472' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='277'><Message>At Utils.scala:[line 472]</Message></SourceLine><SourceLine endBytecode='328' classname='org.apache.spark.util.Utils$' start='485' end='485' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='328'><Message>At Utils.scala:[line 485]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='f35e66d8ebaa36fda9d0805d6cd53cb8' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File;' name='doFetchFile' primary='true'><SourceLine endBytecode='1024' classname='org.apache.spark.util.Utils$' start='652' end='696' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.doFetchFile(String, File, String, SparkConf, SecurityManager, Configuration)</Message></Method><SourceLine endBytecode='372' classname='org.apache.spark.util.Utils$' start='687' end='687' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='372' primary='true'><Message>At Utils.scala:[line 687]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 5'><Message>Unknown source org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 5</Message></String><SourceLine endBytecode='520' classname='org.apache.spark.SparkContext' start='1552' end='1552' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='520'><Message>At SparkContext.scala:[line 1552]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.deploy.DependencyUtils' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='9'><Message>In DependencyUtils.scala</Message></SourceLine><SourceLine endBytecode='26' classname='org.apache.spark.deploy.DependencyUtils$' start='120' end='120' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='26'><Message>At DependencyUtils.scala:[line 120]</Message></SourceLine><SourceLine endBytecode='220' classname='org.apache.spark.deploy.DependencyUtils$' start='131' end='131' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='220'><Message>At DependencyUtils.scala:[line 131]</Message></SourceLine><SourceLine endBytecode='1' classname='org.apache.spark.deploy.DriverDescription' start='21' end='21' sourcepath='org/apache/spark/deploy/DriverDescription.scala' sourcefile='DriverDescription.scala' startBytecode='1'><Message>At DriverDescription.scala:[line 21]</Message></SourceLine><SourceLine endBytecode='135' classname='org.apache.spark.deploy.SparkSubmit$' start='434' end='434' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='135'><Message>At SparkSubmit.scala:[line 434]</Message></SourceLine><SourceLine endBytecode='46' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13$$anonfun$apply$3' start='448' end='448' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='46'><Message>At SparkSubmit.scala:[line 448]</Message></SourceLine><SourceLine endBytecode='34' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7' start='401' end='401' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='34'><Message>At SparkSubmit.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='107' classname='org.apache.spark.deploy.worker.DriverRunner' start='155' end='155' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='107'><Message>At DriverRunner.scala:[line 155]</Message></SourceLine><SourceLine endBytecode='78' classname='org.apache.spark.deploy.worker.DriverRunner' start='156' end='156' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='78'><Message>At DriverRunner.scala:[line 156]</Message></SourceLine><SourceLine endBytecode='104' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' start='743' end='743' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='104'><Message>At Executor.scala:[line 743]</Message></SourceLine><SourceLine endBytecode='36' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='748' end='748' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='36'><Message>At Executor.scala:[line 748]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='749' end='749' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='63'><Message>At Executor.scala:[line 749]</Message></SourceLine><SourceLine endBytecode='187' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='755' end='755' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='187'><Message>At Executor.scala:[line 755]</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='277' classname='org.apache.spark.util.Utils$' start='472' end='472' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='277'><Message>At Utils.scala:[line 472]</Message></SourceLine><SourceLine endBytecode='328' classname='org.apache.spark.util.Utils$' start='485' end='485' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='328'><Message>At Utils.scala:[line 485]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2034' end='2034' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2034]</Message></SourceLine><SourceLine endBytecode='65' classname='org.apache.spark.util.Utils$' start='2042' end='2042' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='65'><Message>At Utils.scala:[line 2042]</Message></SourceLine><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$' start='2043' end='2043' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='62'><Message>At Utils.scala:[line 2043]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='77761f9871caa329be135ece9375516d' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/net/URI;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File;' name='doFetchFile' primary='true'><SourceLine endBytecode='1024' classname='org.apache.spark.util.Utils$' start='652' end='696' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.doFetchFile(String, File, String, SparkConf, SecurityManager, Configuration)</Message></Method><SourceLine endBytecode='361' classname='org.apache.spark.util.Utils$' start='687' end='687' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='361' primary='true'><Message>At Utils.scala:[line 687]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/net/URI;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/net/URI;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getScheme()Ljava/lang/String;'><Message>Unknown source java/net/URI.getScheme()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 5'><Message>Unknown source org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 5</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><SourceLine endBytecode='520' classname='org.apache.spark.SparkContext' start='1552' end='1552' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='520'><Message>At SparkContext.scala:[line 1552]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.deploy.DependencyUtils' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='9'><Message>In DependencyUtils.scala</Message></SourceLine><SourceLine endBytecode='26' classname='org.apache.spark.deploy.DependencyUtils$' start='120' end='120' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='26'><Message>At DependencyUtils.scala:[line 120]</Message></SourceLine><SourceLine endBytecode='220' classname='org.apache.spark.deploy.DependencyUtils$' start='131' end='131' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='220'><Message>At DependencyUtils.scala:[line 131]</Message></SourceLine><SourceLine endBytecode='1' classname='org.apache.spark.deploy.DriverDescription' start='21' end='21' sourcepath='org/apache/spark/deploy/DriverDescription.scala' sourcefile='DriverDescription.scala' startBytecode='1'><Message>At DriverDescription.scala:[line 21]</Message></SourceLine><SourceLine endBytecode='135' classname='org.apache.spark.deploy.SparkSubmit$' start='434' end='434' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='135'><Message>At SparkSubmit.scala:[line 434]</Message></SourceLine><SourceLine endBytecode='46' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13$$anonfun$apply$3' start='448' end='448' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='46'><Message>At SparkSubmit.scala:[line 448]</Message></SourceLine><SourceLine endBytecode='34' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7' start='401' end='401' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='34'><Message>At SparkSubmit.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='107' classname='org.apache.spark.deploy.worker.DriverRunner' start='155' end='155' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='107'><Message>At DriverRunner.scala:[line 155]</Message></SourceLine><SourceLine endBytecode='78' classname='org.apache.spark.deploy.worker.DriverRunner' start='156' end='156' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='78'><Message>At DriverRunner.scala:[line 156]</Message></SourceLine><SourceLine endBytecode='104' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' start='743' end='743' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='104'><Message>At Executor.scala:[line 743]</Message></SourceLine><SourceLine endBytecode='42' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='748' end='748' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='42'><Message>At Executor.scala:[line 748]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='749' end='749' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='63'><Message>At Executor.scala:[line 749]</Message></SourceLine><SourceLine endBytecode='187' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='755' end='755' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='187'><Message>At Executor.scala:[line 755]</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='277' classname='org.apache.spark.util.Utils$' start='472' end='472' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='277'><Message>At Utils.scala:[line 472]</Message></SourceLine><SourceLine endBytecode='328' classname='org.apache.spark.util.Utils$' start='485' end='485' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='328'><Message>At Utils.scala:[line 485]</Message></SourceLine><SourceLine endBytecode='16' classname='org.apache.spark.util.Utils$' start='653' end='653' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='16'><Message>At Utils.scala:[line 653]</Message></SourceLine><SourceLine endBytecode='40' classname='org.apache.spark.util.Utils$' start='655' end='655' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='40'><Message>At Utils.scala:[line 655]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2034' end='2034' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2034]</Message></SourceLine><SourceLine endBytecode='65' classname='org.apache.spark.util.Utils$' start='2042' end='2042' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='65'><Message>At Utils.scala:[line 2042]</Message></SourceLine><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$' start='2043' end='2043' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='62'><Message>At Utils.scala:[line 2043]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6e9dcedc3fb2346da3f209ea211c9a07' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/InputStream;Ljava/io/File;Z)V' name='downloadFile' primary='true'><SourceLine endBytecode='309' classname='org.apache.spark.util.Utils$' start='527' end='539' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.downloadFile(String, InputStream, File, boolean)</Message></Method><SourceLine endBytecode='18' classname='org.apache.spark.util.Utils$' start='527' end='527' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='18' primary='true'><Message>At Utils.scala:[line 527]</Message></SourceLine><String role='Sink method' value='java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;'><Message>Sink method java/io/File.createTempFile(Ljava/lang/String;Ljava/lang/String;Ljava/io/File;)Ljava/io/File;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><SourceLine endBytecode='15' classname='org.apache.spark.util.Utils$' start='528' end='528' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='15'><Message>At Utils.scala:[line 528]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='22aef374a17aeac9b445759d3fac2655' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/InputStream;Ljava/io/File;Z)V' name='downloadFile' primary='true'><SourceLine endBytecode='309' classname='org.apache.spark.util.Utils$' start='527' end='539' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.downloadFile(String, InputStream, File, boolean)</Message></Method><SourceLine endBytecode='15' classname='org.apache.spark.util.Utils$' start='528' end='528' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='15' primary='true'><Message>At Utils.scala:[line 528]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d078c0589e151f1c639b209a92a30ad6' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;JZ)Ljava/io/File;' name='fetchFile' primary='true'><SourceLine endBytecode='1121' classname='org.apache.spark.util.Utils$' start='456' end='476' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.fetchFile(String, File, SparkConf, SecurityManager, Configuration, long, boolean)</Message></Method><SourceLine endBytecode='21' classname='org.apache.spark.util.Utils$' start='457' end='457' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='21' primary='true'><Message>At Utils.scala:[line 457]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/ArrayOps.last()Ljava/lang/Object;'><Message>Unknown source scala/collection/mutable/ArrayOps.last()Ljava/lang/Object;</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.decodeFileNameInURI(Ljava/net/URI;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.decodeFileNameInURI(Ljava/net/URI;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='61' classname='org.apache.spark.util.Utils$' start='432' end='432' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='61'><Message>At Utils.scala:[line 432]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.util.Utils$' start='456' end='456' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='9'><Message>At Utils.scala:[line 456]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b7e79fc0f8da4bfd43f3a1bc84a36d14' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;JZ)Ljava/io/File;' name='fetchFile' primary='true'><SourceLine endBytecode='1121' classname='org.apache.spark.util.Utils$' start='456' end='476' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.fetchFile(String, File, SparkConf, SecurityManager, Configuration, long, boolean)</Message></Method><SourceLine endBytecode='197' classname='org.apache.spark.util.Utils$' start='462' end='462' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='197' primary='true'><Message>At Utils.scala:[line 462]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.getLocalDir(Lorg/apache/spark/SparkConf;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.getLocalDir(Lorg/apache/spark/SparkConf;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String><SourceLine endBytecode='194' classname='org.apache.spark.util.Utils$' start='462' end='462' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='194'><Message>At Utils.scala:[line 462]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d10c1c0419520f784360f4de0d471220' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='1'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;JZ)Ljava/io/File;' name='fetchFile' primary='true'><SourceLine endBytecode='1121' classname='org.apache.spark.util.Utils$' start='456' end='476' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.fetchFile(String, File, SparkConf, SecurityManager, Configuration, long, boolean)</Message></Method><SourceLine endBytecode='210' classname='org.apache.spark.util.Utils$' start='463' end='463' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='210' primary='true'><Message>At Utils.scala:[line 463]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='183' classname='org.apache.spark.util.Utils$' start='461' end='461' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='183'><Message>At Utils.scala:[line 461]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='1' instanceHash='d10c1c0419520f784360f4de0d471220' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='1'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;JZ)Ljava/io/File;' name='fetchFile' primary='true'><SourceLine endBytecode='1121' classname='org.apache.spark.util.Utils$' start='456' end='476' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.fetchFile(String, File, SparkConf, SecurityManager, Configuration, long, boolean)</Message></Method><SourceLine endBytecode='247' classname='org.apache.spark.util.Utils$' start='469' end='469' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='247' primary='true'><Message>At Utils.scala:[line 469]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='112' classname='org.apache.spark.util.Utils$' start='460' end='460' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='112'><Message>At Utils.scala:[line 460]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1134a548efdd09d29e24c56b650fcfad' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Lorg/apache/hadoop/fs/Path;Ljava/io/File;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/spark/SparkConf;Lorg/apache/hadoop/conf/Configuration;ZLscala/Option;)V' name='fetchHcfsFile' primary='true'><SourceLine endBytecode='415' classname='org.apache.spark.util.Utils$' start='712' end='721' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.fetchHcfsFile(Path, File, FileSystem, SparkConf, Configuration, boolean, Option)</Message></Method><SourceLine endBytecode='35' classname='org.apache.spark.util.Utils$' start='715' end='715' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='35' primary='true'><Message>At Utils.scala:[line 715]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;'><Message>Unknown source scala/Option.getOrElse(Lscala/Function0;)Ljava/lang/Object;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cfa12020d3ad10afa467c1cb2af06115' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/io/File;Ljava/lang/String;)Lorg/apache/hadoop/fs/Path;' name='getFilePath' primary='true'><SourceLine endBytecode='111' classname='org.apache.spark.util.Utils$' start='1907' end='1909' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.getFilePath(File, String)</Message></Method><SourceLine endBytecode='16' classname='org.apache.spark.util.Utils$' start='1908' end='1908' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='16' primary='true'><Message>At Utils.scala:[line 1908]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.getFilePath(Ljava/io/File;Ljava/lang/String;)Lorg/apache/hadoop/fs/Path; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.getFilePath(Ljava/io/File;Ljava/lang/String;)Lorg/apache/hadoop/fs/Path; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>In Utils.scala</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='311c24906ad565c64e306fb28f7fdd71' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;)Lscala/collection/Map;' name='getPropertiesFromFile' primary='true'><SourceLine endBytecode='400' classname='org.apache.spark.util.Utils$' start='2112' end='2126' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.getPropertiesFromFile(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2112' end='2112' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5' primary='true'><Message>At Utils.scala:[line 2112]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.getPropertiesFromFile(Ljava/lang/String;)Lscala/collection/Map; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.getPropertiesFromFile(Ljava/lang/String;)Lscala/collection/Map; parameter 0</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$defaultSparkProperties$1' start='89' end='89' sourcepath='org/apache/spark/deploy/SparkSubmitArguments.scala' sourcefile='SparkSubmitArguments.scala' startBytecode='5'><Message>At SparkSubmitArguments.scala:[line 89]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$defaultSparkProperties$1' start='90' end='90' sourcepath='org/apache/spark/deploy/SparkSubmitArguments.scala' sourcefile='SparkSubmitArguments.scala' startBytecode='4'><Message>At SparkSubmitArguments.scala:[line 90]</Message></SourceLine><SourceLine endBytecode='1' classname='org.apache.spark.storage.FileBasedTopologyMapper' start='71' end='71' sourcepath='org/apache/spark/storage/TopologyMapper.scala' sourcefile='TopologyMapper.scala' startBytecode='1'><Message>At TopologyMapper.scala:[line 71]</Message></SourceLine><SourceLine endBytecode='54' classname='org.apache.spark.storage.FileBasedTopologyMapper' start='74' end='74' sourcepath='org/apache/spark/storage/TopologyMapper.scala' sourcefile='TopologyMapper.scala' startBytecode='54'><Message>At TopologyMapper.scala:[line 74]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$$anonfun$loadDefaultSparkProperties$1' start='2085' end='2085' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2085]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils$$anonfun$loadDefaultSparkProperties$1' start='2086' end='2086' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>At Utils.scala:[line 2086]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='d73f089f7cb3b466305a9202dacdf39c' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/nio/file/Paths.get(Ljava/net/URI;)Ljava/nio/file/Path;) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/io/File;)Z' name='isSymlink' primary='true'><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$' start='1081' end='1081' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.isSymlink(File)</Message></Method><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils$' start='1081' end='1081' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4' primary='true'><Message>At Utils.scala:[line 1081]</Message></SourceLine><String role='Sink method' value='java/nio/file/Paths.get(Ljava/net/URI;)Ljava/nio/file/Path;'><Message>Sink method java/nio/file/Paths.get(Ljava/net/URI;)Ljava/nio/file/Path;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.toURI()Ljava/net/URI;'><Message>Unknown source java/io/File.toURI()Ljava/net/URI;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='9611e0cc957c548570be12f4a806ef27' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;JJJ)Ljava/lang/String;' name='offsetBytes' primary='true'><SourceLine endBytecode='382' classname='org.apache.spark.util.Utils$' start='1581' end='1595' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.offsetBytes(String, long, long, long)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='1581' end='1581' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5' primary='true'><Message>At Utils.scala:[line 1581]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.offsetBytes(Ljava/lang/String;JJJ)Ljava/lang/String; parameter 6'><Message>Unknown source org/apache/spark/util/Utils$.offsetBytes(Ljava/lang/String;JJJ)Ljava/lang/String; parameter 6</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='8' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='8'><Message>In Utils.scala</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cb531e985183103816cc502c230bc76' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;)Ljava/net/URI;' name='resolveURI' primary='true'><SourceLine endBytecode='238' classname='org.apache.spark.util.Utils$' start='2034' end='2048' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.resolveURI(String)</Message></Method><SourceLine endBytecode='31' classname='org.apache.spark.util.Utils$' start='2041' end='2041' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='31' primary='true'><Message>At Utils.scala:[line 2041]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0</Message></String><SourceLine endBytecode='613' classname='org.apache.spark.SparkContext' start='401' end='401' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='613'><Message>At SparkContext.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.deploy.DependencyUtils' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='9'><Message>In DependencyUtils.scala</Message></SourceLine><SourceLine endBytecode='26' classname='org.apache.spark.deploy.DependencyUtils$' start='120' end='120' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='26'><Message>At DependencyUtils.scala:[line 120]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$addJarsToClassPath$1' start='73' end='73' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='5'><Message>At DependencyUtils.scala:[line 73]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$addJarsToClassPath$1' start='74' end='74' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='8'><Message>At DependencyUtils.scala:[line 74]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2' start='139' end='139' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='5'><Message>At DependencyUtils.scala:[line 139]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2' start='140' end='140' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='4'><Message>At DependencyUtils.scala:[line 140]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='178' end='178' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='5'><Message>At RPackageUtils.scala:[line 178]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='179' end='179' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='8'><Message>At RPackageUtils.scala:[line 179]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.SparkSubmit$' start='426' end='426' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='4'><Message>At SparkSubmit.scala:[line 426]</Message></SourceLine><SourceLine endBytecode='135' classname='org.apache.spark.deploy.SparkSubmit$' start='434' end='434' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='135'><Message>At SparkSubmit.scala:[line 434]</Message></SourceLine><SourceLine endBytecode='2653' classname='org.apache.spark.deploy.SparkSubmit$' start='490' end='490' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2653'><Message>At SparkSubmit.scala:[line 490]</Message></SourceLine><SourceLine endBytecode='2779' classname='org.apache.spark.deploy.SparkSubmit$' start='504' end='504' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2779'><Message>At SparkSubmit.scala:[line 504]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.SparkSubmit$' start='893' end='893' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='4'><Message>At SparkSubmit.scala:[line 893]</Message></SourceLine><SourceLine endBytecode='46' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13$$anonfun$apply$3' start='448' end='448' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='46'><Message>At SparkSubmit.scala:[line 448]</Message></SourceLine><SourceLine endBytecode='34' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7' start='401' end='401' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='34'><Message>At SparkSubmit.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='94' classname='org.apache.spark.deploy.SparkSubmitArguments' start='488' end='488' sourcepath='org/apache/spark/deploy/SparkSubmitArguments.scala' sourcefile='SparkSubmitArguments.scala' startBytecode='94'><Message>At SparkSubmitArguments.scala:[line 488]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2034' end='2034' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2034]</Message></SourceLine><SourceLine endBytecode='28' classname='org.apache.spark.util.Utils$' start='2041' end='2041' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='28'><Message>At Utils.scala:[line 2041]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$$anonfun$nonLocalPaths$1' start='2066' end='2066' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2066]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils$$anonfun$nonLocalPaths$1' start='2067' end='2067' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>At Utils.scala:[line 2067]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils$$anonfun$resolveURIs$2' start='2056' end='2056' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>At Utils.scala:[line 2056]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='b15d79a58ebe6292ac054b06c46bdae5' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;)Ljava/net/URI;' name='resolveURI' primary='true'><SourceLine endBytecode='238' classname='org.apache.spark.util.Utils$' start='2034' end='2048' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.resolveURI(String)</Message></Method><SourceLine endBytecode='77' classname='org.apache.spark.util.Utils$' start='2048' end='2048' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='77' primary='true'><Message>At Utils.scala:[line 2048]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.resolveURI(Ljava/lang/String;)Ljava/net/URI; parameter 0</Message></String><SourceLine endBytecode='613' classname='org.apache.spark.SparkContext' start='401' end='401' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='613'><Message>At SparkContext.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.deploy.DependencyUtils' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='9'><Message>In DependencyUtils.scala</Message></SourceLine><SourceLine endBytecode='26' classname='org.apache.spark.deploy.DependencyUtils$' start='120' end='120' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='26'><Message>At DependencyUtils.scala:[line 120]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$addJarsToClassPath$1' start='73' end='73' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='5'><Message>At DependencyUtils.scala:[line 73]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$addJarsToClassPath$1' start='74' end='74' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='8'><Message>At DependencyUtils.scala:[line 74]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2' start='139' end='139' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='5'><Message>At DependencyUtils.scala:[line 139]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2' start='140' end='140' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='4'><Message>At DependencyUtils.scala:[line 140]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='178' end='178' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='5'><Message>At RPackageUtils.scala:[line 178]</Message></SourceLine><SourceLine endBytecode='8' classname='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1' start='179' end='179' sourcepath='org/apache/spark/deploy/RPackageUtils.scala' sourcefile='RPackageUtils.scala' startBytecode='8'><Message>At RPackageUtils.scala:[line 179]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.SparkSubmit$' start='426' end='426' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='4'><Message>At SparkSubmit.scala:[line 426]</Message></SourceLine><SourceLine endBytecode='135' classname='org.apache.spark.deploy.SparkSubmit$' start='434' end='434' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='135'><Message>At SparkSubmit.scala:[line 434]</Message></SourceLine><SourceLine endBytecode='2653' classname='org.apache.spark.deploy.SparkSubmit$' start='490' end='490' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2653'><Message>At SparkSubmit.scala:[line 490]</Message></SourceLine><SourceLine endBytecode='2779' classname='org.apache.spark.deploy.SparkSubmit$' start='504' end='504' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='2779'><Message>At SparkSubmit.scala:[line 504]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.deploy.SparkSubmit$' start='893' end='893' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='4'><Message>At SparkSubmit.scala:[line 893]</Message></SourceLine><SourceLine endBytecode='46' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13$$anonfun$apply$3' start='448' end='448' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='46'><Message>At SparkSubmit.scala:[line 448]</Message></SourceLine><SourceLine endBytecode='34' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7' start='401' end='401' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='34'><Message>At SparkSubmit.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='94' classname='org.apache.spark.deploy.SparkSubmitArguments' start='488' end='488' sourcepath='org/apache/spark/deploy/SparkSubmitArguments.scala' sourcefile='SparkSubmitArguments.scala' startBytecode='94'><Message>At SparkSubmitArguments.scala:[line 488]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$$anonfun$nonLocalPaths$1' start='2066' end='2066' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2066]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils$$anonfun$nonLocalPaths$1' start='2067' end='2067' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>At Utils.scala:[line 2067]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils$$anonfun$resolveURIs$2' start='2056' end='2056' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>At Utils.scala:[line 2056]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='a95a4da94a61dc352ac6c1125c7b773' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;)Ljava/lang/String;' name='stripDirectory' primary='true'><SourceLine endBytecode='63' classname='org.apache.spark.util.Utils$' start='1938' end='1938' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.stripDirectory(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='1938' end='1938' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5' primary='true'><Message>At Utils.scala:[line 1938]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.stripDirectory(Ljava/lang/String;)Ljava/lang/String; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.stripDirectory(Ljava/lang/String;)Ljava/lang/String; parameter 0</Message></String><SourceLine endBytecode='1' classname='org.apache.spark.deploy.SparkSubmitArguments' start='59' end='59' sourcepath='org/apache/spark/deploy/SparkSubmitArguments.scala' sourcefile='SparkSubmitArguments.scala' startBytecode='1'><Message>At SparkSubmitArguments.scala:[line 59]</Message></SourceLine><SourceLine endBytecode='1193' classname='org.apache.spark.deploy.SparkSubmitArguments' start='236' end='236' sourcepath='org/apache/spark/deploy/SparkSubmitArguments.scala' sourcefile='SparkSubmitArguments.scala' startBytecode='1193'><Message>At SparkSubmitArguments.scala:[line 236]</Message></SourceLine><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3fac49fe158c8263e4820623e6546e3f' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/io/File;)Ljava/io/File;' name='tempFileWith' primary='true'><SourceLine endBytecode='88' classname='org.apache.spark.util.Utils$' start='2592' end='2592' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.tempFileWith(File)</Message></Method><SourceLine endBytecode='33' classname='org.apache.spark.util.Utils$' start='2592' end='2592' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='33' primary='true'><Message>At Utils.scala:[line 2592]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='15' classname='org.apache.spark.util.Utils$' start='2592' end='2592' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='15'><Message>At Utils.scala:[line 2592]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='398c884a957c92a3766336272e35179a' cweid='22' rank='15' abbrev='SECPTI' category='SECURITY' priority='3' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/lang/String;)Ljava/io/File;' name='createDirectory' primary='true'><SourceLine endBytecode='352' classname='org.apache.spark.util.Utils$' start='289' end='306' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.createDirectory(String, String)</Message></Method><SourceLine endBytecode='116' classname='org.apache.spark.util.Utils$' start='299' end='299' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='116' primary='true'><Message>At Utils.scala:[line 299]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.createDirectory(Ljava/lang/String;Ljava/lang/String;)Ljava/io/File; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$.createDirectory(Ljava/lang/String;Ljava/lang/String;)Ljava/io/File; parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><String role='Method usage' value='detected only with safe arguments'><Message>Method usage detected only with safe arguments</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='113' classname='org.apache.spark.util.Utils$' start='299' end='299' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='113'><Message>At Utils.scala:[line 299]</Message></SourceLine><SourceLine endBytecode='3' classname='org.apache.spark.util.Utils$' start='316' end='316' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='3'><Message>At Utils.scala:[line 316]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1f333021e49ef3830ec92848213d6a4a' cweid='330' rank='12' abbrev='SECPR' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator</ShortMessage><LongMessage>This random generator (java.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='()V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='310' classname='org.apache.spark.util.Utils$' start='79' end='2642' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.util.Utils$()</Message></Method><SourceLine endBytecode='17' classname='org.apache.spark.util.Utils$' start='80' end='80' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='17' primary='true'><Message>At Utils.scala:[line 80]</Message></SourceLine><String value='java.util.Random'><Message>Value java.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='80fadb29f18e95e100718a275dad9b29' cweid='330' rank='12' abbrev='SECPR' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator</ShortMessage><LongMessage>This random generator (java.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='()Ljava/util/Random;' name='randomizeInPlace$default$2' primary='true'><SourceLine endBytecode='49' classname='org.apache.spark.util.Utils$' start='890' end='890' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.randomizeInPlace$default$2()</Message></Method><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils$' start='890' end='890' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4' primary='true'><Message>At Utils.scala:[line 890]</Message></SourceLine><String value='java.util.Random'><Message>Value java.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e0fb3b6f6a3b9547f963a4028d58ec4f' cweid='918' rank='12' abbrev='SECSSSRFUC' category='SECURITY' priority='2' type='URLCONNECTION_SSRF_FD' instanceOccurrenceMax='0'><ShortMessage>URLConnection Server-Side Request Forgery (SSRF) and File Disclosure</ShortMessage><LongMessage>This web server request could be used by an attacker to expose internal services and filesystem.</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File;' name='doFetchFile' primary='true'><SourceLine endBytecode='1024' classname='org.apache.spark.util.Utils$' start='652' end='696' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.doFetchFile(String, File, String, SparkConf, SecurityManager, Configuration)</Message></Method><SourceLine endBytecode='226' classname='org.apache.spark.util.Utils$' start='669' end='669' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='226' primary='true'><Message>At Utils.scala:[line 669]</Message></SourceLine><String role='Sink method' value='java/net/URL.openConnection()Ljava/net/URLConnection;'><Message>Sink method java/net/URL.openConnection()Ljava/net/URLConnection;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='java/net/URI.getHost()Ljava/lang/String;'><Message>Unknown source java/net/URI.getHost()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.getScheme()Ljava/lang/String;'><Message>Unknown source java/net/URI.getScheme()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.toURL()Ljava/net/URL;'><Message>Unknown source java/net/URI.toURL()Ljava/net/URL;</Message></String><String role='Unknown source' value='org/apache/spark/SecurityManager.getSecretKey()Ljava/lang/String;'><Message>Unknown source org/apache/spark/SecurityManager.getSecretKey()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ILjava/lang/String;Ljava/lang/String;Ljava/lang/String;)V'><Message>Unknown source java/net/URI.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;ILjava/lang/String;Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 5'><Message>Unknown source org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 5</Message></String><String role='Unknown source' value='java/net/URI.getPath()Ljava/lang/String;'><Message>Unknown source java/net/URI.getPath()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.constructURIForAuthentication(Ljava/net/URI;Lorg/apache/spark/SecurityManager;)Ljava/net/URI;'><Message>Unknown source org/apache/spark/util/Utils$.constructURIForAuthentication(Ljava/net/URI;Lorg/apache/spark/SecurityManager;)Ljava/net/URI;</Message></String><String role='Unknown source' value='java/net/URI.getQuery()Ljava/lang/String;'><Message>Unknown source java/net/URI.getQuery()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.constructURIForAuthentication(Ljava/net/URI;Lorg/apache/spark/SecurityManager;)Ljava/net/URI; parameter 1'><Message>Unknown source org/apache/spark/util/Utils$.constructURIForAuthentication(Ljava/net/URI;Lorg/apache/spark/SecurityManager;)Ljava/net/URI; parameter 1</Message></String><String role='Unknown source' value='org/apache/spark/SecurityManager.getHttpUser()Ljava/lang/String;'><Message>Unknown source org/apache/spark/SecurityManager.getHttpUser()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/net/URI.getFragment()Ljava/lang/String;'><Message>Unknown source java/net/URI.getFragment()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='520' classname='org.apache.spark.SparkContext' start='1552' end='1552' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='520'><Message>At SparkContext.scala:[line 1552]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.deploy.DependencyUtils' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='9'><Message>In DependencyUtils.scala</Message></SourceLine><SourceLine endBytecode='26' classname='org.apache.spark.deploy.DependencyUtils$' start='120' end='120' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='26'><Message>At DependencyUtils.scala:[line 120]</Message></SourceLine><SourceLine endBytecode='220' classname='org.apache.spark.deploy.DependencyUtils$' start='131' end='131' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='220'><Message>At DependencyUtils.scala:[line 131]</Message></SourceLine><SourceLine endBytecode='1' classname='org.apache.spark.deploy.DriverDescription' start='21' end='21' sourcepath='org/apache/spark/deploy/DriverDescription.scala' sourcefile='DriverDescription.scala' startBytecode='1'><Message>At DriverDescription.scala:[line 21]</Message></SourceLine><SourceLine endBytecode='135' classname='org.apache.spark.deploy.SparkSubmit$' start='434' end='434' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='135'><Message>At SparkSubmit.scala:[line 434]</Message></SourceLine><SourceLine endBytecode='46' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13$$anonfun$apply$3' start='448' end='448' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='46'><Message>At SparkSubmit.scala:[line 448]</Message></SourceLine><SourceLine endBytecode='34' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7' start='401' end='401' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='34'><Message>At SparkSubmit.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='107' classname='org.apache.spark.deploy.worker.DriverRunner' start='155' end='155' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='107'><Message>At DriverRunner.scala:[line 155]</Message></SourceLine><SourceLine endBytecode='78' classname='org.apache.spark.deploy.worker.DriverRunner' start='156' end='156' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='78'><Message>At DriverRunner.scala:[line 156]</Message></SourceLine><SourceLine endBytecode='104' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' start='743' end='743' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='104'><Message>At Executor.scala:[line 743]</Message></SourceLine><SourceLine endBytecode='42' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='748' end='748' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='42'><Message>At Executor.scala:[line 748]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='749' end='749' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='63'><Message>At Executor.scala:[line 749]</Message></SourceLine><SourceLine endBytecode='187' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='755' end='755' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='187'><Message>At Executor.scala:[line 755]</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='31' classname='org.apache.spark.util.Utils$' start='406' end='406' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='31'><Message>At Utils.scala:[line 406]</Message></SourceLine><SourceLine endBytecode='54' classname='org.apache.spark.util.Utils$' start='407' end='407' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='54'><Message>At Utils.scala:[line 407]</Message></SourceLine><SourceLine endBytecode='72' classname='org.apache.spark.util.Utils$' start='408' end='408' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='72'><Message>At Utils.scala:[line 408]</Message></SourceLine><SourceLine endBytecode='277' classname='org.apache.spark.util.Utils$' start='472' end='472' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='277'><Message>At Utils.scala:[line 472]</Message></SourceLine><SourceLine endBytecode='328' classname='org.apache.spark.util.Utils$' start='485' end='485' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='328'><Message>At Utils.scala:[line 485]</Message></SourceLine><SourceLine endBytecode='16' classname='org.apache.spark.util.Utils$' start='653' end='653' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='16'><Message>At Utils.scala:[line 653]</Message></SourceLine><SourceLine endBytecode='40' classname='org.apache.spark.util.Utils$' start='655' end='655' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='40'><Message>At Utils.scala:[line 655]</Message></SourceLine><SourceLine endBytecode='216' classname='org.apache.spark.util.Utils$' start='668' end='668' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='216'><Message>At Utils.scala:[line 668]</Message></SourceLine><SourceLine endBytecode='223' classname='org.apache.spark.util.Utils$' start='669' end='669' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='223'><Message>At Utils.scala:[line 669]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2034' end='2034' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2034]</Message></SourceLine><SourceLine endBytecode='65' classname='org.apache.spark.util.Utils$' start='2042' end='2042' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='65'><Message>At Utils.scala:[line 2042]</Message></SourceLine><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$' start='2043' end='2043' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='62'><Message>At Utils.scala:[line 2043]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='cd5e9be76e4a1e8f697b019f2b71e794' cweid='918' rank='12' abbrev='SECSSSRFUC' category='SECURITY' priority='2' type='URLCONNECTION_SSRF_FD' instanceOccurrenceMax='0'><ShortMessage>URLConnection Server-Side Request Forgery (SSRF) and File Disclosure</ShortMessage><LongMessage>This web server request could be used by an attacker to expose internal services and filesystem.</LongMessage><Class classname='org.apache.spark.util.Utils$' primary='true'><SourceLine classname='org.apache.spark.util.Utils$' start='79' end='2806' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 79-2806]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$' signature='(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File;' name='doFetchFile' primary='true'><SourceLine endBytecode='1024' classname='org.apache.spark.util.Utils$' start='652' end='696' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$.doFetchFile(String, File, String, SparkConf, SecurityManager, Configuration)</Message></Method><SourceLine endBytecode='259' classname='org.apache.spark.util.Utils$' start='673' end='673' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='259' primary='true'><Message>At Utils.scala:[line 673]</Message></SourceLine><String role='Sink method' value='java/net/URL.openConnection()Ljava/net/URLConnection;'><Message>Sink method java/net/URL.openConnection()Ljava/net/URLConnection;</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/net/URL.&lt;init&gt;(Ljava/lang/String;)V'><Message>Unknown source java/net/URL.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 5'><Message>Unknown source org/apache/spark/util/Utils$.doFetchFile(Ljava/lang/String;Ljava/io/File;Ljava/lang/String;Lorg/apache/spark/SparkConf;Lorg/apache/spark/SecurityManager;Lorg/apache/hadoop/conf/Configuration;)Ljava/io/File; parameter 5</Message></String><SourceLine endBytecode='520' classname='org.apache.spark.SparkContext' start='1552' end='1552' sourcepath='org/apache/spark/SparkContext.scala' sourcefile='SparkContext.scala' startBytecode='520'><Message>At SparkContext.scala:[line 1552]</Message></SourceLine><SourceLine endBytecode='9' classname='org.apache.spark.deploy.DependencyUtils' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='9'><Message>In DependencyUtils.scala</Message></SourceLine><SourceLine endBytecode='26' classname='org.apache.spark.deploy.DependencyUtils$' start='120' end='120' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='26'><Message>At DependencyUtils.scala:[line 120]</Message></SourceLine><SourceLine endBytecode='220' classname='org.apache.spark.deploy.DependencyUtils$' start='131' end='131' sourcepath='org/apache/spark/deploy/DependencyUtils.scala' sourcefile='DependencyUtils.scala' startBytecode='220'><Message>At DependencyUtils.scala:[line 131]</Message></SourceLine><SourceLine endBytecode='1' classname='org.apache.spark.deploy.DriverDescription' start='21' end='21' sourcepath='org/apache/spark/deploy/DriverDescription.scala' sourcefile='DriverDescription.scala' startBytecode='1'><Message>At DriverDescription.scala:[line 21]</Message></SourceLine><SourceLine endBytecode='135' classname='org.apache.spark.deploy.SparkSubmit$' start='434' end='434' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='135'><Message>At SparkSubmit.scala:[line 434]</Message></SourceLine><SourceLine endBytecode='46' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13$$anonfun$apply$3' start='448' end='448' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='46'><Message>At SparkSubmit.scala:[line 448]</Message></SourceLine><SourceLine endBytecode='34' classname='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7' start='401' end='401' sourcepath='org/apache/spark/deploy/SparkSubmit.scala' sourcefile='SparkSubmit.scala' startBytecode='34'><Message>At SparkSubmit.scala:[line 401]</Message></SourceLine><SourceLine endBytecode='107' classname='org.apache.spark.deploy.worker.DriverRunner' start='155' end='155' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='107'><Message>At DriverRunner.scala:[line 155]</Message></SourceLine><SourceLine endBytecode='78' classname='org.apache.spark.deploy.worker.DriverRunner' start='156' end='156' sourcepath='org/apache/spark/deploy/worker/DriverRunner.scala' sourcefile='DriverRunner.scala' startBytecode='78'><Message>At DriverRunner.scala:[line 156]</Message></SourceLine><SourceLine endBytecode='104' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3' start='743' end='743' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='104'><Message>At Executor.scala:[line 743]</Message></SourceLine><SourceLine endBytecode='36' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='748' end='748' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='36'><Message>At Executor.scala:[line 748]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='749' end='749' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='63'><Message>At Executor.scala:[line 749]</Message></SourceLine><SourceLine endBytecode='187' classname='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5' start='755' end='755' sourcepath='org/apache/spark/executor/Executor.scala' sourcefile='Executor.scala' startBytecode='187'><Message>At Executor.scala:[line 755]</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='277' classname='org.apache.spark.util.Utils$' start='472' end='472' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='277'><Message>At Utils.scala:[line 472]</Message></SourceLine><SourceLine endBytecode='328' classname='org.apache.spark.util.Utils$' start='485' end='485' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='328'><Message>At Utils.scala:[line 485]</Message></SourceLine><SourceLine endBytecode='256' classname='org.apache.spark.util.Utils$' start='673' end='673' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='256'><Message>At Utils.scala:[line 673]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$' start='2034' end='2034' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 2034]</Message></SourceLine><SourceLine endBytecode='65' classname='org.apache.spark.util.Utils$' start='2042' end='2042' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='65'><Message>At Utils.scala:[line 2042]</Message></SourceLine><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$' start='2043' end='2043' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='62'><Message>At Utils.scala:[line 2043]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='732a979f0f412995713a99326abb6f76' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$$anon$6' primary='true'><SourceLine classname='org.apache.spark.util.Utils$$anon$6' start='1531' end='1533' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 1531-1533]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$$anon$6</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$$anon$6' signature='(Ljava/lang/String;)Ljava/lang/Long;' name='load' primary='true'><SourceLine endBytecode='72' classname='org.apache.spark.util.Utils$$anon$6' start='1533' end='1533' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$$anon$6.load(String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$$anon$6' start='1533' end='1533' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11' primary='true'><Message>At Utils.scala:[line 1533]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$$anon$6.load(Ljava/lang/String;)Ljava/lang/Long; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$$anon$6.load(Ljava/lang/String;)Ljava/lang/Long; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$$anon$6' start='1531' end='1531' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 1531]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='6776652561b69ddb0acdefe0fca42b2f' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2' primary='true'><SourceLine classname='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2' start='2134' end='2134' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[line 2134]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2' signature='(Ljava/lang/String;)Ljava/io/File;' name='apply' primary='true'><SourceLine endBytecode='117' classname='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2' start='2134' end='2134' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2.apply(String)</Message></Method><SourceLine endBytecode='62' classname='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2' start='2134' end='2134' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='62' primary='true'><Message>At Utils.scala:[line 2134]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='59' classname='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2' start='2134' end='2134' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='59'><Message>At Utils.scala:[line 2134]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='fd1820f285627725dad671a365eec4fa' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2' primary='true'><SourceLine classname='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2' start='843' end='857' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[lines 843-857]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2' signature='(Ljava/lang/String;)Lscala/collection/Iterable;' name='apply' primary='true'><SourceLine endBytecode='280' classname='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2' start='845' end='844' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2.apply(String)</Message></Method><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2' start='845' end='845' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5' primary='true'><Message>At Utils.scala:[line 845]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$$anonfun$getOrCreateLocalRootDirsImpl$2.apply(Ljava/lang/String;)Lscala/collection/Iterable; parameter 0'><Message>Unknown source org/apache/spark/util/Utils$$anonfun$getOrCreateLocalRootDirsImpl$2.apply(Ljava/lang/String;)Lscala/collection/Iterable; parameter 0</Message></String><String role='Method usage' value='not detected'><Message>Method usage not detected</Message></String><SourceLine endBytecode='5' classname='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2' start='843' end='843' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='5'><Message>At Utils.scala:[line 843]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='c64920d114c822ddd271cf66f1e03db3' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$copyRecursive$1' primary='true'><SourceLine classname='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$copyRecursive$1' start='630' end='630' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala'><Message>At Utils.scala:[line 630]</Message></SourceLine><Message>In class org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$copyRecursive$1</Message></Class><Method isStatic='false' classname='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$copyRecursive$1' signature='(Ljava/io/File;)V' name='apply' primary='true'><SourceLine endBytecode='74' classname='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$copyRecursive$1' start='630' end='630' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$copyRecursive$1.apply(File)</Message></Method><SourceLine endBytecode='16' classname='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$copyRecursive$1' start='630' end='630' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='16' primary='true'><Message>At Utils.scala:[line 630]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getName()Ljava/lang/String;'><Message>Unknown source java/io/File.getName()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='39bc7e7be192740b6b167ab770b51429' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' primary='true'><SourceLine classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' start='48' end='662' sourcepath='org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter.java' sourcefile='UnsafeExternalSorter.java'><Message>At UnsafeExternalSorter.java:[lines 48-662]</Message></SourceLine><Message>In class org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter</Message></Class><Method isStatic='false' classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' signature='()V' name='deleteSpillFiles' primary='true'><SourceLine endBytecode='171' classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' start='312' end='320' sourcepath='org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter.java' sourcefile='UnsafeExternalSorter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.deleteSpillFiles()</Message></Method><SourceLine endBytecode='59' classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' start='316' end='316' sourcepath='org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter.java' sourcefile='UnsafeExternalSorter.java' startBytecode='59' primary='true'><Message>At UnsafeExternalSorter.java:[line 316]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.error(Ljava/lang/String;Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='3c53fe4802ed5e5c019974749ec97f16' cweid='117' rank='15' abbrev='SECCRLFLOG' category='SECURITY' priority='3' type='CRLF_INJECTION_LOGS' instanceOccurrenceMax='0'><ShortMessage>Potential CRLF Injection for logs</ShortMessage><LongMessage>This use of org/slf4j/Logger.info(Ljava/lang/String;[Ljava/lang/Object;)V might be used to include CRLF characters into log messages</LongMessage><Class classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' primary='true'><SourceLine classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' start='48' end='662' sourcepath='org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter.java' sourcefile='UnsafeExternalSorter.java'><Message>At UnsafeExternalSorter.java:[lines 48-662]</Message></SourceLine><Message>In class org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter</Message></Class><Method isStatic='false' classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' signature='(JLorg/apache/spark/memory/MemoryConsumer;)J' name='spill' primary='true'><SourceLine endBytecode='490' classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' start='198' end='237' sourcepath='org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter.java' sourcefile='UnsafeExternalSorter.java' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.spill(long, MemoryConsumer)</Message></Method><SourceLine endBytecode='106' classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' start='209' end='209' sourcepath='org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter.java' sourcefile='UnsafeExternalSorter.java' startBytecode='106' primary='true'><Message>At UnsafeExternalSorter.java:[line 209]</Message></SourceLine><String role='Sink method' value='org/slf4j/Logger.info(Ljava/lang/String;[Ljava/lang/Object;)V'><Message>Sink method org/slf4j/Logger.info(Ljava/lang/String;[Ljava/lang/Object;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(Lscala/math/BigInt;)Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils$.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;'><Message>Unknown source scala/math/BigDecimal$.apply(Lscala/math/BigInt;Ljava/math/MathContext;)Lscala/math/BigDecimal;</Message></String><String role='Unknown source' value='org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/Utils.bytesToString(J)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/collection/immutable/StringOps.formatLocal(Ljava/util/Locale;Lscala/collection/Seq;)Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/math/BigDecimal.toString()Ljava/lang/String;'><Message>Unknown source scala/math/BigDecimal.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='4' classname='org.apache.spark.util.Utils' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='4'><Message>In Utils.scala</Message></SourceLine><SourceLine endBytecode='11' classname='org.apache.spark.util.Utils$' start='1168' end='1168' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='11'><Message>At Utils.scala:[line 1168]</Message></SourceLine><SourceLine endBytecode='86' classname='org.apache.spark.util.Utils$' start='1180' end='1180' sourcepath='org/apache/spark/util/Utils.scala' sourcefile='Utils.scala' startBytecode='86'><Message>At Utils.scala:[line 1180]</Message></SourceLine><SourceLine endBytecode='68' classname='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter' start='211' end='211' sourcepath='org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter.java' sourcefile='UnsafeExternalSorter.java' startBytecode='68'><Message>At UnsafeExternalSorter.java:[line 211]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='2f707796c95a9a7b931fab09c22a795' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.logging.RollingFileAppender' primary='true'><SourceLine classname='org.apache.spark.util.logging.RollingFileAppender' start='41' end='157' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala'><Message>At RollingFileAppender.scala:[lines 41-157]</Message></SourceLine><Message>In class org.apache.spark.util.logging.RollingFileAppender</Message></Class><Method isStatic='false' classname='org.apache.spark.util.logging.RollingFileAppender' signature='()V' name='moveFile' primary='true'><SourceLine endBytecode='498' classname='org.apache.spark.util.logging.RollingFileAppender' start='111' end='110' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.logging.RollingFileAppender.moveFile()</Message></Method><SourceLine endBytecode='45' classname='org.apache.spark.util.logging.RollingFileAppender' start='112' end='112' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='45' primary='true'><Message>At RollingFileAppender.scala:[line 112]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/io/File;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='java/io/File.getName()Ljava/lang/String;'><Message>Unknown source java/io/File.getName()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/logging/RollingPolicy.generateRolledOverFileSuffix()Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/logging/RollingPolicy.generateRolledOverFileSuffix()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='35' classname='org.apache.spark.util.logging.RollingFileAppender' start='113' end='113' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='35'><Message>At RollingFileAppender.scala:[line 113]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='1dc84c1ac0b3993ef5cf73f3df5b8ff8' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.logging.RollingFileAppender' primary='true'><SourceLine classname='org.apache.spark.util.logging.RollingFileAppender' start='41' end='157' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala'><Message>At RollingFileAppender.scala:[lines 41-157]</Message></SourceLine><Message>In class org.apache.spark.util.logging.RollingFileAppender</Message></Class><Method isStatic='false' classname='org.apache.spark.util.logging.RollingFileAppender' signature='()V' name='moveFile' primary='true'><SourceLine endBytecode='498' classname='org.apache.spark.util.logging.RollingFileAppender' start='111' end='110' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.logging.RollingFileAppender.moveFile()</Message></Method><SourceLine endBytecode='178' classname='org.apache.spark.util.logging.RollingFileAppender' start='127' end='127' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='178' primary='true'><Message>At RollingFileAppender.scala:[line 127]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;'><Message>Unknown source scala/Predef$.genericWrapArray(Ljava/lang/Object;)Lscala/collection/mutable/WrappedArray;</Message></String><String role='Unknown source' value='scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;'><Message>Unknown source scala/StringContext.s(Lscala/collection/Seq;)Ljava/lang/String;</Message></String><SourceLine endBytecode='175' classname='org.apache.spark.util.logging.RollingFileAppender' start='128' end='128' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='175'><Message>At RollingFileAppender.scala:[line 128]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='304dab6acfde6e4744b3e18ed326c58b' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.logging.RollingFileAppender' primary='true'><SourceLine classname='org.apache.spark.util.logging.RollingFileAppender' start='41' end='157' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala'><Message>At RollingFileAppender.scala:[lines 41-157]</Message></SourceLine><Message>In class org.apache.spark.util.logging.RollingFileAppender</Message></Class><Method isStatic='false' classname='org.apache.spark.util.logging.RollingFileAppender' signature='(Ljava/io/File;)Z' name='rolloverFileExist' primary='true'><SourceLine endBytecode='115' classname='org.apache.spark.util.logging.RollingFileAppender' start='106' end='106' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.logging.RollingFileAppender.rolloverFileExist(File)</Message></Method><SourceLine endBytecode='37' classname='org.apache.spark.util.logging.RollingFileAppender' start='106' end='106' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='37' primary='true'><Message>At RollingFileAppender.scala:[line 106]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/logging/RollingFileAppender$.GZIP_LOG_SUFFIX()Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/logging/RollingFileAppender$.GZIP_LOG_SUFFIX()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/logging/RollingFileAppender$.GZIP_LOG_SUFFIX'><Message>Unknown source org/apache/spark/util/logging/RollingFileAppender$.GZIP_LOG_SUFFIX</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='22' classname='org.apache.spark.util.logging.RollingFileAppender' start='106' end='106' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='22'><Message>At RollingFileAppender.scala:[line 106]</Message></SourceLine><SourceLine endBytecode='1' classname='org.apache.spark.util.logging.RollingFileAppender$' start='177' end='177' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='1'><Message>At RollingFileAppender.scala:[line 177]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='abc372204116933db5fd16694fe40dc1' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.logging.RollingFileAppender' primary='true'><SourceLine classname='org.apache.spark.util.logging.RollingFileAppender' start='41' end='157' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala'><Message>At RollingFileAppender.scala:[lines 41-157]</Message></SourceLine><Message>In class org.apache.spark.util.logging.RollingFileAppender</Message></Class><Method isStatic='false' classname='org.apache.spark.util.logging.RollingFileAppender' signature='(Ljava/io/File;Ljava/io/File;)V' name='rotateFile' primary='true'><SourceLine endBytecode='334' classname='org.apache.spark.util.logging.RollingFileAppender' start='84' end='97' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.logging.RollingFileAppender.rotateFile(File, File)</Message></Method><SourceLine endBytecode='37' classname='org.apache.spark.util.logging.RollingFileAppender' start='85' end='85' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='37' primary='true'><Message>At RollingFileAppender.scala:[line 85]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;'><Message>Unknown source scala/collection/mutable/StringBuilder.toString()Ljava/lang/String;</Message></String><String role='Unknown source' value='java/io/File.getAbsolutePath()Ljava/lang/String;'><Message>Unknown source java/io/File.getAbsolutePath()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/logging/RollingFileAppender$.GZIP_LOG_SUFFIX()Ljava/lang/String;'><Message>Unknown source org/apache/spark/util/logging/RollingFileAppender$.GZIP_LOG_SUFFIX()Ljava/lang/String;</Message></String><String role='Unknown source' value='org/apache/spark/util/logging/RollingFileAppender$.GZIP_LOG_SUFFIX'><Message>Unknown source org/apache/spark/util/logging/RollingFileAppender$.GZIP_LOG_SUFFIX</Message></String><String role='Unknown source' value='scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;'><Message>Unknown source scala/collection/mutable/StringBuilder.append(Ljava/lang/Object;)Lscala/collection/mutable/StringBuilder;</Message></String><SourceLine endBytecode='22' classname='org.apache.spark.util.logging.RollingFileAppender' start='85' end='85' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='22'><Message>At RollingFileAppender.scala:[line 85]</Message></SourceLine><SourceLine endBytecode='1' classname='org.apache.spark.util.logging.RollingFileAppender$' start='177' end='177' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='1'><Message>At RollingFileAppender.scala:[line 177]</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='dec6a371adef93b71c4c67b5d08ca023' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.logging.RollingFileAppender$' primary='true'><SourceLine classname='org.apache.spark.util.logging.RollingFileAppender$' start='44' end='196' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala'><Message>At RollingFileAppender.scala:[lines 44-196]</Message></SourceLine><Message>In class org.apache.spark.util.logging.RollingFileAppender$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.logging.RollingFileAppender$' signature='(Ljava/lang/String;Ljava/lang/String;)Lscala/collection/Seq;' name='getSortedRolledOverFiles' primary='true'><SourceLine endBytecode='305' classname='org.apache.spark.util.logging.RollingFileAppender$' start='186' end='194' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.logging.RollingFileAppender$.getSortedRolledOverFiles(String, String)</Message></Method><SourceLine endBytecode='11' classname='org.apache.spark.util.logging.RollingFileAppender$' start='186' end='186' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='11' primary='true'><Message>At RollingFileAppender.scala:[line 186]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/logging/RollingFileAppender$.getSortedRolledOverFiles(Ljava/lang/String;Ljava/lang/String;)Lscala/collection/Seq; parameter 1'><Message>Unknown source org/apache/spark/util/logging/RollingFileAppender$.getSortedRolledOverFiles(Ljava/lang/String;Ljava/lang/String;)Lscala/collection/Seq; parameter 1</Message></String><SourceLine endBytecode='339' classname='org.apache.spark.deploy.worker.ui.LogPage' start='49' end='49' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='339'><Message>At LogPage.scala:[line 49]</Message></SourceLine><SourceLine endBytecode='489' classname='org.apache.spark.deploy.worker.ui.LogPage' start='51' end='51' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='489'><Message>At LogPage.scala:[line 51]</Message></SourceLine><SourceLine endBytecode='507' classname='org.apache.spark.deploy.worker.ui.LogPage' start='56' end='56' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='507'><Message>At LogPage.scala:[line 56]</Message></SourceLine><SourceLine endBytecode='774' classname='org.apache.spark.deploy.worker.ui.LogPage' start='81' end='81' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='774'><Message>At LogPage.scala:[line 81]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.deploy.worker.ui.LogPage' start='144' end='144' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='63'><Message>At LogPage.scala:[line 144]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.logging.RollingFileAppender' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='5'><Message>In RollingFileAppender.scala</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e25205326a839efa6307277622874918' cweid='22' rank='12' abbrev='SECPTI' category='SECURITY' priority='2' type='PATH_TRAVERSAL_IN' instanceOccurrenceMax='0'><ShortMessage>Potential Path Traversal (file read)</ShortMessage><LongMessage>This API (java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V) reads a file whose location might be specified by user input</LongMessage><Class classname='org.apache.spark.util.logging.RollingFileAppender$' primary='true'><SourceLine classname='org.apache.spark.util.logging.RollingFileAppender$' start='44' end='196' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala'><Message>At RollingFileAppender.scala:[lines 44-196]</Message></SourceLine><Message>In class org.apache.spark.util.logging.RollingFileAppender$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.logging.RollingFileAppender$' signature='(Ljava/lang/String;Ljava/lang/String;)Lscala/collection/Seq;' name='getSortedRolledOverFiles' primary='true'><SourceLine endBytecode='305' classname='org.apache.spark.util.logging.RollingFileAppender$' start='186' end='194' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.logging.RollingFileAppender$.getSortedRolledOverFiles(String, String)</Message></Method><SourceLine endBytecode='72' classname='org.apache.spark.util.logging.RollingFileAppender$' start='191' end='191' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='72' primary='true'><Message>At RollingFileAppender.scala:[line 191]</Message></SourceLine><String role='Sink method' value='java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V'><Message>Sink method java/io/File.&lt;init&gt;(Ljava/lang/String;Ljava/lang/String;)V</Message></String><String role='Sink parameter' value='0'><Message>Sink parameter 0</Message></String><String role='Unknown source' value='org/apache/spark/util/logging/RollingFileAppender$.getSortedRolledOverFiles(Ljava/lang/String;Ljava/lang/String;)Lscala/collection/Seq; parameter 0'><Message>Unknown source org/apache/spark/util/logging/RollingFileAppender$.getSortedRolledOverFiles(Ljava/lang/String;Ljava/lang/String;)Lscala/collection/Seq; parameter 0</Message></String><SourceLine endBytecode='75' classname='org.apache.spark.deploy.worker.ui.LogPage' start='41' end='41' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='75'><Message>At LogPage.scala:[line 41]</Message></SourceLine><SourceLine endBytecode='507' classname='org.apache.spark.deploy.worker.ui.LogPage' start='56' end='56' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='507'><Message>At LogPage.scala:[line 56]</Message></SourceLine><SourceLine endBytecode='75' classname='org.apache.spark.deploy.worker.ui.LogPage' start='66' end='66' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='75'><Message>At LogPage.scala:[line 66]</Message></SourceLine><SourceLine endBytecode='774' classname='org.apache.spark.deploy.worker.ui.LogPage' start='81' end='81' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='774'><Message>At LogPage.scala:[line 81]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.deploy.worker.ui.LogPage' start='132' end='132' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='5'><Message>At LogPage.scala:[line 132]</Message></SourceLine><SourceLine endBytecode='63' classname='org.apache.spark.deploy.worker.ui.LogPage' start='144' end='144' sourcepath='org/apache/spark/deploy/worker/ui/LogPage.scala' sourcefile='LogPage.scala' startBytecode='63'><Message>At LogPage.scala:[line 144]</Message></SourceLine><SourceLine endBytecode='18' classname='org.apache.spark.ui.UIUtils$' start='548' end='548' sourcepath='org/apache/spark/ui/UIUtils.scala' sourcefile='UIUtils.scala' startBytecode='18'><Message>At UIUtils.scala:[line 548]</Message></SourceLine><SourceLine endBytecode='5' classname='org.apache.spark.util.logging.RollingFileAppender' sourcepath='org/apache/spark/util/logging/RollingFileAppender.scala' sourcefile='RollingFileAppender.scala' startBytecode='5'><Message>In RollingFileAppender.scala</Message></SourceLine></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e84148b55b0fa2db1b5fd8cba4ed6708' cweid='330' rank='12' abbrev='SECPRS' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM_SCALA' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator (Scala)</ShortMessage><LongMessage>This Scala random generator (scala.util.Random.nextLong()) is predictable</LongMessage><Class classname='org.apache.spark.util.random.SamplingUtils$' primary='true'><SourceLine classname='org.apache.spark.util.random.SamplingUtils$' start='36' end='113' sourcepath='org/apache/spark/util/random/SamplingUtils.scala' sourcefile='SamplingUtils.scala'><Message>At SamplingUtils.scala:[lines 36-113]</Message></SourceLine><Message>In class org.apache.spark.util.random.SamplingUtils$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.random.SamplingUtils$' signature='()J' name='reservoirSampleAndCount$default$3' primary='true'><SourceLine endBytecode='48' classname='org.apache.spark.util.random.SamplingUtils$' start='36' end='36' sourcepath='org/apache/spark/util/random/SamplingUtils.scala' sourcefile='SamplingUtils.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount$default$3()</Message></Method><SourceLine endBytecode='3' classname='org.apache.spark.util.random.SamplingUtils$' start='36' end='36' sourcepath='org/apache/spark/util/random/SamplingUtils.scala' sourcefile='SamplingUtils.scala' startBytecode='3' primary='true'><Message>At SamplingUtils.scala:[line 36]</Message></SourceLine><String value='scala.util.Random.nextLong()'><Message>Value scala.util.Random.nextLong()</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='e25f7c16eb82d9d8ebf8bdf681577c69' cweid='330' rank='12' abbrev='SECPR' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator</ShortMessage><LongMessage>This random generator (java.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.util.random.XORShiftRandom' primary='true'><SourceLine classname='org.apache.spark.util.random.XORShiftRandom' start='38' end='55' sourcepath='org/apache/spark/util/random/XORShiftRandom.scala' sourcefile='XORShiftRandom.scala'><Message>At XORShiftRandom.scala:[lines 38-55]</Message></SourceLine><Message>In class org.apache.spark.util.random.XORShiftRandom</Message></Class><Method isStatic='false' classname='org.apache.spark.util.random.XORShiftRandom' signature='(J)V' name='&lt;init&gt;' primary='true'><SourceLine endBytecode='72' classname='org.apache.spark.util.random.XORShiftRandom' start='38' end='42' sourcepath='org/apache/spark/util/random/XORShiftRandom.scala' sourcefile='XORShiftRandom.scala' startBytecode='0'></SourceLine><Message>In method new org.apache.spark.util.random.XORShiftRandom(long)</Message></Method><SourceLine endBytecode='2' classname='org.apache.spark.util.random.XORShiftRandom' start='38' end='38' sourcepath='org/apache/spark/util/random/XORShiftRandom.scala' sourcefile='XORShiftRandom.scala' startBytecode='2' primary='true'><Message>At XORShiftRandom.scala:[line 38]</Message></SourceLine><String value='java.util.Random'><Message>Value java.util.Random</Message></String></BugInstance><BugInstance instanceOccurrenceNum='0' instanceHash='5a15f7091869d150651c71a9545d7c81' cweid='330' rank='12' abbrev='SECPR' category='SECURITY' priority='2' type='PREDICTABLE_RANDOM' instanceOccurrenceMax='0'><ShortMessage>Predictable pseudorandom number generator</ShortMessage><LongMessage>This random generator (java.util.Random) is predictable</LongMessage><Class classname='org.apache.spark.util.random.XORShiftRandom$' primary='true'><SourceLine classname='org.apache.spark.util.random.XORShiftRandom$' start='60' end='108' sourcepath='org/apache/spark/util/random/XORShiftRandom.scala' sourcefile='XORShiftRandom.scala'><Message>At XORShiftRandom.scala:[lines 60-108]</Message></SourceLine><Message>In class org.apache.spark.util.random.XORShiftRandom$</Message></Class><Method isStatic='false' classname='org.apache.spark.util.random.XORShiftRandom$' signature='(I)Lscala/collection/immutable/Map;' name='benchmark' primary='true'><SourceLine endBytecode='415' classname='org.apache.spark.util.random.XORShiftRandom$' start='92' end='105' sourcepath='org/apache/spark/util/random/XORShiftRandom.scala' sourcefile='XORShiftRandom.scala' startBytecode='0'></SourceLine><Message>In method org.apache.spark.util.random.XORShiftRandom$.benchmark(int)</Message></Method><SourceLine endBytecode='13' classname='org.apache.spark.util.random.XORShiftRandom$' start='94' end='94' sourcepath='org/apache/spark/util/random/XORShiftRandom.scala' sourcefile='XORShiftRandom.scala' startBytecode='13' primary='true'><Message>At XORShiftRandom.scala:[line 94]</Message></SourceLine><String value='java.util.Random'><Message>Value java.util.Random</Message></String></BugInstance><BugCategory category='SECURITY'><Description>Security</Description></BugCategory><BugPattern cweid='89' abbrev='SQL' category='SECURITY' type='SQL_PREPARED_STATEMENT_GENERATED_FROM_NONCONSTANT_STRING'><ShortDescription>A prepared statement is generated from a nonconstant String</ShortDescription><Details>

  &lt;p&gt;The code creates an SQL prepared statement from a nonconstant String.
If unchecked, tainted data from a user is used in building this String, SQL injection could
be used to make the prepared statement do something unexpected and undesirable.
&lt;/p&gt;

    </Details></BugPattern><BugPattern cweid='319' abbrev='SECUS' category='SECURITY' type='UNENCRYPTED_SOCKET'><ShortDescription>Unencrypted Socket</ShortDescription><Details>
            
&lt;p&gt;
The communication channel used is not encrypted. The traffic could be read by an attacker intercepting the network traffic.
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
Plain socket (Cleartext communication):
&lt;pre&gt;Socket soc = new Socket("www.google.com",80);&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;Solution:&lt;/b&gt;&lt;br/&gt;
SSL Socket (Secure communication):
&lt;pre&gt;Socket soc = SSLSocketFactory.getDefault().createSocket("www.google.com", 443);&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;Beyond using an SSL socket, you need to make sure your use of SSLSocketFactory does all the appropriate certificate validation checks to
make sure you are not subject to man-in-the-middle attacks. Please read the OWASP Transport Layer Protection Cheat Sheet for details on how
to do this correctly.
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2010-A9"&gt;OWASP: Top 10 2010-A9-Insufficient Transport Layer Protection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2013-A6-Sensitive_Data_Exposure"&gt;OWASP: Top 10 2013-A6-Sensitive Data Exposure&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Transport_Layer_Protection_Cheat_Sheet"&gt;OWASP: Transport Layer Protection Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246945/Insufficient%20Transport%20Layer%20Protection"&gt;WASC-04: Insufficient Transport Layer Protection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/319.html"&gt;CWE-319: Cleartext Transmission of Sensitive Information&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='295' abbrev='SECWTM' category='SECURITY' type='WEAK_TRUST_MANAGER'><ShortDescription>TrustManager that accept any certificates</ShortDescription><Details>
            
&lt;p&gt;Empty TrustManager implementations are often used to connect easily to a host that is not signed by a root
&lt;a href="https://en.wikipedia.org/wiki/Certificate_authority"&gt;certificate authority&lt;/a&gt;. As a consequence, this is vulnerable to
&lt;a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack"&gt;Man-in-the-middle attacks&lt;/a&gt;
since the client will trust any certificate.
&lt;/p&gt;
&lt;p&gt;
A TrustManager allowing specific certificates (based on a TrustStore for example) should be built.
Detailed information for a proper implementation is available at:
&lt;a href="https://stackoverflow.com/a/6378872/89769"&gt;[1]&lt;/a&gt;
&lt;a href="https://stackoverflow.com/a/5493452/89769"&gt;[2]&lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;class TrustAllManager implements X509TrustManager {

    @Override
    public void checkClientTrusted(X509Certificate[] x509Certificates, String s) throws CertificateException {
        //Trust any client connecting (no certificate validation)
    }

    @Override
    public void checkServerTrusted(X509Certificate[] x509Certificates, String s) throws CertificateException {
        //Trust any remote server (no certificate validation)
    }

    @Override
    public X509Certificate[] getAcceptedIssuers() {
        return null;
    }
}&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
    &lt;b&gt;Solution (TrustMangager based on a keystore):&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;KeyStore ks = //Load keystore containing the certificates trusted

SSLContext sc = SSLContext.getInstance("TLS");

TrustManagerFactory tmf = TrustManagerFactory.getInstance("SunX509");
tmf.init(ks);

sc.init(kmf.getKeyManagers(), tmf.getTrustManagers(),null);
&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246945/Insufficient%20Transport%20Layer%20Protection"&gt;WASC-04: Insufficient Transport Layer Protection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/295.html"&gt;CWE-295: Improper Certificate Validation&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='319' abbrev='SECUSS' category='SECURITY' type='UNENCRYPTED_SERVER_SOCKET'><ShortDescription>Unencrypted Server Socket</ShortDescription><Details>
            
&lt;p&gt;
The communication channel used is not encrypted. The traffic could be read by an attacker intercepting the network traffic.
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
Plain server socket (Cleartext communication):
&lt;pre&gt;ServerSocket soc = new ServerSocket(1234);&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;Solution:&lt;/b&gt;&lt;br/&gt;
SSL Server Socket (Secure communication):
&lt;pre&gt;ServerSocket soc = SSLServerSocketFactory.getDefault().createServerSocket(1234);&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;Beyond using an SSL server socket, you need to make sure your use of SSLServerSocketFactory does all the appropriate certificate validation checks to
make sure you are not subject to man-in-the-middle attacks. Please read the OWASP Transport Layer Protection Cheat Sheet for details on how
to do this correctly.
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2010-A9"&gt;OWASP: Top 10 2010-A9-Insufficient Transport Layer Protection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2013-A6-Sensitive_Data_Exposure"&gt;OWASP: Top 10 2013-A6-Sensitive Data Exposure&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Transport_Layer_Protection_Cheat_Sheet"&gt;OWASP: Transport Layer Protection Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246945/Insufficient%20Transport%20Layer%20Protection"&gt;WASC-04: Insufficient Transport Layer Protection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/319.html"&gt;CWE-319: Cleartext Transmission of Sensitive Information&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='22' abbrev='SECPTO' category='SECURITY' type='PATH_TRAVERSAL_OUT'><ShortDescription>Potential Path Traversal (file write)</ShortDescription><Details>
            
&lt;p&gt;A file is opened to write to its contents. The filename comes from an &lt;b&gt;input&lt;/b&gt; parameter.
If an unfiltered parameter is passed to this file API, files at an arbitrary filesystem location could be modified.&lt;/p&gt;
&lt;p&gt;This rule identifies &lt;b&gt;potential&lt;/b&gt; path traversal vulnerabilities. In many cases, the constructed file path cannot be controlled
by the user. If that is the case, the reported instance is a false positive.&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246952/Path%20Traversal"&gt;WASC-33: Path Traversal&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Path_Traversal"&gt;OWASP: Path Traversal&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://capec.mitre.org/data/definitions/126.html"&gt;CAPEC-126: Path Traversal&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/22.html"&gt;CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='113' abbrev='SECHRS' category='SECURITY' type='HTTP_RESPONSE_SPLITTING'><ShortDescription>Potential HTTP Response Splitting</ShortDescription><Details>
            
&lt;p&gt;
    When an HTTP request contains unexpected &lt;code&gt;CR&lt;/code&gt; and &lt;code&gt;LF&lt;/code&gt; characters, the server may respond with an output stream
    that is interpreted as two different HTTP responses (instead of one).
    An attacker can control the second response and mount attacks such as cross-site scripting and cache poisoning attacks.
    According to OWASP, the issue has been fixed in virtually all modern Java EE application servers, but it is still better to validate the input.
    If you are concerned about this risk, you should test on the platform of concern to see
    if the underlying platform allows for &lt;code&gt;CR&lt;/code&gt; or &lt;code&gt;LF&lt;/code&gt; characters to be injected into headers.
    This weakness is reported with low priority because it requires the web container to be vulnerable.
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;Code at risk:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;String author = request.getParameter(AUTHOR_PARAMETER);
// ...
Cookie cookie = new Cookie("author", author);
response.addCookie(cookie);&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
    &lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
    &lt;a href="https://www.owasp.org/index.php/HTTP_Response_Splitting"&gt;OWASP: HTTP Response Splitting&lt;/a&gt;&lt;br/&gt;
    &lt;a href="https://cwe.mitre.org/data/definitions/113.html"&gt;CWE-113: Improper Neutralization of CRLF Sequences in HTTP Headers ('HTTP Response Splitting')&lt;/a&gt;
    &lt;a href="https://cwe.mitre.org/data/definitions/93.html"&gt;CWE-93: Improper Neutralization of CRLF Sequences ('CRLF Injection')&lt;/a&gt;&lt;br/&gt;
&lt;/p&gt;


        </Details></BugPattern><BugPattern cweid='117' abbrev='SECCRLFLOG' category='SECURITY' type='CRLF_INJECTION_LOGS'><ShortDescription>Potential CRLF Injection for logs</ShortDescription><Details>
            
&lt;p&gt;
    When data from an untrusted source is put into a logger and not neutralized correctly,
    an attacker could forge log entries or include malicious content.
    Inserted false entries could be used to skew statistics, distract the administrator
    or even to implicate another party in the commission of a malicious act.
    If the log file is processed automatically, the attacker can render the file unusable
    by corrupting the format of the file or injecting unexpected characters.
    An attacker may also inject code or other commands into the log file and take advantage
    of a vulnerability in the log processing utility (e.g. command injection or XSS).
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;Code at risk:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;String val = request.getParameter("user");
String metadata = request.getParameter("metadata");
[...]
if(authenticated) {
    log.info("User " + val + " (" + metadata + ") was authenticated successfully");
}
else {
    log.info("User " + val + " (" + metadata + ") was not authenticated");
}
&lt;/pre&gt;

A malicious user could send the metadata parameter with the value: &lt;code&gt;"Firefox) was authenticated successfully\r\n[INFO] User bbb (Internet Explorer"&lt;/code&gt;.
&lt;/p&gt;

&lt;b&gt;Solution:&lt;/b&gt;&lt;br/&gt;
&lt;p&gt;
You can manually sanitize each parameter.
&lt;pre&gt;
log.info("User " + val.replaceAll("[\r\n]","") + " (" + userAgent.replaceAll("[\r\n]","") + ") was not authenticated");
&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;
You can also configure your logger service to replace new line for all message events. Here is sample configuration for LogBack &lt;a href="https://logback.qos.ch/manual/layouts.html#replace"&gt;using the &lt;code&gt;replace&lt;/code&gt; function&lt;/a&gt;.
&lt;pre&gt;
&amp;lt;pattern&amp;gt;%-5level - %replace(%msg){'[\r\n]', ''}%n&amp;lt;/pattern&amp;gt;
&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;
Finally, you can use a logger implementation that replace new line by spaces.
The project &lt;a href="https://github.com/javabeanz/owasp-security-logging"&gt;OWASP Security Logging&lt;/a&gt; has an implementation for Logback and Log4j.
&lt;/p&gt;

&lt;br/&gt;
&lt;p&gt;
    &lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
    &lt;a href="https://cwe.mitre.org/data/definitions/117.html"&gt;CWE-117: Improper Output Neutralization for Logs&lt;/a&gt;&lt;br/&gt;
    &lt;a href="https://cwe.mitre.org/data/definitions/93.html"&gt;CWE-93: Improper Neutralization of CRLF Sequences ('CRLF Injection')&lt;/a&gt;&lt;br/&gt;
    &lt;a href="https://logback.qos.ch/manual/layouts.html#replace"&gt;CWE-93: Improper Neutralization of CRLF Sequences ('CRLF Injection')&lt;/a&gt;&lt;br/&gt;
    &lt;a href="https://github.com/javabeanz/owasp-security-logging"&gt;OWASP Security Logging&lt;/a&gt;&lt;br/&gt;
&lt;/p&gt;


        </Details></BugPattern><BugPattern cweid='22' abbrev='SECPTI' category='SECURITY' type='PATH_TRAVERSAL_IN'><ShortDescription>Potential Path Traversal (file read)</ShortDescription><Details>
            
&lt;p&gt;A file is opened to read its content. The filename comes from an &lt;b&gt;input&lt;/b&gt; parameter.
If an unfiltered parameter is passed to this file API, files from an arbitrary filesystem location could be read.&lt;/p&gt;
&lt;p&gt;This rule identifies &lt;b&gt;potential&lt;/b&gt; path traversal vulnerabilities. In many cases, the constructed file path cannot be controlled
by the user. If that is the case, the reported instance is a false positive.&lt;/p&gt;
&lt;br/&gt;

&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;@GET
@Path("/images/{image}")
@Produces("images/*")
public Response getImage(@javax.ws.rs.PathParam("image") String image) {
    File file = new File("resources/images/", image); //Weak point

    if (!file.exists()) {
        return Response.status(Status.NOT_FOUND).build();
    }

    return Response.ok().entity(new FileInputStream(file)).build();
}&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;

&lt;p&gt;
    &lt;b&gt;Solution:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;import org.apache.commons.io.FilenameUtils;

@GET
@Path("/images/{image}")
@Produces("images/*")
public Response getImage(@javax.ws.rs.PathParam("image") String image) {
    File file = new File("resources/images/", FilenameUtils.getName(image)); //Fix

    if (!file.exists()) {
        return Response.status(Status.NOT_FOUND).build();
    }

    return Response.ok().entity(new FileInputStream(file)).build();
}&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246952/Path%20Traversal"&gt;WASC: Path Traversal&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Path_Traversal"&gt;OWASP: Path Traversal&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://capec.mitre.org/data/definitions/126.html"&gt;CAPEC-126: Path Traversal&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/22.html"&gt;CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='295' abbrev='SECWHV' category='SECURITY' type='WEAK_HOSTNAME_VERIFIER'><ShortDescription>HostnameVerifier that accept any signed certificates</ShortDescription><Details>
            
&lt;p&gt;A &lt;code&gt;HostnameVerifier&lt;/code&gt; that accept any host are often use because of certificate reuse on many hosts.
As a consequence, this is vulnerable to
&lt;a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack"&gt;Man-in-the-middle attacks&lt;/a&gt;
since the client will trust any certificate.
&lt;/p&gt;
&lt;p&gt;
A TrustManager allowing specific certificates (based on a truststore for example) should be built.
Wildcard certificates should be created for reused on multiples subdomains.
Detailed information for a proper implementation is available at:
&lt;a href="https://stackoverflow.com/a/6378872/89769"&gt;[1]&lt;/a&gt;
&lt;a href="https://stackoverflow.com/a/5493452/89769"&gt;[2]&lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;public class AllHosts implements HostnameVerifier {
    public boolean verify(final String hostname, final SSLSession session) {
        return true;
    }
}&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
    &lt;b&gt;Solution (TrustMangager based on a keystore):&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;KeyStore ks = //Load keystore containing the certificates trusted

SSLContext sc = SSLContext.getInstance("TLS");

TrustManagerFactory tmf = TrustManagerFactory.getInstance("SunX509");
tmf.init(ks);

sc.init(kmf.getKeyManagers(), tmf.getTrustManagers(),null);
&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246945/Insufficient%20Transport%20Layer%20Protection"&gt;WASC-04: Insufficient Transport Layer Protection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/295.html"&gt;CWE-295: Improper Certificate Validation&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='918' abbrev='SECSSSRFUC' category='SECURITY' type='URLCONNECTION_SSRF_FD'><ShortDescription>URLConnection Server-Side Request Forgery (SSRF) and File Disclosure</ShortDescription><Details>
            
&lt;p&gt;
    Server-Side Request Forgery occur when a web server executes a request to a user supplied destination
    parameter that is not validated. Such vulnerabilities could allow an attacker to access internal services
    or to launch attacks from your web server.
&lt;/p&gt;
&lt;p&gt;
    URLConnection can be used with file:// protocol or other protocols to access local filesystem and potentially other services.
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;
&lt;pre&gt;
new URL(String url).openConnection()
&lt;/pre&gt;

&lt;pre&gt;
new URL(String url).openStream()
&lt;/pre&gt;

&lt;pre&gt;
new URL(String url).getContent()
&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Solution/Countermeasures:&lt;/b&gt;&lt;br/&gt;
    &lt;ul&gt;
        &lt;li&gt;Don't accept URL destinations from users&lt;/li&gt;
        &lt;li&gt;Accept a destination key, and use it to look up the target destination associate with the key&lt;/li&gt;
        &lt;li&gt;White list URLs (if possible)&lt;/li&gt;
        &lt;li&gt;Validate that the beginning of the URL is part of a white list&lt;/li&gt;
    &lt;/ul&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/918.html"&gt;CWE-918: Server-Side Request Forgery (SSRF)&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.bishopfox.com/blog/2015/04/vulnerable-by-design-understanding-server-side-request-forgery/"&gt;Understanding Server-Side Request Forgery&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/73.html"&gt;CWE-73: External Control of File Name or Path&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.pwntester.com/blog/2013/11/28/abusing-jar-downloads/"&gt;Abusing jar:// downloads&lt;/a&gt;&lt;br /&gt;
&lt;/p&gt;
            </Details></BugPattern><BugPattern cweid='329' abbrev='STAIV' category='SECURITY' type='STATIC_IV'><ShortDescription>Static IV</ShortDescription><Details>
            
&lt;p&gt;
    Initialization vector must be regenerated for each message to be encrypted.
&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;
&lt;pre&gt;
private static byte[] IV = new byte[16] {(byte)0,(byte)1,(byte)2,[...]};

public void encrypt(String message) throws Exception {

    IvParameterSpec ivSpec = new IvParameterSpec(IV);
[...]
&lt;/pre&gt;
&lt;p&gt;&lt;b&gt;Solution:&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;
&lt;pre&gt;
public void encrypt(String message) throws Exception {

    byte[] iv = new byte[16];
    new SecureRandom().nextBytes(iv);

    IvParameterSpec ivSpec = new IvParameterSpec(iv);
[...]
&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://en.wikipedia.org/wiki/Initialization_vector"&gt;Wikipedia: Initialization vector&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/329.html"&gt;CWE-329: Not Using a Random IV with CBC Mode&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://defuse.ca/cbcmodeiv.htm"&gt;Encryption - CBC Mode IV: Secret or Not?&lt;/a&gt;
&lt;/p&gt;
            
        </Details></BugPattern><BugPattern cweid='89' abbrev='SECSQLIJDBC' category='SECURITY' type='SQL_INJECTION_JDBC'><ShortDescription>Potential JDBC Injection</ShortDescription><Details>
            
&lt;p&gt;
The input values included in SQL queries need to be passed in safely.
Bind variables in prepared statements can be used to easily mitigate the risk of SQL injection.
&lt;/p&gt;

&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
    &lt;pre&gt;Connection conn = [...];
Statement stmt = con.createStatement();
ResultSet rs = stmt.executeQuery("update COFFEES set SALES = "+nbSales+" where COF_NAME = '"+coffeeName+"'");&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Solution:&lt;/b&gt;&lt;br/&gt;
    &lt;pre&gt;Connection conn = [...];
conn.prepareStatement("update COFFEES set SALES = ? where COF_NAME = ?");
updateSales.setInt(1, nbSales);
updateSales.setString(2, coffeeName);&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;

&lt;b&gt;References (JDBC)&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://docs.oracle.com/javase/tutorial/jdbc/basics/prepared.html"&gt;Oracle Documentation: The Java Tutorials &amp;gt; Prepared Statements&lt;/a&gt;&lt;br/&gt;
&lt;b&gt;References (SQL injection)&lt;/b&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246963/SQL%20Injection"&gt;WASC-19: SQL Injection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://capec.mitre.org/data/definitions/66.html"&gt;CAPEC-66: SQL Injection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/89.html"&gt;CWE-89: Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection')&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2013-A1-Injection"&gt;OWASP: Top 10 2013-A1-Injection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/SQL_Injection_Prevention_Cheat_Sheet"&gt;OWASP: SQL Injection Prevention Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Query_Parameterization_Cheat_Sheet"&gt;OWASP: Query Parameterization Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern abbrev='SECSSQ' category='SECURITY' type='SERVLET_QUERY_STRING'><ShortDescription>Untrusted query string</ShortDescription><Details>
            
&lt;p&gt;The query string is the concatenation of the GET parameter names and values. Parameters other than those intended can
be passed in.&lt;/p&gt;
&lt;p&gt;For the URL request &lt;code&gt;/app/servlet.htm?a=1&amp;b=2&lt;/code&gt;, the query string extract will be &lt;code&gt;a=1&amp;b=2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Just as is true for individual parameter values retrieved via methods like &lt;code&gt;HttpServletRequest.getParameter()&lt;/code&gt;,
the value obtained from &lt;code&gt;HttpServletRequest.getQueryString()&lt;/code&gt; should be considered unsafe.
You may need to validate or sanitize anything pulled from the query string before passing it to sensitive APIs.
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;Reference&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/20.html"&gt;CWE-20: Improper Input Validation&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='79' abbrev='SECXSS2' category='SECURITY' type='XSS_SERVLET'><ShortDescription>Potential XSS in Servlet</ShortDescription><Details>
            
&lt;p&gt;
A potential XSS was found. It could be used to execute unwanted JavaScript in a client's browser. (See references)
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;
&lt;pre&gt;protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
    String input1 = req.getParameter("input1");
    [...]
    resp.getWriter().write(input1);
}&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Solution:&lt;/b&gt;
&lt;pre&gt;protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
    String input1 = req.getParameter("input1");
    [...]
    resp.getWriter().write(Encode.forHtml(input1));
}&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
The best defense against XSS is context sensitive output encoding like the example above. There are typically 4 contexts to consider:
HTML, JavaScript, CSS (styles), and URLs. Please follow the XSS protection rules defined in the OWASP XSS Prevention Cheat Sheet,
which explains these defenses in significant detail.
&lt;/p&gt;
&lt;p&gt;Note that this XSS in Servlet rule looks for similar issues, but looks for them in a different way than the existing
'XSS: Servlet reflected cross site scripting vulnerability' and 'XSS: Servlet reflected cross site scripting vulnerability in error page' rules in FindBugs.
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246920/Cross%20Site%20Scripting"&gt;WASC-8: Cross Site Scripting&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/XSS_%28Cross_Site_Scripting%29_Prevention_Cheat_Sheet"&gt;OWASP: XSS Prevention Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2013-A3-Cross-Site_Scripting_%28XSS%29"&gt;OWASP: Top 10 2013-A3: Cross-Site Scripting (XSS)&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/79.html"&gt;CWE-79: Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://code.google.com/p/owasp-java-encoder/"&gt;OWASP Java Encoder&lt;/a&gt;&lt;br/&gt;
&lt;/p&gt;
            
        </Details></BugPattern><BugPattern abbrev='SECSSL' category='SECURITY' type='SSL_CONTEXT'><ShortDescription>Weak SSLContext</ShortDescription><Details>
            
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;

    &lt;pre&gt;SSLContext.getInstance("SSL");&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;p&gt;&lt;b&gt;Solution:&lt;/b&gt;&lt;br/&gt;

Upgrade your implementation to the following, and configure &lt;code&gt;https.protocols&lt;/code&gt; JVM option to include TLSv1.2:&lt;/p&gt;
&lt;pre&gt;SSLContext.getInstance("TLS");&lt;/pre&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://blogs.oracle.com/java-platform-group/entry/diagnosing_tls_ssl_and_https"&gt;Diagnosing TLS, SSL, and HTTPS&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern abbrev='SECJRS' category='SECURITY' type='JAXRS_ENDPOINT'><ShortDescription>Found JAX-RS REST endpoint</ShortDescription><Details>
            
&lt;p&gt;This method is part of a REST Web Service (JSR311).&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;The security of this web service should be analyzed. For example:&lt;/b&gt;
&lt;ul&gt;
&lt;li&gt;Authentication, if enforced, should be tested.&lt;/li&gt;
&lt;li&gt;Access control, if enforced, should be tested.&lt;/li&gt;
&lt;li&gt;The inputs should be tracked for potential vulnerabilities.&lt;/li&gt;
&lt;li&gt;The communication should ideally be over SSL.&lt;/li&gt;
&lt;li&gt;If the service supports writes (e.g., via POST), its vulnerability to CSRF should be investigated.&lt;sup&gt;[1]&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/REST_Assessment_Cheat_Sheet"&gt;OWASP: REST Assessment Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/REST_Security_Cheat_Sheet"&gt;OWASP: REST Security Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Web_Service_Security_Cheat_Sheet"&gt;OWASP: Web Service Security Cheat Sheet&lt;/a&gt;&lt;br/&gt;
1. &lt;a href="https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)"&gt;OWASP: Cross-Site Request Forgery&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Cross-Site_Request_Forgery_%28CSRF%29_Prevention_Cheat_Sheet"&gt;OWASP: CSRF Prevention Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/20.html"&gt;CWE-20: Improper Input Validation&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='601' abbrev='SECUR' category='SECURITY' type='UNVALIDATED_REDIRECT'><ShortDescription>Unvalidated Redirect</ShortDescription><Details>
            
&lt;p&gt;
    Unvalidated redirects occur when an application redirects a user to a destination URL specified by a user supplied
    parameter that is not validated. Such vulnerabilities can be used to facilitate phishing attacks.
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Scenario&lt;/b&gt;&lt;br/&gt;
    1. A user is tricked into visiting the malicious URL: &lt;code&gt;http://website.com/login?redirect=http://evil.vvebsite.com/fake/login&lt;/code&gt;&lt;br/&gt;
    2. The user is redirected to a fake login page that looks like a site they trust. (&lt;code&gt;http://evil.vvebsite.com/fake/login&lt;/code&gt;)&lt;br/&gt;
    3. The user enters his credentials.&lt;br/&gt;
    4. The evil site steals the user's credentials and redirects him to the original website.&lt;br/&gt;
    &lt;br/&gt;
    This attack is plausible because most users don't double check the URL after the redirection. Also, redirection to
    an authentication page is very common.
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;/br/&gt;
    &lt;pre&gt;protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
    [...]
    resp.sendRedirect(req.getParameter("redirectUrl"));
    [...]
}&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Solution/Countermeasures:&lt;/b&gt;&lt;br/&gt;
    &lt;ul&gt;
        &lt;li&gt;Don't accept redirection destinations from users&lt;/li&gt;
        &lt;li&gt;Accept a destination key, and use it to look up the target (legal) destination&lt;/li&gt;
        &lt;li&gt;Accept only relative paths&lt;/li&gt;
        &lt;li&gt;White list URLs (if possible)&lt;/li&gt;
        &lt;li&gt;Validate that the beginning of the URL is part of a white list&lt;/li&gt;
    &lt;/ul&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="http://projects.webappsec.org/w/page/13246981/URL%20Redirector%20Abuse"&gt;WASC-38: URL Redirector Abuse&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2013-A10-Unvalidated_Redirects_and_Forwards"&gt;OWASP: Top 10 2013-A10: Unvalidated Redirects and Forwards&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Unvalidated_Redirects_and_Forwards_Cheat_Sheet"&gt;OWASP: Unvalidated Redirects and Forwards Cheat Sheet&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/601.html"&gt;CWE-601: URL Redirection to Untrusted Site ('Open Redirect')&lt;/a&gt;
&lt;/p&gt;
            
        </Details></BugPattern><BugPattern cweid='330' abbrev='SECPRS' category='SECURITY' type='PREDICTABLE_RANDOM_SCALA'><ShortDescription>Predictable pseudorandom number generator (Scala)</ShortDescription><Details>
            
&lt;p&gt;The use of a predictable random value can lead to vulnerabilities when used in certain security critical contexts. For example, when the value is used as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a CSRF token: a predictable token can lead to a CSRF attack as an attacker will know the value of the token&lt;/li&gt;
&lt;li&gt;a password reset token (sent by email): a predictable password token can lead to an account takeover, since an attacker will guess the URL of the "change password" form&lt;/li&gt;
&lt;li&gt;any other secret value&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
A quick fix could be to replace the use of &lt;code&gt;java.util.Random&lt;/code&gt; with something stronger, such as &lt;b&gt;java.security.SecureRandom&lt;/b&gt;.
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;import scala.util.Random

def generateSecretToken() {
    val result = Seq.fill(16)(Random.nextInt)
    return result.map("%02x" format _).mkString
}&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Solution:&lt;/b&gt;
&lt;pre&gt;import java.security.SecureRandom

def generateSecretToken() {
    val rand = new SecureRandom()
    val value = Array.ofDim[Byte](16)
    rand.nextBytes(value)
    return value.map("%02x" format _).mkString
}&lt;/pre&gt;
&lt;/p&gt;
&lt;!--&lt;p&gt;
&lt;b&gt;Solution:&lt;/b&gt;
&lt;pre&gt;import java.security.SecureRandom
import scala.util.Random._

def generateSecretToken() {
    val secRandom = javaRandomToRandom(new SecureRandom())
    val result = Seq.fill(16)(secRandom.nextInt)
    return result.map("%02x" format _).mkString
}&lt;/pre&gt;
&lt;/p&gt;--&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://jazzy.id.au/2010/09/20/cracking_random_number_generators_part_1.html"&gt;Cracking Random Number Generators - Part 1 (http://jazzy.id.au)&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.securecoding.cert.org/confluence/display/java/MSC02-J.+Generate+strong+random+numbers"&gt;CERT: MSC02-J. Generate strong random numbers&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/330.html"&gt;CWE-330: Use of Insufficiently Random Values&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://blog.h3xstream.com/2014/12/predicting-struts-csrf-token-cve-2014.html"&gt;Predicting Struts CSRF Token (Example of real-life vulnerability and exploitation)&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern abbrev='SECSH' category='SECURITY' type='SERVLET_HEADER'><ShortDescription>HTTP headers untrusted</ShortDescription><Details>
            
&lt;p&gt;Request headers can easily be altered by the requesting user. In general, no assumption should be made that
the request came from a regular browser without modification by an attacker. As such, it is recommended that you
not trust this value in any security decisions you make with respect to a request.&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;Reference&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/807.html"&gt;CWE-807: Untrusted Inputs in a Security Decision&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='209' abbrev='ERRMSG' category='SECURITY' type='INFORMATION_EXPOSURE_THROUGH_AN_ERROR_MESSAGE'><ShortDescription>Information Exposure Through An Error Message</ShortDescription><Details>
            
&lt;p&gt;
The sensitive information may be valuable information on its own (such as a password), or it may be useful for launching other, more deadly attacks. If an attack fails, an attacker may use error information provided by the server to launch another more focused attack. For example, an attempt to exploit a path traversal weakness (CWE-22) might yield the full pathname of the installed application. In turn, this could be used to select the proper number of ".." sequences to navigate to the targeted file. An attack using SQL injection (CWE-89) might not initially succeed, but an error message could reveal the malformed query, which would expose query logic and possibly even passwords or other sensitive information used within the query.
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;try {
  out = httpResponse.getOutputStream()
} catch (Exception e) {
  e.printStackTrace(out);
}&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/209.html"&gt;CWE-209: Information Exposure Through an Error Message&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/211.html"&gt;CWE-211: Information Exposure Through Externally-Generated Error Message&lt;/a&gt;&lt;br/&gt;
&lt;/p&gt;
            
        </Details></BugPattern><BugPattern cweid='330' abbrev='SECPR' category='SECURITY' type='PREDICTABLE_RANDOM'><ShortDescription>Predictable pseudorandom number generator</ShortDescription><Details>
            
&lt;p&gt;The use of a predictable random value can lead to vulnerabilities when used in certain security critical contexts. For example, when the value is used as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a CSRF token: a predictable token can lead to a CSRF attack as an attacker will know the value of the token&lt;/li&gt;
&lt;li&gt;a password reset token (sent by email): a predictable password token can lead to an account takeover, since an attacker will guess the URL of the "change password" form&lt;/li&gt;
&lt;li&gt;any other secret value&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
A quick fix could be to replace the use of &lt;code&gt;java.util.Random&lt;/code&gt; with something stronger, such as &lt;code&gt;java.security.SecureRandom&lt;/code&gt;.
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;String generateSecretToken() {
    Random r = new Random();
    return Long.toHexString(r.nextLong());
}&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;Solution:&lt;/b&gt;
&lt;pre&gt;import org.apache.commons.codec.binary.Hex;

String generateSecretToken() {
    SecureRandom secRandom = new SecureRandom();

    byte[] result = new byte[32];
    secRandom.nextBytes(result);
    return Hex.encodeHexString(result);
}&lt;/pre&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://jazzy.id.au/2010/09/20/cracking_random_number_generators_part_1.html"&gt;Cracking Random Number Generators - Part 1 (https://jazzy.id.au)&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.securecoding.cert.org/confluence/display/java/MSC02-J.+Generate+strong+random+numbers"&gt;CERT: MSC02-J. Generate strong random numbers&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/330.html"&gt;CWE-330: Use of Insufficiently Random Values&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://blog.h3xstream.com/2014/12/predicting-struts-csrf-token-cve-2014.html"&gt;Predicting Struts CSRF Token (Example of real-life vulnerability and exploitation)&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='502' abbrev='SECOBDES' category='SECURITY' type='OBJECT_DESERIALIZATION'><ShortDescription>Object deserialization is used in {1}</ShortDescription><Details>
            
&lt;p&gt;
    Object deserialization of untrusted data can lead to remote code execution, if there is a class in classpath that allows
    the trigger of malicious operation.
&lt;/p&gt;
&lt;p&gt;
    Libraries developers tend to fix class that provided potential malicious trigger. There are still classes that are
    known to trigger Denial of Service&lt;sup&gt;[1]&lt;/sup&gt;.
&lt;/p&gt;
&lt;p&gt;
    Deserialization is a sensible operation that has a great history of vulnerabilities. The web application might
    become vulnerable as soon as a new vulnerability is found in the Java Virtual Machine&lt;sup&gt;[2] [3]&lt;/sup&gt;.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;Code at risk:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;
public UserData deserializeObject(InputStream receivedFile) throws IOException, ClassNotFoundException {

    try (ObjectInputStream in = new ObjectInputStream(receivedFile)) {
        return (UserData) in.readObject();
    }
}
&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;Solutions:&lt;/b&gt;&lt;br/&gt;
&lt;p&gt;
Avoid deserializing object provided by remote users.
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/502.html"&gt;CWE-502: Deserialization of Untrusted Data&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Deserialization_of_untrusted_data"&gt;Deserialization of untrusted data&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.oracle.com/technetwork/java/seccodeguide-139067.html#8"&gt;Serialization and Deserialization &lt;/a&gt;&lt;br/&gt;
&lt;a href="https://github.com/frohoff/ysoserial"&gt;A tool for generating payloads that exploit unsafe Java object deserialization&lt;/a&gt;&lt;br/&gt;
[1] &lt;a href="https://gist.github.com/coekie/a27cc406fc9f3dc7a70d"&gt;Example of Denial of Service using the class &lt;code&gt;java.util.HashSet&lt;/code&gt;&lt;/a&gt;&lt;br/&gt;
[2] &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2015-2590"&gt;OpenJDK: Deserialization issue in ObjectInputStream.readSerialData() (CVE-2015-2590)&lt;/a&gt;&lt;br/&gt;
[3] &lt;a href="https://www.rapid7.com/db/modules/exploit/multi/browser/java_calendar_deserialize"&gt;Rapid7: Sun Java Calendar Deserialization Privilege Escalation (CVE-2008-5353)&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='176' abbrev='SECUNI' category='SECURITY' type='IMPROPER_UNICODE'><ShortDescription>Improper handling of Unicode transformations</ShortDescription><Details>
            
&lt;p&gt;
Unexpected behavior in unicode transformations can sometimes lead to bugs, some of them affecting software security.
A code that applies the uppercase transformation to two strings could mistakenly interpret both strings as being equal.
&lt;/p&gt;

&lt;p&gt;
In the code bellow, the string &lt;code&gt;"ADM\u0131N"&lt;/code&gt; would cause the condition to be true.
When the uppercase transformation is applied, the character `\u0131` will becomme '\u0049' (I).
It can be an issue if the developer only one user to be &lt;code&gt;"ADMIN"&lt;/code&gt;.&lt;br/&gt;
&lt;pre&gt;
if(username.toUpperCase().equals("ADMIN")) {
  //...
}
&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;
Similar characters transformations can occurs with normalization functions.
In the code bellow, the string &lt;code&gt;"BAC\u212AUP"&lt;/code&gt; would cause the condition to be true.
When the normalization transformation is applied, the character `\u212A` will becomme '\u0048' (K).&lt;br/&gt;
&lt;pre&gt;
if(Normalizer.normalize(input, Normalizer.Form.NFC).equals("BACKUP")) {
  //...
}
&lt;/pre&gt;
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://www.gosecure.net/blog/2020/08/04/unicode-for-security-professionals/"&gt;Unicode for Security Professionals&lt;/a&gt;&lt;br/&gt;
&lt;a href="http://websec.github.io/unicode-security-guide/character-transformations/"&gt;Unicode Security Guide: Character Transformations&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/176.html"&gt;CWE-176: Improper Handling of Unicode Encoding&lt;/a&gt;&lt;br/&gt;
&lt;a href="http://unicode.org/reports/tr36/"&gt;Unicode: Unicode Security Considerations&lt;/a&gt;&lt;br/&gt;
&lt;/p&gt;

            
        </Details></BugPattern><BugPattern abbrev='SECFSM' category='SECURITY' type='FORMAT_STRING_MANIPULATION'><ShortDescription>Format String Manipulation</ShortDescription><Details>
            
&lt;p&gt;
Allowing user input to control format parameters could enable an attacker to cause exceptions to be thrown or leak information.&lt;br/&gt;
Attackers may be able to modify the format string argument, such that an exception is thrown. If this exception is left uncaught, it may crash the application. Alternatively, if sensitive information is used within the unused arguments, attackers may change the format string to reveal this information.&lt;br/&gt;
The example code below lets the user specify the decimal points to which it shows the balance. The user can in fact specify anything causing an exception to be thrown which could lead to application failure. Even more critical within this example, if an attacker can specify the user input &lt;code&gt;"2f %3$s %4$.2"&lt;/code&gt;, the format string would be &lt;code&gt;"The customer: %s %s has the balance %4$.2f %3$s %4$.2"&lt;/code&gt;. This would then lead to the sensitive &lt;code&gt;accountNo&lt;/code&gt; to be included within the resulting string.
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;Formatter formatter = new Formatter(Locale.US);
String format = "The customer: %s %s has the balance %4$." + userInput + "f";
formatter.format(format, firstName, lastName, accountNo, balance);&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Solution:&lt;/b&gt;&lt;br/&gt;
Avoid using user controlled values in the format string argument.
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/134.html"&gt;CWE-134: Use of Externally-Controlled Format String&lt;/a&gt;&lt;br/&gt;
&lt;/p&gt;
            
        </Details></BugPattern><BugPattern cweid='78' abbrev='SECCI' category='SECURITY' type='COMMAND_INJECTION'><ShortDescription>Potential Command Injection</ShortDescription><Details>
            
&lt;p&gt;The highlighted API is used to execute a system command. If unfiltered input is passed to this API, it can lead to arbitrary command execution.&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;import java.lang.Runtime;

Runtime r = Runtime.getRuntime();
r.exec("/bin/sh -c some_tool" + input);&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Command_Injection"&gt;OWASP: Command Injection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2013-A1-Injection"&gt;OWASP: Top 10 2013-A1-Injection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/78.html"&gt;CWE-78: Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern abbrev='SECSP' category='SECURITY' type='SERVLET_PARAMETER'><ShortDescription>Untrusted servlet parameter</ShortDescription><Details>
            
&lt;p&gt;The Servlet can read GET and POST parameters from various methods. The value obtained should be considered unsafe.
You may need to validate or sanitize those values before passing them to sensitive APIs such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SQL query (May leads to SQL injection)&lt;/li&gt;
&lt;li&gt;File opening (May leads to path traversal)&lt;/li&gt;
&lt;li&gt;Command execution (Potential Command injection)&lt;/li&gt;
&lt;li&gt;HTML construction (Potential XSS)&lt;/li&gt;
&lt;li&gt;etc...&lt;/li&gt;
&lt;/ul&gt;

&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;Reference&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/20.html"&gt;CWE-20: Improper Input Validation&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='78' abbrev='SECSCI' category='SECURITY' type='SCALA_COMMAND_INJECTION'><ShortDescription>Potential Command Injection (Scala)</ShortDescription><Details>
            
&lt;p&gt;The highlighted API is used to execute a system command. If unfiltered input is passed to this API, it can lead to arbitrary command execution.&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;def executeCommand(value:String) = Action {
    val result = value.!
    Ok("Result:\n"+result)
}&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Command_Injection"&gt;OWASP: Command Injection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2013-A1-Injection"&gt;OWASP: Top 10 2013-A1-Injection&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/78.html"&gt;CWE-78: Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern cweid='502' abbrev='SECDESGAD' category='SECURITY' type='DESERIALIZATION_GADGET'><ShortDescription>This class could be used as deserialization gadget</ShortDescription><Details>
            
&lt;p&gt;
Deserialization gadget are class that could be used by an attacker to take advantage of a remote API using Native Serialization.
This class is either adding custom behavior to deserialization with the &lt;code&gt;readObject&lt;/code&gt; method (Serializable) or can be called
 from a serialized object (InvocationHandler).
&lt;/p&gt;
&lt;p&gt;
This detector is intended to be used mostly by researcher. The real issue is using deserialization for remote operation.
Removing gadget is a hardening practice to reduce the risk of being exploited.
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://cwe.mitre.org/data/definitions/502.html"&gt;CWE-502: Deserialization of Untrusted Data&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Deserialization_of_untrusted_data"&gt;Deserialization of untrusted data&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.oracle.com/technetwork/java/seccodeguide-139067.html#8"&gt;Serialization and Deserialization &lt;/a&gt;&lt;br/&gt;
&lt;a href="https://github.com/frohoff/ysoserial"&gt;A tool for generating payloads that exploit unsafe Java object deserialization&lt;/a&gt;&lt;br/&gt;
[1] &lt;a href="https://gist.github.com/coekie/a27cc406fc9f3dc7a70d"&gt;Example of Denial of Service using the class &lt;code&gt;java.util.HashSet&lt;/code&gt;&lt;/a&gt;&lt;br/&gt;
[2] &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2015-2590"&gt;OpenJDK: Deserialization issue in ObjectInputStream.readSerialData() (CVE-2015-2590)&lt;/a&gt;&lt;br/&gt;
[3] &lt;a href="https://www.rapid7.com/db/modules/exploit/multi/browser/java_calendar_deserialize"&gt;Rapid7: Sun Java Calendar Deserialization Privilege Escalation (CVE-2008-5353)&lt;/a&gt;
&lt;/p&gt;

        </Details></BugPattern><BugPattern abbrev='SECURLR' category='SECURITY' type='URL_REWRITING'><ShortDescription>URL rewriting method</ShortDescription><Details>
            
&lt;p&gt;
The implementation of this method includes the logic to determine whether the session ID needs to be encoded in the URL.&lt;br/&gt;
URL rewriting has significant security risks. Since session ID appears in the URL, it may be easily seen by third parties. Session ID in the URL can be disclosed in many ways, for example:&lt;br/&gt;
&lt;ul&gt;
    &lt;li&gt;Log files,&lt;/li&gt;
    &lt;li&gt;The browser history,&lt;/li&gt;
    &lt;li&gt;By copy-and-pasting it into an e-mail or posting,&lt;/li&gt;
    &lt;li&gt;The HTTP Referrer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Vulnerable Code:&lt;/b&gt;&lt;br/&gt;
&lt;pre&gt;out.println("Click &amp;lt;a href=" +
                res.encodeURL(HttpUtils.getRequestURL(req).toString()) +
                "&amp;gt;here&amp;lt;/a&amp;gt;");&lt;/pre&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;b&gt;Solution:&lt;/b&gt;&lt;br/&gt;
Avoid using those methods. If you are looking to encode a URL String or form parameters do not confuse the URL rewriting methods with the URLEncoder class.
&lt;/p&gt;
&lt;br/&gt;
&lt;p&gt;
&lt;b&gt;References&lt;/b&gt;&lt;br/&gt;
&lt;a href="https://www.owasp.org/index.php/Top_10_2010-A3-Broken_Authentication_and_Session_Management"&gt;OWASP Top 10 2010-A3-Broken Authentication and Session Management&lt;/a&gt;&lt;br/&gt;
&lt;/p&gt;
            
        </Details></BugPattern><BugCode abbrev='SECPR'><Description>Predictable Pseudo Random Generator</Description></BugCode><BugCode abbrev='SECFSM'><Description>Format String Manipulation</Description></BugCode><BugCode abbrev='SECSSSRFUC'><Description>URLConnection Server-Side Request Forgery</Description></BugCode><BugCode abbrev='SECSQLIJDBC'><Description>SQL Injection (JDBC)</Description></BugCode><BugCode abbrev='SECPRS'><Description>Predictable Pseudo Random Generator (Scala)</Description></BugCode><BugCode abbrev='ERRMSG'><Description>Information Exposure Through An Error Message</Description></BugCode><BugCode abbrev='SECSSL'><Description>SSLContext</Description></BugCode><BugCode abbrev='STAIV'><Description>Static IV</Description></BugCode><BugCode abbrev='SECXSS2'><Description>Potential XSS in Servlet</Description></BugCode><BugCode abbrev='SECWHV'><Description>Weak HostVerifier Implementation</Description></BugCode><BugCode abbrev='SECCI'><Description>Command Injection</Description></BugCode><BugCode abbrev='SECCRLFLOG'><Description>CRLF Injection for logs</Description></BugCode><BugCode abbrev='SECSCI'><Description>Command Injection (Scala)</Description></BugCode><BugCode abbrev='SECUSS'><Description>Unencrypted Server Socket</Description></BugCode><BugCode abbrev='SECSSQ'><Description>Query String</Description></BugCode><BugCode abbrev='SECURLR'><Description>URL Rewriting Methods</Description></BugCode><BugCode abbrev='SQL'><Description>Potential SQL Problem</Description></BugCode><BugCode abbrev='SECWTM'><Description>Weak TrustManager Implementation</Description></BugCode><BugCode abbrev='SECUNI'><Description>Improper handling of Unicode transformations</Description></BugCode><BugCode abbrev='SECOBDES'><Description>Object deserialization is used</Description></BugCode><BugCode abbrev='SECPTO'><Description>Potential Path Traversal (File Write)</Description></BugCode><BugCode abbrev='SECJRS'><Description>JAX-RS REST Endpoint</Description></BugCode><BugCode abbrev='SECSH'><Description>HTTP Headers Untrusted</Description></BugCode><BugCode abbrev='SECDESGAD'><Description>Deserialization gadget</Description></BugCode><BugCode abbrev='SECHRS'><Description>HTTP Response Splitting</Description></BugCode><BugCode abbrev='SECPTI'><Description>Potential Path Traversal (file read)</Description></BugCode><BugCode abbrev='SECUR'><Description>Unvalidated Redirect</Description></BugCode><BugCode abbrev='SECSP'><Description>Servlet Parameter</Description></BugCode><BugCode abbrev='SECUS'><Description>Unencrypted Socket</Description></BugCode><Errors missingClasses='4' errors='0'><MissingClass>apply</MissingClass><MissingClass>compare</MissingClass><MissingClass>get</MissingClass><MissingClass>onTaskCompletion</MissingClass></Errors><FindBugsSummary num_packages='58' total_classes='7216' priority_1='14' priority_2='171' priority_3='124' total_size='116539' clock_seconds='101.34' referenced_classes='9125' vm_version='25.312-b07' total_bugs='309' java_version='1.8.0_312' gc_seconds='1.62' alloc_mbytes='7282.00' cpu_seconds='379.03' peak_mbytes='3349.49' timestamp='Fri, 15 Apr 2022 09:55:03 -0300'><FileStats path='org/apache/spark/Accumulable.scala' size='86' bugCount='0'></FileStats><FileStats path='org/apache/spark/Accumulator.scala' size='97' bugCount='0'></FileStats><FileStats path='org/apache/spark/Aggregator.scala' size='62' bugCount='0'></FileStats><FileStats path='org/apache/spark/ContextCleaner.scala' size='498' bugCount='0'></FileStats><FileStats path='org/apache/spark/Dependency.scala' size='101' bugCount='0'></FileStats><FileStats path='org/apache/spark/ExecutorAllocationClient.scala' size='20' bugCount='0'></FileStats><FileStats path='org/apache/spark/ExecutorAllocationManager.scala' size='888' bugCount='0'></FileStats><FileStats path='org/apache/spark/FutureAction.scala' size='288' bugCount='0'></FileStats><FileStats path='org/apache/spark/HeartbeatReceiver.scala' size='434' bugCount='0'></FileStats><FileStats path='org/apache/spark/InternalAccumulator.scala' size='147' bugCount='0'></FileStats><FileStats path='org/apache/spark/InterruptibleIterator.scala' size='106' bugCount='0'></FileStats><FileStats path='org/apache/spark/JobExecutionStatus.java' size='17' bugCount='0'></FileStats><FileStats path='org/apache/spark/MapOutputStatistics.scala' size='7' bugCount='0'></FileStats><FileStats path='org/apache/spark/MapOutputTracker.scala' size='1003' bugHash='423623a1721697d7f2e8e2ffce1d5b98' bugCount='1'></FileStats><FileStats path='org/apache/spark/Partition.scala' size='12' bugCount='0'></FileStats><FileStats path='org/apache/spark/Partitioner.scala' size='365' bugHash='9df62136fe93f4a3fe8e146046bc6019' bugCount='2'></FileStats><FileStats path='org/apache/spark/SSLOptions.scala' size='543' bugHash='3f34a29cd6889debc330fce4a7840cb3' bugCount='2'></FileStats><FileStats path='org/apache/spark/SecurityManager.scala' size='450' bugHash='8d0539436e0e2865d093aff75d585086' bugCount='4'></FileStats><FileStats path='org/apache/spark/SerializableWritable.scala' size='39' bugCount='0'></FileStats><FileStats path='org/apache/spark/SparkConf.scala' size='891' bugCount='0'></FileStats><FileStats path='org/apache/spark/SparkContext.scala' size='2812' bugHash='5610dd839fa75583d84c3cfd69639d6b' bugCount='7'></FileStats><FileStats path='org/apache/spark/SparkEnv.scala' size='464' bugHash='e4a870f826b3122ebb7f56f1125c37d2' bugCount='1'></FileStats><FileStats path='org/apache/spark/SparkException.scala' size='37' bugCount='0'></FileStats><FileStats path='org/apache/spark/SparkExecutorInfo.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/spark/SparkFiles.scala' size='19' bugHash='2843956283da7416249d08a890aa49d9' bugCount='1'></FileStats><FileStats path='org/apache/spark/SparkFirehoseListener.java' size='80' bugCount='0'></FileStats><FileStats path='org/apache/spark/SparkJobInfo.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/spark/SparkStageInfo.java' size='9' bugCount='0'></FileStats><FileStats path='org/apache/spark/SparkStatusTracker.scala' size='127' bugCount='0'></FileStats><FileStats path='org/apache/spark/StatusAPIImpl.scala' size='54' bugCount='0'></FileStats><FileStats path='org/apache/spark/TaskContext.scala' size='62' bugCount='0'></FileStats><FileStats path='org/apache/spark/TaskContextImpl.scala' size='175' bugCount='0'></FileStats><FileStats path='org/apache/spark/TaskEndReason.scala' size='454' bugCount='0'></FileStats><FileStats path='org/apache/spark/TaskKilledException.scala' size='7' bugCount='0'></FileStats><FileStats path='org/apache/spark/TaskNotSerializableException.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/TaskState.scala' size='48' bugCount='0'></FileStats><FileStats path='org/apache/spark/TestUtils.scala' size='340' bugHash='f5a80e38f8ad2199a5adb40398a88159' bugCount='11'></FileStats><FileStats path='org/apache/spark/api/java/JavaDoubleRDD.scala' size='131' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaFutureAction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaHadoopRDD.scala' size='18' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaNewHadoopRDD.scala' size='18' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaPairRDD.scala' size='433' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaRDD.scala' size='93' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaRDDLike.scala' size='553' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaSparkContext.scala' size='255' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaSparkContextVarargsWorkaround.java' size='27' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaSparkStatusTracker.scala' size='15' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/JavaUtils.scala' size='92' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/Optional.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/StorageLevels.java' size='30' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/CoGroupFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/DoubleFlatMapFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/DoubleFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/FilterFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/FlatMapFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/FlatMapFunction2.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/FlatMapGroupsFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/ForeachFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/ForeachPartitionFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/Function.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/Function0.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/Function2.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/Function3.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/Function4.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/MapFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/MapGroupsFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/MapPartitionsFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/PairFlatMapFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/PairFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/ReduceFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/VoidFunction.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/VoidFunction2.java' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/function/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/java/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/python/PythonGatewayServer.scala' size='110' bugHash='93939eda53f5e9b647e954a17eeea8c6' bugCount='1'></FileStats><FileStats path='org/apache/spark/api/python/PythonHadoopUtil.scala' size='204' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/python/PythonPartitioner.scala' size='21' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/python/PythonRDD.scala' size='619' bugHash='0823fbbe88f5b263b0ef7b880f23431b' bugCount='7'></FileStats><FileStats path='org/apache/spark/api/python/PythonRunner.scala' size='655' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/python/PythonUtils.scala' size='50' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/python/PythonWorkerFactory.scala' size='340' bugHash='2b73321e99f4fbb1cdd8d6f5b4f2fe0b' bugCount='4'></FileStats><FileStats path='org/apache/spark/api/python/SerDeUtil.scala' size='425' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/python/WriteInputFormatTestDataGenerator.scala' size='248' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/r/JVMObjectTracker.scala' size='65' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/r/RBackend.scala' size='151' bugHash='ab021f11a09738171d027246efc4d912' bugCount='3'></FileStats><FileStats path='org/apache/spark/api/r/RBackendHandler.scala' size='288' bugHash='a032394dcda48990af6dfea4b08ad05e' bugCount='3'></FileStats><FileStats path='org/apache/spark/api/r/RRDD.scala' size='141' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/r/RRunner.scala' size='542' bugHash='d2fe8511e996136aa967e2f544b847d0' bugCount='3'></FileStats><FileStats path='org/apache/spark/api/r/RUtils.scala' size='77' bugHash='3790765a7e3968b959b98313843b8686' bugCount='1'></FileStats><FileStats path='org/apache/spark/api/r/SerDe.scala' size='521' bugCount='0'></FileStats><FileStats path='org/apache/spark/api/r/SparkRDefaults.scala' size='20' bugCount='0'></FileStats><FileStats path='org/apache/spark/broadcast/Broadcast.scala' size='66' bugCount='0'></FileStats><FileStats path='org/apache/spark/broadcast/BroadcastFactory.scala' size='5' bugCount='0'></FileStats><FileStats path='org/apache/spark/broadcast/BroadcastManager.scala' size='57' bugCount='0'></FileStats><FileStats path='org/apache/spark/broadcast/TorrentBroadcast.scala' size='360' bugCount='0'></FileStats><FileStats path='org/apache/spark/broadcast/TorrentBroadcastFactory.scala' size='11' bugCount='0'></FileStats><FileStats path='org/apache/spark/broadcast/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/ApplicationDescription.scala' size='92' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/Client.scala' size='354' bugHash='579c40d78af14a700eca13e3742e84f4' bugCount='2'></FileStats><FileStats path='org/apache/spark/deploy/ClientArguments.scala' size='110' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/Command.scala' size='50' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/DependencyUtils.scala' size='187' bugHash='2b6e0be7616960f547073debdcfa3dc7' bugCount='2'></FileStats><FileStats path='org/apache/spark/deploy/DeployMessage.scala' size='1213' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/DriverDescription.scala' size='47' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/ExecutorDescription.scala' size='17' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/ExecutorState.scala' size='41' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/ExternalShuffleService.scala' size='163' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/ExternalShuffleServiceSource.scala' size='11' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/FaultToleranceTest.scala' size='848' bugHash='b3307c249bc295381d25d260cf389fc8' bugCount='5'></FileStats><FileStats path='org/apache/spark/deploy/JsonProtocol.scala' size='524' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/LocalSparkCluster.scala' size='113' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/PythonRunner.scala' size='168' bugHash='25bca9e8225e52d7db028b9dd134197a' bugCount='2'></FileStats><FileStats path='org/apache/spark/deploy/RPackageUtils.scala' size='284' bugHash='c38e9a6f4d3898769ba097f6b861692a' bugCount='6'></FileStats><FileStats path='org/apache/spark/deploy/RRunner.scala' size='97' bugHash='0073d04019f85a470a3d7eeb4084b27a' bugCount='2'></FileStats><FileStats path='org/apache/spark/deploy/SparkApplication.scala' size='20' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/SparkCuratorUtil.scala' size='101' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/SparkHadoopUtil.scala' size='513' bugHash='677fc950f367706dd07c14d9d01cb05f' bugCount='1'></FileStats><FileStats path='org/apache/spark/deploy/SparkSubmit.scala' size='1328' bugHash='b4eb70981d93089adf52995580e2f7fa' bugCount='9'></FileStats><FileStats path='org/apache/spark/deploy/SparkSubmitArguments.scala' size='829' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/client/StandaloneAppClient.scala' size='434' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/client/StandaloneAppClientListener.scala' size='7' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/history/ApplicationCache.scala' size='410' bugHash='e1760e0c55b3d2c9ea76bbba099cc946' bugCount='3'></FileStats><FileStats path='org/apache/spark/deploy/history/ApplicationHistoryProvider.scala' size='61' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/history/FsHistoryProvider.scala' size='1409' bugHash='229ee4d87be285ad1d2064aa048f817c' bugCount='1'></FileStats><FileStats path='org/apache/spark/deploy/history/HistoryPage.scala' size='78' bugHash='b8e1b9fe062386fba94ff36c9b7d9d61' bugCount='1'></FileStats><FileStats path='org/apache/spark/deploy/history/HistoryServer.scala' size='264' bugHash='d8fb596c7b1d64e2c0373c837e0bcb7a' bugCount='5'></FileStats><FileStats path='org/apache/spark/deploy/history/HistoryServerArguments.scala' size='58' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/history/HistoryServerDiskManager.scala' size='377' bugHash='94c0511f57f063a147c426e908bc0206' bugCount='3'></FileStats><FileStats path='org/apache/spark/deploy/history/config.scala' size='46' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/ApplicationInfo.scala' size='140' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/ApplicationSource.scala' size='36' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/ApplicationState.scala' size='37' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/DriverInfo.scala' size='45' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/DriverState.scala' size='45' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/ExecutorDesc.scala' size='38' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/FileSystemPersistenceEngine.scala' size='103' bugHash='bf20871bcf97973b805ffc79e99dc0a6' bugCount='4'></FileStats><FileStats path='org/apache/spark/deploy/master/LeaderElectionAgent.scala' size='19' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/Master.scala' size='1745' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/MasterArguments.scala' size='84' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/MasterMessages.scala' size='132' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/MasterSource.scala' size='55' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/PersistenceEngine.scala' size='39' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/RecoveryModeFactory.scala' size='54' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/RecoveryState.scala' size='30' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/WorkerInfo.scala' size='108' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/WorkerState.scala' size='30' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/ZooKeeperLeaderElectionAgent.scala' size='98' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/ZooKeeperPersistenceEngine.scala' size='76' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/master/ui/ApplicationPage.scala' size='157' bugHash='fc7a59c8d09f9ad867eef934b8c516dd' bugCount='1'></FileStats><FileStats path='org/apache/spark/deploy/master/ui/MasterPage.scala' size='379' bugHash='d99bc754876b9fee4262211dab63b1dc' bugCount='2'></FileStats><FileStats path='org/apache/spark/deploy/master/ui/MasterWebUI.scala' size='93' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/rest/RestSubmissionClient.scala' size='534' bugHash='46d52d1c306be2249e9f8060c0b0b796' bugCount='3'></FileStats><FileStats path='org/apache/spark/deploy/rest/RestSubmissionServer.scala' size='292' bugHash='bc5ab6152f292b638cd194735c68902a' bugCount='1'></FileStats><FileStats path='org/apache/spark/deploy/rest/StandaloneRestServer.scala' size='202' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/rest/SubmitRestProtocolException.scala' size='17' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/rest/SubmitRestProtocolMessage.scala' size='85' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/rest/SubmitRestProtocolRequest.scala' size='106' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/rest/SubmitRestProtocolResponse.scala' size='72' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/security/HBaseDelegationTokenProvider.scala' size='76' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/security/HadoopDelegationTokenManager.scala' size='203' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/security/HadoopDelegationTokenProvider.scala' size='4' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/security/HadoopFSDelegationTokenProvider.scala' size='166' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/security/HiveDelegationTokenProvider.scala' size='174' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/worker/CommandUtils.scala' size='139' bugHash='dd20d5a721f51cb155e49252a5b90fa8' bugCount='1'></FileStats><FileStats path='org/apache/spark/deploy/worker/DriverRunner.scala' size='293' bugHash='04990f01e500f00208738a74c3c1f1a0' bugCount='2'></FileStats><FileStats path='org/apache/spark/deploy/worker/DriverWrapper.scala' size='121' bugHash='e7bb63ed69df51aa2eaa91c5327b7a5d' bugCount='1'></FileStats><FileStats path='org/apache/spark/deploy/worker/ExecutorRunner.scala' size='233' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/worker/Worker.scala' size='1430' bugHash='2e7373f46dd81fb33e62adb5c71bb763' bugCount='6'></FileStats><FileStats path='org/apache/spark/deploy/worker/WorkerArguments.scala' size='115' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/worker/WorkerSource.scala' size='51' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/worker/WorkerWatcher.scala' size='120' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/worker/ui/LogPage.scala' size='217' bugHash='3b7381f640309af84342bf569d059637' bugCount='15'></FileStats><FileStats path='org/apache/spark/deploy/worker/ui/WorkerPage.scala' size='202' bugCount='0'></FileStats><FileStats path='org/apache/spark/deploy/worker/ui/WorkerWebUI.scala' size='47' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/CoarseGrainedExecutorBackend.scala' size='403' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/CommitDeniedException.scala' size='11' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/Executor.scala' size='910' bugHash='df4ef41f6c0f39a53b2ad4e10f47d9be' bugCount='4'></FileStats><FileStats path='org/apache/spark/executor/ExecutorBackend.scala' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/ExecutorExitCode.scala' size='42' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/ExecutorSource.scala' size='204' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/InputMetrics.scala' size='49' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/OutputMetrics.scala' size='36' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/ShuffleReadMetrics.scala' size='138' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/ShuffleWriteMetrics.scala' size='34' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/TaskMetrics.scala' size='298' bugCount='0'></FileStats><FileStats path='org/apache/spark/executor/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/input/FixedLengthBinaryInputFormat.scala' size='61' bugCount='0'></FileStats><FileStats path='org/apache/spark/input/FixedLengthBinaryRecordReader.scala' size='73' bugCount='0'></FileStats><FileStats path='org/apache/spark/input/PortableDataStream.scala' size='136' bugCount='0'></FileStats><FileStats path='org/apache/spark/input/WholeTextFileInputFormat.scala' size='28' bugCount='0'></FileStats><FileStats path='org/apache/spark/input/WholeTextFileRecordReader.scala' size='74' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/Logging.scala' size='132' bugHash='6a723d7fba43d57c548ba0a8d84dab69' bugCount='10'></FileStats><FileStats path='org/apache/spark/internal/config/ConfigBuilder.scala' size='367' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/config/ConfigEntry.scala' size='168' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/config/ConfigProvider.scala' size='34' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/config/ConfigReader.scala' size='112' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/config/package.scala' size='610' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/io/FileCommitProtocol.scala' size='42' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/io/HadoopMapRedCommitProtocol.scala' size='8' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.scala' size='269' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/io/HadoopWriteConfigUtil.scala' size='11' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/io/SparkHadoopWriter.scala' size='384' bugCount='0'></FileStats><FileStats path='org/apache/spark/internal/io/SparkHadoopWriterUtils.scala' size='49' bugCount='0'></FileStats><FileStats path='org/apache/spark/io/CompressionCodec.scala' size='160' bugCount='0'></FileStats><FileStats path='org/apache/spark/io/NioBufferedFileInputStream.java' size='63' bugCount='0'></FileStats><FileStats path='org/apache/spark/io/ReadAheadInputStream.java' size='233' bugHash='ffefa4374d077ada29db3a847bee510a' bugCount='1'></FileStats><FileStats path='org/apache/spark/io/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/launcher/LauncherBackend.scala' size='112' bugHash='5d362df683e44e339798218dc8f29cfc' bugCount='1'></FileStats><FileStats path='org/apache/spark/launcher/SparkSubmitArgumentsParser.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/launcher/WorkerCommandBuilder.scala' size='22' bugCount='0'></FileStats><FileStats path='org/apache/spark/mapred/SparkHadoopMapRedUtil.scala' size='113' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/ExecutionMemoryPool.scala' size='132' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/MemoryConsumer.java' size='57' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/MemoryManager.scala' size='118' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/MemoryMode.java' size='12' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/MemoryPool.scala' size='24' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/SparkOutOfMemoryError.java' size='7' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/StaticMemoryManager.scala' size='94' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/StorageMemoryPool.scala' size='88' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/TaskMemoryManager.java' size='206' bugHash='f8717ea19db4096f2322063581dc0019' bugCount='11'></FileStats><FileStats path='org/apache/spark/memory/TooLargePageException.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/UnifiedMemoryManager.scala' size='138' bugCount='0'></FileStats><FileStats path='org/apache/spark/memory/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/MetricsConfig.scala' size='166' bugHash='e3f7e7f57b01a0cf9a1b3d1444feb751' bugCount='1'></FileStats><FileStats path='org/apache/spark/metrics/MetricsSystem.scala' size='272' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/ConsoleSink.scala' size='43' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/CsvSink.scala' size='55' bugHash='e5f1bf7cc79071776af7439a3638525a' bugCount='1'></FileStats><FileStats path='org/apache/spark/metrics/sink/GraphiteSink.scala' size='93' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/JmxSink.scala' size='17' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/MetricsServlet.scala' size='64' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/Sink.scala' size='4' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/Slf4jSink.scala' size='44' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/StatsdReporter.scala' size='318' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/StatsdSink.scala' size='115' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/sink/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/source/JvmSource.scala' size='13' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/source/Source.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/source/StaticSources.scala' size='112' bugCount='0'></FileStats><FileStats path='org/apache/spark/metrics/source/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/network/BlockDataManager.scala' size='4' bugCount='0'></FileStats><FileStats path='org/apache/spark/network/BlockTransferService.scala' size='52' bugCount='0'></FileStats><FileStats path='org/apache/spark/network/netty/NettyBlockRpcServer.scala' size='79' bugCount='0'></FileStats><FileStats path='org/apache/spark/network/netty/NettyBlockTransferService.scala' size='168' bugCount='0'></FileStats><FileStats path='org/apache/spark/network/netty/SparkTransportConf.scala' size='34' bugCount='0'></FileStats><FileStats path='org/apache/spark/package.scala' size='82' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/ApproximateActionListener.scala' size='54' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/ApproximateEvaluator.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/BoundedDouble.scala' size='24' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/CountEvaluator.scala' size='37' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/GroupedCountEvaluator.scala' size='63' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/MeanEvaluator.scala' size='34' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/PartialResult.scala' size='97' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/SumEvaluator.scala' size='44' bugCount='0'></FileStats><FileStats path='org/apache/spark/partial/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/AsyncRDDActions.scala' size='275' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/BinaryFileRDD.scala' size='36' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/BlockRDD.scala' size='69' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/CartesianRDD.scala' size='122' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/CheckpointRDD.scala' size='23' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/CoGroupedRDD.scala' size='250' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/CoalescedRDD.scala' size='499' bugHash='fdece2857d16c7664dabb6205b5207d2' bugCount='1'></FileStats><FileStats path='org/apache/spark/rdd/DoubleRDDFunctions.scala' size='324' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/EmptyRDD.scala' size='7' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/HadoopRDD.scala' size='449' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/InputFileBlockHolder.scala' size='68' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/JdbcRDD.scala' size='192' bugHash='e17771c7395083fdd1d8173659595377' bugCount='2'></FileStats><FileStats path='org/apache/spark/rdd/LocalCheckpointRDD.scala' size='23' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/LocalRDDCheckpointData.scala' size='76' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/MapPartitionsRDD.scala' size='30' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/NewHadoopRDD.scala' size='420' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/OrderedRDDFunctions.scala' size='95' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/PairRDDFunctions.scala' size='1507' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/ParallelCollectionRDD.scala' size='188' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/PartitionPruningRDD.scala' size='58' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/PartitionerAwareUnionRDD.scala' size='184' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/PartitionwiseSampledRDD.scala' size='53' bugHash='333995e37bb060b81e5260ab086f5920' bugCount='1'></FileStats><FileStats path='org/apache/spark/rdd/PipedRDD.scala' size='334' bugHash='290e04a50fe0182567aa5054dd2085f6' bugCount='5'></FileStats><FileStats path='org/apache/spark/rdd/RDD.scala' size='2482' bugHash='ada6b6d89fcf811cc308870c9580d741' bugCount='2'></FileStats><FileStats path='org/apache/spark/rdd/RDDCheckpointData.scala' size='78' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/RDDOperationScope.scala' size='162' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/ReliableCheckpointRDD.scala' size='394' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/ReliableRDDCheckpointData.scala' size='118' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/SequenceFileRDDFunctions.scala' size='94' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/ShuffledRDD.scala' size='89' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/SubtractedRDD.scala' size='129' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/UnionRDD.scala' size='129' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/WholeTextFileRDD.scala' size='33' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/ZippedPartitionsRDD.scala' size='242' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/ZippedWithIndexRDD.scala' size='59' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/coalesce-public.scala' size='20' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/rdd/util/PeriodicRDDCheckpointer.scala' size='26' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcAddress.scala' size='43' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcCallContext.scala' size='4' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcEndpoint.scala' size='65' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcEndpointAddress.scala' size='64' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcEndpointNotFoundException.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcEndpointRef.scala' size='40' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcEnv.scala' size='113' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcEnvStoppedException.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/RpcTimeout.scala' size='72' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/netty/Dispatcher.scala' size='222' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/netty/Inbox.scala' size='393' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/netty/NettyRpcCallContext.scala' size='47' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/netty/NettyRpcEnv.scala' size='752' bugHash='fd34d2439e9e1f985a84708f68741cd3' bugCount='1'></FileStats><FileStats path='org/apache/spark/rpc/netty/NettyStreamManager.scala' size='77' bugHash='b7d3d44402d91a59fdfc24e50eb2c131' bugCount='1'></FileStats><FileStats path='org/apache/spark/rpc/netty/Outbox.scala' size='270' bugCount='0'></FileStats><FileStats path='org/apache/spark/rpc/netty/RpcEndpointVerifier.scala' size='61' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/AccumulableInfo.scala' size='72' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/ActiveJob.scala' size='37' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/AsyncEventQueue.scala' size='207' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/BlacklistTracker.scala' size='584' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/DAGScheduler.scala' size='1906' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/DAGSchedulerEvent.scala' size='538' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/DAGSchedulerSource.scala' size='56' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/EventLoggingListener.scala' size='380' bugHash='4ce0e47ee26c0305806ca9a513067023' bugCount='1'></FileStats><FileStats path='org/apache/spark/scheduler/ExecutorFailuresInTaskSet.scala' size='33' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/ExecutorLossReason.scala' size='104' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/ExternalClusterManager.scala' size='5' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/InputFormatInfo.scala' size='183' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/JobListener.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/JobResult.scala' size='56' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/JobWaiter.scala' size='60' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/LiveListenerBus.scala' size='261' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/MapStatus.scala' size='211' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/OutputCommitCoordinator.scala' size='389' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/Pool.scala' size='149' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/ReplayListenerBus.scala' size='150' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/ResultStage.scala' size='30' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/ResultTask.scala' size='47' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/Schedulable.scala' size='17' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/SchedulableBuilder.scala' size='322' bugHash='f1326b93f95a2ede5022108cba304a70' bugCount='1'></FileStats><FileStats path='org/apache/spark/scheduler/SchedulerBackend.scala' size='25' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/SchedulingAlgorithm.scala' size='43' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/SchedulingMode.scala' size='26' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/ShuffleMapStage.scala' size='43' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/ShuffleMapTask.scala' size='92' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/SparkListener.scala' size='1053' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/SparkListenerBus.scala' size='56' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/SplitInfo.scala' size='78' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/Stage.scala' size='83' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/StageInfo.scala' size='110' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/StatsReportListener.scala' size='401' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/Task.scala' size='166' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskDescription.scala' size='127' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskInfo.scala' size='87' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskLocality.scala' size='38' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskLocation.scala' size='128' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskResult.scala' size='114' bugHash='987b91301be652f77ccab2faf720e1fc' bugCount='1'></FileStats><FileStats path='org/apache/spark/scheduler/TaskResultGetter.scala' size='182' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskScheduler.scala' size='25' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskSchedulerImpl.scala' size='976' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskSet.scala' size='23' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskSetBlacklist.scala' size='179' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/TaskSetManager.scala' size='1370' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/WorkerOffer.scala' size='35' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/cluster/CoarseGrainedClusterMessage.scala' size='597' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend.scala' size='824' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/cluster/ExecutorData.scala' size='19' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/cluster/ExecutorInfo.scala' size='38' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/cluster/SchedulerBackendUtils.scala' size='43' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/cluster/StandaloneSchedulerBackend.scala' size='296' bugCount='0'></FileStats><FileStats path='org/apache/spark/scheduler/local/LocalSchedulerBackend.scala' size='324' bugHash='a2d03fa370272fa38747e8be3e02f264' bugCount='1'></FileStats><FileStats path='org/apache/spark/scheduler/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/security/CryptoStreamUtils.scala' size='152' bugHash='3d5ef96549fcf93d77c8ede93b47353e' bugCount='4'></FileStats><FileStats path='org/apache/spark/security/GroupMappingServiceProvider.scala' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/security/ShellBasedGroupsMappingProvider.scala' size='37' bugCount='0'></FileStats><FileStats path='org/apache/spark/serializer/DummySerializerInstance.java' size='35' bugCount='0'></FileStats><FileStats path='org/apache/spark/serializer/GenericAvroSerializer.scala' size='167' bugCount='0'></FileStats><FileStats path='org/apache/spark/serializer/JavaSerializer.scala' size='149' bugHash='987298f2f9ed23dbfb4f7bb6e94355a7' bugCount='1'></FileStats><FileStats path='org/apache/spark/serializer/KryoSerializer.scala' size='534' bugCount='0'></FileStats><FileStats path='org/apache/spark/serializer/SerializationDebugger.scala' size='353' bugCount='0'></FileStats><FileStats path='org/apache/spark/serializer/Serializer.scala' size='73' bugCount='0'></FileStats><FileStats path='org/apache/spark/serializer/SerializerManager.scala' size='143' bugCount='0'></FileStats><FileStats path='org/apache/spark/serializer/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/BaseShuffleHandle.scala' size='9' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/BlockStoreShuffleReader.scala' size='138' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/FetchFailedException.scala' size='36' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/IndexShuffleBlockResolver.scala' size='188' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/ShuffleBlockResolver.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/ShuffleHandle.scala' size='5' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/ShuffleManager.scala' size='7' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/ShuffleReader.scala' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/ShuffleWriter.scala' size='5' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java' size='115' bugHash='066a74ecee4f002111c009b879c3217e' bugCount='2'></FileStats><FileStats path='org/apache/spark/shuffle/sort/PackedRecordPointer.java' size='29' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/sort/ShuffleExternalSorter.java' size='189' bugHash='a31e29dd1a0fea4b5b1296a64ba370c9' bugCount='2'></FileStats><FileStats path='org/apache/spark/shuffle/sort/ShuffleInMemorySorter.java' size='101' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/sort/ShuffleSortDataFormat.java' size='42' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/sort/SortShuffleManager.scala' size='151' bugHash='6f00c84ae9de9925dbdb383f47e2d74e' bugCount='4'></FileStats><FileStats path='org/apache/spark/shuffle/sort/SortShuffleWriter.scala' size='110' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/sort/SpillInfo.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/spark/shuffle/sort/UnsafeShuffleWriter.java' size='250' bugHash='cd24500291f9b4ca24da9654be26d3dc' bugCount='3'></FileStats><FileStats path='org/apache/spark/status/AppHistoryServerPlugin.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/AppStatusListener.scala' size='1381' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/AppStatusStore.scala' size='854' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/AppStatusUtils.scala' size='42' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/ElementTrackingStore.scala' size='142' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/KVUtils.scala' size='86' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/LiveEntity.scala' size='1201' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/api/v1/ApiRootResource.scala' size='160' bugHash='6ee6fcffb1bbfd5e235147b4fafb3a11' bugCount='3'></FileStats><FileStats path='org/apache/spark/status/api/v1/ApplicationListResource.scala' size='70' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/api/v1/ApplicationStatus.java' size='13' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/api/v1/JacksonMessageWriter.scala' size='34' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/api/v1/OneApplicationResource.scala' size='174' bugHash='38fffed6f95cfad24ba8a566b3295efb' bugCount='10'></FileStats><FileStats path='org/apache/spark/status/api/v1/SecurityFilter.scala' size='18' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/api/v1/SimpleDateParam.scala' size='21' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/api/v1/StageStatus.java' size='19' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/api/v1/StagesResource.scala' size='109' bugHash='21b0e5fd838c57c61a967d0a90c9418b' bugCount='4'></FileStats><FileStats path='org/apache/spark/status/api/v1/TaskSorting.java' size='24' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/api/v1/api.scala' size='817' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/config.scala' size='52' bugCount='0'></FileStats><FileStats path='org/apache/spark/status/storeTypes.scala' size='700' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockException.scala' size='31' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockId.scala' size='417' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockInfoManager.scala' size='438' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockManager.scala' size='1808' bugHash='4e00b1140960a9d77fa9b962e13558af' bugCount='1'></FileStats><FileStats path='org/apache/spark/storage/BlockManagerId.scala' size='118' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockManagerManagedBuffer.scala' size='31' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockManagerMaster.scala' size='239' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockManagerMasterEndpoint.scala' size='783' bugHash='a6b2ce03d8609449bf8ef4093c7915eb' bugCount='1'></FileStats><FileStats path='org/apache/spark/storage/BlockManagerMessages.scala' size='610' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockManagerSlaveEndpoint.scala' size='184' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockManagerSource.scala' size='204' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockNotFoundException.scala' size='3' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/BlockReplicationPolicy.scala' size='199' bugHash='6f149c2338ceb81a306027b52cff986b' bugCount='2'></FileStats><FileStats path='org/apache/spark/storage/BlockUpdatedInfo.scala' size='51' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/DiskBlockManager.scala' size='205' bugHash='48d43d1edecf01c5dd5bd4f4b56a6ef1' bugCount='2'></FileStats><FileStats path='org/apache/spark/storage/DiskBlockObjectWriter.scala' size='269' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/DiskStore.scala' size='337' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/FileSegment.scala' size='28' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/RDDInfo.scala' size='88' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/ShuffleBlockFetcherIterator.scala' size='772' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/StorageLevel.scala' size='234' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/StorageUtils.scala' size='586' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/TimeTrackingOutputStream.java' size='33' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/TopologyMapper.scala' size='92' bugCount='0'></FileStats><FileStats path='org/apache/spark/storage/memory/MemoryStore.scala' size='931' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/ConsoleProgressBar.scala' size='126' bugHash='cfbd8743f1993063d8fa9b820c212758' bugCount='1'></FileStats><FileStats path='org/apache/spark/ui/JettyUtils.scala' size='650' bugHash='6a8e2fdc3f131085ab177b8410d39733' bugCount='11'></FileStats><FileStats path='org/apache/spark/ui/PagedTable.scala' size='228' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/SparkUI.scala' size='185' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/ToolTips.scala' size='117' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/UIUtils.scala' size='639' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/UIWorkloadGenerator.scala' size='207' bugHash='e6d02e6315bd701d6d42845f47a90cc2' bugCount='1'></FileStats><FileStats path='org/apache/spark/ui/WebUI.scala' size='285' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/env/EnvironmentPage.scala' size='118' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/exec/ExecutorThreadDumpPage.scala' size='110' bugHash='9393e5e1cf13e790308286aa624db085' bugCount='1'></FileStats><FileStats path='org/apache/spark/ui/exec/ExecutorsTab.scala' size='34' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/jobs/AllJobsPage.scala' size='799' bugHash='e0d63e4563b6360c5fe01f230b90d8bb' bugCount='6'></FileStats><FileStats path='org/apache/spark/ui/jobs/AllStagesPage.scala' size='194' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/jobs/ExecutorTable.scala' size='164' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/jobs/JobPage.scala' size='416' bugHash='7ebedde0a30338ad0b64ee9cdf8ac6d5' bugCount='1'></FileStats><FileStats path='org/apache/spark/ui/jobs/JobsTab.scala' size='67' bugHash='61f190f8ebd5e6903160652222304409' bugCount='1'></FileStats><FileStats path='org/apache/spark/ui/jobs/PoolPage.scala' size='87' bugHash='2d61b2541fb9016ff3c8baedc23cd62b' bugCount='1'></FileStats><FileStats path='org/apache/spark/ui/jobs/PoolTable.scala' size='39' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/jobs/StagePage.scala' size='1287' bugHash='fddb295e62c74c455ada4486e4da149f' bugCount='7'></FileStats><FileStats path='org/apache/spark/ui/jobs/StageTable.scala' size='711' bugHash='c1842a51201dd57097b5288925112a36' bugCount='6'></FileStats><FileStats path='org/apache/spark/ui/jobs/StagesTab.scala' size='72' bugHash='fbd693c2f74cea4aa8946d3103e5df93' bugCount='1'></FileStats><FileStats path='org/apache/spark/ui/jobs/TaskDetailsClassNames.scala' size='38' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/scope/RDDOperationGraph.scala' size='440' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/storage/RDDPage.scala' size='440' bugHash='c4c2bb98b73db34b73eae5ae433ced08' bugCount='6'></FileStats><FileStats path='org/apache/spark/ui/storage/StoragePage.scala' size='222' bugCount='0'></FileStats><FileStats path='org/apache/spark/ui/storage/StorageTab.scala' size='5' bugCount='0'></FileStats><FileStats path='org/apache/spark/unsafe/map/BytesToBytesMap.java' size='479' bugHash='1412677266e32528b0a98dbeeef53c50' bugCount='2'></FileStats><FileStats path='org/apache/spark/unsafe/map/HashMapGrowthStrategy.java' size='16' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/AccumulatorV2.scala' size='359' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/Benchmark.scala' size='253' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/BoundedPriorityQueue.scala' size='166' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ByteBufferInputStream.scala' size='32' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ByteBufferOutputStream.scala' size='49' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/CausedBy.scala' size='22' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/Clock.scala' size='25' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ClosureCleaner.scala' size='633' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/CollectionsUtils.scala' size='75' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/CommandLineUtils.scala' size='31' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/CompletionIterator.scala' size='122' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/Distribution.scala' size='79' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/EnumUtil.java' size='13' bugHash='89aa25c676beebea880f5418bef5ed1f' bugCount='1'></FileStats><FileStats path='org/apache/spark/util/EventLoop.scala' size='91' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/IdGenerator.scala' size='8' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/IntParam.scala' size='11' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/JsonProtocol.scala' size='2697' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ListenerBus.scala' size='80' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ManualClock.scala' size='20' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/MemoryParam.scala' size='11' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/MutablePair.scala' size='1023' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/MutableURLClassLoader.scala' size='35' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/NextIterator.scala' size='132' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ParentClassLoader.scala' size='9' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/PeriodicCheckpointer.scala' size='129' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/RpcUtils.scala' size='39' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/SerializableBuffer.scala' size='42' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/SerializableConfiguration.scala' size='32' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/SerializableJobConf.scala' size='32' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ShutdownHookManager.scala' size='257' bugHash='570a1c0e3a0c65d22f1447c268fb5bfa' bugCount='1'></FileStats><FileStats path='org/apache/spark/util/SignalUtils.scala' size='146' bugHash='5faa556aaaf95648a4fd443697daf2c4' bugCount='1'></FileStats><FileStats path='org/apache/spark/util/SizeEstimator.scala' size='342' bugHash='ed390c0e1205a99a7f8f253067600e4e' bugCount='1'></FileStats><FileStats path='org/apache/spark/util/SparkExitCode.scala' size='20' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/SparkUncaughtExceptionHandler.scala' size='55' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/StatCounter.scala' size='114' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ThreadStackTrace.scala' size='54' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/ThreadUtils.scala' size='137' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/TimeStampedHashMap.scala' size='406' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/UninterruptibleThread.scala' size='37' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/Utils.scala' size='3331' bugHash='f5958922b37267aa85833eaddd6aa4cf' bugCount='32'></FileStats><FileStats path='org/apache/spark/util/VersionUtils.scala' size='25' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/AppendOnlyMap.scala' size='587' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/BitSet.scala' size='219' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/CompactBuffer.scala' size='419' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/ExternalAppendOnlyMap.scala' size='911' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/ExternalSorter.scala' size='1338' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/MedianHeap.scala' size='36' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/OpenHashMap.scala' size='605' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/OpenHashSet.scala' size='676' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/PartitionedAppendOnlyMap.scala' size='22' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/PartitionedPairBuffer.scala' size='209' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/PrimitiveKeyOpenHashMap.scala' size='809' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/PrimitiveVector.scala' size='362' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/SizeTracker.scala' size='76' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/SizeTrackingAppendOnlyMap.scala' size='32' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/SizeTrackingVector.scala' size='29' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/SortDataFormat.scala' size='37' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/Sorter.scala' size='11' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/Spillable.scala' size='90' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/TimSort.java' size='427' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/Utils.scala' size='17' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/WritablePartitionedPairCollection.scala' size='53' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/PrefixComparator.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/PrefixComparators.java' size='147' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/RadixSort.java' size='116' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/RecordComparator.java' size='4' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/RecordPointerAndKeyPrefix.java' size='5' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/UnsafeExternalSorter.java' size='388' bugHash='215bdd40ef4ac387ac1226ff645763ff' bugCount='2'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/UnsafeInMemorySorter.java' size='202' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/UnsafeSortDataFormat.java' size='47' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/UnsafeSorterIterator.java' size='10' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/UnsafeSorterSpillMerger.java' size='52' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/UnsafeSorterSpillReader.java' size='79' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/collection/unsafe/sort/UnsafeSorterSpillWriter.java' size='74' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/io/ChunkedByteBuffer.scala' size='172' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/io/ChunkedByteBufferOutputStream.scala' size='100' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/logging/FileAppender.scala' size='282' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/logging/RollingFileAppender.scala' size='217' bugHash='530a96954981ff0ca9ab21b419f1efc4' bugCount='6'></FileStats><FileStats path='org/apache/spark/util/logging/RollingPolicy.scala' size='167' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/random/Pseudorandom.scala' size='2' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/random/RandomSampler.scala' size='325' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/random/SamplingUtils.scala' size='79' bugHash='db1a8571bbdbe3477e5e1250aeb7af8e' bugCount='1'></FileStats><FileStats path='org/apache/spark/util/random/StratifiedSamplingUtils.scala' size='386' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/random/XORShiftRandom.scala' size='72' bugHash='2434a08e971719b9c24c1fdfacee33b6' bugCount='2'></FileStats><FileStats path='org/apache/spark/util/random/package.scala' size='6' bugCount='0'></FileStats><FileStats path='org/apache/spark/util/taskListeners.scala' size='49' bugCount='0'></FileStats><PackageStats package='org.apache.spark' priority_1='3' total_bugs='29' priority_2='26' total_size='10836' total_types='745'><ClassStats bugs='0' size='58' interface='false' sourceFile='Accumulable.scala' class='org.apache.spark.Accumulable'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Accumulable.scala' class='org.apache.spark.Accumulable$$anonfun$1'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='Accumulable.scala' class='org.apache.spark.AccumulableParam'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.Accumulator'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.Accumulator$'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Accumulator.scala' class='org.apache.spark.AccumulatorParam'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.AccumulatorParam$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.AccumulatorParam$DoubleAccumulatorParam$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.AccumulatorParam$FloatAccumulatorParam$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.AccumulatorParam$IntAccumulatorParam$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.AccumulatorParam$LongAccumulatorParam$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.AccumulatorParam$StringAccumulatorParam$'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='Accumulator.scala' class='org.apache.spark.AccumulatorParam$class'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='Aggregator.scala' class='org.apache.spark.Aggregator'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Aggregator.scala' class='org.apache.spark.Aggregator$'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='Aggregator.scala' class='org.apache.spark.Aggregator$$anonfun$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Aggregator.scala' class='org.apache.spark.Aggregator$$anonfun$updateMetrics$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanAccum'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanAccum$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanBroadcast'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanBroadcast$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanCheckpoint'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanCheckpoint$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanRDD'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanRDD$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanShuffle'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanShuffle$'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanerListener'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanupTask'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.CleanupTaskWeakReference'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.ComplexFutureAction'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.ComplexFutureAction$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.ComplexFutureAction$$anonfun$cancel$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.ComplexFutureAction$$anonfun$jobIds$1'></ClassStats><ClassStats bugs='0' size='127' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anon$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anon$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanCheckpoint$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanCheckpoint$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanCheckpoint$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanCheckpoint$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupAccum$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupAccum$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupAccum$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupAccum$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupBroadcast$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupBroadcast$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupBroadcast$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupBroadcast$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupRDD$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupRDD$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupRDD$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupRDD$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupShuffle$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupShuffle$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupShuffle$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$doCleanupShuffle$4'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ContextCleaner.scala' class='org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='Dependency.scala' class='org.apache.spark.Dependency'></ClassStats><ClassStats bugs='0' size='71' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ExceptionFailure'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ExceptionFailure$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ExceptionFailure$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ExceptionFailure$$anonfun$exception$1'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='ExecutorAllocationClient.scala' class='org.apache.spark.ExecutorAllocationClient'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExecutorAllocationClient.scala' class='org.apache.spark.ExecutorAllocationClient$class'></ClassStats><ClassStats bugs='0' size='290' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anon$2$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$addExecutors$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$addExecutors$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$addExecutors$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$canBeKilled$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$canBeKilled$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorAdded$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorBusy$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorIdle$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorRemoved$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorRemoved$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onExecutorRemoved$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onSchedulerBacklogged$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$onSchedulerQueueEmpty$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$org$apache$spark$ExecutorAllocationManager$$schedule$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$removeExecutors$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$removeExecutors$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$removeExecutors$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$removeExecutors$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$removeExecutors$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$removeExecutors$3$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$removeExecutors$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$updateAndSyncNumExecutorsTarget$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$$anonfun$updateAndSyncNumExecutorsTarget$2'></ClassStats><ClassStats bugs='0' size='126' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onSpeculativeTaskSubmitted$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onStageSubmitted$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onStageSubmitted$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onStageSubmitted$1$$anonfun$apply$6$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onTaskEnd$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onTaskEnd$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onTaskStart$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onTaskStart$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$onTaskStart$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$pendingSpeculativeTasks$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$pendingSpeculativeTasks$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$pendingSpeculativeTasks$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$pendingTasks$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$pendingTasks$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$pendingTasks$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$updateExecutorPlacementHints$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$updateExecutorPlacementHints$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener$$anonfun$updateExecutorPlacementHints$1$$anonfun$apply$9$$anonfun$2'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationManagerSource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationManagerSource$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationManagerSource$$anon$1$$anonfun$getValue$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationManagerSource$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationManagerSource$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationManagerSource$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationManagerSource$$anonfun$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorAllocationManager.scala' class='org.apache.spark.ExecutorAllocationManager$ExecutorAllocationManagerSource$$anonfun$7'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ExecutorLostFailure'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ExecutorLostFailure$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ExecutorLostFailure$$anonfun$toErrorString$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ExecutorLostFailure$$anonfun$toErrorString$2'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.ExecutorRegistered'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.ExecutorRegistered$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.ExecutorRemoved'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.ExecutorRemoved$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.ExpireDeadHosts'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.ExpireDeadHosts$'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.FetchFailed'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.FetchFailed$'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='FutureAction.scala' class='org.apache.spark.FutureAction'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.FutureAction$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.FutureAction$class'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.GetMapOutputMessage'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.GetMapOutputMessage$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.GetMapOutputStatuses'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.GetMapOutputStatuses$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='Accumulable.scala' class='org.apache.spark.GrowableAccumulableParam'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.HashPartitioner'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.HashPartitioner$$anonfun$6'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.Heartbeat'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.Heartbeat$'></ClassStats><ClassStats bugs='0' size='93' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$addExecutor$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3$$anon$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3$$anon$3$$anonfun$run$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$org$apache$spark$HeartbeatReceiver$$expireDeadHosts$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anon$2$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatReceiver$$anonfun$removeExecutor$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.HeartbeatResponse$'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='InternalAccumulator.scala' class='org.apache.spark.InternalAccumulator'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='InternalAccumulator.scala' class='org.apache.spark.InternalAccumulator$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='InternalAccumulator.scala' class='org.apache.spark.InternalAccumulator$input$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='InternalAccumulator.scala' class='org.apache.spark.InternalAccumulator$output$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='InternalAccumulator.scala' class='org.apache.spark.InternalAccumulator$shuffleRead$'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='InternalAccumulator.scala' class='org.apache.spark.InternalAccumulator$shuffleWrite$'></ClassStats><ClassStats bugs='0' size='106' interface='false' sourceFile='InterruptibleIterator.scala' class='org.apache.spark.InterruptibleIterator'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.JavaFutureActionWrapper'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.JavaFutureActionWrapper$$anonfun$jobIds$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='JobExecutionStatus.java' class='org.apache.spark.JobExecutionStatus'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='FutureAction.scala' class='org.apache.spark.JobSubmitter'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputStatistics.scala' class='org.apache.spark.MapOutputStatistics'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker'></ClassStats><ClassStats bugs='0' size='77' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$askTracker$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2$$anonfun$apply$7$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$deserializeMapStatuses$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$1'></ClassStats><ClassStats bugs='1' size='6' priority_1='1' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$deserializeObject$1$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$3'></ClassStats><ClassStats bugs='0' size='132' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$findMissingPartitions$2'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getLocationsWithLargestOutputs$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getLocationsWithLargestOutputs$1$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getLocationsWithLargestOutputs$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getMapSizesByExecutorId$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getMapSizesByExecutorId$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getNumAvailableOutputs$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getNumAvailableOutputs$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getNumCachedSerializedBroadcast$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getPreferredLocationsForShuffle$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getStatistics$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getStatistics$1$$anonfun$5'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getStatistics$1$$anonfun$5$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getStatistics$1$$anonfun$5$$anonfun$apply$2$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getStatistics$1$$anonfun$5$$anonfun$apply$2$$anonfun$apply$mcV$sp$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getStatistics$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$getStatistics$1$$anonfun$apply$5$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$incrementEpoch$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$rangeGrouped$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$removeOutputsOnExecutor$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$removeOutputsOnHost$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$$anonfun$unregisterShuffle$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$MessageLoop'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$MessageLoop$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMaster$MessageLoop$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMasterEndpoint'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMasterEndpoint$$anonfun$3'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMasterEndpoint$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMasterEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMasterEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerMessage'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerWorker'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerWorker$$anonfun$getMapSizesByExecutorId$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerWorker$$anonfun$getStatuses$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerWorker$$anonfun$getStatuses$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerWorker$$anonfun$getStatuses$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerWorker$$anonfun$getStatuses$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerWorker$$anonfun$getStatuses$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.MapOutputTrackerWorker$$anonfun$updateEpoch$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Dependency.scala' class='org.apache.spark.NarrowDependency'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Dependency.scala' class='org.apache.spark.OneToOneDependency'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='Partition.scala' class='org.apache.spark.Partition'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Partition.scala' class='org.apache.spark.Partition$class'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.Partitioner'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.Partitioner$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.Partitioner$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.Partitioner$$anonfun$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.Partitioner$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.Partitioner$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.Partitioner$$anonfun$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Dependency.scala' class='org.apache.spark.RangeDependency'></ClassStats><ClassStats bugs='0' size='88' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$10'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$10$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$12'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$9'></ClassStats><ClassStats bugs='2' size='19' priority_1='2' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$readObject$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Partitioner.scala' class='org.apache.spark.RangePartitioner$$anonfun$writeObject$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.Resubmitted'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.Resubmitted$'></ClassStats><ClassStats bugs='0' size='149' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions'></ClassStats><ClassStats bugs='0' size='105' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$10$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$11'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$13$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$14$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$15$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$16$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$17$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$17$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$18$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$19'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$5'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$7$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$8$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$9$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$createJettySslContextFactory$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$createJettySslContextFactory$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$createJettySslContextFactory$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$createJettySslContextFactory$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$createJettySslContextFactory$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$createJettySslContextFactory$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$createJettySslContextFactory$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$createJettySslContextFactory$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$liftedTree1$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$parse$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$parse$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$toString$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SSLOptions.scala' class='org.apache.spark.SSLOptions$$anonfun$toString$2'></ClassStats><ClassStats bugs='0' size='212' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$'></ClassStats><ClassStats bugs='3' size='9' priority_2='3' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anon$1'></ClassStats><ClassStats bugs='1' size='5' priority_2='1' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anon$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anon$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$checkModifyPermissions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$checkModifyPermissions$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$checkModifyPermissions$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$checkUIViewPermissions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$checkUIViewPermissions$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$checkUIViewPermissions$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$credulousTrustStoreManagers$lzycompute$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$getSSLOptions$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$getSecretKey$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$getSecretKey$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$getSecretKey$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$getSecretKey$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$initializeAuth$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$setAcls$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$setAdminAcls$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$setAdminAclsGroups$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$setModifyAcls$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$setModifyAclsGroups$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$setViewAcls$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$setViewAclsGroups$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$stringToSet$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SecurityManager.scala' class='org.apache.spark.SecurityManager$$anonfun$stringToSet$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SerializableWritable.scala' class='org.apache.spark.SerializableWritable'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SerializableWritable.scala' class='org.apache.spark.SerializableWritable$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SerializableWritable.scala' class='org.apache.spark.SerializableWritable$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='Dependency.scala' class='org.apache.spark.ShuffleDependency'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Dependency.scala' class='org.apache.spark.ShuffleDependency$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Dependency.scala' class='org.apache.spark.ShuffleDependency$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Dependency.scala' class='org.apache.spark.ShuffleDependency$$anonfun$2'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.ShuffleStatus'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.ShuffleStatus$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.ShuffleStatus$$anonfun$findMissingPartitions$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.ShuffleStatus$$anonfun$invalidateSerializedMapOutputStatusCache$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.ShuffleStatus$$anonfun$removeOutputsByFilter$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.ShuffleStatus$$anonfun$removeOutputsOnExecutor$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.ShuffleStatus$$anonfun$removeOutputsOnHost$1'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction$$anonfun$onComplete$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction$$anonfun$result$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction$$anonfun$transform$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction$$anonfun$transform$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction$$anonfun$transformWith$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction$$anonfun$transformWith$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction$$anonfun$value$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FutureAction.scala' class='org.apache.spark.SimpleFutureAction$$anonfun$value$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='246' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf'></ClassStats><ClassStats bugs='0' size='124' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$5$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$clone$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$contains$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$get$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$get$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getAll$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getAllWithPrefix$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getAllWithPrefix$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getAvroSchema$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getAvroSchema$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getBoolean$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getBoolean$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getDeprecatedConfig$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getDeprecatedConfig$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getDouble$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getDouble$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getInt$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getInt$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getLong$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getLong$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getOption$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$getWithSubstitution$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$loadFromSystemProperties$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$loadFromSystemProperties$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$loadFromSystemProperties$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$logDeprecationWarning$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$logDeprecationWarning$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$logDeprecationWarning$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$logDeprecationWarning$2$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$logDeprecationWarning$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$registerAvroSchemas$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$registerKryoClasses$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$registerKryoClasses$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$registerKryoClasses$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$setAll$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$setExecutorEnv$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$setExecutorEnv$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$setJars$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$setJars$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$setJars$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$setJars$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$toDebugString$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$10'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$4'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$7'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$$anonfun$validateSettings$9'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$AlternateConfig'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$AlternateConfig$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$DeprecatedConfig'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkConf.scala' class='org.apache.spark.SparkConf$DeprecatedConfig$'></ClassStats><ClassStats bugs='6' size='875' priority_2='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext'></ClassStats><ClassStats bugs='0' size='203' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anon$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anon$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anon$3$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$1'></ClassStats><ClassStats bugs='1' size='9' priority_2='1' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$14'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$15$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$17'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$18$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$18$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$19'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$2$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$20'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$21'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$21$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$22'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$23'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$24'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$25'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$26'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$32'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$33'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$34'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$35'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$38'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$39'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$7$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$accumulable$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$accumulable$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$accumulableCollection$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$accumulator$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$accumulator$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$addFile$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$addJar$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$addJar$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$addJarFile$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$arrayToArrayWritable$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2$$anonfun$apply$17'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$4$$anonfun$36'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$4$$anonfun$37'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$4$$anonfun$apply$18'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$binaryFiles$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$binaryRecords$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$binaryRecords$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$binaryRecords$1$$anonfun$apply$10$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$broadcast$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$broadcast$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$broadcast$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$checkpointFile$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$deployMode$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getCallSite$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getCallSite$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getExecutorIds$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getExecutorMemoryStatus$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getExecutorThreadDump$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getLocalProperty$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getOrCreate$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getRDDStorageInfo$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getRDDStorageInfo$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$getSparkHome$1'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$hadoopFile$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$30'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$hadoopFile$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$hadoopFile$3'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$hadoopRDD$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$killAndReplaceExecutor$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$killExecutors$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$makeRDD$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$makeRDD$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$makeRDD$2$$anonfun$29'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$makeRDD$2$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$newAPIHadoopFile$2'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$newAPIHadoopRDD$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$objectFile$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$objectFile$1$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$org$apache$spark$SparkContext$$createTaskScheduler$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$org$apache$spark$SparkContext$$warnSparkMem$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$parallelize$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$range$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$range$1$$anonfun$28'></ClassStats><ClassStats bugs='0' size='115' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$range$1$$anonfun$28$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$range$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$requestExecutors$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$requestTotalExecutors$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$runApproximateJob$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$runApproximateJob$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$runJob$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$runJob$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$runJob$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$runJob$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$runJob$5'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$sequenceFile$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$sequenceFile$2'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$sequenceFile$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$sequenceFile$3$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$setCheckpointDir$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$setCheckpointDir$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$setLogLevel$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$setupAndStartListenerBus$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$setupAndStartListenerBus$1$$anonfun$apply$15$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$10$$anonfun$apply$mcV$sp$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$13'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$2$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$4$$anonfun$apply$mcV$sp$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$5$$anonfun$apply$mcV$sp$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$7$$anonfun$apply$mcV$sp$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$stop$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$submitMapStage$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$textFile$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$uiWebUrl$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$union$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$union$1$$anonfun$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$union$1$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$union$2'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$wholeTextFiles$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkContext$$anonfun$wholeTextFiles$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='SparkException.scala' class='org.apache.spark.SparkDriverExecutionException'></ClassStats><ClassStats bugs='1' size='110' priority_2='1' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv'></ClassStats><ClassStats bugs='0' size='197' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$create$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$create$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$create$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$create$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$create$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$createDriverEnv$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$createDriverEnv$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$createPythonWorker$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$destroyPythonWorker$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$registerOrLookupEndpoint$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$releasePythonWorker$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkEnv.scala' class='org.apache.spark.SparkEnv$$anonfun$stop$2'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='SparkException.scala' class='org.apache.spark.SparkException'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='SparkExecutorInfo.java' class='org.apache.spark.SparkExecutorInfo'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='StatusAPIImpl.scala' class='org.apache.spark.SparkExecutorInfoImpl'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='SparkFiles.scala' class='org.apache.spark.SparkFiles'></ClassStats><ClassStats bugs='1' size='9' priority_2='1' interface='false' sourceFile='SparkFiles.scala' class='org.apache.spark.SparkFiles$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkFiles.scala' class='org.apache.spark.SparkFiles$$anonfun$getRootDirectory$1'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='SparkFirehoseListener.java' class='org.apache.spark.SparkFirehoseListener'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='SparkJobInfo.java' class='org.apache.spark.SparkJobInfo'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StatusAPIImpl.scala' class='org.apache.spark.SparkJobInfoImpl'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkMasterRegex'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.SparkMasterRegex$'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='SparkStageInfo.java' class='org.apache.spark.SparkStageInfo'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='StatusAPIImpl.scala' class='org.apache.spark.SparkStageInfoImpl'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getActiveJobIds$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getActiveStageIds$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getExecutorInfos$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getExecutorInfos$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getExecutorInfos$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getJobIdsForGroup$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getJobIdsForGroup$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getJobInfo$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getJobInfo$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getStageInfo$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getStageInfo$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getStageInfo$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkStatusTracker.scala' class='org.apache.spark.SparkStatusTracker$$anonfun$getStageInfo$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='SparkException.scala' class='org.apache.spark.SparkUserAppException'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkException.scala' class='org.apache.spark.SparkUserAppException$'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.SpillListener'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.SpillListener$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.SpillListener$$anonfun$onTaskEnd$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.StopMapOutputTracker'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MapOutputTracker.scala' class='org.apache.spark.StopMapOutputTracker$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.Success'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.Success$'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskCommitDenied'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskCommitDenied$'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='TaskContext.scala' class='org.apache.spark.TaskContext'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TaskContext.scala' class='org.apache.spark.TaskContext$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskContext.scala' class='org.apache.spark.TaskContext$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskContext.scala' class='org.apache.spark.TaskContext$$anon$2'></ClassStats><ClassStats bugs='0' size='130' interface='false' sourceFile='TaskContextImpl.scala' class='org.apache.spark.TaskContextImpl'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskContextImpl.scala' class='org.apache.spark.TaskContextImpl$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='TaskContextImpl.scala' class='org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskContextImpl.scala' class='org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskContextImpl.scala' class='org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskContextImpl.scala' class='org.apache.spark.TaskContextImpl$$anonfun$markTaskFailed$1'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskEndReason'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskFailedReason'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskFailedReason$class'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskKilled'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskKilled$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskKilledException.scala' class='org.apache.spark.TaskKilledException'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='TaskNotSerializableException.scala' class='org.apache.spark.TaskNotSerializableException'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskResultLost'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.TaskResultLost$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.TaskSchedulerIsSet'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='HeartbeatReceiver.scala' class='org.apache.spark.TaskSchedulerIsSet$'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TaskState.scala' class='org.apache.spark.TaskState'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='TaskState.scala' class='org.apache.spark.TaskState$'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils'></ClassStats><ClassStats bugs='6' size='105' priority_2='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$'></ClassStats><ClassStats bugs='3' size='9' priority_2='3' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anon$1'></ClassStats><ClassStats bugs='1' size='5' priority_2='1' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anon$2'></ClassStats><ClassStats bugs='1' size='8' priority_2='1' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$1$$anonfun$apply$mcI$sp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$10'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$assertNotSpilled$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$assertSpilled$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$createCompiledClass$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$createCompiledClass$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$createJar$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$createJar$1$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$createJar$1$$anonfun$7'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$createJarWithFiles$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$$anonfun$httpResponseCode$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TestUtils.scala' class='org.apache.spark.TestUtils$JavaSourceFromString'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.ThrowableSerializationWrapper'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.UnknownReason'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskEndReason.scala' class='org.apache.spark.UnknownReason$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$40'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$40$$anonfun$apply$19'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$41'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$41$$anonfun$apply$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$42'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$42$$anonfun$apply$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$43'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$43$$anonfun$apply$22'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$44'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$44$$anonfun$apply$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$45'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$45$$anonfun$apply$24'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$46'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$46$$anonfun$apply$25'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$booleanWritableConverter$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$bytesWritableConverter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$doubleWritableConverter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$floatWritableConverter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$intWritableConverter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$longWritableConverter$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$simpleWritableConverter$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$simpleWritableConverter$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$stringWritableConverter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$writableWritableConverter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$writableWritableConverter$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$writableWritableConverterFn$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$writableWritableConverterFn$1$$anonfun$apply$26'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableConverter$$anonfun$writableWritableConverterFn$1$$anonfun$apply$27'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$booleanWritableFactory$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$bytesWritableFactory$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$doubleWritableFactory$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$floatWritableFactory$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$intWritableFactory$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$longWritableFactory$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$simpleWritableFactory$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$stringWritableFactory$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkContext.scala' class='org.apache.spark.WritableFactory$$anonfun$writableWritableFactory$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='package.scala' class='org.apache.spark.package'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='package.scala' class='org.apache.spark.package$'></ClassStats><ClassStats bugs='0' size='48' interface='false' sourceFile='package.scala' class='org.apache.spark.package$SparkBuildInfo$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.api.java' total_bugs='0' total_size='1720' total_types='94'><ClassStats bugs='0' size='82' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.AbstractJavaRDDLike'></ClassStats><ClassStats bugs='0' size='94' interface='false' sourceFile='JavaDoubleRDD.scala' class='org.apache.spark.api.java.JavaDoubleRDD'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JavaDoubleRDD.scala' class='org.apache.spark.api.java.JavaDoubleRDD$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaDoubleRDD.scala' class='org.apache.spark.api.java.JavaDoubleRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JavaDoubleRDD.scala' class='org.apache.spark.api.java.JavaDoubleRDD$$anonfun$filter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaDoubleRDD.scala' class='org.apache.spark.api.java.JavaDoubleRDD$$anonfun$histogram$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaDoubleRDD.scala' class='org.apache.spark.api.java.JavaDoubleRDD$$anonfun$wrapRDD$1'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='JavaFutureAction.java' class='org.apache.spark.api.java.JavaFutureAction'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JavaHadoopRDD.scala' class='org.apache.spark.api.java.JavaHadoopRDD'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaHadoopRDD.scala' class='org.apache.spark.api.java.JavaHadoopRDD$$anonfun$mapPartitionsWithInputSplit$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JavaNewHadoopRDD.scala' class='org.apache.spark.api.java.JavaNewHadoopRDD'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaNewHadoopRDD.scala' class='org.apache.spark.api.java.JavaNewHadoopRDD$$anonfun$mapPartitionsWithInputSplit$1'></ClassStats><ClassStats bugs='0' size='254' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$cogroupResult2ToJava$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$cogroupResult3ToJava$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$cogroupResultToJava$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$countByKeyApprox$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$countByKeyApprox$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$filter$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$fn$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$fullOuterJoin$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$fullOuterJoin$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$fullOuterJoin$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$groupByResultToJava$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$keys$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$leftOuterJoin$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$leftOuterJoin$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$leftOuterJoin$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$rightOuterJoin$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$rightOuterJoin$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$rightOuterJoin$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$sampleByKey$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$sampleByKeyExact$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaPairRDD.scala' class='org.apache.spark.api.java.JavaPairRDD$$anonfun$values$1'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='JavaRDD.scala' class='org.apache.spark.api.java.JavaRDD'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JavaRDD.scala' class='org.apache.spark.api.java.JavaRDD$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDD.scala' class='org.apache.spark.api.java.JavaRDD$$anonfun$filter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDD.scala' class='org.apache.spark.api.java.JavaRDD$$anonfun$fn$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDD.scala' class='org.apache.spark.api.java.JavaRDD$$anonfun$randomSplit$1'></ClassStats><ClassStats bugs='0' size='82' interface='true' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$collectAsync$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$collectPartitions$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$countAsync$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$countByValueApprox$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$countByValueApprox$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$flatMapToDouble$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$10$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$2$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$5$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$6$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$8$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$9$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$foreach$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachAsync$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachAsync$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartitionAsync$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartitionAsync$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$glom$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsToDouble$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsToDouble$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$mapPartitionsWithIndex$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$mapToDouble$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$$anonfun$takeAsync$1'></ClassStats><ClassStats bugs='0' size='198' interface='false' sourceFile='JavaRDDLike.scala' class='org.apache.spark.api.java.JavaRDDLike$class'></ClassStats><ClassStats bugs='0' size='210' interface='false' sourceFile='JavaSparkContext.scala' class='org.apache.spark.api.java.JavaSparkContext'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='JavaSparkContext.scala' class='org.apache.spark.api.java.JavaSparkContext$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaSparkContext.scala' class='org.apache.spark.api.java.JavaSparkContext$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaSparkContext.scala' class='org.apache.spark.api.java.JavaSparkContext$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaSparkContext.scala' class='org.apache.spark.api.java.JavaSparkContext$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaSparkContext.scala' class='org.apache.spark.api.java.JavaSparkContext$$anonfun$getPersistentRDDs$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaSparkContext.scala' class='org.apache.spark.api.java.JavaSparkContext$$anonfun$parallelizeDoubles$1'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='JavaSparkContextVarargsWorkaround.java' class='org.apache.spark.api.java.JavaSparkContextVarargsWorkaround'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='JavaSparkStatusTracker.scala' class='org.apache.spark.api.java.JavaSparkStatusTracker'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='JavaUtils.scala' class='org.apache.spark.api.java.JavaUtils'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JavaUtils.scala' class='org.apache.spark.api.java.JavaUtils$'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='JavaUtils.scala' class='org.apache.spark.api.java.JavaUtils$SerializableMapWrapper'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='JavaUtils.scala' class='org.apache.spark.api.java.JavaUtils$SerializableMapWrapper$$anon$1'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='JavaUtils.scala' class='org.apache.spark.api.java.JavaUtils$SerializableMapWrapper$$anon$1$$anon$2'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='JavaUtils.scala' class='org.apache.spark.api.java.JavaUtils$SerializableMapWrapper$$anon$1$$anon$2$$anon$3'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='JavaUtils.scala' class='org.apache.spark.api.java.JavaUtils$SerializableMapWrapper$$anonfun$get$1'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='Optional.java' class='org.apache.spark.api.java.Optional'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='StorageLevels.java' class='org.apache.spark.api.java.StorageLevels'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.api.java.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.api.java.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.api.java.function' total_bugs='0' total_size='50' total_types='24'><ClassStats bugs='0' size='2' interface='true' sourceFile='CoGroupFunction.java' class='org.apache.spark.api.java.function.CoGroupFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='DoubleFlatMapFunction.java' class='org.apache.spark.api.java.function.DoubleFlatMapFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='DoubleFunction.java' class='org.apache.spark.api.java.function.DoubleFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='FilterFunction.java' class='org.apache.spark.api.java.function.FilterFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='FlatMapFunction.java' class='org.apache.spark.api.java.function.FlatMapFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='FlatMapFunction2.java' class='org.apache.spark.api.java.function.FlatMapFunction2'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='FlatMapGroupsFunction.java' class='org.apache.spark.api.java.function.FlatMapGroupsFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ForeachFunction.java' class='org.apache.spark.api.java.function.ForeachFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ForeachPartitionFunction.java' class='org.apache.spark.api.java.function.ForeachPartitionFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Function.java' class='org.apache.spark.api.java.function.Function'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Function0.java' class='org.apache.spark.api.java.function.Function0'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Function2.java' class='org.apache.spark.api.java.function.Function2'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Function3.java' class='org.apache.spark.api.java.function.Function3'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Function4.java' class='org.apache.spark.api.java.function.Function4'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='MapFunction.java' class='org.apache.spark.api.java.function.MapFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='MapGroupsFunction.java' class='org.apache.spark.api.java.function.MapGroupsFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='MapPartitionsFunction.java' class='org.apache.spark.api.java.function.MapPartitionsFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='PairFlatMapFunction.java' class='org.apache.spark.api.java.function.PairFlatMapFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='PairFunction.java' class='org.apache.spark.api.java.function.PairFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ReduceFunction.java' class='org.apache.spark.api.java.function.ReduceFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='VoidFunction.java' class='org.apache.spark.api.java.function.VoidFunction'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='VoidFunction2.java' class='org.apache.spark.api.java.function.VoidFunction2'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.api.java.function.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.api.java.function.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.api.python' total_bugs='12' priority_2='12' total_size='2672' total_types='166'><ClassStats bugs='0' size='63' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$$anonfun$3'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$$anonfun$compute$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$$anonfun$compute$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$MonitorThread'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$MonitorThread$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$MonitorThread$$anonfun$run$3'></ClassStats><ClassStats bugs='0' size='164' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1$$anonfun$applyOrElse$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1$$anonfun$applyOrElse$4'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$handleEndOfDataSection$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$handlePythonException$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$handleTimingData$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$4$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$5$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1$$anonfun$6'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.BytesToString'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.ChainedPythonFunctions'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.ChainedPythonFunctions$'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.Converter'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.Converter$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.Converter$$anonfun$getInstance$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.Converter$$anonfun$getInstance$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.Converter$$anonfun$getInstance$1$$anonfun$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.Converter$$anonfun$getInstance$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.Converter$$anonfun$getInstance$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.DoubleArrayToWritableConverter'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.DoubleArrayToWritableConverter$$anonfun$convert$2'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.DoubleArrayWritable'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.JavaToWritableConverter'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.JavaToWritableConverter$$anonfun$org$apache$spark$api$python$JavaToWritableConverter$$convertToWritable$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.JavaToWritableConverter$$anonfun$org$apache$spark$api$python$JavaToWritableConverter$$convertToWritable$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PairwiseRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PairwiseRDD$$anonfun$compute$1'></ClassStats><ClassStats bugs='1' size='41' priority_2='1' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonAccumulatorV2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonAccumulatorV2$$anonfun$merge$1'></ClassStats><ClassStats bugs='1' size='36' priority_2='1' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonBroadcast'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonBroadcast$$anonfun$finalize$1'></ClassStats><ClassStats bugs='2' size='17' priority_2='2' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1$$anonfun$apply$mcJ$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonBroadcast$$anonfun$readObject$1$$anonfun$apply$mcJ$sp$2'></ClassStats><ClassStats bugs='1' size='12' priority_2='1' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonBroadcast$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.PythonEvalType'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.PythonEvalType$'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonException'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonFunction'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonFunction$'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='PythonGatewayServer.scala' class='org.apache.spark.api.python.PythonGatewayServer'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='PythonGatewayServer.scala' class='org.apache.spark.api.python.PythonGatewayServer$'></ClassStats><ClassStats bugs='1' size='25' priority_2='1' interface='false' sourceFile='PythonGatewayServer.scala' class='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonGatewayServer.scala' class='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonGatewayServer.scala' class='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonGatewayServer.scala' class='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1$$anonfun$apply$mcV$sp$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonGatewayServer.scala' class='org.apache.spark.api.python.PythonGatewayServer$$anonfun$main$1$$anonfun$apply$mcV$sp$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.PythonHadoopUtil'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.PythonHadoopUtil$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.PythonHadoopUtil$$anonfun$convertRDD$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.PythonHadoopUtil$$anonfun$mapToConf$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.PythonHadoopUtil$$anonfun$mergeConfs$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='PythonPartitioner.scala' class='org.apache.spark.api.python.PythonPartitioner'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD'></ClassStats><ClassStats bugs='2' size='201' priority_2='2' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anon$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anon$1$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anon$1$$anonfun$run$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$getKeyValueTypes$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$getKeyValueTypes$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$getWorkerBroadcasts$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$valueOfPair$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$valueOfPair$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRDD.scala' class='org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.PythonRunner'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.PythonRunner$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.PythonRunner$$anon$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.PythonRunner$$anon$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PythonUtils.scala' class='org.apache.spark.api.python.PythonUtils'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='PythonUtils.scala' class='org.apache.spark.api.python.PythonUtils$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonUtils.scala' class='org.apache.spark.api.python.PythonUtils$$anonfun$mergePythonPaths$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonUtils.scala' class='org.apache.spark.api.python.PythonUtils$$anonfun$sparkPythonPath$1'></ClassStats><ClassStats bugs='4' size='189' priority_2='4' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$3$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$liftedTree1$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$liftedTree1$1$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$org$apache$spark$api$python$PythonWorkerFactory$$cleanupIdleWorkers$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$redirectStreamsToStderr$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$releaseWorker$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$stopDaemon$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$stopWorker$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$$anonfun$stopWorker$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PythonWorkerFactory.scala' class='org.apache.spark.api.python.PythonWorkerFactory$MonitorThread'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil'></ClassStats><ClassStats bugs='0' size='83' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$checkPickle$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$checkPickle$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$checkPickle$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$checkPickle$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$isPair$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$javaToPython$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$pairRDDToPython$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$pairRDDToPython$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$pairRDDToPython$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$pythonToJava$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$pythonToJava$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$pythonToPairRDD$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$$anonfun$toJavaArray$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$ArrayConstructor'></ClassStats><ClassStats bugs='0' size='121' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDeUtil.scala' class='org.apache.spark.api.python.SerDeUtil$ByteArrayConstructor'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.SpecialLengths'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.api.python.SpecialLengths$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.TestInputKeyConverter'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.TestInputValueConverter'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.TestInputValueConverter$$anonfun$convert$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.TestOutputKeyConverter'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.TestOutputValueConverter'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.TestWritable'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.TestWritable$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WritableToDoubleArrayConverter'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WritableToDoubleArrayConverter$$anonfun$convert$3'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.WritableToJavaConverter'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.WritableToJavaConverter$$anonfun$org$apache$spark$api$python$WritableToJavaConverter$$convertWritable$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonHadoopUtil.scala' class='org.apache.spark.api.python.WritableToJavaConverter$$anonfun$org$apache$spark$api$python$WritableToJavaConverter$$convertWritable$2'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$5$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$6'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$generateData$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WriteInputFormatTestDataGenerator.scala' class='org.apache.spark.api.python.WriteInputFormatTestDataGenerator$$anonfun$generateData$1$$anonfun$apply$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.api.r' priority_1='2' total_bugs='10' priority_2='5' priority_3='3' total_size='1805' total_types='95'><ClassStats bugs='0' size='26' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.BaseRRDD'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.BufferedStreamThread'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.BufferedStreamThread$$anonfun$getLines$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.BufferedStreamThread$$anonfun$getLines$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.BufferedStreamThread$$anonfun$run$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.BufferedStreamThread$$anonfun$run$5$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='JVMObjectTracker.scala' class='org.apache.spark.api.r.JVMObjectId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JVMObjectTracker.scala' class='org.apache.spark.api.r.JVMObjectId$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JVMObjectTracker.scala' class='org.apache.spark.api.r.JVMObjectId$$anonfun$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='JVMObjectTracker.scala' class='org.apache.spark.api.r.JVMObjectTracker'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JVMObjectTracker.scala' class='org.apache.spark.api.r.JVMObjectTracker$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.PairwiseRRDD'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.PairwiseRRDD$$anonfun$$lessinit$greater$1'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='RBackend.scala' class='org.apache.spark.api.r.RBackend'></ClassStats><ClassStats bugs='3' size='54' priority_1='2' priority_2='1' interface='false' sourceFile='RBackend.scala' class='org.apache.spark.api.r.RBackend$'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RBackend.scala' class='org.apache.spark.api.r.RBackend$$anon$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RBackend.scala' class='org.apache.spark.api.r.RBackend$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RBackend.scala' class='org.apache.spark.api.r.RBackend$$anonfun$main$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RBackend.scala' class='org.apache.spark.api.r.RBackend$$anonfun$main$2'></ClassStats><ClassStats bugs='1' size='134' priority_3='1' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anon$1'></ClassStats><ClassStats bugs='1' size='7' priority_3='1' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$channelRead0$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$exceptionCaught$1'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$findMatchedSignature$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$findMatchedSignature$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$1'></ClassStats><ClassStats bugs='1' size='9' priority_3='1' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$4$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$handleMethodCall$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RBackendHandler.scala' class='org.apache.spark.api.r.RBackendHandler$$anonfun$readArgs$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.RRDD'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.RRDD$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.RRDD$$anonfun$$lessinit$greater$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.RRDD$$anonfun$createSparkContext$5'></ClassStats><ClassStats bugs='1' size='123' priority_2='1' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner'></ClassStats><ClassStats bugs='2' size='65' priority_2='2' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$'></ClassStats><ClassStats bugs='0' size='111' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anon$1'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anon$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anon$2$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anon$2$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anon$2$$anonfun$run$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anon$2$$anonfun$run$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anon$2$$anonfun$run$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anonfun$3'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunner$$anonfun$org$apache$spark$api$r$RRunner$$read$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunnerModes'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.RRunnerModes$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RUtils.scala' class='org.apache.spark.api.r.RUtils'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='RUtils.scala' class='org.apache.spark.api.r.RUtils$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RUtils.scala' class='org.apache.spark.api.r.RUtils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RUtils.scala' class='org.apache.spark.api.r.RUtils$$anonfun$2'></ClassStats><ClassStats bugs='1' size='7' priority_2='1' interface='false' sourceFile='RUtils.scala' class='org.apache.spark.api.r.RUtils$$anonfun$isSparkRInstalled$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RUtils.scala' class='org.apache.spark.api.r.RUtils$$anonfun$localSparkRPackagePath$1'></ClassStats><ClassStats bugs='0' size='68' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe'></ClassStats><ClassStats bugs='0' size='279' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readArray$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readArray$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readArray$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readArray$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readBooleanArr$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readBytesArr$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readDoubleArr$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readIntArr$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readList$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$readStringArr$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeBooleanArr$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeDoubleArr$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeIntArr$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeObject$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeObject$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeObject$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeObject$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeObject$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerDe$$anonfun$writeStringArr$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerializationFormats'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SerDe.scala' class='org.apache.spark.api.r.SerializationFormats$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkRDefaults.scala' class='org.apache.spark.api.r.SparkRDefaults'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkRDefaults.scala' class='org.apache.spark.api.r.SparkRDefaults$'></ClassStats><ClassStats bugs='0' size='2' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.SpecialLengths'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.api.r.SpecialLengths$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.StringRRDD'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRDD.scala' class='org.apache.spark.api.r.StringRRDD$$anonfun$$lessinit$greater$3'></ClassStats></PackageStats><PackageStats package='org.apache.spark.broadcast' total_bugs='0' total_size='505' total_types='32'><ClassStats bugs='0' size='59' interface='false' sourceFile='Broadcast.scala' class='org.apache.spark.broadcast.Broadcast'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Broadcast.scala' class='org.apache.spark.broadcast.Broadcast$$anonfun$destroy$1'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='BroadcastFactory.scala' class='org.apache.spark.broadcast.BroadcastFactory'></ClassStats><ClassStats bugs='0' size='57' interface='false' sourceFile='BroadcastManager.scala' class='org.apache.spark.broadcast.BroadcastManager'></ClassStats><ClassStats bugs='0' size='86' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$blockifyObject$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$blockifyObject$2'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$releaseLock$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1$$anonfun$apply$2$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1$$anonfun$apply$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1$$anonfun$apply$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1$$anonfun$apply$2$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$unBlockifyObject$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$unpersist$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$writeBlocks$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TorrentBroadcast.scala' class='org.apache.spark.broadcast.TorrentBroadcast$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TorrentBroadcastFactory.scala' class='org.apache.spark.broadcast.TorrentBroadcastFactory'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.broadcast.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.broadcast.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy' priority_1='1' total_bugs='29' priority_2='25' priority_3='3' total_size='7110' total_types='491'><ClassStats bugs='0' size='67' interface='false' sourceFile='ApplicationDescription.scala' class='org.apache.spark.deploy.ApplicationDescription'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ApplicationDescription.scala' class='org.apache.spark.deploy.ApplicationDescription$'></ClassStats><ClassStats bugs='0' size='2' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.Client'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.Client$'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientApp'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientApp$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientApp$$anonfun$7'></ClassStats><ClassStats bugs='0' size='91' interface='false' sourceFile='ClientArguments.scala' class='org.apache.spark.deploy.ClientArguments'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ClientArguments.scala' class='org.apache.spark.deploy.ClientArguments$'></ClassStats><ClassStats bugs='2' size='125' priority_3='2' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$asyncSendToMasterAndForwardReply$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$asyncSendToMasterAndForwardReply$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$asyncSendToMasterAndForwardReply$1$$anonfun$apply$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$onDisconnected$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$onDisconnected$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$onError$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$onNetworkError$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$onNetworkError$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$onNetworkError$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$pollAndReportStatus$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$pollAndReportStatus$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$pollAndReportStatus$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$pollAndReportStatus$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$pollAndReportStatus$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$pollAndReportStatus$6'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Client.scala' class='org.apache.spark.deploy.ClientEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='Command.scala' class='org.apache.spark.deploy.Command'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Command.scala' class='org.apache.spark.deploy.Command$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils'></ClassStats><ClassStats bugs='2' size='47' priority_2='2' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$addJarsToClassPath$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$downloadFile$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$downloadFileList$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$downloadFileList$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveAndDownloadJars$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveAndDownloadJars$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveAndDownloadJars$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveAndDownloadJars$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2$$anonfun$apply$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2$$anonfun$apply$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DependencyUtils.scala' class='org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessage'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ApplicationFinished'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ApplicationFinished$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ApplicationRemoved'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ApplicationRemoved$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$DriverStateChanged'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$DriverStateChanged$'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$DriverStatusResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$DriverStatusResponse$'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ExecutorAdded'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ExecutorAdded$'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ExecutorStateChanged'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ExecutorStateChanged$'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ExecutorUpdated'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ExecutorUpdated$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$Heartbeat'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$Heartbeat$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$KillDriver'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$KillDriver$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$KillDriverResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$KillDriverResponse$'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$KillExecutor'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$KillExecutor$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$KillExecutors'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$KillExecutors$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$LaunchDriver'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$LaunchDriver$'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$LaunchExecutor'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$LaunchExecutor$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$MasterChangeAcknowledged'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$MasterChangeAcknowledged$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$MasterChanged'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$MasterChanged$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$MasterInStandby$'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$MasterStateResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$MasterStateResponse$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$MasterStateResponse$$anonfun$restUri$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ReconnectWorker'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ReconnectWorker$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisterApplication'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisterApplication$'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisterWorker'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisterWorker$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisterWorkerFailed'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisterWorkerFailed$'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisterWorkerResponse'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisteredApplication'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisteredApplication$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisteredWorker'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RegisteredWorker$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestDriverStatus'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestDriverStatus$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestExecutors'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestExecutors$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestKillDriver'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestKillDriver$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestMasterState$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestSubmitDriver'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestSubmitDriver$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$RequestWorkerState$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$ReregisterWithMaster$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$SendHeartbeat$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$StopAppClient$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$SubmitDriverResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$SubmitDriverResponse$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$UnregisterApplication'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$UnregisterApplication$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkDirCleanup$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkerLatestState'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkerLatestState$'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkerRemoved'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkerRemoved$'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkerSchedulerStateResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkerSchedulerStateResponse$'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkerStateResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DeployMessage.scala' class='org.apache.spark.deploy.DeployMessages$WorkerStateResponse$'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.Docker'></ClassStats><ClassStats bugs='2' size='38' priority_2='2' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.Docker$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.Docker$$anonfun$getLastProcessId$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.Docker$$anonfun$makeRunCmd$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.DockerId'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='DriverDescription.scala' class='org.apache.spark.deploy.DriverDescription'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DriverDescription.scala' class='org.apache.spark.deploy.DriverDescription$'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ExecutorDescription.scala' class='org.apache.spark.deploy.ExecutorDescription'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='ExecutorState.scala' class='org.apache.spark.deploy.ExecutorState'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ExecutorState.scala' class='org.apache.spark.deploy.ExecutorState$'></ClassStats><ClassStats bugs='0' size='77' interface='false' sourceFile='ExternalShuffleService.scala' class='org.apache.spark.deploy.ExternalShuffleService'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='ExternalShuffleService.scala' class='org.apache.spark.deploy.ExternalShuffleService$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExternalShuffleService.scala' class='org.apache.spark.deploy.ExternalShuffleService$$anonfun$main$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalShuffleService.scala' class='org.apache.spark.deploy.ExternalShuffleService$$anonfun$main$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalShuffleService.scala' class='org.apache.spark.deploy.ExternalShuffleService$$anonfun$main$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalShuffleService.scala' class='org.apache.spark.deploy.ExternalShuffleService$$anonfun$main$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalShuffleService.scala' class='org.apache.spark.deploy.ExternalShuffleService$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalShuffleService.scala' class='org.apache.spark.deploy.ExternalShuffleService$$anonfun$start$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExternalShuffleServiceSource.scala' class='org.apache.spark.deploy.ExternalShuffleServiceSource'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest'></ClassStats><ClassStats bugs='0' size='166' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$11'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$2'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$3'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$4'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$5'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$6$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$7'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$7$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='1' size='14' priority_3='1' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$8$$anonfun$apply$mcZ$sp$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$9$$anonfun$apply$mcZ$sp$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$getMasterUrls$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$addMasters$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$addMasters$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$addWorkers$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$addWorkers$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$assertValidClusterState$4$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$createClient$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$killLeader$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$killLeader$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$stateValid$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$terminateCluster$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$terminateCluster$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$org$apache$spark$deploy$FaultToleranceTest$$terminateCluster$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$test$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$test$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$test$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$test$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$test$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$$anonfun$test$6'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.FaultToleranceTest$delayedInit$body'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkApplication.scala' class='org.apache.spark.deploy.JavaMainApplication'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkApplication.scala' class='org.apache.spark.deploy.JavaMainApplication$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol'></ClassStats><ClassStats bugs='0' size='72' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationDescription$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationDescription$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationDescription$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationDescription$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationDescription$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationDescription$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeApplicationInfo$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeDriverInfo$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeExecutorRunner$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeExecutorRunner$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeExecutorRunner$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$19'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeMasterState$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerInfo$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.deploy.JsonProtocol$$anonfun$writeWorkerState$9'></ClassStats><ClassStats bugs='0' size='64' interface='false' sourceFile='LocalSparkCluster.scala' class='org.apache.spark.deploy.LocalSparkCluster'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LocalSparkCluster.scala' class='org.apache.spark.deploy.LocalSparkCluster$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='LocalSparkCluster.scala' class='org.apache.spark.deploy.LocalSparkCluster$$anonfun$start$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalSparkCluster.scala' class='org.apache.spark.deploy.LocalSparkCluster$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalSparkCluster.scala' class='org.apache.spark.deploy.LocalSparkCluster$$anonfun$stop$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalSparkCluster.scala' class='org.apache.spark.deploy.LocalSparkCluster$$anonfun$stop$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalSparkCluster.scala' class='org.apache.spark.deploy.LocalSparkCluster$$anonfun$stop$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalSparkCluster.scala' class='org.apache.spark.deploy.LocalSparkCluster$$anonfun$stop$5'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.OptionAssigner'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.OptionAssigner$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner'></ClassStats><ClassStats bugs='1' size='65' priority_2='1' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$5'></ClassStats><ClassStats bugs='1' size='7' priority_2='1' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$formatPaths$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$formatPaths$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$formatPaths$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$main$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$main$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PythonRunner.scala' class='org.apache.spark.deploy.PythonRunner$$anonfun$main$3'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils'></ClassStats><ClassStats bugs='5' size='123' priority_2='5' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anon$1$$anonfun$accept$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anon$1$$anonfun$accept$2'></ClassStats><ClassStats bugs='1' size='16' priority_2='1' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$checkAndBuildRPackage$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$org$apache$spark$deploy$RPackageUtils$$listFilesRecursively$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$org$apache$spark$deploy$RPackageUtils$$print$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$org$apache$spark$deploy$RPackageUtils$$print$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$org$apache$spark$deploy$RPackageUtils$$print$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$org$apache$spark$deploy$RPackageUtils$$print$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$zipRLibraries$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RPackageUtils.scala' class='org.apache.spark.deploy.RPackageUtils$$anonfun$zipRLibraries$2'></ClassStats><ClassStats bugs='0' size='2' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner'></ClassStats><ClassStats bugs='2' size='47' priority_1='1' priority_2='1' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RRunner.scala' class='org.apache.spark.deploy.RRunner$$anonfun$6'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='SparkApplication.scala' class='org.apache.spark.deploy.SparkApplication'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='SparkCuratorUtil.scala' class='org.apache.spark.deploy.SparkCuratorUtil'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='SparkCuratorUtil.scala' class='org.apache.spark.deploy.SparkCuratorUtil$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkCuratorUtil.scala' class='org.apache.spark.deploy.SparkCuratorUtil$$anonfun$deleteRecursive$1'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.SparkDocker'></ClassStats><ClassStats bugs='1' size='27' priority_2='1' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.SparkDocker$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.SparkDocker$$anonfun$startNode$1'></ClassStats><ClassStats bugs='1' size='182' priority_2='1' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anon$1$$anonfun$apply$mcJ$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anon$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anon$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anon$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$1$$anonfun$apply$mcJ$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$2$$anonfun$apply$mcJ$sp$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$5'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$6$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$addDelegationTokens$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$appendSparkHadoopConfigs$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$appendSparkHadoopConfigs$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$appendSparkHadoopConfigs$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$checkAccessPermission$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$createSparkUser$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$dumpTokens$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFSBytesWrittenOnThreadCallback$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$globPath$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$globPath$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$globPath$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$isGlobPath$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$listFilesSorted$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$loginUserFromKeytab$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$org$apache$spark$deploy$SparkHadoopUtil$$appendSparkHadoopConfigs$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$org$apache$spark$deploy$SparkHadoopUtil$$appendSparkHadoopConfigs$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$org$apache$spark$deploy$SparkHadoopUtil$$appendSparkHadoopConfigs$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$recurse$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$recurse$2$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$substituteHadoopVariables$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$substituteHadoopVariables$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopUtil.scala' class='org.apache.spark.deploy.SparkHadoopUtil$$anonfun$tokenToString$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit'></ClassStats><ClassStats bugs='5' size='535' priority_2='5' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$org$apache$spark$deploy$SparkSubmit$$runMain$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$10'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$11$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$12$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$13$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$14$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$17'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$21'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$22'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$23'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$23$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$6'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$8'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmit$$anonfun$shouldDownload$1$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitAction'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitAction$'></ClassStats><ClassStats bugs='0' size='458' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$defaultSparkProperties$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$defaultSparkProperties$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$defaultSparkProperties$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$getSqlShellOptions$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$ignoreNonSparkProperties$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$17'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$20'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$21'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$22'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$23'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$25'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$26'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$28'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$29'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$30'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$31'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$loadEnvironmentArguments$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$mergeDefaultSparkProperties$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$mergeDefaultSparkProperties$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmitArguments.scala' class='org.apache.spark.deploy.SparkSubmitArguments$$anonfun$validateSubmitArguments$9'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils'></ClassStats><ClassStats bugs='2' size='137' priority_2='2' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$addDependenciesToIvy$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$addExclusionRules$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$extractMavenCoordinates$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$extractMavenCoordinates$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$extractMavenCoordinates$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$extractMavenCoordinates$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$extractMavenCoordinates$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$loadIvySettings$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$loadIvySettings$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$1'></ClassStats><ClassStats bugs='2' size='9' priority_2='2' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processIvyPathArg$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processRemoteRepoArg$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processRemoteRepoArg$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processRemoteRepoArg$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processRemoteRepoArg$3$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$processRemoteRepoArg$3$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$resolveDependencyPaths$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$$anonfun$resolveMavenCoordinates$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$MavenCoordinate'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkSubmit.scala' class='org.apache.spark.deploy.SparkSubmitUtils$MavenCoordinate$'></ClassStats><ClassStats bugs='1' size='65' priority_2='1' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.TestMasterInfo'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.TestMasterInfo$$anonfun$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.TestMasterInfo$$anonfun$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.TestMasterInfo$$anonfun$readState$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.TestMasterInfo$$anonfun$readState$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.TestMasterInfo$$anonfun$readState$3'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.TestWorkerInfo'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FaultToleranceTest.scala' class='org.apache.spark.deploy.TestWorkerInfo$$anonfun$14'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy.client' total_bugs='0' total_size='441' total_types='32'><ClassStats bugs='0' size='69' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$$anonfun$killExecutors$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$$anonfun$requestTotalExecutors$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='103' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$2$$anonfun$run$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anon$2$$anonfun$run$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$onDisconnected$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$onDisconnected$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$onNetworkError$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$onStart$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$onStop$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$org$apache$spark$deploy$client$StandaloneAppClient$ClientEndpoint$$askAndReplyAsync$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$org$apache$spark$deploy$client$StandaloneAppClient$ClientEndpoint$$sendToMaster$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$5'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneAppClient.scala' class='org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='StandaloneAppClientListener.scala' class='org.apache.spark.deploy.client.StandaloneAppClientListener'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy.history' priority_1='2' total_bugs='13' priority_2='8' priority_3='3' total_size='2703' total_types='182'><ClassStats bugs='0' size='38' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.AppListingListener'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.AppListingListener$MutableApplicationInfo'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.AppListingListener$MutableAttemptInfo'></ClassStats><ClassStats bugs='0' size='110' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anon$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anon$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anon$2$$anonfun$onRemoval$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$get$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$org$apache$spark$deploy$history$ApplicationCache$$loadApplicationEntry$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$org$apache$spark$deploy$history$ApplicationCache$$loadApplicationEntry$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$registerFilter$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$registerFilter$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCache$$anonfun$toString$1'></ClassStats><ClassStats bugs='3' size='50' priority_1='1' priority_2='1' priority_3='1' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCacheCheckFilter'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCacheCheckFilter$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCacheCheckFilter$$anonfun$4'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.ApplicationCacheOperations'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ApplicationHistoryProvider.scala' class='org.apache.spark.deploy.history.ApplicationHistoryProvider'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.ApplicationInfoWrapper'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.ApplicationInfoWrapper$$anonfun$24'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.ApplicationInfoWrapper$$anonfun$oldestAttempt$1'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.ApplicationStoreInfo'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.ApplicationStoreInfo$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.AttemptInfoWrapper'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.CacheEntry'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.CacheKey'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.CacheKey$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.CacheKey$$anonfun$toString$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.CacheKey$$anonfun$toString$3'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.CacheMetrics'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.CacheMetrics$$anonfun$init$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApplicationCache.scala' class='org.apache.spark.deploy.history.CacheMetrics$$anonfun$toString$4'></ClassStats><ClassStats bugs='0' size='361' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anon$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anon$2$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$11'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$12$$anon$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$12$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$14'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$15'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$15$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$15$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$17'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$19'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$20'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$21'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$21$$anonfun$apply$19'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$22'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$23'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$3$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$3$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$3$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$2$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$3$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$4$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$checkForLogs$5'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$cleanLogs$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$cleanLogs$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$cleanLogs$1$$anonfun$apply$mcV$sp$1$$anonfun$18'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$cleanLogs$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$cleanLogs$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$13$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$cleanLogs$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$cleanLogs$1$$anonfun$apply$mcV$sp$2$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAppUI$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAttempt$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getAttempt$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getListing$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getNewLastScanTime$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$getNewLastScanTime$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$loadDiskStore$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$loadDiskStore$1$$anonfun$apply$18'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$loadDiskStore$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$onUIDetached$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$onUIDetached$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$deleteLog$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$deleteLog$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$rebuildAppStore$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$rebuildAppStore$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$rebuildAppStore$2$$anonfun$apply$17'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$startPolling$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$startPolling$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$startPolling$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$startPolling$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$org$apache$spark$deploy$history$FsHistoryProvider$$startPolling$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$replay$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$replay$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$replay$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$replay$3$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$startSafeModeCheckThread$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$startSafeModeCheckThread$1$$anon$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$startSafeModeCheckThread$1$$anon$3$$anonfun$uncaughtException$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$stop$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$writeEventLogs$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$writeEventLogs$1$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$writeEventLogs$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$writeEventLogs$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProvider$$anonfun$writeEventLogs$4'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProviderMetadata'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.FsHistoryProviderMetadata$'></ClassStats><ClassStats bugs='1' size='51' priority_3='1' interface='false' sourceFile='HistoryPage.scala' class='org.apache.spark.deploy.history.HistoryPage'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryPage.scala' class='org.apache.spark.deploy.history.HistoryPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HistoryPage.scala' class='org.apache.spark.deploy.history.HistoryPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryPage.scala' class='org.apache.spark.deploy.history.HistoryPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HistoryPage.scala' class='org.apache.spark.deploy.history.HistoryPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='78' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$'></ClassStats><ClassStats bugs='4' size='21' priority_1='1' priority_2='2' priority_3='1' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$1'></ClassStats><ClassStats bugs='1' size='8' priority_2='1' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anon$1$$anonfun$doGet$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$attachSparkUI$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$attachSparkUI$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$createSecurityManager$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$createSecurityManager$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$detachSparkUI$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$detachSparkUI$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$main$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServer.scala' class='org.apache.spark.deploy.history.HistoryServer$$anonfun$org$apache$spark$deploy$history$HistoryServer$$loadAppUi$1'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='HistoryServerArguments.scala' class='org.apache.spark.deploy.history.HistoryServerArguments'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServerArguments.scala' class='org.apache.spark.deploy.history.HistoryServerArguments$$anonfun$setLogDirectory$1'></ClassStats><ClassStats bugs='1' size='129' priority_2='1' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager'></ClassStats><ClassStats bugs='1' size='7' priority_2='1' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$1'></ClassStats><ClassStats bugs='1' size='11' priority_2='1' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$initialize$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$initialize$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$initialize$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$lease$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$openStore$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$org$apache$spark$deploy$history$HistoryServerDiskManager$$makeRoom$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$org$apache$spark$deploy$history$HistoryServerDiskManager$$makeRoom$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$org$apache$spark$deploy$history$HistoryServerDiskManager$$makeRoom$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$org$apache$spark$deploy$history$HistoryServerDiskManager$$makeRoom$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$org$apache$spark$deploy$history$HistoryServerDiskManager$$makeRoom$5'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$$anonfun$release$1'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$Lease'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$Lease$$anonfun$commit$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='HistoryServerDiskManager.scala' class='org.apache.spark.deploy.history.HistoryServerDiskManager$Lease$$anonfun$commit$2'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='ApplicationHistoryProvider.scala' class='org.apache.spark.deploy.history.LoadedAppUI'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ApplicationHistoryProvider.scala' class='org.apache.spark.deploy.history.LoadedAppUI$'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.LogInfo'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FsHistoryProvider.scala' class='org.apache.spark.deploy.history.LogInfo$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='config.scala' class='org.apache.spark.deploy.history.config'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='config.scala' class='org.apache.spark.deploy.history.config$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy.master' total_bugs='4' priority_2='4' total_size='2914' total_types='201'><ClassStats bugs='0' size='114' interface='false' sourceFile='ApplicationInfo.scala' class='org.apache.spark.deploy.master.ApplicationInfo'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApplicationInfo.scala' class='org.apache.spark.deploy.master.ApplicationInfo$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationInfo.scala' class='org.apache.spark.deploy.master.ApplicationInfo$$anonfun$org$apache$spark$deploy$master$ApplicationInfo$$init$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ApplicationInfo.scala' class='org.apache.spark.deploy.master.ApplicationInfo$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='ApplicationSource.scala' class='org.apache.spark.deploy.master.ApplicationSource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationSource.scala' class='org.apache.spark.deploy.master.ApplicationSource$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationSource.scala' class='org.apache.spark.deploy.master.ApplicationSource$$anon$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationSource.scala' class='org.apache.spark.deploy.master.ApplicationSource$$anon$3'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ApplicationState.scala' class='org.apache.spark.deploy.master.ApplicationState'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='ApplicationState.scala' class='org.apache.spark.deploy.master.ApplicationState$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PersistenceEngine.scala' class='org.apache.spark.deploy.master.BlackHolePersistenceEngine'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='DriverInfo.scala' class='org.apache.spark.deploy.master.DriverInfo'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DriverInfo.scala' class='org.apache.spark.deploy.master.DriverInfo$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='DriverState.scala' class='org.apache.spark.deploy.master.DriverState'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='DriverState.scala' class='org.apache.spark.deploy.master.DriverState$'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='ExecutorDesc.scala' class='org.apache.spark.deploy.master.ExecutorDesc'></ClassStats><ClassStats bugs='4' size='57' priority_2='4' interface='false' sourceFile='FileSystemPersistenceEngine.scala' class='org.apache.spark.deploy.master.FileSystemPersistenceEngine'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileSystemPersistenceEngine.scala' class='org.apache.spark.deploy.master.FileSystemPersistenceEngine$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileSystemPersistenceEngine.scala' class='org.apache.spark.deploy.master.FileSystemPersistenceEngine$$anonfun$read$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='FileSystemPersistenceEngine.scala' class='org.apache.spark.deploy.master.FileSystemPersistenceEngine$$anonfun$serializeIntoFile$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='FileSystemPersistenceEngine.scala' class='org.apache.spark.deploy.master.FileSystemPersistenceEngine$$anonfun$serializeIntoFile$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileSystemPersistenceEngine.scala' class='org.apache.spark.deploy.master.FileSystemPersistenceEngine$$anonfun$unpersist$1'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='RecoveryModeFactory.scala' class='org.apache.spark.deploy.master.FileSystemRecoveryModeFactory'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RecoveryModeFactory.scala' class='org.apache.spark.deploy.master.FileSystemRecoveryModeFactory$$anonfun$createPersistenceEngine$1'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='LeaderElectionAgent.scala' class='org.apache.spark.deploy.master.LeaderElectable'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='LeaderElectionAgent.scala' class='org.apache.spark.deploy.master.LeaderElectionAgent'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='LeaderElectionAgent.scala' class='org.apache.spark.deploy.master.LeaderElectionAgent$class'></ClassStats><ClassStats bugs='0' size='454' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$19'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$20'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$21'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onDisconnected$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onDisconnected$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onDisconnected$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onStart$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onStart$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onStart$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onStart$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onStart$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onStart$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$onStop$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$allocateWorkerResourceToExecutors$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$beginRecovery$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$beginRecovery$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$beginRecovery$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$beginRecovery$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$beginRecovery$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$beginRecovery$3$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$beginRecovery$3$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$canCompleteRecovery$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$canCompleteRecovery$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$7'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$8$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$8$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$8$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$completeRecovery$9'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$formatExecutorIds$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$formatExecutorIds$1$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$handleKillExecutors$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$handleKillExecutors$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$handleKillExecutors$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$handleKillExecutors$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$handleRequestExecutors$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$handleRequestExecutors$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$launchDriver$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$launchExecutor$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$registerApplication$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$registerWorker$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$registerWorker$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$registerWorker$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeDriver$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeDriver$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeDriver$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$2$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$3$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$3$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$removeWorker$6'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$schedule$1'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$scheduleExecutorsOnWorkers$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$scheduleExecutorsOnWorkers$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$timeOutDeadWorkers$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$org$apache$spark$deploy$master$Master$$timeOutDeadWorkers$1$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='122' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anon$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anon$2$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$10'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$12'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$13'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$17'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$18'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$19$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$19$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$20'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$21'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$21$$anonfun$11'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$22'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$22$$anonfun$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$23'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$25'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receive$1$$anonfun$applyOrElse$9'></ClassStats><ClassStats bugs='0' size='65' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$26'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$27'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$28'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$29'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$30'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$32'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$removeApplication$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$removeApplication$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$removeApplication$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$removeApplication$4'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$startExecutorsOnWorkers$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$startExecutorsOnWorkers$1$$anonfun$16'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$startExecutorsOnWorkers$1$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$startExecutorsOnWorkers$1$$anonfun$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$startExecutorsOnWorkers$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$startExecutorsOnWorkers$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Master.scala' class='org.apache.spark.deploy.master.Master$$anonfun$startExecutorsOnWorkers$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='78' interface='false' sourceFile='MasterArguments.scala' class='org.apache.spark.deploy.master.MasterArguments'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterArguments.scala' class='org.apache.spark.deploy.master.MasterArguments$$anonfun$1'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$BeginRecovery'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$BeginRecovery$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$BoundPortsRequest$'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$BoundPortsResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$BoundPortsResponse$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$CheckForWorkerTimeOut$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$CompleteRecovery$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$ElectedLeader$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MasterMessages.scala' class='org.apache.spark.deploy.master.MasterMessages$RevokedLeadership$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='MasterSource.scala' class='org.apache.spark.deploy.master.MasterSource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterSource.scala' class='org.apache.spark.deploy.master.MasterSource$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterSource.scala' class='org.apache.spark.deploy.master.MasterSource$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterSource.scala' class='org.apache.spark.deploy.master.MasterSource$$anon$2$$anonfun$getValue$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterSource.scala' class='org.apache.spark.deploy.master.MasterSource$$anon$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterSource.scala' class='org.apache.spark.deploy.master.MasterSource$$anon$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterSource.scala' class='org.apache.spark.deploy.master.MasterSource$$anon$4$$anonfun$getValue$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LeaderElectionAgent.scala' class='org.apache.spark.deploy.master.MonarchyLeaderAgent'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='PersistenceEngine.scala' class='org.apache.spark.deploy.master.PersistenceEngine'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PersistenceEngine.scala' class='org.apache.spark.deploy.master.PersistenceEngine$$anonfun$readPersistedData$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='RecoveryState.scala' class='org.apache.spark.deploy.master.RecoveryState'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RecoveryState.scala' class='org.apache.spark.deploy.master.RecoveryState$'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='RecoveryModeFactory.scala' class='org.apache.spark.deploy.master.StandaloneRecoveryModeFactory'></ClassStats><ClassStats bugs='0' size='90' interface='false' sourceFile='WorkerInfo.scala' class='org.apache.spark.deploy.master.WorkerInfo'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerInfo.scala' class='org.apache.spark.deploy.master.WorkerInfo$$anonfun$hasExecutor$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='WorkerInfo.scala' class='org.apache.spark.deploy.master.WorkerInfo$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='WorkerState.scala' class='org.apache.spark.deploy.master.WorkerState'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WorkerState.scala' class='org.apache.spark.deploy.master.WorkerState$'></ClassStats><ClassStats bugs='0' size='72' interface='false' sourceFile='ZooKeeperLeaderElectionAgent.scala' class='org.apache.spark.deploy.master.ZooKeeperLeaderElectionAgent'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ZooKeeperLeaderElectionAgent.scala' class='org.apache.spark.deploy.master.ZooKeeperLeaderElectionAgent$$anonfun$isLeader$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ZooKeeperLeaderElectionAgent.scala' class='org.apache.spark.deploy.master.ZooKeeperLeaderElectionAgent$$anonfun$notLeader$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ZooKeeperLeaderElectionAgent.scala' class='org.apache.spark.deploy.master.ZooKeeperLeaderElectionAgent$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ZooKeeperLeaderElectionAgent.scala' class='org.apache.spark.deploy.master.ZooKeeperLeaderElectionAgent$LeadershipStatus$'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='ZooKeeperPersistenceEngine.scala' class='org.apache.spark.deploy.master.ZooKeeperPersistenceEngine'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ZooKeeperPersistenceEngine.scala' class='org.apache.spark.deploy.master.ZooKeeperPersistenceEngine$$anonfun$org$apache$spark$deploy$master$ZooKeeperPersistenceEngine$$deserializeFromFile$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ZooKeeperPersistenceEngine.scala' class='org.apache.spark.deploy.master.ZooKeeperPersistenceEngine$$anonfun$read$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ZooKeeperPersistenceEngine.scala' class='org.apache.spark.deploy.master.ZooKeeperPersistenceEngine$$anonfun$read$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RecoveryModeFactory.scala' class='org.apache.spark.deploy.master.ZooKeeperRecoveryModeFactory'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy.master.ui' total_bugs='3' priority_3='3' total_size='629' total_types='44'><ClassStats bugs='1' size='100' priority_3='1' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage$$anonfun$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationPage.scala' class='org.apache.spark.deploy.master.ui.ApplicationPage$$anonfun$render$2'></ClassStats><ClassStats bugs='2' size='214' priority_3='2' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$12'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$9'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$handleAppKillRequest$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$handleAppKillRequest$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$handleDriverKillRequest$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$org$apache$spark$deploy$master$ui$MasterPage$$driverRow$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterPage.scala' class='org.apache.spark.deploy.master.ui.MasterPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MasterWebUI.scala' class='org.apache.spark.deploy.master.ui.MasterWebUI$$anonfun$idToUiAddress$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy.rest' total_bugs='4' priority_2='4' total_size='1308' total_types='100'><ClassStats bugs='0' size='45' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.CreateSubmissionRequest'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.CreateSubmissionRequest$$anonfun$assertProperty$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.CreateSubmissionRequest$$anonfun$assertProperty$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.CreateSubmissionRequest$$anonfun$assertProperty$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.CreateSubmissionRequest$$anonfun$assertPropertyIsBoolean$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.CreateSubmissionRequest$$anonfun$assertPropertyIsMemory$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.CreateSubmissionRequest$$anonfun$assertPropertyIsNumeric$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.CreateSubmissionRequest$$anonfun$assertPropertyIsSet$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SubmitRestProtocolResponse.scala' class='org.apache.spark.deploy.rest.CreateSubmissionResponse'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SubmitRestProtocolResponse.scala' class='org.apache.spark.deploy.rest.ErrorResponse'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.ErrorServlet'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.ErrorServlet$$anonfun$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.KillRequestServlet'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.KillRequestServlet$$anonfun$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.KillRequestServlet$$anonfun$4'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SubmitRestProtocolResponse.scala' class='org.apache.spark.deploy.rest.KillSubmissionResponse'></ClassStats><ClassStats bugs='1' size='53' priority_2='1' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestServlet'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestServlet$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestServlet$$anonfun$findUnknownFields$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestServlet$$anonfun$parseSubmissionId$1'></ClassStats><ClassStats bugs='3' size='147' priority_2='3' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$createSubmission$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$createSubmission$2'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$createSubmission$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$filterSystemEnvironment$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$getBaseUrl$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$killSubmission$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$killSubmission$2'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$killSubmission$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$get$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$handleConnectionException$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$handleRestResponse$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$handleUnexpectedRestResponse$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$post$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$postJson$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$postJson$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$postJson$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$reportSubmissionStatus$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$reportSubmissionStatus$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$org$apache$spark$deploy$rest$RestSubmissionClient$$reportSubmissionStatus$3'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$pollSubmissionStatus$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$pollSubmissionStatus$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$pollSubmissionStatus$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$pollSubmissionStatus$1$$anonfun$apply$mcVI$sp$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$pollSubmissionStatus$1$$anonfun$apply$mcVI$sp$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$pollSubmissionStatus$1$$anonfun$apply$mcVI$sp$4$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$pollSubmissionStatus$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$requestSubmissionStatus$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$requestSubmissionStatus$2'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClient$$anonfun$requestSubmissionStatus$3'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClientApp'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionClient.scala' class='org.apache.spark.deploy.rest.RestSubmissionClientApp$$anonfun$5'></ClassStats><ClassStats bugs='0' size='82' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestSubmissionServer'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestSubmissionServer$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestSubmissionServer$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestSubmissionServer$$anonfun$org$apache$spark$deploy$rest$RestSubmissionServer$$doStart$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestSubmissionServer$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.RestSubmissionServer$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneKillRequestServlet'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneRestServer'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneStatusRequestServlet'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneStatusRequestServlet$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneStatusRequestServlet$$anonfun$handleStatus$1'></ClassStats><ClassStats bugs='0' size='57' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneRestServer.scala' class='org.apache.spark.deploy.rest.StandaloneSubmitRequestServlet$$anonfun$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.StatusRequestServlet'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.StatusRequestServlet$$anonfun$5'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.StatusRequestServlet$$anonfun$6'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='SubmitRestProtocolResponse.scala' class='org.apache.spark.deploy.rest.SubmissionStatusResponse'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RestSubmissionServer.scala' class='org.apache.spark.deploy.rest.SubmitRequestServlet'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='SubmitRestProtocolException.scala' class='org.apache.spark.deploy.rest.SubmitRestConnectionException'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='SubmitRestProtocolException.scala' class='org.apache.spark.deploy.rest.SubmitRestMissingFieldException'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='SubmitRestProtocolException.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolException'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SubmitRestProtocolException.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolException$'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='SubmitRestProtocolMessage.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolMessage'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='SubmitRestProtocolMessage.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolMessage$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SubmitRestProtocolMessage.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolMessage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SubmitRestProtocolMessage.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolMessage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SubmitRestProtocolMessage.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolMessage$$anonfun$parseAction$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SubmitRestProtocolRequest.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolRequest'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='SubmitRestProtocolResponse.scala' class='org.apache.spark.deploy.rest.SubmitRestProtocolResponse'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy.security' total_bugs='0' total_size='623' total_types='51'><ClassStats bugs='0' size='50' interface='false' sourceFile='HBaseDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HBaseDelegationTokenProvider'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HBaseDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HBaseDelegationTokenProvider$$anonfun$hbaseConf$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HBaseDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HBaseDelegationTokenProvider$$anonfun$obtainDelegationTokens$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HBaseDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HBaseDelegationTokenProvider$$anonfun$obtainDelegationTokens$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HBaseDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HBaseDelegationTokenProvider$$anonfun$obtainDelegationTokens$3'></ClassStats><ClassStats bugs='0' size='71' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$$lessinit$greater$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$4$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$4$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$getDelegationTokenProviders$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$getDelegationTokenProviders$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$isServiceEnabled$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$isServiceEnabled$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$isServiceEnabled$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$isServiceEnabled$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$obtainDelegationTokens$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$obtainDelegationTokens$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$obtainDelegationTokens$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopDelegationTokenManager.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenManager$$anonfun$safeCreateProvider$1'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='HadoopDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopDelegationTokenProvider'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$getTokenRenewalInterval$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$getTokenRenewalInterval$1$$anonfun$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$getTokenRenewalInterval$1$$anonfun$5'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$getTokenRenewalInterval$1$$anonfun$5$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$getTokenRenewalInterval$1$$anonfun$5$$anonfun$apply$1$$anonfun$apply$mcJ$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$getTokenRenewer$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$getTokenRenewer$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$org$apache$spark$deploy$security$HadoopFSDelegationTokenProvider$$fetchDelegationTokens$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopFSDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HadoopFSDelegationTokenProvider$$anonfun$org$apache$spark$deploy$security$HadoopFSDelegationTokenProvider$$fetchDelegationTokens$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='72' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$doAsRealUser$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$hiveConf$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$hiveConf$2'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$obtainDelegationTokens$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$obtainDelegationTokens$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$obtainDelegationTokens$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$obtainDelegationTokens$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$obtainDelegationTokens$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$obtainDelegationTokens$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$obtainDelegationTokens$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HiveDelegationTokenProvider.scala' class='org.apache.spark.deploy.security.HiveDelegationTokenProvider$$anonfun$obtainDelegationTokens$7'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy.worker' total_bugs='10' priority_2='10' total_size='2502' total_types='166'><ClassStats bugs='0' size='38' interface='false' sourceFile='CommandUtils.scala' class='org.apache.spark.deploy.worker.CommandUtils'></ClassStats><ClassStats bugs='1' size='62' priority_2='1' interface='false' sourceFile='CommandUtils.scala' class='org.apache.spark.deploy.worker.CommandUtils$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='CommandUtils.scala' class='org.apache.spark.deploy.worker.CommandUtils$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CommandUtils.scala' class='org.apache.spark.deploy.worker.CommandUtils$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CommandUtils.scala' class='org.apache.spark.deploy.worker.CommandUtils$$anonfun$buildLocalCommand$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CommandUtils.scala' class='org.apache.spark.deploy.worker.CommandUtils$$anonfun$buildProcessBuilder$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CommandUtils.scala' class='org.apache.spark.deploy.worker.CommandUtils$$anonfun$buildProcessBuilder$2'></ClassStats><ClassStats bugs='2' size='152' priority_2='2' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anon$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anon$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anon$2$$anonfun$sleep$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anonfun$downloadUserJar$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anonfun$kill$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anonfun$kill$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anonfun$kill$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anonfun$runCommandWithRetry$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anonfun$runCommandWithRetry$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.DriverRunner$$anonfun$runDriver$1'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='DriverWrapper.scala' class='org.apache.spark.deploy.worker.DriverWrapper'></ClassStats><ClassStats bugs='1' size='65' priority_2='1' interface='false' sourceFile='DriverWrapper.scala' class='org.apache.spark.deploy.worker.DriverWrapper$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DriverWrapper.scala' class='org.apache.spark.deploy.worker.DriverWrapper$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DriverWrapper.scala' class='org.apache.spark.deploy.worker.DriverWrapper$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DriverWrapper.scala' class='org.apache.spark.deploy.worker.DriverWrapper$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DriverWrapper.scala' class='org.apache.spark.deploy.worker.DriverWrapper$$anonfun$main$1'></ClassStats><ClassStats bugs='0' size='168' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$killProcess$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$killProcess$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anonfun$org$apache$spark$deploy$worker$ExecutorRunner$$killProcess$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExecutorRunner.scala' class='org.apache.spark.deploy.worker.ExecutorRunner$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.ProcessBuilderLike'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.ProcessBuilderLike$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.ProcessBuilderLike$$anon$3'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='DriverRunner.scala' class='org.apache.spark.deploy.worker.Sleeper'></ClassStats><ClassStats bugs='3' size='420' priority_2='3' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker'></ClassStats><ClassStats bugs='0' size='72' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anon$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anon$4$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anon$4$$anonfun$run$2$$anonfun$apply$mcV$sp$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anon$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anon$5$$anonfun$run$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anon$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anon$6$$anonfun$run$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$17'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$6'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$createWorkDir$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleDriverStateChanged$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleDriverStateChanged$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleDriverStateChanged$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleDriverStateChanged$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleDriverStateChanged$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$2$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$2$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$2$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$handleExecutorStateChanged$2$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$isUseLocalNodeSSLConfig$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$main$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$masterDisconnected$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onDisconnected$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onDisconnected$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onDisconnected$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onStart$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onStart$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onStart$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onStart$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onStop$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$onStop$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$cancelLastRegistrationRetry$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$cancelLastRegistrationRetry$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$changeMaster$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$handleRegisterResponse$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$handleRegisterResponse$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$handleRegisterResponse$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$handleRegisterResponse$4'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='1' size='7' priority_2='1' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$9'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$maybeCleanupApplication$1$$anonfun$apply$5$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$registerWithMaster$1'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2$$anonfun$run$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$2$$anonfun$run$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anon$3$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$reregisterWithMaster$1$$anonfun$apply$mcV$sp$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$sendToMaster$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters$1$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters$1$$anon$1$$anonfun$run$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$org$apache$spark$deploy$worker$Worker$$tryRegisterAllMasters$1$$anon$1$$anonfun$run$6'></ClassStats><ClassStats bugs='1' size='106' priority_2='1' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$1$$anonfun$apply$mcV$sp$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$1$$anonfun$apply$mcV$sp$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$1$$anonfun$apply$mcV$sp$8$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$10'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$10$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$10$$anonfun$11$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receive$1$$anonfun$applyOrElse$9'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$startExternalShuffleService$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$trimFinishedDriversIfNecessary$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Worker.scala' class='org.apache.spark.deploy.worker.Worker$$anonfun$trimFinishedExecutorsIfNecessary$1'></ClassStats><ClassStats bugs='0' size='115' interface='false' sourceFile='WorkerArguments.scala' class='org.apache.spark.deploy.worker.WorkerArguments'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='WorkerSource.scala' class='org.apache.spark.deploy.worker.WorkerSource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerSource.scala' class='org.apache.spark.deploy.worker.WorkerSource$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerSource.scala' class='org.apache.spark.deploy.worker.WorkerSource$$anon$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerSource.scala' class='org.apache.spark.deploy.worker.WorkerSource$$anon$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerSource.scala' class='org.apache.spark.deploy.worker.WorkerSource$$anon$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerSource.scala' class='org.apache.spark.deploy.worker.WorkerSource$$anon$5'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher$$anonfun$onConnected$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher$$anonfun$onDisconnected$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher$$anonfun$onNetworkError$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher$$anonfun$onNetworkError$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerWatcher.scala' class='org.apache.spark.deploy.worker.WorkerWatcher$$anonfun$receive$1$$anonfun$applyOrElse$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.deploy.worker.ui' total_bugs='15' priority_2='3' priority_3='12' total_size='466' total_types='27'><ClassStats bugs='15' size='122' priority_2='3' priority_3='12' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$getLog$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$getLog$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$getLog$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$getLog$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LogPage.scala' class='org.apache.spark.deploy.worker.ui.LogPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='141' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$driverRow$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$driverRow$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerPage.scala' class='org.apache.spark.deploy.worker.ui.WorkerPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='WorkerWebUI.scala' class='org.apache.spark.deploy.worker.ui.WorkerWebUI'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='WorkerWebUI.scala' class='org.apache.spark.deploy.worker.ui.WorkerWebUI$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerWebUI.scala' class='org.apache.spark.deploy.worker.ui.WorkerWebUI$$anonfun$initialize$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.executor' total_bugs='4' priority_2='4' total_size='2133' total_types='120'><ClassStats bugs='0' size='94' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend'></ClassStats><ClassStats bugs='0' size='73' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$exitExecutor$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$exitExecutor$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$extractLogUrls$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$extractLogUrls$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$onDisconnected$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$onDisconnected$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$onDisconnected$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$onStart$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$onStart$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$onStart$3'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1$$anonfun$applyOrElse$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1$$anonfun$applyOrElse$4'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1$$anonfun$apply$mcV$sp$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedExecutorBackend.scala' class='org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$statusUpdate$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='CommitDeniedException.scala' class='org.apache.spark.executor.CommitDeniedException'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='InputMetrics.scala' class='org.apache.spark.executor.DataReadMethod'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='InputMetrics.scala' class='org.apache.spark.executor.DataReadMethod$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='OutputMetrics.scala' class='org.apache.spark.executor.DataWriteMethod'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='OutputMetrics.scala' class='org.apache.spark.executor.DataWriteMethod$'></ClassStats><ClassStats bugs='0' size='210' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anon$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1'></ClassStats><ClassStats bugs='1' size='7' priority_2='1' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$addReplClassLoaderIfNeeded$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$addReplClassLoaderIfNeeded$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$createClassLoader$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$killAllTasks$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$killTask$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$computeTotalGcTime$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$reportHeartBeat$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$reportHeartBeat$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$reportHeartBeat$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$reportHeartBeat$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='1' size='13' priority_2='1' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$3$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$4'></ClassStats><ClassStats bugs='2' size='23' priority_2='2' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$11'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$$anonfun$org$apache$spark$executor$Executor$$updateDependencies$5$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskReaper'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskReaper$$anonfun$run$10'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskReaper$$anonfun$run$11'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskReaper$$anonfun$run$11$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskReaper$$anonfun$run$12'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskReaper$$anonfun$run$13'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskReaper$$anonfun$run$14'></ClassStats><ClassStats bugs='0' size='235' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$kill$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$4$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Executor.scala' class='org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$9'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ExecutorBackend.scala' class='org.apache.spark.executor.ExecutorBackend'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorExitCode.scala' class='org.apache.spark.executor.ExecutorExitCode'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='ExecutorExitCode.scala' class='org.apache.spark.executor.ExecutorExitCode$'></ClassStats><ClassStats bugs='0' size='112' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anon$1$$anonfun$getValue$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anon$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anon$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anon$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anon$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anonfun$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anonfun$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anonfun$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anonfun$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anonfun$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorSource.scala' class='org.apache.spark.executor.ExecutorSource$$anonfun$org$apache$spark$executor$ExecutorSource$$fileStats$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='InputMetrics.scala' class='org.apache.spark.executor.InputMetrics'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='OutputMetrics.scala' class='org.apache.spark.executor.OutputMetrics'></ClassStats><ClassStats bugs='0' size='79' interface='false' sourceFile='ShuffleReadMetrics.scala' class='org.apache.spark.executor.ShuffleReadMetrics'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ShuffleReadMetrics.scala' class='org.apache.spark.executor.ShuffleReadMetrics$$anonfun$setMergeValues$1'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='ShuffleWriteMetrics.scala' class='org.apache.spark.executor.ShuffleWriteMetrics'></ClassStats><ClassStats bugs='0' size='178' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$empty$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$fromAccumulatorInfos$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$fromAccumulatorInfos$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$fromAccumulatorInfos$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$fromAccumulators$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$nameToAccums$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$nonZeroInternalAccums$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$register$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskMetrics.scala' class='org.apache.spark.executor.TaskMetrics$$anonfun$registered$1'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='ShuffleReadMetrics.scala' class='org.apache.spark.executor.TempShuffleReadMetrics'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.executor.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.executor.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.input' total_bugs='0' total_size='372' total_types='17'><ClassStats bugs='0' size='5' interface='true' sourceFile='WholeTextFileRecordReader.scala' class='org.apache.spark.input.Configurable'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WholeTextFileRecordReader.scala' class='org.apache.spark.input.Configurable$class'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='WholeTextFileRecordReader.scala' class='org.apache.spark.input.ConfigurableCombineFileRecordReader'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='FixedLengthBinaryInputFormat.scala' class='org.apache.spark.input.FixedLengthBinaryInputFormat'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='FixedLengthBinaryInputFormat.scala' class='org.apache.spark.input.FixedLengthBinaryInputFormat$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FixedLengthBinaryInputFormat.scala' class='org.apache.spark.input.FixedLengthBinaryInputFormat$$anonfun$isSplitable$1'></ClassStats><ClassStats bugs='0' size='73' interface='false' sourceFile='FixedLengthBinaryRecordReader.scala' class='org.apache.spark.input.FixedLengthBinaryRecordReader'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='PortableDataStream.scala' class='org.apache.spark.input.PortableDataStream'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='PortableDataStream.scala' class='org.apache.spark.input.StreamBasedRecordReader'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='PortableDataStream.scala' class='org.apache.spark.input.StreamFileInputFormat'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PortableDataStream.scala' class='org.apache.spark.input.StreamFileInputFormat$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PortableDataStream.scala' class='org.apache.spark.input.StreamFileInputFormat$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PortableDataStream.scala' class='org.apache.spark.input.StreamInputFormat'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PortableDataStream.scala' class='org.apache.spark.input.StreamRecordReader'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='WholeTextFileInputFormat.scala' class='org.apache.spark.input.WholeTextFileInputFormat'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WholeTextFileInputFormat.scala' class='org.apache.spark.input.WholeTextFileInputFormat$$anonfun$1'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='WholeTextFileRecordReader.scala' class='org.apache.spark.input.WholeTextFileRecordReader'></ClassStats></PackageStats><PackageStats package='org.apache.spark.internal' total_bugs='10' priority_3='10' total_size='132' total_types='4'><ClassStats bugs='0' size='19' interface='true' sourceFile='Logging.scala' class='org.apache.spark.internal.Logging'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='Logging.scala' class='org.apache.spark.internal.Logging$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Logging.scala' class='org.apache.spark.internal.Logging$$anonfun$1'></ClassStats><ClassStats bugs='10' size='69' priority_3='10' interface='false' sourceFile='Logging.scala' class='org.apache.spark.internal.Logging$class'></ClassStats></PackageStats><PackageStats package='org.apache.spark.internal.config' total_bugs='0' total_size='1291' total_types='73'><ClassStats bugs='0' size='67' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$booleanConf$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$bytesConf$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$bytesConf$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$doubleConf$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$doubleConf$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$fallbackConf$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$intConf$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$intConf$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$longConf$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$longConf$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$regexConf$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$regexConf$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$stringConf$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$timeConf$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigBuilder$$anonfun$timeConf$2'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntry'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntry$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntry$$anonfun$readString$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntry$$anonfun$readString$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntry$$anonfun$registerEntry$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntryWithDefault'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntryWithDefault$$anonfun$readFrom$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntryWithDefaultFunction'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntryWithDefaultString'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.ConfigEntryWithDefaultString$$anonfun$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigHelpers'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigHelpers$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigHelpers$$anonfun$stringToSeq$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.ConfigHelpers$$anonfun$stringToSeq$2'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ConfigProvider.scala' class='org.apache.spark.internal.config.ConfigProvider'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader$$anonfun$get$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader$$anonfun$org$apache$spark$internal$config$ConfigReader$$getOrDefault$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader$$anonfun$org$apache$spark$internal$config$ConfigReader$$substitute$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader$$anonfun$org$apache$spark$internal$config$ConfigReader$$substitute$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader$$anonfun$org$apache$spark$internal$config$ConfigReader$$substitute$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader$$anonfun$org$apache$spark$internal$config$ConfigReader$$substitute$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigReader.scala' class='org.apache.spark.internal.config.ConfigReader$$anonfun$org$apache$spark$internal$config$ConfigReader$$substitute$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ConfigProvider.scala' class='org.apache.spark.internal.config.EnvProvider'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.FallbackConfigEntry'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.FallbackConfigEntry$$anonfun$readFrom$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigProvider.scala' class='org.apache.spark.internal.config.MapProvider'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.OptionalConfigEntry'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.OptionalConfigEntry$$anonfun$$lessinit$greater$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigEntry.scala' class='org.apache.spark.internal.config.OptionalConfigEntry$$anonfun$$lessinit$greater$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigProvider.scala' class='org.apache.spark.internal.config.SparkConfigProvider'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigProvider.scala' class='org.apache.spark.internal.config.SparkConfigProvider$$anonfun$get$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ConfigProvider.scala' class='org.apache.spark.internal.config.SystemProvider'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$$lessinit$greater$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$$lessinit$greater$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$checkValue$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$checkValues$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$createOptional$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$createWithDefault$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$createWithDefaultFunction$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$createWithDefaultString$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$toSequence$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$toSequence$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConfigBuilder.scala' class='org.apache.spark.internal.config.TypedConfigBuilder$$anonfun$transform$1'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package'></ClassStats><ClassStats bugs='0' size='553' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='package.scala' class='org.apache.spark.internal.config.package$$anonfun$8'></ClassStats></PackageStats><PackageStats package='org.apache.spark.internal.io' total_bugs='0' total_size='763' total_types='48'><ClassStats bugs='0' size='17' interface='false' sourceFile='FileCommitProtocol.scala' class='org.apache.spark.internal.io.FileCommitProtocol'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='FileCommitProtocol.scala' class='org.apache.spark.internal.io.FileCommitProtocol$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FileCommitProtocol.scala' class='org.apache.spark.internal.io.FileCommitProtocol$EmptyTaskCommitMessage$'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='FileCommitProtocol.scala' class='org.apache.spark.internal.io.FileCommitProtocol$TaskCommitMessage'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopMapRedCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapRedCommitProtocol'></ClassStats><ClassStats bugs='0' size='89' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil$$anonfun$assertConf$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil$$anonfun$getOutputFormat$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil$$anonfun$initWriter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil$$anonfun$write$3'></ClassStats><ClassStats bugs='0' size='126' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$abortTask$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$abortTask$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$commitJob$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$commitJob$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$commitJob$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$commitJob$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$commitJob$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$commitJob$6'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$commitJob$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$newTaskTempFile$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopMapReduceCommitProtocol.scala' class='org.apache.spark.internal.io.HadoopMapReduceCommitProtocol$$anonfun$newTaskTempFile$2'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil$$anonfun$closeWriter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil$$anonfun$getOutputFormat$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil$$anonfun$initWriter$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.HadoopMapReduceWriteConfigUtil$$anonfun$write$4'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='HadoopWriteConfigUtil.scala' class='org.apache.spark.internal.io.HadoopWriteConfigUtil'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter$'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$2'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$write$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopWriter.scala' class='org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$write$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkHadoopWriterUtils.scala' class='org.apache.spark.internal.io.SparkHadoopWriterUtils'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='SparkHadoopWriterUtils.scala' class='org.apache.spark.internal.io.SparkHadoopWriterUtils$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.io' total_bugs='1' priority_3='1' total_size='462' total_types='17'><ClassStats bugs='0' size='3' interface='true' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.CompressionCodec'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.CompressionCodec$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.CompressionCodec$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.CompressionCodec$$anonfun$createCodec$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.CompressionCodec$$anonfun$getShortName$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.CompressionCodec$$anonfun$getShortName$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.LZ4CompressionCodec'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.LZFCompressionCodec'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='NioBufferedFileInputStream.java' class='org.apache.spark.io.NioBufferedFileInputStream'></ClassStats><ClassStats bugs='1' size='199' priority_3='1' interface='false' sourceFile='ReadAheadInputStream.java' class='org.apache.spark.io.ReadAheadInputStream'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='ReadAheadInputStream.java' class='org.apache.spark.io.ReadAheadInputStream$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.SnappyCompressionCodec'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.SnappyCompressionCodec$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.SnappyOutputStreamWrapper'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CompressionCodec.scala' class='org.apache.spark.io.ZStdCompressionCodec'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.io.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.io.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.launcher' total_bugs='1' priority_2='1' total_size='137' total_types='11'><ClassStats bugs='1' size='55' priority_2='1' interface='false' sourceFile='LauncherBackend.scala' class='org.apache.spark.launcher.LauncherBackend'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LauncherBackend.scala' class='org.apache.spark.launcher.LauncherBackend$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LauncherBackend.scala' class='org.apache.spark.launcher.LauncherBackend$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LauncherBackend.scala' class='org.apache.spark.launcher.LauncherBackend$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LauncherBackend.scala' class='org.apache.spark.launcher.LauncherBackend$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LauncherBackend.scala' class='org.apache.spark.launcher.LauncherBackend$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LauncherBackend.scala' class='org.apache.spark.launcher.LauncherBackend$$anonfun$3'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='LauncherBackend.scala' class='org.apache.spark.launcher.LauncherBackend$BackendConnection'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='SparkSubmitArgumentsParser.scala' class='org.apache.spark.launcher.SparkSubmitArgumentsParser'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='WorkerCommandBuilder.scala' class='org.apache.spark.launcher.WorkerCommandBuilder'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WorkerCommandBuilder.scala' class='org.apache.spark.launcher.WorkerCommandBuilder$$anonfun$buildCommand$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.mapred' total_bugs='0' total_size='113' total_types='6'><ClassStats bugs='0' size='32' interface='false' sourceFile='SparkHadoopMapRedUtil.scala' class='org.apache.spark.mapred.SparkHadoopMapRedUtil'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='SparkHadoopMapRedUtil.scala' class='org.apache.spark.mapred.SparkHadoopMapRedUtil$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopMapRedUtil.scala' class='org.apache.spark.mapred.SparkHadoopMapRedUtil$$anonfun$commitTask$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopMapRedUtil.scala' class='org.apache.spark.mapred.SparkHadoopMapRedUtil$$anonfun$commitTask$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopMapRedUtil.scala' class='org.apache.spark.mapred.SparkHadoopMapRedUtil$$anonfun$performCommit$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkHadoopMapRedUtil.scala' class='org.apache.spark.mapred.SparkHadoopMapRedUtil$$anonfun$performCommit$1$2'></ClassStats></PackageStats><PackageStats package='org.apache.spark.memory' total_bugs='11' priority_3='11' total_size='886' total_types='31'><ClassStats bugs='0' size='78' interface='false' sourceFile='ExecutionMemoryPool.scala' class='org.apache.spark.memory.ExecutionMemoryPool'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutionMemoryPool.scala' class='org.apache.spark.memory.ExecutionMemoryPool$$anonfun$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExecutionMemoryPool.scala' class='org.apache.spark.memory.ExecutionMemoryPool$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutionMemoryPool.scala' class='org.apache.spark.memory.ExecutionMemoryPool$$anonfun$acquireMemory$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutionMemoryPool.scala' class='org.apache.spark.memory.ExecutionMemoryPool$$anonfun$acquireMemory$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutionMemoryPool.scala' class='org.apache.spark.memory.ExecutionMemoryPool$$anonfun$acquireMemory$default$3$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutionMemoryPool.scala' class='org.apache.spark.memory.ExecutionMemoryPool$$anonfun$acquireMemory$default$4$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutionMemoryPool.scala' class='org.apache.spark.memory.ExecutionMemoryPool$$anonfun$getMemoryUsageForTask$1'></ClassStats><ClassStats bugs='0' size='57' interface='false' sourceFile='MemoryConsumer.java' class='org.apache.spark.memory.MemoryConsumer'></ClassStats><ClassStats bugs='0' size='106' interface='false' sourceFile='MemoryManager.scala' class='org.apache.spark.memory.MemoryManager'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryManager.scala' class='org.apache.spark.memory.MemoryManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryManager.scala' class='org.apache.spark.memory.MemoryManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='MemoryMode.java' class='org.apache.spark.memory.MemoryMode'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='MemoryPool.scala' class='org.apache.spark.memory.MemoryPool'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkOutOfMemoryError.java' class='org.apache.spark.memory.SparkOutOfMemoryError'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='StaticMemoryManager.scala' class='org.apache.spark.memory.StaticMemoryManager'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='StaticMemoryManager.scala' class='org.apache.spark.memory.StaticMemoryManager$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StaticMemoryManager.scala' class='org.apache.spark.memory.StaticMemoryManager$$anonfun$acquireStorageMemory$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StaticMemoryManager.scala' class='org.apache.spark.memory.StaticMemoryManager$$anonfun$acquireStorageMemory$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StaticMemoryManager.scala' class='org.apache.spark.memory.StaticMemoryManager$$anonfun$acquireUnrollMemory$1'></ClassStats><ClassStats bugs='0' size='79' interface='false' sourceFile='StorageMemoryPool.scala' class='org.apache.spark.memory.StorageMemoryPool'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StorageMemoryPool.scala' class='org.apache.spark.memory.StorageMemoryPool$$anonfun$releaseMemory$1'></ClassStats><ClassStats bugs='11' size='206' priority_3='11' interface='false' sourceFile='TaskMemoryManager.java' class='org.apache.spark.memory.TaskMemoryManager'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='TooLargePageException.java' class='org.apache.spark.memory.TooLargePageException'></ClassStats><ClassStats bugs='0' size='73' interface='false' sourceFile='UnifiedMemoryManager.scala' class='org.apache.spark.memory.UnifiedMemoryManager'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='UnifiedMemoryManager.scala' class='org.apache.spark.memory.UnifiedMemoryManager$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='UnifiedMemoryManager.scala' class='org.apache.spark.memory.UnifiedMemoryManager$$anonfun$acquireExecutionMemory$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='UnifiedMemoryManager.scala' class='org.apache.spark.memory.UnifiedMemoryManager$$anonfun$acquireExecutionMemory$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='UnifiedMemoryManager.scala' class='org.apache.spark.memory.UnifiedMemoryManager$$anonfun$acquireStorageMemory$1'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.memory.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.memory.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.metrics' total_bugs='1' priority_2='1' total_size='438' total_types='34'><ClassStats bugs='1' size='76' priority_2='1' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$getInstance$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$initialize$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$initialize$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$initialize$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$initialize$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$initialize$4$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$initialize$4$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$initialize$4$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$loadPropertiesFromFile$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$subProperties$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsConfig.scala' class='org.apache.spark.metrics.MetricsConfig$$anonfun$subProperties$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='106' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$buildRegistryName$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$buildRegistryName$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$getServletHandlers$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$getServletHandlers$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$getServletHandlers$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$getSourcesByName$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$registerSinks$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$registerSinks$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$registerSource$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$registerSources$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$registerSources$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$report$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$start$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$start$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsSystem.scala' class='org.apache.spark.metrics.MetricsSystem$$anonfun$stop$2'></ClassStats></PackageStats><PackageStats package='org.apache.spark.metrics.sink' total_bugs='1' priority_2='1' total_size='759' total_types='43'><ClassStats bugs='0' size='43' interface='false' sourceFile='ConsoleSink.scala' class='org.apache.spark.metrics.sink.ConsoleSink'></ClassStats><ClassStats bugs='1' size='55' priority_2='1' interface='false' sourceFile='CsvSink.scala' class='org.apache.spark.metrics.sink.CsvSink'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='GraphiteSink.scala' class='org.apache.spark.metrics.sink.GraphiteSink'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='GraphiteSink.scala' class='org.apache.spark.metrics.sink.GraphiteSink$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='GraphiteSink.scala' class='org.apache.spark.metrics.sink.GraphiteSink$$anonfun$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='JmxSink.scala' class='org.apache.spark.metrics.sink.JmxSink'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='MetricsServlet.scala' class='org.apache.spark.metrics.sink.MetricsServlet'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MetricsServlet.scala' class='org.apache.spark.metrics.sink.MetricsServlet$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MetricsServlet.scala' class='org.apache.spark.metrics.sink.MetricsServlet$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MetricsServlet.scala' class='org.apache.spark.metrics.sink.MetricsServlet$$anonfun$getHandlers$1'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='Sink.scala' class='org.apache.spark.metrics.sink.Sink'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='Slf4jSink.scala' class='org.apache.spark.metrics.sink.Slf4jSink'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdMetricType'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdMetricType$'></ClassStats><ClassStats bugs='0' size='106' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$format$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$org$apache$spark$metrics$sink$StatsdReporter$$reportGauge$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$1$$anonfun$apply$mcV$sp$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$1$$anonfun$apply$mcV$sp$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$1$$anonfun$apply$mcV$sp$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$2'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$3$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$3$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$4$$anonfun$applyOrElse$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$4$$anonfun$applyOrElse$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdReporter.scala' class='org.apache.spark.metrics.sink.StatsdReporter$$anonfun$report$6'></ClassStats><ClassStats bugs='0' size='67' interface='false' sourceFile='StatsdSink.scala' class='org.apache.spark.metrics.sink.StatsdSink'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='StatsdSink.scala' class='org.apache.spark.metrics.sink.StatsdSink$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsdSink.scala' class='org.apache.spark.metrics.sink.StatsdSink$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsdSink.scala' class='org.apache.spark.metrics.sink.StatsdSink$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.metrics.sink.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.metrics.sink.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.metrics.source' total_bugs='0' total_size='134' total_types='10'><ClassStats bugs='0' size='11' interface='false' sourceFile='StaticSources.scala' class='org.apache.spark.metrics.source.CodegenMetrics'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='StaticSources.scala' class='org.apache.spark.metrics.source.CodegenMetrics$'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='StaticSources.scala' class='org.apache.spark.metrics.source.HiveCatalogMetrics'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='StaticSources.scala' class='org.apache.spark.metrics.source.HiveCatalogMetrics$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='JvmSource.scala' class='org.apache.spark.metrics.source.JvmSource'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='Source.scala' class='org.apache.spark.metrics.source.Source'></ClassStats><ClassStats bugs='0' size='2' interface='false' sourceFile='StaticSources.scala' class='org.apache.spark.metrics.source.StaticSources'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StaticSources.scala' class='org.apache.spark.metrics.source.StaticSources$'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.metrics.source.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.metrics.source.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.network' total_bugs='0' total_size='56' total_types='3'><ClassStats bugs='0' size='4' interface='true' sourceFile='BlockDataManager.scala' class='org.apache.spark.network.BlockDataManager'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='BlockTransferService.scala' class='org.apache.spark.network.BlockTransferService'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockTransferService.scala' class='org.apache.spark.network.BlockTransferService$$anon$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.network.netty' total_bugs='0' total_size='281' total_types='19'><ClassStats bugs='0' size='55' interface='false' sourceFile='NettyBlockRpcServer.scala' class='org.apache.spark.network.netty.NettyBlockRpcServer'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NettyBlockRpcServer.scala' class='org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyBlockRpcServer.scala' class='org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NettyBlockRpcServer.scala' class='org.apache.spark.network.netty.NettyBlockRpcServer$$anonfun$receive$2'></ClassStats><ClassStats bugs='0' size='75' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anon$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anon$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anon$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anon$3$$anonfun$onFailure$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anon$3$$anonfun$onSuccess$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anonfun$createServer$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anonfun$fetchBlocks$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anonfun$fetchBlocks$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anonfun$fetchBlocks$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anonfun$init$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NettyBlockTransferService.scala' class='org.apache.spark.network.netty.NettyBlockTransferService$$anonfun$shuffleMetrics$1'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='SparkTransportConf.scala' class='org.apache.spark.network.netty.SparkTransportConf'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkTransportConf.scala' class='org.apache.spark.network.netty.SparkTransportConf$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkTransportConf.scala' class='org.apache.spark.network.netty.SparkTransportConf$$anon$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.partial' total_bugs='0' total_size='362' total_types='20'><ClassStats bugs='0' size='47' interface='false' sourceFile='ApproximateActionListener.scala' class='org.apache.spark.partial.ApproximateActionListener'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApproximateActionListener.scala' class='org.apache.spark.partial.ApproximateActionListener$$anonfun$taskSucceeded$1'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ApproximateEvaluator.scala' class='org.apache.spark.partial.ApproximateEvaluator'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='BoundedDouble.scala' class='org.apache.spark.partial.BoundedDouble'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='CountEvaluator.scala' class='org.apache.spark.partial.CountEvaluator'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CountEvaluator.scala' class='org.apache.spark.partial.CountEvaluator$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='GroupedCountEvaluator.scala' class='org.apache.spark.partial.GroupedCountEvaluator'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='GroupedCountEvaluator.scala' class='org.apache.spark.partial.GroupedCountEvaluator$$anonfun$currentResult$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='GroupedCountEvaluator.scala' class='org.apache.spark.partial.GroupedCountEvaluator$$anonfun$currentResult$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='GroupedCountEvaluator.scala' class='org.apache.spark.partial.GroupedCountEvaluator$$anonfun$merge$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='GroupedCountEvaluator.scala' class='org.apache.spark.partial.GroupedCountEvaluator$$anonfun$merge$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='GroupedCountEvaluator.scala' class='org.apache.spark.partial.GroupedCountEvaluator$$anonfun$merge$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MeanEvaluator.scala' class='org.apache.spark.partial.MeanEvaluator'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='PartialResult.scala' class='org.apache.spark.partial.PartialResult'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='PartialResult.scala' class='org.apache.spark.partial.PartialResult$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PartialResult.scala' class='org.apache.spark.partial.PartialResult$$anonfun$setFailure$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PartialResult.scala' class='org.apache.spark.partial.PartialResult$$anonfun$setFinalValue$1'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='SumEvaluator.scala' class='org.apache.spark.partial.SumEvaluator'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.partial.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.partial.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.rdd' total_bugs='11' priority_2='10' priority_3='1' total_size='9317' total_types='732'><ClassStats bugs='0' size='36' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$6$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$collectAsync$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$countAsync$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$countAsync$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachAsync$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachPartitionAsync$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachPartitionAsync$1$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$foreachPartitionAsync$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$org$apache$spark$rdd$AsyncRDDActions$$anonfun$$continue$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncRDDActions.scala' class='org.apache.spark.rdd.AsyncRDDActions$$anonfun$takeAsync$1$$anonfun$org$apache$spark$rdd$AsyncRDDActions$$anonfun$$continue$1$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='BinaryFileRDD.scala' class='org.apache.spark.rdd.BinaryFileRDD'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BinaryFileRDD.scala' class='org.apache.spark.rdd.BinaryFileRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='BlockRDD.scala' class='org.apache.spark.rdd.BlockRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockRDD.scala' class='org.apache.spark.rdd.BlockRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockRDD.scala' class='org.apache.spark.rdd.BlockRDD$$anonfun$removeBlocks$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockRDD.scala' class='org.apache.spark.rdd.BlockRDDPartition'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianPartition'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianPartition$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianRDD'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianRDD$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianRDD$$anon$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianRDD$$anonfun$compute$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianRDD$$anonfun$compute$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CartesianRDD.scala' class='org.apache.spark.rdd.CartesianRDD$$anonfun$getPartitions$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CheckpointRDD.scala' class='org.apache.spark.rdd.CheckpointRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CheckpointRDD.scala' class='org.apache.spark.rdd.CheckpointRDDPartition'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDDCheckpointData.scala' class='org.apache.spark.rdd.CheckpointState'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RDDCheckpointData.scala' class='org.apache.spark.rdd.CheckpointState$'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupPartition'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$getDependencies$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$getDependencies$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$getDependencies$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.CoGroupedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD$$anonfun$6'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDD$$anonfun$getPartitions$1$$anonfun$7'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDDPartition'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDDPartition$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDDPartition$$anonfun$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDDPartition$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDDPartition$$anonfun$2$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDDPartition$$anonfun$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDDPartition$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.CoalescedRDDPartition$$anonfun$writeObject$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='1' size='100' priority_2='1' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$currPrefLocs$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$getLeastGroupHash$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$getLeastGroupHash$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$getPartitions$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$setupGroups$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$setupGroups$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$4'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$6'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$8'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$$anonfun$throwBalls$9'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$PartitionLocations'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$PartitionLocations$$anonfun$getAllPrefLocs$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$PartitionLocations$$anonfun$getAllPrefLocs$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoalescedRDD.scala' class='org.apache.spark.rdd.DefaultPartitionCoalescer$PartitionLocations$$anonfun$getAllPrefLocs$2'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$1$$anonfun$3$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$1$$anonfun$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$1$$anonfun$customRange$1$1'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$2$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$2$$anonfun$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$2$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$histogram$2$$anonfun$org$apache$spark$rdd$DoubleRDDFunctions$$anonfun$$mergeCounters$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$mean$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$meanApprox$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$meanApprox$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$popStdev$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$popVariance$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sampleStdev$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sampleVariance$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$stats$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$stats$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$stats$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$stdev$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sum$1$$anonfun$apply$mcD$sp$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sumApprox$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sumApprox$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DoubleRDDFunctions.scala' class='org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$variance$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EmptyRDD.scala' class='org.apache.spark.rdd.EmptyRDD'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopPartition'></ClassStats><ClassStats bugs='0' size='103' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$'></ClassStats><ClassStats bugs='0' size='83' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$close$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$close$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$getNext$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$liftedTree1$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$org$apache$spark$rdd$HadoopRDD$$anon$$updateBytesRead$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$convertSplitLocationInfo$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$convertSplitLocationInfo$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$convertSplitLocationInfo$1$$anonfun$apply$5$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$4$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$5$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$5$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getPreferredLocations$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$getPreferredLocations$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$$anonfun$persist$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$HadoopMapPartitionsWithSplitRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='HadoopRDD.scala' class='org.apache.spark.rdd.HadoopRDD$HadoopMapPartitionsWithSplitRDD$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='InputFileBlockHolder.scala' class='org.apache.spark.rdd.InputFileBlockHolder'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='InputFileBlockHolder.scala' class='org.apache.spark.rdd.InputFileBlockHolder$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InputFileBlockHolder.scala' class='org.apache.spark.rdd.InputFileBlockHolder$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InputFileBlockHolder.scala' class='org.apache.spark.rdd.InputFileBlockHolder$$anonfun$set$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='InputFileBlockHolder.scala' class='org.apache.spark.rdd.InputFileBlockHolder$$anonfun$set$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='InputFileBlockHolder.scala' class='org.apache.spark.rdd.InputFileBlockHolder$$anonfun$set$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='InputFileBlockHolder.scala' class='org.apache.spark.rdd.InputFileBlockHolder$FileBlock'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcPartition'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$'></ClassStats><ClassStats bugs='2' size='46' priority_2='1' priority_3='1' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anon$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anon$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anon$1$$anonfun$close$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anon$1$$anonfun$close$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anon$1$$anonfun$close$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anon$1$$anonfun$close$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anonfun$$lessinit$greater$default$7$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anonfun$4'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$$anonfun$resultSetToObjectArray$1'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='JdbcRDD.scala' class='org.apache.spark.rdd.JdbcRDD$ConnectionFactory'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='LocalCheckpointRDD.scala' class='org.apache.spark.rdd.LocalCheckpointRDD'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalCheckpointRDD.scala' class='org.apache.spark.rdd.LocalCheckpointRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='LocalRDDCheckpointData.scala' class='org.apache.spark.rdd.LocalRDDCheckpointData'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='LocalRDDCheckpointData.scala' class='org.apache.spark.rdd.LocalRDDCheckpointData$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='LocalRDDCheckpointData.scala' class='org.apache.spark.rdd.LocalRDDCheckpointData$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalRDDCheckpointData.scala' class='org.apache.spark.rdd.LocalRDDCheckpointData$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalRDDCheckpointData.scala' class='org.apache.spark.rdd.LocalRDDCheckpointData$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LocalRDDCheckpointData.scala' class='org.apache.spark.rdd.LocalRDDCheckpointData$$anonfun$doCheckpoint$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='MapPartitionsRDD.scala' class='org.apache.spark.rdd.MapPartitionsRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MapPartitionsRDD.scala' class='org.apache.spark.rdd.MapPartitionsRDD$'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.NarrowCoGroupSplitDep'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.NarrowCoGroupSplitDep$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='CoGroupedRDD.scala' class='org.apache.spark.rdd.NarrowCoGroupSplitDep$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopPartition'></ClassStats><ClassStats bugs='0' size='71' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$'></ClassStats><ClassStats bugs='0' size='206' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$hasNext$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$liftedTree1$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$org$apache$spark$rdd$NewHadoopRDD$$anon$$close$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$org$apache$spark$rdd$NewHadoopRDD$$anon$$close$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anon$1$$anonfun$org$apache$spark$rdd$NewHadoopRDD$$anon$$updateBytesRead$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anonfun$getConf$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anonfun$getPreferredLocations$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anonfun$getPreferredLocations$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$$anonfun$persist$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$NewHadoopMapPartitionsWithSplitRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NewHadoopRDD.scala' class='org.apache.spark.rdd.NewHadoopRDD$NewHadoopMapPartitionsWithSplitRDD$'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='OrderedRDDFunctions.scala' class='org.apache.spark.rdd.OrderedRDDFunctions'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='OrderedRDDFunctions.scala' class='org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$filterByRange$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='OrderedRDDFunctions.scala' class='org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$filterByRange$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OrderedRDDFunctions.scala' class='org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$filterByRange$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='OrderedRDDFunctions.scala' class='org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$repartitionAndSortWithinPartitions$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='OrderedRDDFunctions.scala' class='org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1'></ClassStats><ClassStats bugs='0' size='234' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$aggregateByKey$3'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$1$$anonfun$apply$42'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$2$$anonfun$apply$43'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$3$$anonfun$apply$44'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$6'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$7'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$8'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$cogroup$9'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1$$anonfun$apply$36'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKey$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKey$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKey$3'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$combineByKeyWithClassTag$3'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$1$$anonfun$apply$18'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$2$$anonfun$apply$19'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countApproxDistinctByKey$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKeyApprox$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKeyApprox$1$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$flatMapValues$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$flatMapValues$1$$anonfun$apply$39'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$flatMapValues$1$$anonfun$apply$39$$anonfun$apply$40'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$flatMapValues$1$$anonfun$apply$39$$anonfun$apply$40$$anonfun$apply$41'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$foldByKey$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$foldByKey$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$foldByKey$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$foldByKey$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$foldByKey$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$fullOuterJoin$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$fullOuterJoin$1$$anonfun$apply$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$fullOuterJoin$1$$anonfun$apply$31$$anonfun$apply$32'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$fullOuterJoin$1$$anonfun$apply$31$$anonfun$apply$33'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$fullOuterJoin$1$$anonfun$apply$31$$anonfun$apply$34'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$fullOuterJoin$1$$anonfun$apply$31$$anonfun$apply$34$$anonfun$apply$35'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$fullOuterJoin$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$fullOuterJoin$3'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$1$$anonfun$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupByKey$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupWith$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupWith$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$groupWith$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20$$anonfun$apply$21'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$1$$anonfun$apply$20$$anonfun$apply$21$$anonfun$apply$22'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$join$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$keys$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$1$$anonfun$apply$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$1$$anonfun$apply$23$$anonfun$apply$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$1$$anonfun$apply$23$$anonfun$apply$25'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$1$$anonfun$apply$23$$anonfun$apply$25$$anonfun$apply$26'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$leftOuterJoin$3'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$lookup$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$lookup$1$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$lookup$1$$anonfun$11$$anonfun$apply$46'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$lookup$1$$anonfun$11$$anonfun$apply$47'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$lookup$1$$anonfun$apply$48'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$lookup$1$$anonfun$apply$49'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$37'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$37$$anonfun$apply$38'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$partitionBy$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKeyLocally$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKeyLocally$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKeyLocally$1$$anonfun$3$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKeyLocally$1$$anonfun$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKeyLocally$1$$anonfun$4$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$rightOuterJoin$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$rightOuterJoin$1$$anonfun$apply$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$rightOuterJoin$1$$anonfun$apply$27$$anonfun$apply$28'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$rightOuterJoin$1$$anonfun$apply$27$$anonfun$apply$29'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$rightOuterJoin$1$$anonfun$apply$27$$anonfun$apply$29$$anonfun$apply$30'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$rightOuterJoin$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$rightOuterJoin$3'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$sampleByKey$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$sampleByKey$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$sampleByKey$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$sampleByKeyExact$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$sampleByKeyExact$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$sampleByKeyExact$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$3'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopFile$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$subtractByKey$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$subtractByKey$1$$anonfun$apply$45'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$subtractByKey$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$subtractByKey$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PairRDDFunctions.scala' class='org.apache.spark.rdd.PairRDDFunctions$$anonfun$values$1'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionPartition'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionPartition$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionPartition$$anonfun$readObject$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionPartition$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionPartition$$anonfun$writeObject$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD$$anonfun$getPreferredLocations$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD$$anonfun$positions$1$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD$$anonfun$slice$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD$$anonfun$slice$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD$$anonfun$slice$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ParallelCollectionRDD.scala' class='org.apache.spark.rdd.ParallelCollectionRDD$$anonfun$slice$4'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='coalesce-public.scala' class='org.apache.spark.rdd.PartitionCoalescer'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='coalesce-public.scala' class='org.apache.spark.rdd.PartitionGroup'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='coalesce-public.scala' class='org.apache.spark.rdd.PartitionGroup$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PartitionPruningRDD.scala' class='org.apache.spark.rdd.PartitionPruningRDD'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PartitionPruningRDD.scala' class='org.apache.spark.rdd.PartitionPruningRDD$'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PartitionPruningRDD.scala' class='org.apache.spark.rdd.PartitionPruningRDDPartition'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$$lessinit$greater$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$4'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$5$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$compute$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$getPreferredLocations$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDD$$anonfun$org$apache$spark$rdd$PartitionerAwareUnionRDD$$currPrefLocs$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDDPartition'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDDPartition$$anonfun$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDDPartition$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PartitionerAwareUnionRDD.scala' class='org.apache.spark.rdd.PartitionerAwareUnionRDDPartition$$anonfun$writeObject$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='1' size='24' priority_2='1' interface='false' sourceFile='PartitionwiseSampledRDD.scala' class='org.apache.spark.rdd.PartitionwiseSampledRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PartitionwiseSampledRDD.scala' class='org.apache.spark.rdd.PartitionwiseSampledRDD$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PartitionwiseSampledRDD.scala' class='org.apache.spark.rdd.PartitionwiseSampledRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='PartitionwiseSampledRDD.scala' class='org.apache.spark.rdd.PartitionwiseSampledRDDPartition'></ClassStats><ClassStats bugs='1' size='53' priority_2='1' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$'></ClassStats><ClassStats bugs='0' size='132' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$1'></ClassStats><ClassStats bugs='1' size='8' priority_2='1' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$cleanup$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$1$$anonfun$propagateChildException$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$2$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$3$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$3$$anonfun$run$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anon$3$$anonfun$run$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anonfun$compute$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anonfun$compute$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anonfun$compute$3'></ClassStats><ClassStats bugs='3' size='11' priority_2='3' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anonfun$compute$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$$anonfun$compute$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PipedRDD.scala' class='org.apache.spark.rdd.PipedRDD$NotEqualsFileNameFilter'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='PartitionPruningRDD.scala' class='org.apache.spark.rdd.PruneDependency'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PartitionPruningRDD.scala' class='org.apache.spark.rdd.PruneDependency$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionPruningRDD.scala' class='org.apache.spark.rdd.PruneDependency$$anonfun$2'></ClassStats><ClassStats bugs='0' size='509' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$$plus$plus$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$34'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$35'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$36'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$37'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$38'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$6'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$7'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$aggregate$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$21$$anonfun$apply$39'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$cartesian$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$checkpointRDD$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$coalesce$1'></ClassStats><ClassStats bugs='1' size='9' priority_2='1' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$8$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$coalesce$1$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$collect$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$collect$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$collect$2$$anonfun$apply$31'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$collectPartitions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$collectPartitions$1$$anonfun$apply$57'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$count$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApprox$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApprox$1$$anonfun$26'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApprox$1$$anonfun$apply$43'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApproxDistinct$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApproxDistinct$1$$anonfun$apply$mcJ$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApproxDistinct$1$$anonfun$apply$mcJ$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApproxDistinct$1$$anonfun$apply$mcJ$sp$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApproxDistinct$1$$anonfun$apply$mcJ$sp$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApproxDistinct$1$$anonfun$apply$mcJ$sp$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApproxDistinct$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countApproxDistinct$2$$anonfun$apply$mcJ$sp$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countByValue$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countByValue$1$$anonfun$apply$44'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countByValueApprox$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countByValueApprox$1$$anonfun$27'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countByValueApprox$1$$anonfun$27$$anonfun$apply$46'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countByValueApprox$1$$anonfun$27$$anonfun$apply$46$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countByValueApprox$1$$anonfun$27$$anonfun$apply$46$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$countByValueApprox$1$$anonfun$apply$45'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$dependencies$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$dependencies$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$distinct$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$distinct$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$distinct$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$distinct$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$distinct$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$doCheckpoint$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$doCheckpoint$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$doCheckpoint$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$filter$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$filter$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$first$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$firstDebugString$1$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$flatMap$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$flatMap$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$fold$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$19'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$foreach$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$getCreationSite$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$getCreationSite$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$getNarrowAncestors$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$glom$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$glom$1$$anonfun$apply$21'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$groupBy$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$groupBy$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$groupBy$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$groupBy$3$$anonfun$apply$22'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$1$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$1$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$1$$anonfun$9'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$2$$anonfun$apply$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$2$$anonfun$apply$19'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$2$$anonfun$apply$20'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$intersection$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$isCheckpointedAndMaterialized$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$isEmpty$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$keyBy$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$keyBy$1$$anonfun$apply$56'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$localCheckpoint$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$localCheckpoint$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$localCheckpoint$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$map$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$map$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$apply$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$max$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$max$1$$anonfun$apply$51'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$min$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$min$1$$anonfun$apply$52'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$numericRDDToDoubleRDDFunctions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$debugString$1$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$org$apache$spark$rdd$RDD$$visit$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$partitions$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$partitions$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$partitions$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$partitions$2$$anonfun$apply$3$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$persist$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$pipe$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$pipe$2'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$pipe$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$preferredLocations$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$preferredLocations$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$randomSampleWithRange$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$randomSplit$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$randomSplit$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$randomSplit$3'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$randomSplit$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$randomSplit$4$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$randomSplit$4$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$randomSplit$4$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$reduce$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$14'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$apply$36'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$repartition$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$retag$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$sample$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$sample$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$sample$2$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsObjectFile$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsObjectFile$1$$anonfun$32'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsObjectFile$1$$anonfun$32$$anonfun$apply$55'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsObjectFile$1$$anonfun$33'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30$$anonfun$apply$53'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2$$anonfun$31'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2$$anonfun$31$$anonfun$apply$54'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$shuffleDebugString$1$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$sortBy$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$1$$anonfun$13'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$3$$anon$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$3$$anonfun$apply$32'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$3$$anonfun$apply$33'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$3$$anonfun$apply$34'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$subtract$3$$anonfun$apply$35'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$take$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$28'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$apply$49'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$29'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$apply$50'></ClassStats><ClassStats bugs='1' size='30' priority_2='1' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$takeSample$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$takeSample$1$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$takeSample$1$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$takeSample$1$$anonfun$apply$17'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$toLocalIterator$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$toLocalIterator$1$$anonfun$apply$30'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$toLocalIterator$1$$anonfun$org$apache$spark$rdd$RDD$$anonfun$$collectPartition$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$toString$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$toString$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$top$1'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$23$$anonfun$apply$41'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$25$$anonfun$apply$42'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$apply$40'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeReduce$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeReduce$1$$anonfun$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeReduce$1$$anonfun$17'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeReduce$1$$anonfun$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeReduce$1$$anonfun$apply$37'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$treeReduce$1$$anonfun$apply$38'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$union$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$unpersist$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zip$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zip$1$$anonfun$apply$27'></ClassStats><ClassStats bugs='0' size='106' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zip$1$$anonfun$apply$27$$anon$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipPartitions$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipPartitions$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipPartitions$3'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipPartitions$4'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipPartitions$5'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipPartitions$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipWithIndex$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipWithUniqueId$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipWithUniqueId$1$$anonfun$apply$47'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDD.scala' class='org.apache.spark.rdd.RDD$$anonfun$zipWithUniqueId$1$$anonfun$apply$47$$anonfun$apply$48'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='RDDCheckpointData.scala' class='org.apache.spark.rdd.RDDCheckpointData'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDCheckpointData.scala' class='org.apache.spark.rdd.RDDCheckpointData$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDCheckpointData.scala' class='org.apache.spark.rdd.RDDCheckpointData$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDCheckpointData.scala' class='org.apache.spark.rdd.RDDCheckpointData$$anonfun$getPartitions$2'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope'></ClassStats><ClassStats bugs='0' size='64' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$$anonfun$4$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$$anonfun$getAllScopes$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationScope.scala' class='org.apache.spark.rdd.RDDOperationScope$$anonfun$getAllScopes$2'></ClassStats><ClassStats bugs='0' size='48' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD'></ClassStats><ClassStats bugs='0' size='138' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$6'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$7$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$7$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$getPartitions$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$getPreferredLocations$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$getPreferredLocations$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$org$apache$spark$rdd$ReliableCheckpointRDD$$readCheckpointedPartitionerFile$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$org$apache$spark$rdd$ReliableCheckpointRDD$$readCheckpointedPartitionerFile$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$org$apache$spark$rdd$ReliableCheckpointRDD$$readCheckpointedPartitionerFile$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$readCheckpointFile$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionToCheckpointFile$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionToCheckpointFile$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionToCheckpointFile$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionToCheckpointFile$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionToCheckpointFile$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionerToCheckpointDir$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionerToCheckpointDir$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionerToCheckpointDir$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writePartitionerToCheckpointDir$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableCheckpointRDD.scala' class='org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$writeRDDToCheckpointDirectory$2'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='ReliableRDDCheckpointData.scala' class='org.apache.spark.rdd.ReliableRDDCheckpointData'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='ReliableRDDCheckpointData.scala' class='org.apache.spark.rdd.ReliableRDDCheckpointData$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableRDDCheckpointData.scala' class='org.apache.spark.rdd.ReliableRDDCheckpointData$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReliableRDDCheckpointData.scala' class='org.apache.spark.rdd.ReliableRDDCheckpointData$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReliableRDDCheckpointData.scala' class='org.apache.spark.rdd.ReliableRDDCheckpointData$$anonfun$checkpointPath$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableRDDCheckpointData.scala' class='org.apache.spark.rdd.ReliableRDDCheckpointData$$anonfun$cleanCheckpoint$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ReliableRDDCheckpointData.scala' class='org.apache.spark.rdd.ReliableRDDCheckpointData$$anonfun$doCheckpoint$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReliableRDDCheckpointData.scala' class='org.apache.spark.rdd.ReliableRDDCheckpointData$$anonfun$doCheckpoint$2'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='SequenceFileRDDFunctions.scala' class='org.apache.spark.rdd.SequenceFileRDDFunctions'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='SequenceFileRDDFunctions.scala' class='org.apache.spark.rdd.SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SequenceFileRDDFunctions.scala' class='org.apache.spark.rdd.SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SequenceFileRDDFunctions.scala' class='org.apache.spark.rdd.SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SequenceFileRDDFunctions.scala' class='org.apache.spark.rdd.SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SequenceFileRDDFunctions.scala' class='org.apache.spark.rdd.SequenceFileRDDFunctions$$anonfun$saveAsSequenceFile$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='ShuffledRDD.scala' class='org.apache.spark.rdd.ShuffledRDD'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ShuffledRDD.scala' class='org.apache.spark.rdd.ShuffledRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffledRDD.scala' class='org.apache.spark.rdd.ShuffledRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ShuffledRDD.scala' class='org.apache.spark.rdd.ShuffledRDDPartition'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD$$anonfun$compute$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD$$anonfun$compute$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD$$anonfun$compute$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD$$anonfun$compute$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD$$anonfun$getPartitions$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD$$anonfun$rddDependency$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SubtractedRDD.scala' class='org.apache.spark.rdd.SubtractedRDD$$anonfun$rddDependency$1$2'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionPartition'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionPartition$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionRDD'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionRDD$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionRDD$$anonfun$getDependencies$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionRDD$$anonfun$getPartitions$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='UnionRDD.scala' class='org.apache.spark.rdd.UnionRDD$$anonfun$getPartitions$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='WholeTextFileRDD.scala' class='org.apache.spark.rdd.WholeTextFileRDD'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='WholeTextFileRDD.scala' class='org.apache.spark.rdd.WholeTextFileRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsBaseRDD'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsBaseRDD$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsBaseRDD$$anonfun$$lessinit$greater$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsBaseRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsBaseRDD$$anonfun$getPartitions$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsBaseRDD$$anonfun$getPartitions$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsBaseRDD$$anonfun$getPartitions$3$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsBaseRDD$$anonfun$getPartitions$3$$anonfun$3'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsPartition'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsPartition$$anonfun$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsPartition$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsPartition$$anonfun$writeObject$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsRDD2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsRDD2$'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsRDD3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsRDD3$'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsRDD4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ZippedPartitionsRDD.scala' class='org.apache.spark.rdd.ZippedPartitionsRDD4$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ZippedWithIndexRDD.scala' class='org.apache.spark.rdd.ZippedWithIndexRDD'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ZippedWithIndexRDD.scala' class='org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ZippedWithIndexRDD.scala' class='org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ZippedWithIndexRDD.scala' class='org.apache.spark.rdd.ZippedWithIndexRDD$$anonfun$getPartitions$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ZippedWithIndexRDD.scala' class='org.apache.spark.rdd.ZippedWithIndexRDDPartition'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.rdd.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.rdd.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.rdd.util' total_bugs='0' total_size='26' total_types='2'><ClassStats bugs='0' size='20' interface='false' sourceFile='PeriodicRDDCheckpointer.scala' class='org.apache.spark.rdd.util.PeriodicRDDCheckpointer'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PeriodicRDDCheckpointer.scala' class='org.apache.spark.rdd.util.PeriodicRDDCheckpointer$$anonfun$getCheckpointFiles$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.rpc' total_bugs='0' total_size='407' total_types='29'><ClassStats bugs='0' size='27' interface='false' sourceFile='RpcAddress.scala' class='org.apache.spark.rpc.RpcAddress'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='RpcAddress.scala' class='org.apache.spark.rpc.RpcAddress$'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='RpcCallContext.scala' class='org.apache.spark.rpc.RpcCallContext'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='RpcEndpoint.scala' class='org.apache.spark.rpc.RpcEndpoint'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RpcEndpoint.scala' class='org.apache.spark.rpc.RpcEndpoint$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RpcEndpoint.scala' class='org.apache.spark.rpc.RpcEndpoint$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RpcEndpoint.scala' class='org.apache.spark.rpc.RpcEndpoint$$anonfun$self$1'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='RpcEndpoint.scala' class='org.apache.spark.rpc.RpcEndpoint$class'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='RpcEndpointAddress.scala' class='org.apache.spark.rpc.RpcEndpointAddress'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='RpcEndpointAddress.scala' class='org.apache.spark.rpc.RpcEndpointAddress$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RpcEndpointAddress.scala' class='org.apache.spark.rpc.RpcEndpointAddress$$anonfun$1'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='RpcEndpointNotFoundException.scala' class='org.apache.spark.rpc.RpcEndpointNotFoundException'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='RpcEndpointRef.scala' class='org.apache.spark.rpc.RpcEndpointRef'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='RpcEnv.scala' class='org.apache.spark.rpc.RpcEnv'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='RpcEnv.scala' class='org.apache.spark.rpc.RpcEnv$'></ClassStats><ClassStats bugs='0' size='48' interface='false' sourceFile='RpcEnv.scala' class='org.apache.spark.rpc.RpcEnvConfig'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RpcEnv.scala' class='org.apache.spark.rpc.RpcEnvConfig$'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='RpcEndpoint.scala' class='org.apache.spark.rpc.RpcEnvFactory'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='RpcEnv.scala' class='org.apache.spark.rpc.RpcEnvFileServer'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RpcEnv.scala' class='org.apache.spark.rpc.RpcEnvFileServer$$anonfun$validateDirectoryUri$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RpcEnv.scala' class='org.apache.spark.rpc.RpcEnvFileServer$class'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='RpcEnvStoppedException.scala' class='org.apache.spark.rpc.RpcEnvStoppedException'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='RpcTimeout.scala' class='org.apache.spark.rpc.RpcTimeout'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='RpcTimeout.scala' class='org.apache.spark.rpc.RpcTimeout$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RpcTimeout.scala' class='org.apache.spark.rpc.RpcTimeout$$anonfun$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='RpcTimeout.scala' class='org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RpcTimeout.scala' class='org.apache.spark.rpc.RpcTimeout$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='RpcTimeout.scala' class='org.apache.spark.rpc.RpcTimeoutException'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='RpcEndpoint.scala' class='org.apache.spark.rpc.ThreadSafeRpcEndpoint'></ClassStats></PackageStats><PackageStats package='org.apache.spark.rpc.netty' total_bugs='2' priority_2='1' priority_3='1' total_size='1822' total_types='96'><ClassStats bugs='0' size='119' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$$anonfun$postLocalMessage$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$$anonfun$postOneWayMessage$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$$anonfun$postRemoteMessage$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$$anonfun$postToAll$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$$anonfun$postToAll$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$$anonfun$postToAll$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$EndpointData'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$MessageLoop'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Dispatcher.scala' class='org.apache.spark.rpc.netty.Dispatcher$MessageLoop$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='89' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox$$anonfun$onDrop$1'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox$$anonfun$process$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox$$anonfun$safelyCall$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.Inbox$$anonfun$safelyCall$2'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.InboxMessage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyRpcCallContext.scala' class='org.apache.spark.rpc.netty.LocalNettyRpcCallContext'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='NettyRpcCallContext.scala' class='org.apache.spark.rpc.netty.NettyRpcCallContext'></ClassStats><ClassStats bugs='1' size='39' priority_3='1' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEndpointRef'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEndpointRef$$anonfun$send$2'></ClassStats><ClassStats bugs='0' size='230' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$ask$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$ask$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$ask$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$asyncSetupEndpointRefByURI$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$deserialize$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$deserialize$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$openChannel$6'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$org$apache$spark$rpc$netty$NettyRpcEnv$$downloadClient$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$org$apache$spark$rpc$netty$NettyRpcEnv$$onSuccess$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$postToOutbox$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$send$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$FileDownloadCallback'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$FileDownloadCallback$$anonfun$onFailure$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$FileDownloadChannel'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnv$FileDownloadChannel$$anonfun$1'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnvFactory'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcEnvFactory$$anonfun$4'></ClassStats><ClassStats bugs='0' size='76' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcHandler'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.NettyRpcHandler$$anonfun$exceptionCaught$1'></ClassStats><ClassStats bugs='1' size='45' priority_2='1' interface='false' sourceFile='NettyStreamManager.scala' class='org.apache.spark.rpc.netty.NettyStreamManager'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyStreamManager.scala' class='org.apache.spark.rpc.netty.NettyStreamManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='NettyStreamManager.scala' class='org.apache.spark.rpc.netty.NettyStreamManager$$anonfun$addDirectory$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NettyStreamManager.scala' class='org.apache.spark.rpc.netty.NettyStreamManager$$anonfun$addFile$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='NettyStreamManager.scala' class='org.apache.spark.rpc.netty.NettyStreamManager$$anonfun$addJar$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.OnStart'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.OnStart$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.OnStop'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.OnStop$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.OneWayMessage'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.OneWayMessage$'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.OneWayOutboxMessage'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.OneWayOutboxMessage$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.OneWayOutboxMessage$$anonfun$onFailure$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.OneWayOutboxMessage$$anonfun$onFailure$2'></ClassStats><ClassStats bugs='0' size='97' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.Outbox'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.Outbox$$anon$1'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.OutboxMessage'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='NettyRpcCallContext.scala' class='org.apache.spark.rpc.netty.RemoteNettyRpcCallContext'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.RemoteProcessConnected'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.RemoteProcessConnected$'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.RemoteProcessConnectionError'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.RemoteProcessConnectionError$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.RemoteProcessDisconnected'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.RemoteProcessDisconnected$'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.RequestMessage'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.RequestMessage$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='RpcEndpointVerifier.scala' class='org.apache.spark.rpc.netty.RpcEndpointVerifier'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RpcEndpointVerifier.scala' class='org.apache.spark.rpc.netty.RpcEndpointVerifier$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RpcEndpointVerifier.scala' class='org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='RpcEndpointVerifier.scala' class='org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RpcEndpointVerifier.scala' class='org.apache.spark.rpc.netty.RpcEndpointVerifier$CheckExistence$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.RpcFailure'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='NettyRpcEnv.scala' class='org.apache.spark.rpc.netty.RpcFailure$'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.RpcMessage'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Inbox.scala' class='org.apache.spark.rpc.netty.RpcMessage$'></ClassStats><ClassStats bugs='0' size='67' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.RpcOutboxMessage'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.RpcOutboxMessage$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Outbox.scala' class='org.apache.spark.rpc.netty.RpcOutboxMessage$$anonfun$onTimeout$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.scheduler' priority_1='1' total_bugs='3' priority_2='2' total_size='11266' total_types='709'><ClassStats bugs='0' size='50' interface='false' sourceFile='AccumulableInfo.scala' class='org.apache.spark.scheduler.AccumulableInfo'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='AccumulableInfo.scala' class='org.apache.spark.scheduler.AccumulableInfo$'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='ActiveJob.scala' class='org.apache.spark.scheduler.ActiveJob'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ActiveJob.scala' class='org.apache.spark.scheduler.ActiveJob$$anonfun$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.AllJobsCancelled'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.AllJobsCancelled$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.AskPermissionToCommitOutput'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.AskPermissionToCommitOutput$'></ClassStats><ClassStats bugs='0' size='123' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anon$2'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anon$3'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anonfun$post$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anonfun$post$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AsyncEventQueue.scala' class='org.apache.spark.scheduler.AsyncEventQueue$$anonfun$post$3'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.BeginEvent'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.BeginEvent$'></ClassStats><ClassStats bugs='0' size='139' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker'></ClassStats><ClassStats bugs='0' size='67' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$applyBlacklistTimeout$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$applyBlacklistTimeout$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$applyBlacklistTimeout$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$applyBlacklistTimeout$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$getBlacklistTimeout$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$getBlacklistTimeout$1$$anonfun$apply$mcJ$sp$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$isBlacklistEnabled$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$isBlacklistEnabled$1$$anonfun$apply$mcZJ$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$isBlacklistEnabled$1$$anonfun$apply$mcZJ$sp$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$org$apache$spark$scheduler$BlacklistTracker$$killBlacklistedExecutor$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$org$apache$spark$scheduler$BlacklistTracker$$killBlacklistedExecutor$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$org$apache$spark$scheduler$BlacklistTracker$$killExecutorsOnBlacklistedNode$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$org$apache$spark$scheduler$BlacklistTracker$$killExecutorsOnBlacklistedNode$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$org$apache$spark$scheduler$BlacklistTracker$$killExecutorsOnBlacklistedNode$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$updateBlacklistForFetchFailure$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$updateBlacklistForFetchFailure$2'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$updateBlacklistForSuccessfulTaskSet$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$updateBlacklistForSuccessfulTaskSet$1$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$updateBlacklistForSuccessfulTaskSet$1$$anonfun$6'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$updateBlacklistForSuccessfulTaskSet$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$updateBlacklistForSuccessfulTaskSet$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$$anonfun$validateBlacklistConfs$1'></ClassStats><ClassStats bugs='0' size='51' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$ExecutorFailureList'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$ExecutorFailureList$$anonfun$addFailures$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$ExecutorFailureList$$anonfun$dropFailuresWithTimeoutBefore$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$ExecutorFailureList$TaskId'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistTracker$ExecutorFailureList$TaskId$'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistedExecutor'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlacklistTracker.scala' class='org.apache.spark.scheduler.BlacklistedExecutor$'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.CompletionEvent'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.CompletionEvent$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.CompressedMapStatus'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.CompressedMapStatus$$anonfun$$lessinit$greater$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.CompressedMapStatus$$anonfun$readExternal$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.CompressedMapStatus$$anonfun$writeExternal$1'></ClassStats><ClassStats bugs='0' size='747' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$12$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$13$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$14'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$15'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$16'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$17'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$19'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$5$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$9$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$activeJobForStage$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cancelJob$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cancelJobGroup$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$2'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanupStateForJobAndIndependentStages$3$$anonfun$removeStage$1$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$createShuffleMapStage$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$getMissingAncestorShuffleDependencies$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$getOrCreateParentStages$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$getShuffleDependencies$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleExecutorAdded$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobCancellation$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobCancellation$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobSubmitted$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobSubmitted$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobSubmitted$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobSubmitted$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobSubmitted$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleMapStageSubmitted$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleMapStageSubmitted$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleMapStageSubmitted$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleMapStageSubmitted$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleMapStageSubmitted$5'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$11'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$12'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$13'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$14'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskCompletion$9'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$handleWorkerRemoved$1'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$22'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1$$anonfun$apply$mcVI$sp$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getOrCreateShuffleMapStage$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$markStageAsFinished$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$markStageAsFinished$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$removeExecutorAndUnregisterOutputs$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$removeExecutorAndUnregisterOutputs$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$removeExecutorAndUnregisterOutputs$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$removeExecutorAndUnregisterOutputs$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$resubmitFailedStages$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$resubmitFailedStages$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$resubmitFailedStages$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$runJob$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$runJob$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitJob$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitJob$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitMissingTasks$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitMissingTasks$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitMissingTasks$2$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitMissingTasks$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitWaitingChildStages$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitWaitingChildStages$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitWaitingChildStages$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitWaitingChildStages$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitWaitingChildStages$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$submitWaitingChildStages$6'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$updateJobIdStageIdMapsList$1$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$visit$1$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGScheduler$$anonfun$visit$2$1'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.DAGSchedulerEvent'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGSchedulerEventProcessLoop'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGSchedulerEventProcessLoop$$anonfun$onError$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DAGScheduler.scala' class='org.apache.spark.scheduler.DAGSchedulerEventProcessLoop$$anonfun$onError$2'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='DAGSchedulerSource.scala' class='org.apache.spark.scheduler.DAGSchedulerSource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGSchedulerSource.scala' class='org.apache.spark.scheduler.DAGSchedulerSource$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGSchedulerSource.scala' class='org.apache.spark.scheduler.DAGSchedulerSource$$anon$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGSchedulerSource.scala' class='org.apache.spark.scheduler.DAGSchedulerSource$$anon$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGSchedulerSource.scala' class='org.apache.spark.scheduler.DAGSchedulerSource$$anon$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DAGSchedulerSource.scala' class='org.apache.spark.scheduler.DAGSchedulerSource$$anon$5'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='TaskResult.scala' class='org.apache.spark.scheduler.DirectTaskResult'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='TaskResult.scala' class='org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1'></ClassStats><ClassStats bugs='1' size='9' priority_1='1' interface='false' sourceFile='TaskResult.scala' class='org.apache.spark.scheduler.DirectTaskResult$$anonfun$readExternal$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskResult.scala' class='org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskResult.scala' class='org.apache.spark.scheduler.DirectTaskResult$$anonfun$writeExternal$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='1' size='183' priority_2='1' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$7$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$logEvent$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$logEvent$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$logEvent$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$openEventLog$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$openEventLog$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$start$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$stop$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$stop$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoggingListener.scala' class='org.apache.spark.scheduler.EventLoggingListener$$anonfun$stop$4'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.ExecutorAdded'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.ExecutorAdded$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.ExecutorCacheTaskLocation'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.ExecutorCacheTaskLocation$'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.ExecutorExited'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.ExecutorExited$'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='ExecutorFailuresInTaskSet.scala' class='org.apache.spark.scheduler.ExecutorFailuresInTaskSet'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorFailuresInTaskSet.scala' class='org.apache.spark.scheduler.ExecutorFailuresInTaskSet$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorFailuresInTaskSet.scala' class='org.apache.spark.scheduler.ExecutorFailuresInTaskSet$$anonfun$getNumTaskFailures$1'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.ExecutorKilled'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.ExecutorKilled$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.ExecutorLossReason'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.ExecutorLost'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.ExecutorLost$'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='ExternalClusterManager.scala' class='org.apache.spark.scheduler.ExternalClusterManager'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FIFOSchedulableBuilder'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SchedulingAlgorithm.scala' class='org.apache.spark.scheduler.FIFOSchedulingAlgorithm'></ClassStats><ClassStats bugs='0' size='124' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$addTaskSetManager$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$addTaskSetManager$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildDefaultPool$1'></ClassStats><ClassStats bugs='1' size='10' priority_2='1' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$buildPools$5'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$org$apache$spark$scheduler$FairSchedulableBuilder$$buildFairSchedulerPool$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$org$apache$spark$scheduler$FairSchedulableBuilder$$buildFairSchedulerPool$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$org$apache$spark$scheduler$FairSchedulableBuilder$$getIntValue$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$org$apache$spark$scheduler$FairSchedulableBuilder$$getSchedulingModeValue$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.FairSchedulableBuilder$$anonfun$org$apache$spark$scheduler$FairSchedulableBuilder$$getSchedulingModeValue$2'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='SchedulingAlgorithm.scala' class='org.apache.spark.scheduler.FairSchedulingAlgorithm'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.GettingResultEvent'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.GettingResultEvent$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.HDFSCacheTaskLocation'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.HDFSCacheTaskLocation$'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$3'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$readExternal$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$readExternal$2$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.HostTaskLocation'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.HostTaskLocation$'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='TaskResult.scala' class='org.apache.spark.scheduler.IndirectTaskResult'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskResult.scala' class='org.apache.spark.scheduler.IndirectTaskResult$'></ClassStats><ClassStats bugs='0' size='99' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$computePreferredLocations$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$computePreferredLocations$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$computePreferredLocations$1$$anonfun$apply$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$computePreferredLocations$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$org$apache$spark$scheduler$InputFormatInfo$$findPreferredLocations$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$prefLocsFromMapredInputFormat$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$prefLocsFromMapreduceInputFormat$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$validate$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$validate$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='InputFormatInfo.scala' class='org.apache.spark.scheduler.InputFormatInfo$$anonfun$validate$3'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.JobCancelled'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.JobCancelled$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='JobResult.scala' class='org.apache.spark.scheduler.JobFailed'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JobResult.scala' class='org.apache.spark.scheduler.JobFailed$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.JobGroupCancelled'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.JobGroupCancelled$'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='JobListener.scala' class='org.apache.spark.scheduler.JobListener'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='JobResult.scala' class='org.apache.spark.scheduler.JobResult'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.JobSubmitted'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.JobSubmitted$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='JobResult.scala' class='org.apache.spark.scheduler.JobSucceeded'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='JobResult.scala' class='org.apache.spark.scheduler.JobSucceeded$'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='JobWaiter.scala' class='org.apache.spark.scheduler.JobWaiter'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JobWaiter.scala' class='org.apache.spark.scheduler.JobWaiter$$anonfun$jobFailed$1'></ClassStats><ClassStats bugs='0' size='100' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$activeQueues$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$findListenersByClass$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$listeners$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$removeListener$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$removeListener$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$start$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBus$$anonfun$waitUntilEmpty$1'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBusMetrics'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBusMetrics$$anonfun$getTimerForListenerClass$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LiveListenerBus.scala' class='org.apache.spark.scheduler.LiveListenerBusMetrics$$anonfun$getTimerForListenerClass$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.LossReasonPending'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.LossReasonPending$'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.MapStageSubmitted'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.MapStageSubmitted$'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.MapStatus'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='MapStatus.scala' class='org.apache.spark.scheduler.MapStatus$'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinationMessage'></ClassStats><ClassStats bugs='0' size='95' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$attemptFailed$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$canCommit$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$handleAskPermissionToCommit$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$handleAskPermissionToCommit$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$handleAskPermissionToCommit$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$handleAskPermissionToCommit$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$handleAskPermissionToCommit$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$taskCompleted$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$taskCompleted$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$$anonfun$taskCompleted$3'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint$$anonfun$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$StageState'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$StageState$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.OutputCommitCoordinator$StageState$$anonfun$1'></ClassStats><ClassStats bugs='0' size='105' interface='false' sourceFile='Pool.scala' class='org.apache.spark.scheduler.Pool'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Pool.scala' class='org.apache.spark.scheduler.Pool$$anonfun$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Pool.scala' class='org.apache.spark.scheduler.Pool$$anonfun$checkSpeculatableTasks$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Pool.scala' class='org.apache.spark.scheduler.Pool$$anonfun$executorLost$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Pool.scala' class='org.apache.spark.scheduler.Pool$$anonfun$getSchedulableByName$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Pool.scala' class='org.apache.spark.scheduler.Pool$$anonfun$getSortedTaskSetQueue$1'></ClassStats><ClassStats bugs='0' size='77' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$replay$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$replay$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$replay$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$replay$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$replay$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$replay$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ReplayListenerBus.scala' class='org.apache.spark.scheduler.ReplayListenerBus$$anonfun$replay$7'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.ResubmitFailedStages'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.ResubmitFailedStages$'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='ResultStage.scala' class='org.apache.spark.scheduler.ResultStage'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ResultStage.scala' class='org.apache.spark.scheduler.ResultStage$$anonfun$findMissingPartitions$1'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='ResultTask.scala' class='org.apache.spark.scheduler.ResultTask'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ResultTask.scala' class='org.apache.spark.scheduler.ResultTask$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.RuntimePercentage'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.RuntimePercentage$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.RuntimePercentage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.RuntimePercentage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.RuntimePercentage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='17' interface='true' sourceFile='Schedulable.scala' class='org.apache.spark.scheduler.Schedulable'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='SchedulableBuilder.scala' class='org.apache.spark.scheduler.SchedulableBuilder'></ClassStats><ClassStats bugs='0' size='12' interface='true' sourceFile='SchedulerBackend.scala' class='org.apache.spark.scheduler.SchedulerBackend'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SchedulerBackend.scala' class='org.apache.spark.scheduler.SchedulerBackend$class'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='SchedulingAlgorithm.scala' class='org.apache.spark.scheduler.SchedulingAlgorithm'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SchedulingMode.scala' class='org.apache.spark.scheduler.SchedulingMode'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SchedulingMode.scala' class='org.apache.spark.scheduler.SchedulingMode$'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='ShuffleMapStage.scala' class='org.apache.spark.scheduler.ShuffleMapStage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleMapStage.scala' class='org.apache.spark.scheduler.ShuffleMapStage$$anonfun$findMissingPartitions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleMapStage.scala' class='org.apache.spark.scheduler.ShuffleMapStage$$anonfun$removeActiveJob$1'></ClassStats><ClassStats bugs='0' size='73' interface='false' sourceFile='ShuffleMapTask.scala' class='org.apache.spark.scheduler.ShuffleMapTask'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ShuffleMapTask.scala' class='org.apache.spark.scheduler.ShuffleMapTask$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleMapTask.scala' class='org.apache.spark.scheduler.ShuffleMapTask$$anon$1'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.SlaveLost'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ExecutorLossReason.scala' class='org.apache.spark.scheduler.SlaveLost$'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListener'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerApplicationEnd'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerApplicationEnd$'></ClassStats><ClassStats bugs='0' size='43' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerApplicationStart'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerApplicationStart$'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerBlockManagerAdded'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerBlockManagerAdded$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerBlockManagerRemoved'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerBlockManagerRemoved$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerBlockUpdated'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerBlockUpdated$'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='SparkListenerBus.scala' class='org.apache.spark.scheduler.SparkListenerBus'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='SparkListenerBus.scala' class='org.apache.spark.scheduler.SparkListenerBus$class'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerEnvironmentUpdate'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerEnvironmentUpdate$'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerEvent'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerEvent$class'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorAdded'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorAdded$'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorBlacklisted'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorBlacklisted$'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorBlacklistedForStage'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorBlacklistedForStage$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate$'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorRemoved'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorRemoved$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorUnblacklisted'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerExecutorUnblacklisted$'></ClassStats><ClassStats bugs='0' size='26' interface='true' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerInterface'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerJobEnd'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerJobEnd$'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerJobStart'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerJobStart$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerJobStart$$anonfun$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerLogStart'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerLogStart$'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerNodeBlacklisted'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerNodeBlacklisted$'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerNodeBlacklistedForStage'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerNodeBlacklistedForStage$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerNodeUnblacklisted'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerNodeUnblacklisted$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerSpeculativeTaskSubmitted'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerSpeculativeTaskSubmitted$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerStageCompleted'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerStageCompleted$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerStageSubmitted'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerStageSubmitted$'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerTaskEnd'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerTaskEnd$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerTaskGettingResult'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerTaskGettingResult$'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerTaskStart'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerTaskStart$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerUnpersistRDD'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SparkListener.scala' class='org.apache.spark.scheduler.SparkListenerUnpersistRDD$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.SpeculativeTaskSubmitted'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.SpeculativeTaskSubmitted$'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='SplitInfo.scala' class='org.apache.spark.scheduler.SplitInfo'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SplitInfo.scala' class='org.apache.spark.scheduler.SplitInfo$'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SplitInfo.scala' class='org.apache.spark.scheduler.SplitInfo$$anonfun$toSplitInfo$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SplitInfo.scala' class='org.apache.spark.scheduler.SplitInfo$$anonfun$toSplitInfo$2'></ClassStats><ClassStats bugs='0' size='83' interface='false' sourceFile='Stage.scala' class='org.apache.spark.scheduler.Stage'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.StageCancelled'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.StageCancelled$'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='StageInfo.scala' class='org.apache.spark.scheduler.StageInfo'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='StageInfo.scala' class='org.apache.spark.scheduler.StageInfo$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageInfo.scala' class='org.apache.spark.scheduler.StageInfo$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StageInfo.scala' class='org.apache.spark.scheduler.StageInfo$$anonfun$fromStage$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageInfo.scala' class='org.apache.spark.scheduler.StageInfo$$anonfun$fromStage$2'></ClassStats><ClassStats bugs='0' size='76' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener'></ClassStats><ClassStats bugs='0' size='83' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$1$$anonfun$apply$mcJJ$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$extractDoubleDistribution$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$extractLongDistribution$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$8$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$onStageCompleted$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$showBytesDistribution$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$showBytesDistribution$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$showDistribution$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$showDistribution$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$showDistribution$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$showDistribution$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$showDistribution$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StatsReportListener.scala' class='org.apache.spark.scheduler.StatsReportListener$$anonfun$showMillisDistribution$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.StopCoordinator'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='OutputCommitCoordinator.scala' class='org.apache.spark.scheduler.StopCoordinator$'></ClassStats><ClassStats bugs='0' size='131' interface='false' sourceFile='Task.scala' class='org.apache.spark.scheduler.Task'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='Task.scala' class='org.apache.spark.scheduler.Task$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Task.scala' class='org.apache.spark.scheduler.Task$$anonfun$collectAccumulatorUpdates$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Task.scala' class='org.apache.spark.scheduler.Task$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='TaskDescription.scala' class='org.apache.spark.scheduler.TaskDescription'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='TaskDescription.scala' class='org.apache.spark.scheduler.TaskDescription$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskDescription.scala' class='org.apache.spark.scheduler.TaskDescription$$anonfun$decode$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskDescription.scala' class='org.apache.spark.scheduler.TaskDescription$$anonfun$deserializeStringLongMap$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskDescription.scala' class='org.apache.spark.scheduler.TaskDescription$$anonfun$encode$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskDescription.scala' class='org.apache.spark.scheduler.TaskDescription$$anonfun$serializeStringLongMap$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskDescription.scala' class='org.apache.spark.scheduler.TaskDescription$$anonfun$serializeStringLongMap$2'></ClassStats><ClassStats bugs='0' size='87' interface='false' sourceFile='TaskInfo.scala' class='org.apache.spark.scheduler.TaskInfo'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='TaskLocality.scala' class='org.apache.spark.scheduler.TaskLocality'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TaskLocality.scala' class='org.apache.spark.scheduler.TaskLocality$'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.TaskLocation'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.TaskLocation$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskLocation.scala' class='org.apache.spark.scheduler.TaskLocation$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='TaskResult.scala' class='org.apache.spark.scheduler.TaskResult'></ClassStats><ClassStats bugs='0' size='48' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$3'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1$$anonfun$apply$mcV$sp$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$4'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$4$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskResultGetter.scala' class='org.apache.spark.scheduler.TaskResultGetter$$anon$4$$anonfun$run$2$$anonfun$apply$mcV$sp$3'></ClassStats><ClassStats bugs='0' size='18' interface='true' sourceFile='TaskScheduler.scala' class='org.apache.spark.scheduler.TaskScheduler'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskScheduler.scala' class='org.apache.spark.scheduler.TaskScheduler$class'></ClassStats><ClassStats bugs='0' size='355' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anon$1$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anon$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anon$2$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$11'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$3$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$8$$anonfun$9'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$8$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1$$anonfun$apply$mcVJ$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$error$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$error$1$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$error$1$$anonfun$apply$11$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$executorLost$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$getExecutorsAliveOnHost$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$isExecutorBusy$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$killTaskAttempt$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$killTaskAttempt$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$liftedTree2$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$liftedTree2$1$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$logExecutorLoss$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$logExecutorLoss$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$logExecutorLoss$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$nodeBlacklist$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$nodeBlacklist$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$org$apache$spark$scheduler$TaskSchedulerImpl$$cleanupTaskState$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$org$apache$spark$scheduler$TaskSchedulerImpl$$cleanupTaskState$1$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$org$apache$spark$scheduler$TaskSchedulerImpl$$resourceOfferSingleTaskSet$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$org$apache$spark$scheduler$TaskSchedulerImpl$$resourceOfferSingleTaskSet$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$org$apache$spark$scheduler$TaskSchedulerImpl$$resourceOfferSingleTaskSet$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$prioritizeContainers$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$prioritizeContainers$1$$anonfun$12'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$removeExecutor$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$removeExecutor$1$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$removeExecutor$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$removeExecutor$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$removeExecutor$2$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$removeExecutor$3'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1$$anonfun$apply$5$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$3$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$4'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$4$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$runningTasksByExecutors$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$submitTasks$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$submitTasks$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$taskSetFinished$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$taskSetFinished$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$taskSetManagerForAttempt$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$taskSetManagerForAttempt$1$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSchedulerImpl.scala' class='org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$workerRemoved$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TaskSet.scala' class='org.apache.spark.scheduler.TaskSet'></ClassStats><ClassStats bugs='0' size='104' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$isExecutorBlacklistedForTask$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$isNodeBlacklistedForTask$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$updateBlacklistForFailedTask$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$updateBlacklistForFailedTask$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetBlacklist.scala' class='org.apache.spark.scheduler.TaskSetBlacklist$$anonfun$updateBlacklistForFailedTask$3'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.TaskSetFailed'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.TaskSetFailed$'></ClassStats><ClassStats bugs='0' size='484' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$12'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$17'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$19'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$20'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$21'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$22'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$7'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$abortIfCompletelyBlacklisted$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$abortIfCompletelyBlacklisted$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$abortIfCompletelyBlacklisted$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$abortIfCompletelyBlacklisted$1$$anonfun$apply$3$$anonfun$15'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$abortIfCompletelyBlacklisted$1$$anonfun$apply$3$$anonfun$15$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1$$anonfun$apply$10$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1$$anonfun$apply$5$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$canFetchMoreResults$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$checkSpeculatableTasks$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$checkSpeculatableTasks$1$$anonfun$apply$mcVJ$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$checkSpeculatableTasks$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$checkSpeculatableTasks$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$computeValidLocalityLevels$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$computeValidLocalityLevels$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$computeValidLocalityLevels$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$computeValidLocalityLevels$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$10'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$3$$anonfun$8'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$4'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$5$$anonfun$9'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$6'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$7'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$8'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$9$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$9$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$9$$anonfun$apply$2$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueSpeculativeTask$9$$anonfun$apply$2$$anonfun$11'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueTask$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueTask$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueTask$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueTask$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueTask$4$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueTask$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$dequeueTask$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$executorLost$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$executorLost$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$executorLost$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$executorLost$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$executorLost$5'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$executorLost$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$getAllowedLocalityLevel$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$getAllowedLocalityLevel$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$getPendingTasksForExecutor$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$getPendingTasksForHost$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$handleFailedTask$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$handleFailedTask$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$handleFailedTask$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$handleSuccessfulTask$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$handleSuccessfulTask$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$handleSuccessfulTask$2$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$handleSuccessfulTask$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$handleSuccessfulTask$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$hasAttemptOnHost$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$isTaskBlacklistedOnExecOrNode$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$maybeFinishTaskSet$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$moreTasksToRunIn$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$org$apache$spark$scheduler$TaskSetManager$$getPendingTasksForRack$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$recomputeLocality$1'></ClassStats><ClassStats bugs='0' size='48' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$resourceOffer$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$resourceOffer$1$$anonfun$13'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$resourceOffer$1$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='TaskSetManager.scala' class='org.apache.spark.scheduler.TaskSetManager$$anonfun$resourceOffer$1$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='WorkerOffer.scala' class='org.apache.spark.scheduler.WorkerOffer'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='WorkerOffer.scala' class='org.apache.spark.scheduler.WorkerOffer$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.WorkerRemoved'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DAGSchedulerEvent.scala' class='org.apache.spark.scheduler.WorkerRemoved$'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.scheduler.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.scheduler.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.scheduler.cluster' total_bugs='0' total_size='1817' total_types='131'><ClassStats bugs='0' size='1' interface='true' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessage'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$AddWebUIFilter'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$AddWebUIFilter$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$GetExecutorLossReason'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$GetExecutorLossReason$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$KillExecutors'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$KillExecutors$'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$KillExecutorsOnHost'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$KillExecutorsOnHost$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$KillTask'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$KillTask$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$LaunchTask'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$LaunchTask$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisterClusterManager'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisterClusterManager$'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisterExecutor'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisterExecutor$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisterExecutorFailed'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisterExecutorFailed$'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisterExecutorResponse'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RegisteredExecutor$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RemoveExecutor'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RemoveExecutor$'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RemoveWorker'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RemoveWorker$'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RequestExecutors'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RequestExecutors$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RetrieveLastAllocatedExecutorId$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$RetrieveSparkAppConfig$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$ReviveOffers$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$SetupDriver'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$SetupDriver$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$Shutdown$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$SparkAppConfig'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$SparkAppConfig$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$StatusUpdate'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$StatusUpdate$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$StopDriver$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$StopExecutor$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$StopExecutors$'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$UpdateDelegationTokens'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedClusterMessage.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedClusterMessages$UpdateDelegationTokens$'></ClassStats><ClassStats bugs='0' size='224' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$11'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$12'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$14'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$4'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$7$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$isReady$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$isReady$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$killExecutors$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$killExecutorsOnHost$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$removeWorker$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$removeWorker$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$requestExecutors$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$reset$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$start$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$start$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$$anonfun$stopExecutors$1'></ClassStats><ClassStats bugs='0' size='108' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anon$1$$anonfun$run$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$disableExecutor$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$launchTasks$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$launchTasks$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$launchTasks$1$$anonfun$apply$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$launchTasks$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$onDisconnected$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$removeExecutor$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$removeExecutor$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$removeWorker$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1$$anonfun$applyOrElse$5'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$6'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CoarseGrainedSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$9'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ExecutorData.scala' class='org.apache.spark.scheduler.cluster.ExecutorData'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ExecutorInfo.scala' class='org.apache.spark.scheduler.cluster.ExecutorInfo'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorInfo.scala' class='org.apache.spark.scheduler.cluster.ExecutorInfo$$anonfun$hashCode$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorInfo.scala' class='org.apache.spark.scheduler.cluster.ExecutorInfo$$anonfun$hashCode$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SchedulerBackendUtils.scala' class='org.apache.spark.scheduler.cluster.SchedulerBackendUtils'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='SchedulerBackendUtils.scala' class='org.apache.spark.scheduler.cluster.SchedulerBackendUtils$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SchedulerBackendUtils.scala' class='org.apache.spark.scheduler.cluster.SchedulerBackendUtils$$anonfun$getInitialTargetExecutorNumber$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SchedulerBackendUtils.scala' class='org.apache.spark.scheduler.cluster.SchedulerBackendUtils$$anonfun$getInitialTargetExecutorNumber$2'></ClassStats><ClassStats bugs='0' size='141' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$9'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$applicationId$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$applicationId$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$connected$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$dead$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$disconnected$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$doKillExecutors$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$doRequestTotalExecutors$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$executorAdded$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$executorRemoved$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StandaloneSchedulerBackend.scala' class='org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$$anonfun$workerRemoved$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.scheduler.local' total_bugs='1' priority_2='1' total_size='324' total_types='17'><ClassStats bugs='0' size='25' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.KillTask'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.KillTask$'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalEndpoint'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$reviveOffers$1'></ClassStats><ClassStats bugs='0' size='82' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalSchedulerBackend'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$2'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.LocalSchedulerBackend$$anonfun$getUserClasspath$3'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.ReviveOffers'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.ReviveOffers$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.StatusUpdate'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.StatusUpdate$'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.StopExecutor'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='LocalSchedulerBackend.scala' class='org.apache.spark.scheduler.local.StopExecutor$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.security' total_bugs='4' priority_2='4' total_size='191' total_types='8'><ClassStats bugs='0' size='45' interface='false' sourceFile='CryptoStreamUtils.scala' class='org.apache.spark.security.CryptoStreamUtils'></ClassStats><ClassStats bugs='4' size='74' priority_2='4' interface='false' sourceFile='CryptoStreamUtils.scala' class='org.apache.spark.security.CryptoStreamUtils$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='CryptoStreamUtils.scala' class='org.apache.spark.security.CryptoStreamUtils$$anonfun$createInitializationVector$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='CryptoStreamUtils.scala' class='org.apache.spark.security.CryptoStreamUtils$CryptoHelperChannel'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CryptoStreamUtils.scala' class='org.apache.spark.security.CryptoStreamUtils$CryptoParams'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='GroupMappingServiceProvider.scala' class='org.apache.spark.security.GroupMappingServiceProvider'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='ShellBasedGroupsMappingProvider.scala' class='org.apache.spark.security.ShellBasedGroupsMappingProvider'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShellBasedGroupsMappingProvider.scala' class='org.apache.spark.security.ShellBasedGroupsMappingProvider$$anonfun$getGroups$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.serializer' priority_1='1' total_bugs='1' total_size='1460' total_types='75'><ClassStats bugs='0' size='13' interface='false' sourceFile='Serializer.scala' class='org.apache.spark.serializer.DeserializationStream'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Serializer.scala' class='org.apache.spark.serializer.DeserializationStream$$anon$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Serializer.scala' class='org.apache.spark.serializer.DeserializationStream$$anon$2'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='DummySerializerInstance.java' class='org.apache.spark.serializer.DummySerializerInstance'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DummySerializerInstance.java' class='org.apache.spark.serializer.DummySerializerInstance$1'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$4'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$compress$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$compress$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$compress$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$decompress$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$decompress$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$decompress$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$deserializeDatum$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='GenericAvroSerializer.scala' class='org.apache.spark.serializer.GenericAvroSerializer$$anonfun$serializeDatum$1'></ClassStats><ClassStats bugs='1' size='14' priority_1='1' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaDeserializationStream'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaDeserializationStream$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaDeserializationStream$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaDeserializationStream$$anon$1$$anonfun$resolveClass$1'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.JavaIterableWrapperSerializer'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.JavaIterableWrapperSerializer$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.JavaIterableWrapperSerializer$$anonfun$liftedTree1$1$1'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaSerializationStream'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaSerializer'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaSerializer$$anonfun$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaSerializer$$anonfun$readExternal$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaSerializer$$anonfun$writeExternal$1'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='JavaSerializer.scala' class='org.apache.spark.serializer.JavaSerializerInstance'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoDeserializationStream'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoInputObjectInputBridge'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoOutputObjectOutputBridge'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoRegistrator'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializationStream'></ClassStats><ClassStats bugs='0' size='151' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$6'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializer$$anonfun$newKryo$7'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='KryoSerializer.scala' class='org.apache.spark.serializer.KryoSerializerInstance'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$$anonfun$improveException$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$$anonfun$improveException$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$$anonfun$liftedTree1$1$1'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$ListObjectOutput'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$ListObjectOutputStream'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$NullOutputStream'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$ObjectStreamClassMethods'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$ObjectStreamClassMethods$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$ObjectStreamClassMethods$$anonfun$getSlotDescs$extension$1'></ClassStats><ClassStats bugs='0' size='46' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$ObjectStreamClassReflection'></ClassStats><ClassStats bugs='0' size='91' interface='false' sourceFile='SerializationDebugger.scala' class='org.apache.spark.serializer.SerializationDebugger$SerializationDebugger'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Serializer.scala' class='org.apache.spark.serializer.SerializationStream'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Serializer.scala' class='org.apache.spark.serializer.Serializer'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Serializer.scala' class='org.apache.spark.serializer.SerializerInstance'></ClassStats><ClassStats bugs='0' size='101' interface='false' sourceFile='SerializerManager.scala' class='org.apache.spark.serializer.SerializerManager'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerializerManager.scala' class='org.apache.spark.serializer.SerializerManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SerializerManager.scala' class='org.apache.spark.serializer.SerializerManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerializerManager.scala' class='org.apache.spark.serializer.SerializerManager$$anonfun$wrapForEncryption$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerializerManager.scala' class='org.apache.spark.serializer.SerializerManager$$anonfun$wrapForEncryption$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SerializerManager.scala' class='org.apache.spark.serializer.SerializerManager$$anonfun$wrapForEncryption$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SerializerManager.scala' class='org.apache.spark.serializer.SerializerManager$$anonfun$wrapForEncryption$4'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.serializer.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.serializer.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.shuffle' total_bugs='0' total_size='393' total_types='27'><ClassStats bugs='0' size='9' interface='false' sourceFile='BaseShuffleHandle.scala' class='org.apache.spark.shuffle.BaseShuffleHandle'></ClassStats><ClassStats bugs='0' size='81' interface='false' sourceFile='BlockStoreShuffleReader.scala' class='org.apache.spark.shuffle.BlockStoreShuffleReader'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockStoreShuffleReader.scala' class='org.apache.spark.shuffle.BlockStoreShuffleReader$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockStoreShuffleReader.scala' class='org.apache.spark.shuffle.BlockStoreShuffleReader$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockStoreShuffleReader.scala' class='org.apache.spark.shuffle.BlockStoreShuffleReader$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockStoreShuffleReader.scala' class='org.apache.spark.shuffle.BlockStoreShuffleReader$$anonfun$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockStoreShuffleReader.scala' class='org.apache.spark.shuffle.BlockStoreShuffleReader$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockStoreShuffleReader.scala' class='org.apache.spark.shuffle.BlockStoreShuffleReader$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockStoreShuffleReader.scala' class='org.apache.spark.shuffle.BlockStoreShuffleReader$$anonfun$read$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='FetchFailedException.scala' class='org.apache.spark.shuffle.FetchFailedException'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FetchFailedException.scala' class='org.apache.spark.shuffle.FetchFailedException$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FetchFailedException.scala' class='org.apache.spark.shuffle.FetchFailedException$$anonfun$1'></ClassStats><ClassStats bugs='0' size='120' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$blockManager$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$removeDataByMap$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$removeDataByMap$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$writeIndexFileAndCommit$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$writeIndexFileAndCommit$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$writeIndexFileAndCommit$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='IndexShuffleBlockResolver.scala' class='org.apache.spark.shuffle.IndexShuffleBlockResolver$$anonfun$writeIndexFileAndCommit$3'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='FetchFailedException.scala' class='org.apache.spark.shuffle.MetadataFetchFailedException'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ShuffleBlockResolver.scala' class='org.apache.spark.shuffle.ShuffleBlockResolver'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ShuffleHandle.scala' class='org.apache.spark.shuffle.ShuffleHandle'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='ShuffleManager.scala' class='org.apache.spark.shuffle.ShuffleManager'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='ShuffleReader.scala' class='org.apache.spark.shuffle.ShuffleReader'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ShuffleWriter.scala' class='org.apache.spark.shuffle.ShuffleWriter'></ClassStats></PackageStats><PackageStats package='org.apache.spark.shuffle.sort' total_bugs='14' priority_3='14' total_size='997' total_types='24'><ClassStats bugs='0' size='3' interface='false' sourceFile='SortShuffleManager.scala' class='org.apache.spark.shuffle.sort.BypassMergeSortShuffleHandle'></ClassStats><ClassStats bugs='3' size='115' priority_3='3' interface='false' sourceFile='BypassMergeSortShuffleWriter.java' class='org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='PackedRecordPointer.java' class='org.apache.spark.shuffle.sort.PackedRecordPointer'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='SortShuffleManager.scala' class='org.apache.spark.shuffle.sort.SerializedShuffleHandle'></ClassStats><ClassStats bugs='2' size='189' priority_3='2' interface='false' sourceFile='ShuffleExternalSorter.java' class='org.apache.spark.shuffle.sort.ShuffleExternalSorter'></ClassStats><ClassStats bugs='0' size='72' interface='false' sourceFile='ShuffleInMemorySorter.java' class='org.apache.spark.shuffle.sort.ShuffleInMemorySorter'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='ShuffleInMemorySorter.java' class='org.apache.spark.shuffle.sort.ShuffleInMemorySorter$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ShuffleInMemorySorter.java' class='org.apache.spark.shuffle.sort.ShuffleInMemorySorter$ShuffleSorterIterator'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ShuffleInMemorySorter.java' class='org.apache.spark.shuffle.sort.ShuffleInMemorySorter$SortComparator'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='ShuffleSortDataFormat.java' class='org.apache.spark.shuffle.sort.ShuffleSortDataFormat'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='SortShuffleManager.scala' class='org.apache.spark.shuffle.sort.SortShuffleManager'></ClassStats><ClassStats bugs='4' size='45' priority_3='4' interface='false' sourceFile='SortShuffleManager.scala' class='org.apache.spark.shuffle.sort.SortShuffleManager$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SortShuffleManager.scala' class='org.apache.spark.shuffle.sort.SortShuffleManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SortShuffleManager.scala' class='org.apache.spark.shuffle.sort.SortShuffleManager$$anonfun$unregisterShuffle$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SortShuffleManager.scala' class='org.apache.spark.shuffle.sort.SortShuffleManager$$anonfun$unregisterShuffle$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='SortShuffleWriter.scala' class='org.apache.spark.shuffle.sort.SortShuffleWriter'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SortShuffleWriter.scala' class='org.apache.spark.shuffle.sort.SortShuffleWriter$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SortShuffleWriter.scala' class='org.apache.spark.shuffle.sort.SortShuffleWriter$$anonfun$shouldBypassMergeSort$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SortShuffleWriter.scala' class='org.apache.spark.shuffle.sort.SortShuffleWriter$$anonfun$write$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SortShuffleWriter.scala' class='org.apache.spark.shuffle.sort.SortShuffleWriter$$anonfun$write$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SpillInfo.java' class='org.apache.spark.shuffle.sort.SpillInfo'></ClassStats><ClassStats bugs='5' size='237' priority_3='5' interface='false' sourceFile='UnsafeShuffleWriter.java' class='org.apache.spark.shuffle.sort.UnsafeShuffleWriter'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UnsafeShuffleWriter.java' class='org.apache.spark.shuffle.sort.UnsafeShuffleWriter$CloseAndFlushShieldOutputStream'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='UnsafeShuffleWriter.java' class='org.apache.spark.shuffle.sort.UnsafeShuffleWriter$MyByteArrayOutputStream'></ClassStats></PackageStats><PackageStats package='org.apache.spark.status' total_bugs='0' total_size='4461' total_types='245'><ClassStats bugs='0' size='3' interface='true' sourceFile='AppHistoryServerPlugin.scala' class='org.apache.spark.status.AppHistoryServerPlugin'></ClassStats><ClassStats bugs='0' size='395' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$16'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$17'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$17$$anonfun$18'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$20'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$21'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$23'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$activeStages$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$activeStages$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$activeStages$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$getOrCreateExecutor$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onApplicationStart$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onApplicationStart$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onApplicationStart$2$$anonfun$6'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onApplicationStart$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onBlockManagerAdded$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onEnvironmentUpdate$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onEnvironmentUpdate$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onExecutorBlacklistedForStage$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onExecutorMetricsUpdate$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onExecutorMetricsUpdate$1$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onExecutorMetricsUpdate$1$$anonfun$apply$12$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onExecutorRemoved$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onExecutorRemoved$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onJobEnd$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onJobStart$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onJobStart$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onNodeBlacklistedForStage$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onNodeBlacklistedForStage$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageCompleted$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageCompleted$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageCompleted$1$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageCompleted$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageSubmitted$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageSubmitted$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageSubmitted$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageSubmitted$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageSubmitted$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageSubmitted$6'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageSubmitted$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onStageSubmitted$7$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskEnd$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskEnd$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskEnd$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskEnd$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskGettingResult$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskStart$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskStart$1$$anonfun$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskStart$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskStart$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$onTaskStart$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupCachedQuantiles$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupExecutors$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupJobs$1'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupStages$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupStages$1$$anonfun$22'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupStages$1$$anonfun$apply$18'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupStages$1$$anonfun$apply$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupTasks$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$cleanupTasks$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$flush$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$flush$1$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$flush$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$flush$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$flush$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$flush$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$flush$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$killedTasksSummary$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$killedTasksSummary$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$org$apache$spark$status$AppStatusListener$$newRDDOperationCluster$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateBlackListStatus$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateNodeBlackList$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateRDDBlock$1'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateRDDBlock$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateRDDBlock$2$$anonfun$19'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateRDDBlock$2$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateRDDBlock$2$$anonfun$apply$15$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateRDDBlock$2$$anonfun$apply$15$$anonfun$apply$16$$anonfun$apply$17'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusListener.scala' class='org.apache.spark.status.AppStatusListener$$anonfun$updateRDDBlock$3'></ClassStats><ClassStats bugs='0' size='247' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$19'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$22'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$24'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$25'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$26'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$28'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$29'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$30'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$32'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$33'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$34'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$35'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$36'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$37'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$38'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$39'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$40'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$41'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$42'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$43'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$44'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$45'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$46'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$47'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$48'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$49'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$50'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$51'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$52'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$53'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$54'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$55'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$56'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$57'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$58'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$59'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$60'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$61'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$62'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$7$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$7$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$activeStages$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$activeStages$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$executorList$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$executorSummary$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$jobsList$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$operationGraphForJob$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$rddList$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$rddList$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$scanTasks$1$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$scanTasks$1$2'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$scanTasks$1$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$stageData$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$stageList$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$taskList$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$taskList$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$taskSummary$1'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='AppStatusStore.scala' class='org.apache.spark.status.AppStatusStore$$anonfun$taskSummary$2'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.AppStatusStoreMetadata'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.AppStatusStoreMetadata$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AppStatusUtils.scala' class='org.apache.spark.status.AppStatusUtils'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='AppStatusUtils.scala' class='org.apache.spark.status.AppStatusUtils$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppStatusUtils.scala' class='org.apache.spark.status.AppStatusUtils$$anonfun$gettingResultTime$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.AppSummary'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.ApplicationEnvironmentInfoWrapper'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.ApplicationInfoWrapper'></ClassStats><ClassStats bugs='0' size='100' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.CachedQuantile'></ClassStats><ClassStats bugs='0' size='64' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore$$anonfun$close$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore$$anonfun$write$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore$$anonfun$write$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore$$anonfun$write$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore$Trigger'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ElementTrackingStore.scala' class='org.apache.spark.status.ElementTrackingStore$Trigger$'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.ExecutorStageSummaryWrapper'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.ExecutorSummaryWrapper'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.JobDataWrapper'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='KVUtils.scala' class='org.apache.spark.status.KVUtils'></ClassStats><ClassStats bugs='0' size='38' interface='false' sourceFile='KVUtils.scala' class='org.apache.spark.status.KVUtils$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='KVUtils.scala' class='org.apache.spark.status.KVUtils$$anonfun$open$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='KVUtils.scala' class='org.apache.spark.status.KVUtils$KVStoreScalaSerializer'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='KVUtils.scala' class='org.apache.spark.status.KVUtils$MetadataMismatchException'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveEntity'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveEntityHelpers'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveEntityHelpers$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveEntityHelpers$$anonfun$newAccumulatorInfos$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveEntityHelpers$$anonfun$newAccumulatorInfos$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveEntityHelpers$$anonfun$newAccumulatorInfos$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveEntityHelpers$$anonfun$newAccumulatorInfos$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveEntityHelpers$$anonfun$newAccumulatorInfos$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='146' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveExecutor'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveExecutorStageSummary'></ClassStats><ClassStats bugs='0' size='90' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveJob'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveRDD'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveRDD$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveRDD$$anonfun$distribution$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveRDD$$anonfun$partition$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveRDD$$anonfun$removePartition$1'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveRDDDistribution'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveRDDPartition'></ClassStats><ClassStats bugs='0' size='114' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveStage'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveStage$$anonfun$executorSummary$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveStage$$anonfun$toApi$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveStage$$anonfun$toApi$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveStage$$anonfun$toApi$3'></ClassStats><ClassStats bugs='0' size='97' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveTask'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.LiveTask$$anonfun$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.PoolData'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.RDDOperationClusterWrapper'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.RDDOperationClusterWrapper$$anonfun$toRDDOperationCluster$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.RDDOperationClusterWrapper$$anonfun$toRDDOperationCluster$2'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.RDDOperationGraphWrapper'></ClassStats><ClassStats bugs='0' size='250' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.RDDPartitionSeq'></ClassStats><ClassStats bugs='0' size='109' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.RDDPartitionSeq$$anon$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.RDDStorageInfoWrapper'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='LiveEntity.scala' class='org.apache.spark.status.SchedulerPool'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.StageDataWrapper'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.StreamBlockData'></ClassStats><ClassStats bugs='0' size='195' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.TaskDataWrapper'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.TaskIndexNames'></ClassStats><ClassStats bugs='0' size='116' interface='false' sourceFile='storeTypes.scala' class='org.apache.spark.status.TaskIndexNames$'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='config.scala' class='org.apache.spark.status.config'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='config.scala' class='org.apache.spark.status.config$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.status.api.v1' total_bugs='17' priority_3='17' total_size='1459' total_types='86'><ClassStats bugs='10' size='59' priority_3='10' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$allExecutorList$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$environmentInfo$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$executorList$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$getEventLogs$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$getEventLogs$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$jobsList$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$oneJob$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$rddData$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.AbstractApplicationResource$$anonfun$rddList$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.AccumulableInfo'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.ApiRequestContext'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.ApiRequestContext$class'></ClassStats><ClassStats bugs='3' size='17' priority_3='3' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.ApiRootResource'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.ApiRootResource$'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ApplicationAttemptInfo'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ApplicationAttemptInfo$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ApplicationEnvironmentInfo'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ApplicationInfo'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ApplicationInfo$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ApplicationListResource.scala' class='org.apache.spark.status.api.v1.ApplicationListResource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApplicationListResource.scala' class='org.apache.spark.status.api.v1.ApplicationListResource$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationListResource.scala' class='org.apache.spark.status.api.v1.ApplicationListResource$$anonfun$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ApplicationListResource.scala' class='org.apache.spark.status.api.v1.ApplicationListResource$$anonfun$appList$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ApplicationListResource.scala' class='org.apache.spark.status.api.v1.ApplicationListResource$$anonfun$appList$1$$anonfun$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ApplicationListResource.scala' class='org.apache.spark.status.api.v1.ApplicationListResource$$anonfun$appList$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ApplicationStatus.java' class='org.apache.spark.status.api.v1.ApplicationStatus'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.BadParameterException'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.BaseAppResource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.BaseAppResource$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.BaseAppResource$$anonfun$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.BaseAppResource$$anonfun$withUI$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.BaseAppResource$class'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.ErrorWrapper'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.ErrorWrapper$'></ClassStats><ClassStats bugs='0' size='48' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ExecutorStageSummary'></ClassStats><ClassStats bugs='0' size='75' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ExecutorSummary'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.ForbiddenException'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.InputMetricDistributions'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.InputMetrics'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='JacksonMessageWriter.scala' class='org.apache.spark.status.api.v1.JacksonMessageWriter'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JacksonMessageWriter.scala' class='org.apache.spark.status.api.v1.JacksonMessageWriter$'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='JacksonMessageWriter.scala' class='org.apache.spark.status.api.v1.JacksonMessageWriter$$anon$1'></ClassStats><ClassStats bugs='0' size='63' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.JobData'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.MemoryMetrics'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.NotFoundException'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.OneApplicationAttemptResource'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.OneApplicationAttemptResource$$anonfun$getAttempt$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.OneApplicationAttemptResource$$anonfun$getAttempt$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.OneApplicationAttemptResource$$anonfun$getAttempt$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.OneApplicationResource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OneApplicationResource.scala' class='org.apache.spark.status.api.v1.OneApplicationResource$$anonfun$getApp$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.OutputMetricDistributions'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.OutputMetrics'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.RDDDataDistribution'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.RDDPartitionInfo'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.RDDStorageInfo'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.RuntimeInfo'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='SecurityFilter.scala' class='org.apache.spark.status.api.v1.SecurityFilter'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ShuffleReadMetricDistributions'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ShuffleReadMetrics'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ShuffleWriteMetricDistributions'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.ShuffleWriteMetrics'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='SimpleDateParam.scala' class='org.apache.spark.status.api.v1.SimpleDateParam'></ClassStats><ClassStats bugs='0' size='105' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.StageData'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='StageStatus.java' class='org.apache.spark.status.api.v1.StageStatus'></ClassStats><ClassStats bugs='4' size='27' priority_3='4' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource$$anonfun$oneAttemptData$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource$$anonfun$oneAttemptData$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource$$anonfun$stageData$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource$$anonfun$stageList$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource$$anonfun$taskList$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource$$anonfun$taskSummary$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource$$anonfun$taskSummary$1$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagesResource.scala' class='org.apache.spark.status.api.v1.StagesResource$$anonfun$taskSummary$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.TaskData'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.TaskData$'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.TaskMetricDistributions'></ClassStats><ClassStats bugs='0' size='45' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.TaskMetrics'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='TaskSorting.java' class='org.apache.spark.status.api.v1.TaskSorting'></ClassStats><ClassStats bugs='0' size='6' interface='true' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.UIRoot'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.UIRoot$class'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.UIRootFromServletContext'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ApiRootResource.scala' class='org.apache.spark.status.api.v1.UIRootFromServletContext$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='api.scala' class='org.apache.spark.status.api.v1.VersionInfo'></ClassStats></PackageStats><PackageStats package='org.apache.spark.storage' total_bugs='6' priority_2='6' total_size='7760' total_types='521'><ClassStats bugs='1' size='54' priority_2='1' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BasicBlockReplicationPolicy'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BasicBlockReplicationPolicy$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BasicBlockReplicationPolicy$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BasicBlockReplicationPolicy$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BasicBlockReplicationPolicy$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BasicBlockReplicationPolicy$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BasicBlockReplicationPolicy$$anonfun$prioritize$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BasicBlockReplicationPolicy$$anonfun$prioritize$4'></ClassStats><ClassStats bugs='0' size='7' interface='true' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockData'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='BlockException.scala' class='org.apache.spark.storage.BlockException'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockException.scala' class='org.apache.spark.storage.BlockException$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.BlockId'></ClassStats><ClassStats bugs='0' size='58' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.BlockId$'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfo'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfo$'></ClassStats><ClassStats bugs='0' size='159' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$clear$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$downgradeLock$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$downgradeLock$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$getNumberOfMapEntries$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$getNumberOfMapEntries$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$getTaskLockCount$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$getTaskLockCount$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$getTaskLockCount$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$getTaskLockCount$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$lockForReading$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$lockForReading$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$lockForWriting$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$lockForWriting$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$lockNewBlockForWriting$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$org$apache$spark$storage$BlockInfoManager$$currentTaskAttemptId$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$org$apache$spark$storage$BlockInfoManager$$currentTaskAttemptId$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$registerTask$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$removeBlock$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$unlock$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$unlock$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockInfoManager.scala' class='org.apache.spark.storage.BlockInfoManager$$anonfun$unlock$3'></ClassStats><ClassStats bugs='0' size='644' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$14'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$15'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$17'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$19'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$21'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$22'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$24'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$25'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$26'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$27'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$28'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$29'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$30'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$31'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$9'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$asyncReregister$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$blockIdsToHosts$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$blockIdsToHosts$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPut$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPut$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPut$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPut$4'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1$$anonfun$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1$$anonfun$20$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1$$anonfun$20$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutBytes$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$dropFromMemory$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$dropFromMemory$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$dropFromMemory$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$dropFromMemory$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$get$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$get$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getLocalBytes$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getLocalBytes$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getLocalValues$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getLocalValues$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getLocalValues$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getMatchingBlockIds$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getMatchingBlockIds$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getRemoteBytes$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getRemoteBytes$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getRemoteBytes$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getRemoteBytes$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getRemoteBytes$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getRemoteValues$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getSingle$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$getStatus$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$initialize$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$initialize$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$initialize$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$addUpdatedBlockStatusToTaskMetrics$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$doGetLocalBytes$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$doGetLocalBytes$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$doGetLocalBytes$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$getLocationBlockIds$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$getPeers$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$getPeers$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$replicate$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$replicate$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$replicate$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$replicate$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$replicate$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$replicate$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$reportBlockStatus$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$org$apache$spark$storage$BlockManager$$reportBlockStatus$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$putBytes$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$putIterator$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$registerWithExternalShuffleServer$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$registerWithExternalShuffleServer$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$registerWithExternalShuffleServer$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$removeBlock$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$removeBlock$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$removeBlockInternal$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$removeBroadcast$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$removeBroadcast$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$removeRdd$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$replicateBlock$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$replicateBlock$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$replicateBlock$2$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$reportAllBlocks$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$reregister$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$$anonfun$org$apache$spark$storage$BlockManager$RemoteBlockTempFileManager$$keepCleaning$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$$anonfun$org$apache$spark$storage$BlockManager$RemoteBlockTempFileManager$$keepCleaning$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$$anonfun$org$apache$spark$storage$BlockManager$RemoteBlockTempFileManager$$keepCleaning$3'></ClassStats><ClassStats bugs='1' size='14' priority_2='1' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup$$anonfun$cleanUp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$RemoteBlockTempFileManager$ReferenceWithCleanup$$anonfun$cleanUp$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockManager$ShuffleMetricsSource'></ClassStats><ClassStats bugs='0' size='62' interface='false' sourceFile='BlockManagerId.scala' class='org.apache.spark.storage.BlockManagerId'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='BlockManagerId.scala' class='org.apache.spark.storage.BlockManagerId$'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='BlockManagerId.scala' class='org.apache.spark.storage.BlockManagerId$$anonfun$readExternal$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='BlockManagerId.scala' class='org.apache.spark.storage.BlockManagerId$$anonfun$writeExternal$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerId.scala' class='org.apache.spark.storage.BlockManagerId$$anonfun$writeExternal$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='117' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerInfo'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerInfo$$anonfun$updateBlockInfo$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerInfo$$anonfun$updateBlockInfo$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerInfo$$anonfun$updateBlockInfo$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerInfo$$anonfun$updateBlockInfo$4'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerInfo$$anonfun$updateBlockInfo$5'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerInfo$$anonfun$updateBlockInfo$6'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='BlockManagerManagedBuffer.scala' class='org.apache.spark.storage.BlockManagerManagedBuffer'></ClassStats><ClassStats bugs='0' size='122' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$getBlockStatus$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$getBlockStatus$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$registerBlockManager$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$registerBlockManager$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$removeBroadcast$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$removeBroadcast$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$removeExecutor$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$removeExecutorAsync$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$removeRdd$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$removeRdd$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$removeShuffle$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$removeShuffle$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMaster.scala' class='org.apache.spark.storage.BlockManagerMaster$$anonfun$updateBlockInfo$1'></ClassStats><ClassStats bugs='1' size='198' priority_2='1' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$11'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$4'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$5'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$5$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$5$$anonfun$apply$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$6'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$blockStatus$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$blockStatus$1$$anonfun$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$getExecutorEndpointRef$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$getExecutorEndpointRef$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$getLocationsMultipleBlockIds$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$getMatchingBlockIds$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$getMatchingBlockIds$1$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$getMatchingBlockIds$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$getPeers$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$getPeers$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$memoryStatus$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$register$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$register$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeBlockFromWorkers$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeBlockManager$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeBlockManager$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeBlockManager$2$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeBlockManager$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeBroadcast$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeExecutor$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeExecutor$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeRdd$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeRdd$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeRdd$1$$anonfun$apply$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$removeShuffle$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$org$apache$spark$storage$BlockManagerMasterEndpoint$$storageStatus$1'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$BlockLocationsAndStatus'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$BlockLocationsAndStatus$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$BlockManagerHeartbeat'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$BlockManagerHeartbeat$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetBlockStatus'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetBlockStatus$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetExecutorEndpointRef'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetExecutorEndpointRef$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetLocations'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetLocations$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetLocationsAndStatus'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetLocationsAndStatus$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetLocationsMultipleBlockIds'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetLocationsMultipleBlockIds$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetMatchingBlockIds'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetMatchingBlockIds$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetMemoryStatus$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetPeers'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetPeers$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$GetStorageStatus$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$HasCachedBlocks'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$HasCachedBlocks$'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RegisterBlockManager'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RegisterBlockManager$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveBlock'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveBlock$'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveBroadcast'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveBroadcast$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveExecutor'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveExecutor$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveRdd'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveRdd$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveShuffle'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$RemoveShuffle$'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$ReplicateBlock'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$ReplicateBlock$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$StopBlockManagerMaster$'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$ToBlockManagerMaster'></ClassStats><ClassStats bugs='0' size='1' interface='true' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$ToBlockManagerSlave'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$TriggerThreadDump$'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$UpdateBlockInfo'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$UpdateBlockInfo$'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$UpdateBlockInfo$$anonfun$readExternal$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='BlockManagerMessages.scala' class='org.apache.spark.storage.BlockManagerMessages$UpdateBlockInfo$$anonfun$writeExternal$1'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$org$apache$spark$storage$BlockManagerSlaveEndpoint$$doAsync$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$org$apache$spark$storage$BlockManagerSlaveEndpoint$$doAsync$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$org$apache$spark$storage$BlockManagerSlaveEndpoint$$doAsync$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$org$apache$spark$storage$BlockManagerSlaveEndpoint$$doAsync$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$org$apache$spark$storage$BlockManagerSlaveEndpoint$$doAsync$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockManagerSlaveEndpoint.scala' class='org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$4'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$10$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$2$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$2$$anonfun$apply$8$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$3$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$3$$anonfun$apply$9$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$4$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$5$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$5$$anonfun$apply$11$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$6$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$6$$anonfun$apply$12$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$7$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$8$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$8$$anonfun$apply$14$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$9$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockManagerSource.scala' class='org.apache.spark.storage.BlockManagerSource$$anonfun$9$$anonfun$apply$15$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='BlockNotFoundException.scala' class='org.apache.spark.storage.BlockNotFoundException'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BlockReplicationPolicy'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BlockReplicationUtils'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BlockReplicationUtils$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BlockReplicationUtils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BlockReplicationUtils$$anonfun$getRandomSample$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.BlockReplicationUtils$$anonfun$getSampleIds$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.BlockResult'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockStatus'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockManagerMasterEndpoint.scala' class='org.apache.spark.storage.BlockStatus$'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='BlockUpdatedInfo.scala' class='org.apache.spark.storage.BlockUpdatedInfo'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='BlockUpdatedInfo.scala' class='org.apache.spark.storage.BlockUpdatedInfo$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.BroadcastBlockId'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.BroadcastBlockId$'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.BufferReleasingInputStream'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='BlockManager.scala' class='org.apache.spark.storage.ByteBufferBlockData'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.CountingWritableChannel'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='TopologyMapper.scala' class='org.apache.spark.storage.DefaultTopologyMapper'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TopologyMapper.scala' class='org.apache.spark.storage.DefaultTopologyMapper$$anonfun$getTopologyForHost$1'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskBlockData'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskBlockData$$anonfun$toByteBuffer$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskBlockData$$anonfun$toByteBuffer$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskBlockData$$anonfun$toByteBuffer$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskBlockData$$anonfun$toChunkedByteBuffer$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskBlockData$$anonfun$toChunkedByteBuffer$2'></ClassStats><ClassStats bugs='2' size='85' priority_2='2' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$addShutdownHook$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$addShutdownHook$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$addShutdownHook$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$createLocalDirs$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$createLocalDirs$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$createLocalDirs$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$getAllBlocks$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$getAllFiles$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$getAllFiles$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$getAllFiles$3'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$org$apache$spark$storage$DiskBlockManager$$doStop$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DiskBlockManager.scala' class='org.apache.spark.storage.DiskBlockManager$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='162' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$close$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$close$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$org$apache$spark$storage$DiskBlockObjectWriter$$closeResources$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$org$apache$spark$storage$DiskBlockObjectWriter$$closeResources$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$revertPartialWritesAndClose$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$revertPartialWritesAndClose$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$$anonfun$revertPartialWritesAndClose$2$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$ManualCloseBufferedOutputStream$1'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$ManualCloseOutputStream'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskBlockObjectWriter.scala' class='org.apache.spark.storage.DiskBlockObjectWriter$ManualCloseOutputStream$class'></ClassStats><ClassStats bugs='0' size='93' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskStore'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskStore$$anonfun$openForWrite$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskStore$$anonfun$openForWrite$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskStore$$anonfun$put$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskStore$$anonfun$put$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskStore$$anonfun$putBytes$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.DiskStore$$anonfun$remove$1'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.EncryptedBlockData'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.EncryptedBlockData$$anonfun$toByteBuffer$4'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='TopologyMapper.scala' class='org.apache.spark.storage.FileBasedTopologyMapper'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TopologyMapper.scala' class='org.apache.spark.storage.FileBasedTopologyMapper$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='TopologyMapper.scala' class='org.apache.spark.storage.FileBasedTopologyMapper$$anonfun$getTopologyForHost$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TopologyMapper.scala' class='org.apache.spark.storage.FileBasedTopologyMapper$$anonfun$getTopologyForHost$3'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='FileSegment.scala' class='org.apache.spark.storage.FileSegment'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileSegment.scala' class='org.apache.spark.storage.FileSegment$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileSegment.scala' class='org.apache.spark.storage.FileSegment$$anonfun$2'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.RDDBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.RDDBlockId$'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='RDDInfo.scala' class='org.apache.spark.storage.RDDInfo'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='RDDInfo.scala' class='org.apache.spark.storage.RDDInfo$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDInfo.scala' class='org.apache.spark.storage.RDDInfo$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDInfo.scala' class='org.apache.spark.storage.RDDInfo$$anonfun$2'></ClassStats><ClassStats bugs='1' size='33' priority_2='1' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.RandomBlockReplicationPolicy'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.RandomBlockReplicationPolicy$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.RandomBlockReplicationPolicy$$anonfun$prioritize$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BlockReplicationPolicy.scala' class='org.apache.spark.storage.RandomBlockReplicationPolicy$$anonfun$prioritize$2'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.ReadableChannelFileRegion'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='DiskStore.scala' class='org.apache.spark.storage.ReadableChannelFileRegion$$anonfun$transferTo$1'></ClassStats><ClassStats bugs='0' size='336' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anon$1$$anonfun$onBlockFetchFailure$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anon$1$$anonfun$onBlockFetchSuccess$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anon$1$$anonfun$onBlockFetchSuccess$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchLocalBlocks$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchUpToMaxBytes$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchUpToMaxBytes$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchUpToMaxBytes$2$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchUpToMaxBytes$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$initialize$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$initialize$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$initialize$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$initialize$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$next$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$next$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$org$apache$spark$storage$ShuffleBlockFetcherIterator$$cleanup$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$org$apache$spark$storage$ShuffleBlockFetcherIterator$$cleanup$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$org$apache$spark$storage$ShuffleBlockFetcherIterator$$isRemoteAddressMaxedOut$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$sendRequest$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$splitLocalRemoteBlocks$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$splitLocalRemoteBlocks$2'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$splitLocalRemoteBlocks$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$splitLocalRemoteBlocks$3$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$splitLocalRemoteBlocks$3$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$splitLocalRemoteBlocks$3$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$splitLocalRemoteBlocks$4'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$FailureFetchResult'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$FailureFetchResult$'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$FetchRequest'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$FetchRequest$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$FetchRequest$$anonfun$6'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$FetchResult'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$SuccessFetchResult'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ShuffleBlockFetcherIterator.scala' class='org.apache.spark.storage.ShuffleBlockFetcherIterator$SuccessFetchResult$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.ShuffleBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.ShuffleBlockId$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.ShuffleDataBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.ShuffleDataBlockId$'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.ShuffleIndexBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.ShuffleIndexBlockId$'></ClassStats><ClassStats bugs='0' size='111' interface='false' sourceFile='StorageLevel.scala' class='org.apache.spark.storage.StorageLevel'></ClassStats><ClassStats bugs='0' size='79' interface='false' sourceFile='StorageLevel.scala' class='org.apache.spark.storage.StorageLevel$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageLevel.scala' class='org.apache.spark.storage.StorageLevel$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageLevel.scala' class='org.apache.spark.storage.StorageLevel$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageLevel.scala' class='org.apache.spark.storage.StorageLevel$$anonfun$3'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='StorageLevel.scala' class='org.apache.spark.storage.StorageLevel$$anonfun$readExternal$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StorageLevel.scala' class='org.apache.spark.storage.StorageLevel$$anonfun$writeExternal$1'></ClassStats><ClassStats bugs='0' size='135' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$$lessinit$greater$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$addBlock$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$cacheSize$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$cacheSize$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$containsBlock$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$diskUsed$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$diskUsedByRdd$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$diskUsedByRdd$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$getBlock$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$memUsed$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$memUsed$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$memUsedByRdd$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$memUsedByRdd$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$numRddBlocks$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$numRddBlocksById$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$numRddBlocksById$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$offHeapCacheSize$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$offHeapCacheSize$1$$anonfun$apply$mcJJ$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$offHeapMemRemaining$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$offHeapMemRemaining$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$offHeapMemUsed$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$onHeapCacheSize$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$onHeapCacheSize$1$$anonfun$apply$mcJJ$sp$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$onHeapMemRemaining$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$onHeapMemRemaining$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$onHeapMemUsed$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$rddBlocks$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$rddBlocksById$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$$anonfun$rddStorageLevel$1'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$NonRddStorageInfo'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$NonRddStorageInfo$'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$RddStorageInfo'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageStatus$RddStorageInfo$'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils'></ClassStats><ClassStats bugs='0' size='39' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$dispose$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$getRddBlockLocations$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$getRddBlockLocations$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$getRddBlockLocations$1$$anonfun$apply$3$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StorageUtils.scala' class='org.apache.spark.storage.StorageUtils$$anonfun$updateRddInfo$1$$anonfun$8'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.StreamBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.StreamBlockId$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.TaskResultBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.TaskResultBlockId$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.TempLocalBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.TempLocalBlockId$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.TempShuffleBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.TempShuffleBlockId$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.TestBlockId'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.TestBlockId$'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='TimeTrackingOutputStream.java' class='org.apache.spark.storage.TimeTrackingOutputStream'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='TopologyMapper.scala' class='org.apache.spark.storage.TopologyMapper'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='BlockId.scala' class='org.apache.spark.storage.UnrecognizedBlockId'></ClassStats></PackageStats><PackageStats package='org.apache.spark.storage.memory' total_bugs='0' total_size='931' total_types='50'><ClassStats bugs='0' size='2' interface='true' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.BlockEvictionHandler'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.DeserializedMemoryEntry'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.DeserializedMemoryEntry$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.DeserializedValuesHolder'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.DeserializedValuesHolder$$anon$1'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryEntry'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryEntryBuilder'></ClassStats><ClassStats bugs='0' size='284' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$clear$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$currentTaskAttemptId$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$currentTaskAttemptId$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$currentUnrollMemoryForThisTask$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$currentUnrollMemoryForThisTask$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$5$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$evictBlocksToFreeSpace$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$getValues$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$logMemoryUsage$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$logUnrollFailureMessage$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$org$apache$spark$storage$memory$MemoryStore$$getRddId$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$putBytes$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$putBytes$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$putIterator$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$putIterator$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$putIterator$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$putIterator$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$putIteratorAsBytes$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$remove$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.MemoryStore$$anonfun$reserveUnrollMemoryForThisTask$1'></ClassStats><ClassStats bugs='0' size='76' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.PartiallySerializedBlock'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.PartiallySerializedBlock$$anonfun$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.PartiallySerializedBlock$$anonfun$8$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='124' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.PartiallyUnrolledIterator'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.RedirectableOutputStream'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.SerializedMemoryEntry'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.SerializedMemoryEntry$'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.SerializedValuesHolder'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.SerializedValuesHolder$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.SerializedValuesHolder$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.SerializedValuesHolder$$anonfun$7'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='MemoryStore.scala' class='org.apache.spark.storage.memory.ValuesHolder'></ClassStats></PackageStats><PackageStats package='org.apache.spark.ui' priority_1='2' total_bugs='13' priority_2='4' priority_3='7' total_size='2437' total_types='140'><ClassStats bugs='1' size='81' priority_3='1' interface='false' sourceFile='ConsoleProgressBar.scala' class='org.apache.spark.ui.ConsoleProgressBar'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConsoleProgressBar.scala' class='org.apache.spark.ui.ConsoleProgressBar$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ConsoleProgressBar.scala' class='org.apache.spark.ui.ConsoleProgressBar$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConsoleProgressBar.scala' class='org.apache.spark.ui.ConsoleProgressBar$$anonfun$2'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ConsoleProgressBar.scala' class='org.apache.spark.ui.ConsoleProgressBar$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ConsoleProgressBar.scala' class='org.apache.spark.ui.ConsoleProgressBar$$anonfun$3$$anonfun$4'></ClassStats><ClassStats bugs='0' size='69' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils'></ClassStats><ClassStats bugs='1' size='186' priority_3='1' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$'></ClassStats><ClassStats bugs='2' size='13' priority_1='1' priority_2='1' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$1'></ClassStats><ClassStats bugs='1' size='28' priority_3='1' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$2'></ClassStats><ClassStats bugs='1' size='9' priority_3='1' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$2$$anonfun$rewriteTarget$3'></ClassStats><ClassStats bugs='4' size='33' priority_2='2' priority_3='2' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$3'></ClassStats><ClassStats bugs='1' size='7' priority_3='1' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$3$$anonfun$doGet$2'></ClassStats><ClassStats bugs='1' size='20' priority_1='1' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anon$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$4'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$5$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$5$$anonfun$6'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$8'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$addFilters$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$addFilters$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$addFilters$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$addFilters$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$addFilters$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$addFilters$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$addFilters$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$createRedirectHandler$default$3$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$htmlResponderToServlet$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$jsonResponderToServlet$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$startJettyServer$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$$anonfun$toVirtualHosts$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$ServletParams'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$ServletParams$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.JettyUtils$ServletParams$$anonfun$$lessinit$greater$default$3$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PageData'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PageData$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedDataSource'></ClassStats><ClassStats bugs='0' size='13' interface='true' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable$$anonfun$table$1'></ClassStats><ClassStats bugs='0' size='116' interface='false' sourceFile='PagedTable.scala' class='org.apache.spark.ui.PagedTable$class'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.ServerInfo'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JettyUtils.scala' class='org.apache.spark.ui.ServerInfo$'></ClassStats><ClassStats bugs='0' size='102' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$$anonfun$getApplicationInfo$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$$anonfun$getSparkUser$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$$anonfun$getSparkUser$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUI$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkUI.scala' class='org.apache.spark.ui.SparkUITab'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='ToolTips.scala' class='org.apache.spark.ui.ToolTips'></ClassStats><ClassStats bugs='0' size='82' interface='false' sourceFile='ToolTips.scala' class='org.apache.spark.ui.ToolTips$'></ClassStats><ClassStats bugs='0' size='100' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils'></ClassStats><ClassStats bugs='0' size='339' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anon$1$$anonfun$transform$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anon$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$9'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$formatDurationVerbose$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$formatDurationVerbose$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$listingTable$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$listingTable$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$makeDescription$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$makeDescription$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$makeProgressBar$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$makeProgressBar$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$org$apache$spark$ui$UIUtils$$getHeaderContent$1$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$showDagViz$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$showDagViz$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$showDagViz$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$showDagViz$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$uiRoot$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIUtils.scala' class='org.apache.spark.ui.UIUtils$$anonfun$uiRoot$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator'></ClassStats><ClassStats bugs='1' size='41' priority_2='1' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$2$$anonfun$apply$mcJ$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$3$$anonfun$apply$mcJ$sp$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$3$$anonfun$apply$mcJ$sp$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$4$$anonfun$apply$mcJ$sp$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$5'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$5$$anonfun$apply$mcJ$sp$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$6'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$6$$anonfun$apply$mcJ$sp$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$7$$anonfun$apply$mcJ$sp$6'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$main$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$main$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$main$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='UIWorkloadGenerator.scala' class='org.apache.spark.ui.UIWorkloadGenerator$$anonfun$main$1$$anonfun$apply$mcVI$sp$2$$anon$1'></ClassStats><ClassStats bugs='0' size='114' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$attachHandler$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$attachTab$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$bind$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$bind$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$bind$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$boundPort$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$boundPort$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$detachHandler$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$detachPage$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$detachPage$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$detachTab$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$removeStaticHandler$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$removeStaticHandler$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUI$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUIPage'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='WebUI.scala' class='org.apache.spark.ui.WebUITab'></ClassStats></PackageStats><PackageStats package='org.apache.spark.ui.env' total_bugs='0' total_size='118' total_types='7'><ClassStats bugs='0' size='79' interface='false' sourceFile='EnvironmentPage.scala' class='org.apache.spark.ui.env.EnvironmentPage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EnvironmentPage.scala' class='org.apache.spark.ui.env.EnvironmentPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EnvironmentPage.scala' class='org.apache.spark.ui.env.EnvironmentPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EnvironmentPage.scala' class='org.apache.spark.ui.env.EnvironmentPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EnvironmentPage.scala' class='org.apache.spark.ui.env.EnvironmentPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EnvironmentPage.scala' class='org.apache.spark.ui.env.EnvironmentPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='EnvironmentPage.scala' class='org.apache.spark.ui.env.EnvironmentTab'></ClassStats></PackageStats><PackageStats package='org.apache.spark.ui.exec' total_bugs='1' priority_3='1' total_size='144' total_types='11'><ClassStats bugs='1' size='16' priority_3='1' interface='false' sourceFile='ExecutorThreadDumpPage.scala' class='org.apache.spark.ui.exec.ExecutorThreadDumpPage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorThreadDumpPage.scala' class='org.apache.spark.ui.exec.ExecutorThreadDumpPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorThreadDumpPage.scala' class='org.apache.spark.ui.exec.ExecutorThreadDumpPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='ExecutorThreadDumpPage.scala' class='org.apache.spark.ui.exec.ExecutorThreadDumpPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ExecutorThreadDumpPage.scala' class='org.apache.spark.ui.exec.ExecutorThreadDumpPage$$anonfun$3$$anonfun$4'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='ExecutorThreadDumpPage.scala' class='org.apache.spark.ui.exec.ExecutorThreadDumpPage$$anonfun$3$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorThreadDumpPage.scala' class='org.apache.spark.ui.exec.ExecutorThreadDumpPage$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorThreadDumpPage.scala' class='org.apache.spark.ui.exec.ExecutorThreadDumpPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='ExecutorsTab.scala' class='org.apache.spark.ui.exec.ExecutorsPage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorsTab.scala' class='org.apache.spark.ui.exec.ExecutorsPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExecutorsTab.scala' class='org.apache.spark.ui.exec.ExecutorsTab'></ClassStats></PackageStats><PackageStats package='org.apache.spark.ui.jobs' total_bugs='23' priority_3='23' total_size='3874' total_types='251'><ClassStats bugs='6' size='207' priority_3='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$12$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$17'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$22'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$23'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$8'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$makeExecutorEvent$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$makeExecutorEvent$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$makeExecutorEvent$1$$anonfun$apply$1$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$makeExecutorEvent$1$$anonfun$apply$1$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$makeJobEvent$1'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$makeJobEvent$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$makeJobEvent$2$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$makeJobEvent$2$$anonfun$9'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.AllJobsPage$$anonfun$render$2'></ClassStats><ClassStats bugs='0' size='125' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$6'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$7$$anonfun$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$7$$anonfun$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllStagesPage.scala' class='org.apache.spark.ui.jobs.AllStagesPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.ApiHelper'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.ApiHelper$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.ApiHelper$$anonfun$38'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.ApiHelper$$anonfun$hasAccumulators$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.ApiHelper$$anonfun$lastStageNameAndDescription$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.ApiHelper$$anonfun$lastStageNameAndDescription$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.ApiHelper$$anonfun$lastStageNameAndDescription$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.ApiHelper$$anonfun$lastStageNameAndDescription$4'></ClassStats><ClassStats bugs='0' size='54' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$1'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExecutorTable.scala' class='org.apache.spark.ui.jobs.ExecutorTable$$anonfun$createExecutorTable$2$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='52' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$24'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$25'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$25$$anonfun$26'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$25$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$28'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$29'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$30'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$32'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$33'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$34'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$org$apache$spark$ui$jobs$JobDataSource$$jobRow$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$org$apache$spark$ui$jobs$JobDataSource$$jobRow$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$org$apache$spark$ui$jobs$JobDataSource$$jobRow$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobDataSource$$anonfun$sliceData$1'></ClassStats><ClassStats bugs='1' size='209' priority_3='1' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$7'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$8$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$9$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$9$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$makeExecutorEvent$1'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$makeExecutorEvent$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$makeExecutorEvent$1$$anonfun$apply$1$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$makeExecutorEvent$1$$anonfun$apply$1$$anonfun$6'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$makeStageEvent$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$makeStageEvent$1$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$makeStageEvent$1$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$render$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobPage.scala' class='org.apache.spark.ui.jobs.JobPage$$anonfun$render$3'></ClassStats><ClassStats bugs='0' size='101' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobPagedTable'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobPagedTable$$anonfun$35'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobPagedTable$$anonfun$headers$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobPagedTable$$anonfun$headers$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobPagedTable$$anonfun$row$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobPagedTable$$anonfun$row$2'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='AllJobsPage.scala' class='org.apache.spark.ui.jobs.JobTableRowData'></ClassStats><ClassStats bugs='1' size='25' priority_3='1' interface='false' sourceFile='JobsTab.scala' class='org.apache.spark.ui.jobs.JobsTab'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JobsTab.scala' class='org.apache.spark.ui.jobs.JobsTab$$anonfun$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JobsTab.scala' class='org.apache.spark.ui.jobs.JobsTab$$anonfun$handleKillRequest$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JobsTab.scala' class='org.apache.spark.ui.jobs.JobsTab$$anonfun$handleKillRequest$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JobsTab.scala' class='org.apache.spark.ui.jobs.JobsTab$$anonfun$handleKillRequest$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JobsTab.scala' class='org.apache.spark.ui.jobs.JobsTab$$anonfun$handleKillRequest$1$$anonfun$apply$mcVI$sp$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.MissingStageTableRowData'></ClassStats><ClassStats bugs='1' size='31' priority_3='1' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PoolPage.scala' class='org.apache.spark.ui.jobs.PoolPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='PoolTable.scala' class='org.apache.spark.ui.jobs.PoolTable'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PoolTable.scala' class='org.apache.spark.ui.jobs.PoolTable$$anonfun$toNodeSeq$1'></ClassStats><ClassStats bugs='0' size='71' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$22'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$24'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$25'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$26'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$28'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$29'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$30'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$32'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$33'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$34'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$35'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$36'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$org$apache$spark$ui$jobs$StageDataSource$$stageRow$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$org$apache$spark$ui$jobs$StageDataSource$$stageRow$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageDataSource$$anonfun$sliceData$1'></ClassStats><ClassStats bugs='7' size='283' priority_3='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$12'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$13'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$13$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$20'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$21'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$21$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$22'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$23'></ClassStats><ClassStats bugs='0' size='89' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$24'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$24$$anonfun$25'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$24$$anonfun$sizeQuantiles$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$24$$anonfun$sizeQuantilesWithRecords$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$24$$anonfun$timeQuantiles$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$26'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$28'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$29'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='95' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$10'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$32'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$33'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$34'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$35'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$30$$anonfun$9'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$36'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$render$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$render$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.StagePage$$anonfun$render$4'></ClassStats><ClassStats bugs='0' size='163' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$15'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$15$$anonfun$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$15$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$19'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$20'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$headers$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$headers$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StagePagedTable$$anonfun$makeDescription$1'></ClassStats><ClassStats bugs='6' size='97' priority_3='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$14'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$6$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableBase$$anonfun$9'></ClassStats><ClassStats bugs='0' size='57' interface='false' sourceFile='StageTable.scala' class='org.apache.spark.ui.jobs.StageTableRowData'></ClassStats><ClassStats bugs='1' size='29' priority_3='1' interface='false' sourceFile='StagesTab.scala' class='org.apache.spark.ui.jobs.StagesTab'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagesTab.scala' class='org.apache.spark.ui.jobs.StagesTab$$anonfun$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='StagesTab.scala' class='org.apache.spark.ui.jobs.StagesTab$$anonfun$handleKillRequest$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagesTab.scala' class='org.apache.spark.ui.jobs.StagesTab$$anonfun$handleKillRequest$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StagesTab.scala' class='org.apache.spark.ui.jobs.StagesTab$$anonfun$handleKillRequest$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagesTab.scala' class='org.apache.spark.ui.jobs.StagesTab$$anonfun$handleKillRequest$1$$anonfun$apply$mcVI$sp$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskDataSource'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskDataSource$$anonfun$executorLogs$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskDataSource$$anonfun$executorLogs$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskDataSource$$anonfun$executorLogs$1$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskDataSource$$anonfun$executorLogs$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='TaskDetailsClassNames.scala' class='org.apache.spark.ui.jobs.TaskDetailsClassNames'></ClassStats><ClassStats bugs='0' size='26' interface='false' sourceFile='TaskDetailsClassNames.scala' class='org.apache.spark.ui.jobs.TaskDetailsClassNames$'></ClassStats><ClassStats bugs='0' size='170' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$37'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$accumulatorsInfo$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$formatBytes$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$formatDuration$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$formatDuration$1$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$headers$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$metricInfo$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$11'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$6'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$8'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StagePage.scala' class='org.apache.spark.ui.jobs.TaskPagedTable$$anonfun$row$9'></ClassStats></PackageStats><PackageStats package='org.apache.spark.ui.scope' total_bugs='0' total_size='440' total_types='30'><ClassStats bugs='0' size='42' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationCluster'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationCluster$$anonfun$getCachedNodes$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationCluster$$anonfun$getCachedNodes$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationCluster$$anonfun$hashCode$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationCluster$$anonfun$hashCode$2'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationEdge'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationEdge$'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph'></ClassStats><ClassStats bugs='0' size='69' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeDotFile$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeDotFile$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$1'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$5$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$2$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$makeOperationGraph$3$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$org$apache$spark$ui$scope$RDDOperationGraph$$makeDotSubgraph$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationGraph$$anonfun$org$apache$spark$ui$scope$RDDOperationGraph$$makeDotSubgraph$2'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationNode'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDDOperationGraph.scala' class='org.apache.spark.ui.scope.RDDOperationNode$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.ui.storage' total_bugs='6' priority_3='6' total_size='667' total_types='47'><ClassStats bugs='0' size='29' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockDataSource'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockDataSource$$anonfun$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockDataSource$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockDataSource$$anonfun$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockDataSource$$anonfun$19'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockDataSource$$anonfun$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockDataSource$$anonfun$21'></ClassStats><ClassStats bugs='0' size='61' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockPagedTable'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockPagedTable$$anonfun$22'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockTableRowData'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.BlockTableRowData$'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.ExecutorStreamSummary'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.ExecutorStreamSummary$$anonfun$totalDiskSize$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.ExecutorStreamSummary$$anonfun$totalMemSize$1'></ClassStats><ClassStats bugs='6' size='101' priority_3='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$org$apache$spark$ui$storage$RDDPage$$workerRow$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$org$apache$spark$ui$storage$RDDPage$$workerRow$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$org$apache$spark$ui$storage$RDDPage$$workerRow$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$org$apache$spark$ui$storage$RDDPage$$workerRow$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RDDPage.scala' class='org.apache.spark.ui.storage.RDDPage$$anonfun$render$2'></ClassStats><ClassStats bugs='0' size='133' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$org$apache$spark$ui$storage$StoragePage$$streamBlockTableRow$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StoragePage.scala' class='org.apache.spark.ui.storage.StoragePage$$anonfun$render$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='StorageTab.scala' class='org.apache.spark.ui.storage.StorageTab'></ClassStats></PackageStats><PackageStats package='org.apache.spark.unsafe.map' total_bugs='2' priority_3='2' total_size='495' total_types='6'><ClassStats bugs='1' size='227' priority_3='1' interface='false' sourceFile='BytesToBytesMap.java' class='org.apache.spark.unsafe.map.BytesToBytesMap'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='BytesToBytesMap.java' class='org.apache.spark.unsafe.map.BytesToBytesMap$1'></ClassStats><ClassStats bugs='0' size='128' interface='false' sourceFile='BytesToBytesMap.java' class='org.apache.spark.unsafe.map.BytesToBytesMap$Location'></ClassStats><ClassStats bugs='1' size='123' priority_3='1' interface='false' sourceFile='BytesToBytesMap.java' class='org.apache.spark.unsafe.map.BytesToBytesMap$MapIterator'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='HashMapGrowthStrategy.java' class='org.apache.spark.unsafe.map.HashMapGrowthStrategy'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='HashMapGrowthStrategy.java' class='org.apache.spark.unsafe.map.HashMapGrowthStrategy$Doubling'></ClassStats></PackageStats><PackageStats package='org.apache.spark.util' priority_1='2' total_bugs='36' priority_2='30' priority_3='4' total_size='11229' total_types='760'><ClassStats bugs='0' size='11' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorContext'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorContext$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorContext$$anonfun$get$1'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorMetadata'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorMetadata$'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorV2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorV2$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorV2$$anonfun$name$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorV2$$anonfun$name$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorV2$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorV2$$anonfun$register$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.AccumulatorV2$$anonfun$writeReplace$1'></ClassStats><ClassStats bugs='0' size='72' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$$anonfun$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$$anonfun$3'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$$anonfun$addCase$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$Case'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$Case$'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$Result'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$Result$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$Timer'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$Timer$$anonfun$startTiming$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$Timer$$anonfun$stopTiming$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Benchmark.scala' class='org.apache.spark.util.Benchmark$Timer$$anonfun$totalTime$1'></ClassStats><ClassStats bugs='0' size='159' interface='false' sourceFile='BoundedPriorityQueue.scala' class='org.apache.spark.util.BoundedPriorityQueue'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='BoundedPriorityQueue.scala' class='org.apache.spark.util.BoundedPriorityQueue$$anonfun$$plus$plus$eq$1'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='ByteBufferInputStream.scala' class='org.apache.spark.util.ByteBufferInputStream'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='ByteBufferOutputStream.scala' class='org.apache.spark.util.ByteBufferOutputStream'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ByteBufferOutputStream.scala' class='org.apache.spark.util.ByteBufferOutputStream$$anonfun$reset$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ByteBufferOutputStream.scala' class='org.apache.spark.util.ByteBufferOutputStream$$anonfun$toByteBuffer$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ByteBufferOutputStream.scala' class='org.apache.spark.util.ByteBufferOutputStream$$anonfun$write$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ByteBufferOutputStream.scala' class='org.apache.spark.util.ByteBufferOutputStream$$anonfun$write$2'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallSite'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallSite$'></ClassStats><ClassStats bugs='0' size='64' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext'></ClassStats><ClassStats bugs='0' size='53' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$24'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$25'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$26'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$28'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$29'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$30'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$32'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$33'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$34'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$35'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$36'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$37'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$38'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$liftedTree1$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$prepareContext$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CallerContext$$anonfun$setCurrentContext$1'></ClassStats><ClassStats bugs='0' size='2' interface='false' sourceFile='CausedBy.scala' class='org.apache.spark.util.CausedBy'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CausedBy.scala' class='org.apache.spark.util.CausedBy$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CausedBy.scala' class='org.apache.spark.util.CausedBy$$anonfun$unapply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CausedBy.scala' class='org.apache.spark.util.CausedBy$$anonfun$unapply$2'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='MutableURLClassLoader.scala' class='org.apache.spark.util.ChildFirstURLClassLoader'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MutableURLClassLoader.scala' class='org.apache.spark.util.ChildFirstURLClassLoader$$anonfun$getResources$1'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CircularBuffer'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.CircularBuffer$'></ClassStats><ClassStats bugs='0' size='3' interface='true' sourceFile='Clock.scala' class='org.apache.spark.util.Clock'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner'></ClassStats><ClassStats bugs='0' size='136' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$getInnerClosureClasses$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$initAccessedFields$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$initAccessedFields$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$10$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$12$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$13'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$16'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$16$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$17'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$18'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$21'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$22'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$22$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$22$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$23'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$4$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$6$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$8$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$cloneAndSetFields$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$getOuterClassesAndObjects$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$getOuterClassesAndObjects$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ClosureCleaner$$anonfun$setAccessedFields$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.CollectionAccumulator'></ClassStats><ClassStats bugs='0' size='2' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$$anonfun$makeBinarySearch$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$$anonfun$makeBinarySearch$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$$anonfun$makeBinarySearch$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$$anonfun$makeBinarySearch$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$$anonfun$makeBinarySearch$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$$anonfun$makeBinarySearch$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$$anonfun$makeBinarySearch$7'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CollectionsUtils.scala' class='org.apache.spark.util.CollectionsUtils$$anonfun$makeBinarySearch$8'></ClassStats><ClassStats bugs='0' size='9' interface='true' sourceFile='CommandLineUtils.scala' class='org.apache.spark.util.CommandLineUtils'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CommandLineUtils.scala' class='org.apache.spark.util.CommandLineUtils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='CommandLineUtils.scala' class='org.apache.spark.util.CommandLineUtils$class'></ClassStats><ClassStats bugs='0' size='109' interface='false' sourceFile='CompletionIterator.scala' class='org.apache.spark.util.CompletionIterator'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompletionIterator.scala' class='org.apache.spark.util.CompletionIterator$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='CompletionIterator.scala' class='org.apache.spark.util.CompletionIterator$$anon$1'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='Distribution.scala' class='org.apache.spark.util.Distribution'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='Distribution.scala' class='org.apache.spark.util.Distribution$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Distribution.scala' class='org.apache.spark.util.Distribution$$anonfun$getQuantiles$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Distribution.scala' class='org.apache.spark.util.Distribution$$anonfun$showQuantiles$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Distribution.scala' class='org.apache.spark.util.Distribution$$anonfun$showQuantiles$2'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.DoubleAccumulator'></ClassStats><ClassStats bugs='1' size='13' priority_3='1' interface='false' sourceFile='EnumUtil.java' class='org.apache.spark.util.EnumUtil'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='EventLoop.scala' class='org.apache.spark.util.EventLoop'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='EventLoop.scala' class='org.apache.spark.util.EventLoop$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoop.scala' class='org.apache.spark.util.EventLoop$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='EventLoop.scala' class='org.apache.spark.util.EventLoop$$anon$1$$anonfun$run$2'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.FieldAccessFinder'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.FieldAccessFinder$'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.FieldAccessFinder$$anon$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitFieldInsn$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitFieldInsn$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$1'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='IdGenerator.scala' class='org.apache.spark.util.IdGenerator'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.InnerClosureFinder'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.InnerClosureFinder$$anon$4'></ClassStats><ClassStats bugs='0' size='2' interface='false' sourceFile='IntParam.scala' class='org.apache.spark.util.IntParam'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='IntParam.scala' class='org.apache.spark.util.IntParam$'></ClassStats><ClassStats bugs='0' size='132' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol'></ClassStats><ClassStats bugs='0' size='652' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$100'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$101'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$102'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$103'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$104'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$105'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$106'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$107'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$108'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$108$$anonfun$apply$36'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$109'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$22'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$24'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$25'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$26'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$28'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$29'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$30'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$31'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$32'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$33'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$34'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$34$$anonfun$apply$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$35'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$36'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$37'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$38'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$39'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$40'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$41'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$42'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$43'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$44'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$45'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$46'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$47'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$48'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$49'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$50'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$50$$anonfun$apply$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$51'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$52'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$53'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$54'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$55'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$56'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$57'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$58'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$58$$anonfun$apply$24'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$59'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$59$$anonfun$apply$25'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$60'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$61'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$62'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$63'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$64'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$65'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$66'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$67'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$68'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$68$$anonfun$69'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$70'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$71'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$72'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$72$$anonfun$apply$26'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$73'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$74'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$75'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$76'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$77'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$78'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$79'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$80'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$81'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$82'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$83'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$84'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$85'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$86'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$87'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$88'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$89'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$90'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$91'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$92'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$93'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$94'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$94$$anonfun$apply$34'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$95'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$95$$anonfun$apply$35'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$96'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$97'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$98'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$99'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$UUIDToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$UUIDToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumValueFromJson$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumValueFromJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumValueToJson$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumValueToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumValueToJson$2$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$2$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$9$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulablesToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulablesToJson$1$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$accumulablesToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationEndToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationEndToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$applicationStartToJson$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerAddedToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerAddedToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerAddedToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerAddedToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerAddedToJson$4$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerAddedToJson$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerAddedToJson$5$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerIdToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerIdToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerIdToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerRemovedToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockManagerRemovedToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockStatusToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockStatusToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockUpdateToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockUpdatedInfoToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockUpdatedInfoToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$blockUpdatedInfoToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$environmentUpdateToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$exceptionToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorAddedToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorAddedToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorAddedToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorInfoToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorInfoToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorMetricsUpdateToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorMetricsUpdateToJson$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorMetricsUpdateToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorMetricsUpdateToJson$3$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorMetricsUpdateToJson$3$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorMetricsUpdateToJson$3$$anonfun$apply$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorMetricsUpdateToJson$3$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorMetricsUpdateToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorRemovedToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorRemovedToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorRemovedToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$executorRemovedToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobEndToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobEndToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobEndToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobResultToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobStartToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobStartToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobStartToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobStartToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobStartToJson$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobStartToJson$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$jobStartToJson$6$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$logStartToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$logStartToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$mapFromJson$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$propertiesFromJson$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$propertiesFromJson$1$$anonfun$apply$37'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$propertiesFromJson$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$propertiesToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$propertiesToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$4$$anonfun$apply$19'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$rddInfoToJson$9'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stackTraceFromJson$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$21'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$22'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stackTraceToJson$1$$anonfun$apply$23'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stageCompletedToJson$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stageInfoFromJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stageInfoToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stageInfoToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stageInfoToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stageInfoToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stageInfoToJson$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$stageSubmittedToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$storageLevelToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$storageLevelToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$storageLevelToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$storageLevelToJson$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskEndReasonFromJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskEndReasonFromJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskEndReasonFromJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskEndReasonToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskEndToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskEndToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskEndToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskEndToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskGettingResultToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$11'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$12'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskInfoToJson$9'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$1$$anonfun$apply$27'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$1$$anonfun$apply$28'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$1$$anonfun$apply$29'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$2$$anonfun$apply$30'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$3$$anonfun$apply$31'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$3$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$4$$anonfun$apply$32'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$4$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$5'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsFromJson$5$$anonfun$apply$33'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskMetricsToJson$9'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskStartToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskStartToJson$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$taskStartToJson$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$unpersistRDDToJson$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$$anonfun$unpersistRDDToJson$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$JOB_RESULT_FORMATTED_CLASS_NAMES$'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$SPARK_LISTENER_EVENT_FORMATTED_CLASS_NAMES$'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='JsonProtocol.scala' class='org.apache.spark.util.JsonProtocol$TASK_END_REASON_FORMATTED_CLASS_NAMES$'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.KnownSizeEstimation'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.LegacyAccumulatorWrapper'></ClassStats><ClassStats bugs='0' size='10' interface='true' sourceFile='ListenerBus.scala' class='org.apache.spark.util.ListenerBus'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ListenerBus.scala' class='org.apache.spark.util.ListenerBus$$anonfun$findListenersByClass$1'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ListenerBus.scala' class='org.apache.spark.util.ListenerBus$$anonfun$findListenersByClass$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ListenerBus.scala' class='org.apache.spark.util.ListenerBus$$anonfun$listeners$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ListenerBus.scala' class='org.apache.spark.util.ListenerBus$$anonfun$postToAll$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ListenerBus.scala' class='org.apache.spark.util.ListenerBus$$anonfun$removeListener$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ListenerBus.scala' class='org.apache.spark.util.ListenerBus$$anonfun$removeListener$2'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='ListenerBus.scala' class='org.apache.spark.util.ListenerBus$class'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='AccumulatorV2.scala' class='org.apache.spark.util.LongAccumulator'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ManualClock.scala' class='org.apache.spark.util.ManualClock'></ClassStats><ClassStats bugs='0' size='2' interface='false' sourceFile='MemoryParam.scala' class='org.apache.spark.util.MemoryParam'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='MemoryParam.scala' class='org.apache.spark.util.MemoryParam$'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.MethodIdentifier'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.MethodIdentifier$'></ClassStats><ClassStats bugs='0' size='114' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair'></ClassStats><ClassStats bugs='0' size='59' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcCC$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcCD$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcCI$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcCJ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcCZ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcDC$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcDD$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcDI$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcDJ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcDZ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcIC$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcID$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcII$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcIJ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcIZ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcJC$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcJD$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcJI$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcJJ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcJZ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcZC$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcZD$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcZI$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcZJ$sp'></ClassStats><ClassStats bugs='0' size='34' interface='false' sourceFile='MutablePair.scala' class='org.apache.spark.util.MutablePair$mcZZ$sp'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='MutableURLClassLoader.scala' class='org.apache.spark.util.MutableURLClassLoader'></ClassStats><ClassStats bugs='0' size='132' interface='false' sourceFile='NextIterator.scala' class='org.apache.spark.util.NextIterator'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ParentClassLoader.scala' class='org.apache.spark.util.ParentClassLoader'></ClassStats><ClassStats bugs='0' size='76' interface='false' sourceFile='PeriodicCheckpointer.scala' class='org.apache.spark.util.PeriodicCheckpointer'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='PeriodicCheckpointer.scala' class='org.apache.spark.util.PeriodicCheckpointer$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PeriodicCheckpointer.scala' class='org.apache.spark.util.PeriodicCheckpointer$$anonfun$getAllCheckpointFiles$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PeriodicCheckpointer.scala' class='org.apache.spark.util.PeriodicCheckpointer$$anonfun$removeCheckpointFile$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='PeriodicCheckpointer.scala' class='org.apache.spark.util.PeriodicCheckpointer$$anonfun$removeCheckpointFile$2'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.RedirectThread'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.RedirectThread$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.RedirectThread$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.RedirectThread$$anonfun$run$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.RedirectThread$$anonfun$run$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ReturnStatementFinder'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ReturnStatementFinder$$anon$1'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ReturnStatementFinder$$anon$2'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='ClosureCleaner.scala' class='org.apache.spark.util.ReturnStatementInClosureException'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='RpcUtils.scala' class='org.apache.spark.util.RpcUtils'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='RpcUtils.scala' class='org.apache.spark.util.RpcUtils$'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SerializableBuffer.scala' class='org.apache.spark.util.SerializableBuffer'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='SerializableBuffer.scala' class='org.apache.spark.util.SerializableBuffer$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SerializableBuffer.scala' class='org.apache.spark.util.SerializableBuffer$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SerializableConfiguration.scala' class='org.apache.spark.util.SerializableConfiguration'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SerializableConfiguration.scala' class='org.apache.spark.util.SerializableConfiguration$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SerializableConfiguration.scala' class='org.apache.spark.util.SerializableConfiguration$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SerializableJobConf.scala' class='org.apache.spark.util.SerializableJobConf'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SerializableJobConf.scala' class='org.apache.spark.util.SerializableJobConf$$anonfun$readObject$1'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='SerializableJobConf.scala' class='org.apache.spark.util.SerializableJobConf$$anonfun$writeObject$1'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anon$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$2'></ClassStats><ClassStats bugs='1' size='10' priority_2='1' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anonfun$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.ShutdownHookManager$$anonfun$hasRootAsShutdownDeleteDir$1'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils'></ClassStats><ClassStats bugs='0' size='41' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$$anonfun$1$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$$anonfun$register$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1'></ClassStats><ClassStats bugs='1' size='11' priority_3='1' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$$anonfun$registerLogger$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$ActionHandler'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$ActionHandler$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SignalUtils.scala' class='org.apache.spark.util.SignalUtils$ActionHandler$$anonfun$3'></ClassStats><ClassStats bugs='0' size='31' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator'></ClassStats><ClassStats bugs='1' size='197' priority_2='1' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$1'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$2'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$$anonfun$getIsCompressedOops$1'></ClassStats><ClassStats bugs='0' size='21' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$ClassInfo'></ClassStats><ClassStats bugs='0' size='23' interface='false' sourceFile='SizeEstimator.scala' class='org.apache.spark.util.SizeEstimator$SearchState'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkExitCode.scala' class='org.apache.spark.util.SparkExitCode'></ClassStats><ClassStats bugs='0' size='14' interface='false' sourceFile='SparkExitCode.scala' class='org.apache.spark.util.SparkExitCode$'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.SparkShutdownHook'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.SparkShutdownHookManager'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.SparkShutdownHookManager$$anon$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ShutdownHookManager.scala' class='org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='SparkUncaughtExceptionHandler.scala' class='org.apache.spark.util.SparkUncaughtExceptionHandler'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SparkUncaughtExceptionHandler.scala' class='org.apache.spark.util.SparkUncaughtExceptionHandler$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='SparkUncaughtExceptionHandler.scala' class='org.apache.spark.util.SparkUncaughtExceptionHandler$$anonfun$uncaughtException$1'></ClassStats><ClassStats bugs='0' size='96' interface='false' sourceFile='StatCounter.scala' class='org.apache.spark.util.StatCounter'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StatCounter.scala' class='org.apache.spark.util.StatCounter$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StatCounter.scala' class='org.apache.spark.util.StatCounter$$anonfun$merge$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='Clock.scala' class='org.apache.spark.util.SystemClock'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='taskListeners.scala' class='org.apache.spark.util.TaskCompletionListener'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='taskListeners.scala' class='org.apache.spark.util.TaskCompletionListenerException'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='taskListeners.scala' class='org.apache.spark.util.TaskCompletionListenerException$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='taskListeners.scala' class='org.apache.spark.util.TaskCompletionListenerException$$anonfun$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='taskListeners.scala' class='org.apache.spark.util.TaskCompletionListenerException$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='taskListeners.scala' class='org.apache.spark.util.TaskCompletionListenerException$$anonfun$3'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='taskListeners.scala' class='org.apache.spark.util.TaskFailureListener'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='ThreadStackTrace.scala' class='org.apache.spark.util.ThreadStackTrace'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ThreadStackTrace.scala' class='org.apache.spark.util.ThreadStackTrace$'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='ThreadUtils.scala' class='org.apache.spark.util.ThreadUtils'></ClassStats><ClassStats bugs='0' size='80' interface='false' sourceFile='ThreadUtils.scala' class='org.apache.spark.util.ThreadUtils$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ThreadUtils.scala' class='org.apache.spark.util.ThreadUtils$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ThreadUtils.scala' class='org.apache.spark.util.ThreadUtils$$anon$3'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='ThreadUtils.scala' class='org.apache.spark.util.ThreadUtils$$anon$3$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ThreadUtils.scala' class='org.apache.spark.util.ThreadUtils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ThreadUtils.scala' class='org.apache.spark.util.ThreadUtils$$anonfun$2'></ClassStats><ClassStats bugs='0' size='315' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$clearOldValues$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$clearOldValues$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$filter$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$get$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$getTimestamp$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$iterator$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$putAll$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedHashMap$$anonfun$putIfAbsent$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedValue'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='TimeStampedHashMap.scala' class='org.apache.spark.util.TimeStampedValue$'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='UninterruptibleThread.scala' class='org.apache.spark.util.UninterruptibleThread'></ClassStats><ClassStats bugs='0' size='338' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils'></ClassStats><ClassStats bugs='28' size='1212' priority_1='2' priority_2='24' priority_3='2' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anon$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anon$3'></ClassStats><ClassStats bugs='0' size='108' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anon$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anon$4$$anonfun$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anon$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anon$5$$anonfun$run$2'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anon$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$10'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$15'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$16'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$18'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$19'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$21'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$22'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$5'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$5$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$5$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$checkAndGetK8sMasterUrl$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$checkAndGetK8sMasterUrl$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$checkHost$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$checkHostPort$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$classIsLoadable$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$copyFile$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$copyFile$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$copyFile$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$copyFileStreamNIO$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$copyFileStreamNIO$2'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$copyStream$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$copyStream$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$deleteRecursively$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$deleteRecursively$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$doFetchFile$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$doFetchFile$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$doesDirectoryContainAnyNewFiles$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$doesDirectoryContainAnyNewFiles$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$doesDirectoryContainAnyNewFiles$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$downloadFile$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$executeAndGetOutput$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$executeCommand$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$executeCommand$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$executeCommand$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$fetchFile$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$fetchFile$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$fetchHcfsFile$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$findLocalInetAddress$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$findLocalInetAddress$1$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$findLocalInetAddress$1$$anonfun$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$findLocalInetAddress$1$$anonfun$9'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$findLocalInetAddress$1$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$findLocalInetAddress$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$findLocalInetAddress$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$findLocalInetAddress$3'></ClassStats><ClassStats bugs='0' size='27' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getCallSite$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getCallSite$default$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getConfiguredLocalDirs$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getContextOrSparkClassLoader$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getCurrentUserGroups$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$1$$anonfun$apply$12'></ClassStats><ClassStats bugs='1' size='6' priority_2='1' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDefaultPropertiesFile$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDynamicAllocationInitialExecutors$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDynamicAllocationInitialExecutors$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDynamicAllocationInitialExecutors$3'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getDynamicAllocationInitialExecutors$4'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getLocalDir$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getLocalUserJarsForShell$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getLocalUserJarsForShell$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getLocalUserJarsForShell$2$$anonfun$apply$14'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getLocalUserJarsForShell$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$1'></ClassStats><ClassStats bugs='1' size='17' priority_2='1' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getOrCreateLocalRootDirsImpl$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getPropertiesFromFile$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getPropertiesFromFile$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getPropertiesFromFile$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getSystemProperties$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getThreadDump$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getThreadDump$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getThreadDumpForThread$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getUserJars$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getUserJars$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getUserJars$2$$anonfun$apply$13'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$getUserJars$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$isBindCollision$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadDefaultSparkProperties$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$10$$anonfun$apply$11'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadDefaultSparkProperties$1$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='33' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadExtensions$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadExtensions$1$$anonfun$20'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadExtensions$1$$anonfun$apply$18'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadExtensions$1$$anonfun$apply$19'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$loadExtensions$1$$anonfun$apply$20'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$localCanonicalHostName$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$localHostName$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$localHostNameForURI$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$logUncaughtExceptions$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$nonLocalPaths$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$nonLocalPaths$1$$anonfun$12'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$offsetBytes$1'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$offsetBytes$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$offsetBytes$2$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$offsetBytes$2$$anonfun$apply$8'></ClassStats><ClassStats bugs='1' size='7' priority_2='1' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$copyRecursive$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$filesEqualRecursive$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$filesEqualRecursive$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$filesEqualRecursive$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$getCompressedFileLength$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$log$1$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$threadInfoToThreadStackTrace$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$org$apache$spark$util$Utils$$threadInfoToThreadStackTrace$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$parseStandaloneMasterUrls$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$portMaxRetries$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$portMaxRetries$2'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$randomizeInPlace$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$recursiveList$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$recursiveList$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$redact$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$redact$1$$anonfun$apply$15'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$redact$1$$anonfun$apply$16'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$redact$1$$anonfun$apply$17'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$resolveURIs$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$resolveURIs$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$setupSecureURLConnection$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$setupSecureURLConnection$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$sparkJavaOpts$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$sparkJavaOpts$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$sparkJavaOpts$default$2$1'></ClassStats><ClassStats bugs='0' size='37' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1$$anonfun$apply$mcVI$sp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1$$anonfun$apply$mcVI$sp$2'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1$$anonfun$apply$mcVI$sp$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$startServiceOnPort$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$stringToSeq$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$stringToSeq$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$terminateProcess$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$terminateProcess$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$truncatedString$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryLog$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryLogNonFatalError$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryOrIOException$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryOrIOException$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryOrStopSparkContext$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryOrStopSparkContext$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryWithSafeFinally$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryWithSafeFinallyAndFailureCallbacks$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryWithSafeFinallyAndFailureCallbacks$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$tryWithSafeFinallyAndFailureCallbacks$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$unionFileLists$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$unionFileLists$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$unionFileLists$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$updateSparkConfigFromProperties$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$$anonfun$updateSparkConfigFromProperties$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.Utils$Lock'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='VersionUtils.scala' class='org.apache.spark.util.VersionUtils'></ClassStats><ClassStats bugs='0' size='19' interface='false' sourceFile='VersionUtils.scala' class='org.apache.spark.util.VersionUtils$'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.util.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.util.package$'></ClassStats></PackageStats><PackageStats package='org.apache.spark.util.collection' total_bugs='0' total_size='6965' total_types='153'><ClassStats bugs='0' size='292' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$'></ClassStats><ClassStats bugs='0' size='120' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anon$1'></ClassStats><ClassStats bugs='0' size='116' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anon$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anonfun$changeValue$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anonfun$growTable$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anonfun$iterator$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='AppendOnlyMap.scala' class='org.apache.spark.util.collection.AppendOnlyMap$$anonfun$update$1'></ClassStats><ClassStats bugs='0' size='111' interface='false' sourceFile='BitSet.scala' class='org.apache.spark.util.collection.BitSet'></ClassStats><ClassStats bugs='0' size='108' interface='false' sourceFile='BitSet.scala' class='org.apache.spark.util.collection.BitSet$$anon$1'></ClassStats><ClassStats bugs='0' size='292' interface='false' sourceFile='CompactBuffer.scala' class='org.apache.spark.util.collection.CompactBuffer'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='CompactBuffer.scala' class='org.apache.spark.util.collection.CompactBuffer$'></ClassStats><ClassStats bugs='0' size='108' interface='false' sourceFile='CompactBuffer.scala' class='org.apache.spark.util.collection.CompactBuffer$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='CompactBuffer.scala' class='org.apache.spark.util.collection.CompactBuffer$$anonfun$$plus$plus$eq$1'></ClassStats><ClassStats bugs='0' size='279' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$$anonfun$iterator$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$$anonfun$org$apache$spark$util$collection$ExternalAppendOnlyMap$$spillMemoryIteratorToDisk$1'></ClassStats><ClassStats bugs='0' size='187' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator$$anonfun$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator$$anonfun$7'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator$$anonfun$nextBatchStream$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$DiskMapIterator$$anonfun$org$apache$spark$util$collection$ExternalAppendOnlyMap$DiskMapIterator$$cleanup$1'></ClassStats><ClassStats bugs='0' size='151' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$ExternalIterator'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$ExternalIterator$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$ExternalIterator$$anonfun$4'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$ExternalIterator$$anonfun$5'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$ExternalIterator$$anonfun$next$1'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$ExternalIterator$StreamBuffer'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$HashComparator'></ClassStats><ClassStats bugs='0' size='140' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$SpillableIterator'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalAppendOnlyMap.scala' class='org.apache.spark.util.collection.ExternalAppendOnlyMap$SpillableIterator$$anonfun$spill$1'></ClassStats><ClassStats bugs='0' size='237' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$'></ClassStats><ClassStats bugs='0' size='20' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anon$1'></ClassStats><ClassStats bugs='0' size='108' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anon$2'></ClassStats><ClassStats bugs='0' size='132' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anon$3'></ClassStats><ClassStats bugs='0' size='113' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anon$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$4$$anon$6'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$6'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$8'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$9'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$groupByPartition$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$iterator$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$merge$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$merge$1$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$org$apache$spark$util$collection$ExternalSorter$$mergeWithAggregation$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$org$apache$spark$util$collection$ExternalSorter$$spillMemoryIteratorToDisk$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$org$apache$spark$util$collection$ExternalSorter$$spillMemoryIteratorToDisk$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$stop$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$writePartitionedFile$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$writePartitionedFile$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$$anonfun$writePartitionedFile$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='109' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$IteratorForPartition'></ClassStats><ClassStats bugs='0' size='102' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillReader'></ClassStats><ClassStats bugs='0' size='116' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillReader$$anon$5'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillReader$$anonfun$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillReader$$anonfun$nextBatchStream$1'></ClassStats><ClassStats bugs='0' size='144' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillableIterator'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillableIterator$$anon$7'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillableIterator$$anonfun$spill$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillableIterator$$anonfun$spill$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpillableIterator$$anonfun$spill$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='30' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpilledFile'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='ExternalSorter.scala' class='org.apache.spark.util.collection.ExternalSorter$SpilledFile$'></ClassStats><ClassStats bugs='0' size='25' interface='false' sourceFile='SortDataFormat.scala' class='org.apache.spark.util.collection.KVArraySortDataFormat'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='MedianHeap.scala' class='org.apache.spark.util.collection.MedianHeap'></ClassStats><ClassStats bugs='0' size='227' interface='false' sourceFile='OpenHashMap.scala' class='org.apache.spark.util.collection.OpenHashMap'></ClassStats><ClassStats bugs='0' size='125' interface='false' sourceFile='OpenHashMap.scala' class='org.apache.spark.util.collection.OpenHashMap$$anon$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='OpenHashMap.scala' class='org.apache.spark.util.collection.OpenHashMap$$anonfun$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='OpenHashMap.scala' class='org.apache.spark.util.collection.OpenHashMap$$anonfun$2'></ClassStats><ClassStats bugs='0' size='78' interface='false' sourceFile='OpenHashMap.scala' class='org.apache.spark.util.collection.OpenHashMap$mcD$sp'></ClassStats><ClassStats bugs='0' size='78' interface='false' sourceFile='OpenHashMap.scala' class='org.apache.spark.util.collection.OpenHashMap$mcI$sp'></ClassStats><ClassStats bugs='0' size='78' interface='false' sourceFile='OpenHashMap.scala' class='org.apache.spark.util.collection.OpenHashMap$mcJ$sp'></ClassStats><ClassStats bugs='0' size='174' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$'></ClassStats><ClassStats bugs='0' size='107' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$$anon$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$$anonfun$rehash$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$Hasher'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$Hasher$mcI$sp'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$Hasher$mcJ$sp'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$IntHasher'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$LongHasher'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$mcI$sp'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$mcI$sp$$anonfun$rehash$mcI$sp$1'></ClassStats><ClassStats bugs='0' size='137' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$mcJ$sp'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='OpenHashSet.scala' class='org.apache.spark.util.collection.OpenHashSet$mcJ$sp$$anonfun$rehash$mcJ$sp$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PartitionedAppendOnlyMap.scala' class='org.apache.spark.util.collection.PartitionedAppendOnlyMap'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionedAppendOnlyMap.scala' class='org.apache.spark.util.collection.PartitionedAppendOnlyMap$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionedAppendOnlyMap.scala' class='org.apache.spark.util.collection.PartitionedAppendOnlyMap$$anonfun$2'></ClassStats><ClassStats bugs='0' size='65' interface='false' sourceFile='PartitionedPairBuffer.scala' class='org.apache.spark.util.collection.PartitionedPairBuffer'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PartitionedPairBuffer.scala' class='org.apache.spark.util.collection.PartitionedPairBuffer$'></ClassStats><ClassStats bugs='0' size='110' interface='false' sourceFile='PartitionedPairBuffer.scala' class='org.apache.spark.util.collection.PartitionedPairBuffer$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionedPairBuffer.scala' class='org.apache.spark.util.collection.PartitionedPairBuffer$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionedPairBuffer.scala' class='org.apache.spark.util.collection.PartitionedPairBuffer$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionedPairBuffer.scala' class='org.apache.spark.util.collection.PartitionedPairBuffer$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PartitionedPairBuffer.scala' class='org.apache.spark.util.collection.PartitionedPairBuffer$$anonfun$4'></ClassStats><ClassStats bugs='0' size='226' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap'></ClassStats><ClassStats bugs='0' size='120' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$$anon$1'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$$anonfun$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$$anonfun$2'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$mcID$sp'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$mcII$sp'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$mcIJ$sp'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$mcJD$sp'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$mcJI$sp'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='PrimitiveKeyOpenHashMap.scala' class='org.apache.spark.util.collection.PrimitiveKeyOpenHashMap$mcJJ$sp'></ClassStats><ClassStats bugs='0' size='79' interface='false' sourceFile='PrimitiveVector.scala' class='org.apache.spark.util.collection.PrimitiveVector'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PrimitiveVector.scala' class='org.apache.spark.util.collection.PrimitiveVector$'></ClassStats><ClassStats bugs='0' size='109' interface='false' sourceFile='PrimitiveVector.scala' class='org.apache.spark.util.collection.PrimitiveVector$$anon$1'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='PrimitiveVector.scala' class='org.apache.spark.util.collection.PrimitiveVector$mcD$sp'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='PrimitiveVector.scala' class='org.apache.spark.util.collection.PrimitiveVector$mcI$sp'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='PrimitiveVector.scala' class='org.apache.spark.util.collection.PrimitiveVector$mcJ$sp'></ClassStats><ClassStats bugs='0' size='14' interface='true' sourceFile='SizeTracker.scala' class='org.apache.spark.util.collection.SizeTracker'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='SizeTracker.scala' class='org.apache.spark.util.collection.SizeTracker$'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='SizeTracker.scala' class='org.apache.spark.util.collection.SizeTracker$Sample'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='SizeTracker.scala' class='org.apache.spark.util.collection.SizeTracker$Sample$'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='SizeTracker.scala' class='org.apache.spark.util.collection.SizeTracker$class'></ClassStats><ClassStats bugs='0' size='32' interface='false' sourceFile='SizeTrackingAppendOnlyMap.scala' class='org.apache.spark.util.collection.SizeTrackingAppendOnlyMap'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='SizeTrackingVector.scala' class='org.apache.spark.util.collection.SizeTrackingVector'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='SortDataFormat.scala' class='org.apache.spark.util.collection.SortDataFormat'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Sorter.scala' class='org.apache.spark.util.collection.Sorter'></ClassStats><ClassStats bugs='0' size='79' interface='false' sourceFile='Spillable.scala' class='org.apache.spark.util.collection.Spillable'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='Spillable.scala' class='org.apache.spark.util.collection.Spillable$$anonfun$logSpillage$1'></ClassStats><ClassStats bugs='0' size='92' interface='false' sourceFile='TimSort.java' class='org.apache.spark.util.collection.TimSort'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='TimSort.java' class='org.apache.spark.util.collection.TimSort$1'></ClassStats><ClassStats bugs='0' size='334' interface='false' sourceFile='TimSort.java' class='org.apache.spark.util.collection.TimSort$SortState'></ClassStats><ClassStats bugs='0' size='3' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.collection.Utils'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.collection.Utils$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='Utils.scala' class='org.apache.spark.util.collection.Utils$$anon$1'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='WritablePartitionedPairCollection.scala' class='org.apache.spark.util.collection.WritablePartitionedIterator'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='WritablePartitionedPairCollection.scala' class='org.apache.spark.util.collection.WritablePartitionedPairCollection'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='WritablePartitionedPairCollection.scala' class='org.apache.spark.util.collection.WritablePartitionedPairCollection$'></ClassStats><ClassStats bugs='0' size='13' interface='false' sourceFile='WritablePartitionedPairCollection.scala' class='org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WritablePartitionedPairCollection.scala' class='org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$2'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='WritablePartitionedPairCollection.scala' class='org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='WritablePartitionedPairCollection.scala' class='org.apache.spark.util.collection.WritablePartitionedPairCollection$class'></ClassStats></PackageStats><PackageStats package='org.apache.spark.util.collection.unsafe.sort' total_bugs='2' priority_3='2' total_size='1128' total_types='30'><ClassStats bugs='0' size='4' interface='false' sourceFile='PrefixComparator.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparator'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$BinaryPrefixComparator'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$DoublePrefixComparator'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$RadixSortSupport'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$SignedPrefixComparator'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$SignedPrefixComparatorDesc'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$SignedPrefixComparatorDescNullsFirst'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$SignedPrefixComparatorNullsLast'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$StringPrefixComparator'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$UnsignedPrefixComparator'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$UnsignedPrefixComparatorDesc'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$UnsignedPrefixComparatorDescNullsFirst'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='PrefixComparators.java' class='org.apache.spark.util.collection.unsafe.sort.PrefixComparators$UnsignedPrefixComparatorNullsLast'></ClassStats><ClassStats bugs='0' size='116' interface='false' sourceFile='RadixSort.java' class='org.apache.spark.util.collection.unsafe.sort.RadixSort'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='RecordComparator.java' class='org.apache.spark.util.collection.unsafe.sort.RecordComparator'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='RecordPointerAndKeyPrefix.java' class='org.apache.spark.util.collection.unsafe.sort.RecordPointerAndKeyPrefix'></ClassStats><ClassStats bugs='2' size='275' priority_3='2' interface='false' sourceFile='UnsafeExternalSorter.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter'></ClassStats><ClassStats bugs='0' size='36' interface='false' sourceFile='UnsafeExternalSorter.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$ChainedIterator'></ClassStats><ClassStats bugs='0' size='77' interface='false' sourceFile='UnsafeExternalSorter.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator'></ClassStats><ClassStats bugs='0' size='121' interface='false' sourceFile='UnsafeInMemorySorter.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='UnsafeInMemorySorter.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter$1'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='UnsafeInMemorySorter.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter$SortComparator'></ClassStats><ClassStats bugs='0' size='56' interface='false' sourceFile='UnsafeInMemorySorter.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter$SortedIterator'></ClassStats><ClassStats bugs='0' size='47' interface='false' sourceFile='UnsafeSortDataFormat.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeSortDataFormat'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='UnsafeSorterIterator.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeSorterIterator'></ClassStats><ClassStats bugs='0' size='28' interface='false' sourceFile='UnsafeSorterSpillMerger.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillMerger'></ClassStats><ClassStats bugs='0' size='24' interface='false' sourceFile='UnsafeSorterSpillMerger.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillMerger$1'></ClassStats><ClassStats bugs='0' size='79' interface='false' sourceFile='UnsafeSorterSpillReader.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader'></ClassStats><ClassStats bugs='0' size='74' interface='false' sourceFile='UnsafeSorterSpillWriter.java' class='org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter'></ClassStats></PackageStats><PackageStats package='org.apache.spark.util.io' total_bugs='0' total_size='272' total_types='18'><ClassStats bugs='0' size='50' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$5'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$6'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$7'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$dispose$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$getChunks$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBuffer$$anonfun$writeFully$1'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='ChunkedByteBuffer.scala' class='org.apache.spark.util.io.ChunkedByteBufferInputStream'></ClassStats><ClassStats bugs='0' size='66' interface='false' sourceFile='ChunkedByteBufferOutputStream.scala' class='org.apache.spark.util.io.ChunkedByteBufferOutputStream'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBufferOutputStream.scala' class='org.apache.spark.util.io.ChunkedByteBufferOutputStream$$anonfun$toChunkedByteBuffer$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBufferOutputStream.scala' class='org.apache.spark.util.io.ChunkedByteBufferOutputStream$$anonfun$toChunkedByteBuffer$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='ChunkedByteBufferOutputStream.scala' class='org.apache.spark.util.io.ChunkedByteBufferOutputStream$$anonfun$toChunkedByteBuffer$3'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBufferOutputStream.scala' class='org.apache.spark.util.io.ChunkedByteBufferOutputStream$$anonfun$write$1'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='ChunkedByteBufferOutputStream.scala' class='org.apache.spark.util.io.ChunkedByteBufferOutputStream$$anonfun$write$2'></ClassStats></PackageStats><PackageStats package='org.apache.spark.util.logging' total_bugs='6' priority_2='6' total_size='666' total_types='43'><ClassStats bugs='0' size='63' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender'></ClassStats><ClassStats bugs='0' size='70' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anon$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$3'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$5'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$appendStreamToFile$4'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$closeFile$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$createSizeBasedAppender$1$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$createSizeBasedAppender$1$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$createTimeBasedAppender$1$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$createTimeBasedAppender$1$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='FileAppender.scala' class='org.apache.spark.util.logging.FileAppender$$anonfun$openFile$1'></ClassStats><ClassStats bugs='4' size='89' priority_2='4' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender'></ClassStats><ClassStats bugs='2' size='44' priority_2='2' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anon$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$1'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$deleteOldFiles$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$deleteOldFiles$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$deleteOldFiles$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$getSortedRolledOverFiles$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$moveFile$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$moveFile$2'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$moveFile$3'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$moveFile$4'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RollingFileAppender.scala' class='org.apache.spark.util.logging.RollingFileAppender$$anonfun$rollover$1'></ClassStats><ClassStats bugs='0' size='5' interface='true' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.RollingPolicy'></ClassStats><ClassStats bugs='0' size='49' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.SizeBasedRollingPolicy'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.SizeBasedRollingPolicy$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.SizeBasedRollingPolicy$$anonfun$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.SizeBasedRollingPolicy$$anonfun$shouldRollover$1'></ClassStats><ClassStats bugs='0' size='55' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.TimeBasedRollingPolicy'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.TimeBasedRollingPolicy$'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.TimeBasedRollingPolicy$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.TimeBasedRollingPolicy$$anonfun$calculateNextRolloverTime$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RollingPolicy.scala' class='org.apache.spark.util.logging.TimeBasedRollingPolicy$$anonfun$rolledOver$1'></ClassStats></PackageStats><PackageStats package='org.apache.spark.util.random' total_bugs='3' priority_2='3' total_size='870' total_types='62'><ClassStats bugs='0' size='30' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.AcceptanceResult'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.AcceptanceResult$'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.BernoulliCellSampler'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.BernoulliCellSampler$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.BernoulliCellSampler$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.BernoulliCellSampler$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.BernoulliCellSampler$$anonfun$3'></ClassStats><ClassStats bugs='0' size='35' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.BernoulliSampler'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.BernoulliSampler$$anonfun$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SamplingUtils.scala' class='org.apache.spark.util.random.BinomialBounds'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SamplingUtils.scala' class='org.apache.spark.util.random.BinomialBounds$'></ClassStats><ClassStats bugs='0' size='29' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.GapSampling'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.GapSampling$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.GapSampling$$anonfun$6'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.GapSampling$$anonfun$7'></ClassStats><ClassStats bugs='0' size='40' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.GapSamplingReplacement'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.GapSamplingReplacement$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.GapSamplingReplacement$$anonfun$8'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.GapSamplingReplacement$$anonfun$9'></ClassStats><ClassStats bugs='0' size='4' interface='false' sourceFile='SamplingUtils.scala' class='org.apache.spark.util.random.PoissonBounds'></ClassStats><ClassStats bugs='0' size='15' interface='false' sourceFile='SamplingUtils.scala' class='org.apache.spark.util.random.PoissonBounds$'></ClassStats><ClassStats bugs='0' size='44' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.PoissonSampler'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.PoissonSampler$$anonfun$5'></ClassStats><ClassStats bugs='0' size='10' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.PoissonSampler$$anonfun$sample$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.PoissonSampler$$anonfun$sample$2$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='2' interface='true' sourceFile='Pseudorandom.scala' class='org.apache.spark.util.random.Pseudorandom'></ClassStats><ClassStats bugs='0' size='4' interface='true' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.RandomSampler'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.RandomSampler$'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.RandomSampler$$anonfun$sample$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='RandomSampler.scala' class='org.apache.spark.util.random.RandomSampler$class'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='SamplingUtils.scala' class='org.apache.spark.util.random.SamplingUtils'></ClassStats><ClassStats bugs='1' size='33' priority_2='1' interface='false' sourceFile='SamplingUtils.scala' class='org.apache.spark.util.random.SamplingUtils$'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils'></ClassStats><ClassStats bugs='0' size='50' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$'></ClassStats><ClassStats bugs='0' size='16' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$2'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$2$$anonfun$apply$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$computeThresholdByKey$1'></ClassStats><ClassStats bugs='0' size='17' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$computeThresholdByKey$2'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$computeThresholdByKey$2$$anonfun$apply$4'></ClassStats><ClassStats bugs='0' size='6' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$computeThresholdByKey$2$$anonfun$apply$5'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getBernoulliSamplingFunction$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getBernoulliSamplingFunction$1$$anonfun$apply$6'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getCombOp$1'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getCombOp$1$$anonfun$apply$3'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getPoissonSamplingFunction$1'></ClassStats><ClassStats bugs='0' size='18' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getPoissonSamplingFunction$1$$anonfun$apply$7'></ClassStats><ClassStats bugs='0' size='9' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getPoissonSamplingFunction$1$$anonfun$apply$7$$anonfun$1'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getPoissonSamplingFunction$1$$anonfun$apply$7$$anonfun$apply$8'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getPoissonSamplingFunction$2'></ClassStats><ClassStats bugs='0' size='12' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getPoissonSamplingFunction$2$$anonfun$apply$9'></ClassStats><ClassStats bugs='0' size='7' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getPoissonSamplingFunction$2$$anonfun$apply$9$$anonfun$apply$10'></ClassStats><ClassStats bugs='0' size='42' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getSeqOp$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$$anonfun$getSeqOp$1$$anonfun$apply$1'></ClassStats><ClassStats bugs='0' size='22' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$RandomDataGenerator'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='StratifiedSamplingUtils.scala' class='org.apache.spark.util.random.StratifiedSamplingUtils$RandomDataGenerator$$anonfun$3'></ClassStats><ClassStats bugs='1' size='19' priority_2='1' interface='false' sourceFile='XORShiftRandom.scala' class='org.apache.spark.util.random.XORShiftRandom'></ClassStats><ClassStats bugs='1' size='26' priority_2='1' interface='false' sourceFile='XORShiftRandom.scala' class='org.apache.spark.util.random.XORShiftRandom$'></ClassStats><ClassStats bugs='0' size='11' interface='false' sourceFile='XORShiftRandom.scala' class='org.apache.spark.util.random.XORShiftRandom$$anonfun$benchmark$1'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='XORShiftRandom.scala' class='org.apache.spark.util.random.XORShiftRandom$$anonfun$benchmark$2'></ClassStats><ClassStats bugs='0' size='8' interface='false' sourceFile='XORShiftRandom.scala' class='org.apache.spark.util.random.XORShiftRandom$$anonfun$benchmark$3'></ClassStats><ClassStats bugs='0' size='1' interface='false' sourceFile='package.scala' class='org.apache.spark.util.random.package'></ClassStats><ClassStats bugs='0' size='5' interface='false' sourceFile='package.scala' class='org.apache.spark.util.random.package$'></ClassStats></PackageStats><FindBugsProfile><ClassProfile avgMicrosecondsPerInvocation='79' totalMilliseconds='3118' name='edu.umd.cs.findbugs.ba.npe.NullDerefAndRedundantComparisonFinder' maxMicrosecondsPerInvocation='59765' standardDeviationMicrosecondsPerInvocation='619' invocations='39221'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='60' totalMilliseconds='2897' name='edu.umd.cs.findbugs.classfile.engine.ClassDataAnalysisEngine' maxMicrosecondsPerInvocation='1249' standardDeviationMicrosecondsPerInvocation='50' invocations='47978'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='58' totalMilliseconds='2653' name='edu.umd.cs.findbugs.classfile.engine.bcel.IsNullValueDataflowFactory' maxMicrosecondsPerInvocation='17036' standardDeviationMicrosecondsPerInvocation='304' invocations='45418'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='48' totalMilliseconds='2215' name='com.h3xstream.findsecbugs.taintanalysis.TaintDataflowEngine' maxMicrosecondsPerInvocation='38234' standardDeviationMicrosecondsPerInvocation='294' invocations='45418'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='48' totalMilliseconds='2205' name='edu.umd.cs.findbugs.classfile.engine.bcel.TypeDataflowFactory' maxMicrosecondsPerInvocation='19604' standardDeviationMicrosecondsPerInvocation='255' invocations='45613'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='48' totalMilliseconds='2069' name='edu.umd.cs.findbugs.classfile.engine.bcel.UnconditionalValueDerefDataflowFactory' maxMicrosecondsPerInvocation='28851' standardDeviationMicrosecondsPerInvocation='288' invocations='42609'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='39' totalMilliseconds='1792' name='edu.umd.cs.findbugs.classfile.engine.bcel.ValueNumberDataflowFactory' maxMicrosecondsPerInvocation='61998' standardDeviationMicrosecondsPerInvocation='406' invocations='45752'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='44' totalMilliseconds='1661' name='edu.umd.cs.findbugs.detect.FindRefComparison$SpecialTypeAnalysis' maxMicrosecondsPerInvocation='10150' standardDeviationMicrosecondsPerInvocation='193' invocations='37125'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='205' totalMilliseconds='1483' name='edu.umd.cs.findbugs.detect.SerializableIdiom' maxMicrosecondsPerInvocation='14706' standardDeviationMicrosecondsPerInvocation='915' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='1435' name='edu.umd.cs.findbugs.classfile.engine.bcel.CFGFactory' maxMicrosecondsPerInvocation='20352' standardDeviationMicrosecondsPerInvocation='124' invocations='46012'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='97' totalMilliseconds='1352' name='edu.umd.cs.findbugs.classfile.engine.ClassInfoAnalysisEngine' maxMicrosecondsPerInvocation='11249' standardDeviationMicrosecondsPerInvocation='230' invocations='13898'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='128' totalMilliseconds='1168' name='edu.umd.cs.findbugs.detect.FindNoSideEffectMethods' maxMicrosecondsPerInvocation='29227' standardDeviationMicrosecondsPerInvocation='509' invocations='9125'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='115' totalMilliseconds='1055' name='com.mebigfatguy.fbcontrib.collect.CollectMethodsReturningImmutableCollections' maxMicrosecondsPerInvocation='71354' standardDeviationMicrosecondsPerInvocation='1011' invocations='9125'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='21' totalMilliseconds='1051' name='edu.umd.cs.findbugs.classfile.engine.bcel.JavaClassAnalysisEngine' maxMicrosecondsPerInvocation='29577' standardDeviationMicrosecondsPerInvocation='147' invocations='48433'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='0' totalMilliseconds='937' name='edu.umd.cs.findbugs.DetectorToDetector2Adapter' maxMicrosecondsPerInvocation='158' standardDeviationMicrosecondsPerInvocation='0' invocations='2798319'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='93' totalMilliseconds='857' name='edu.umd.cs.findbugs.detect.FieldItemSummary' maxMicrosecondsPerInvocation='7421' standardDeviationMicrosecondsPerInvocation='285' invocations='9125'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='0' totalMilliseconds='816' name='edu.umd.cs.findbugs.ba.npe.TypeQualifierNullnessAnnotationDatabase' maxMicrosecondsPerInvocation='931' standardDeviationMicrosecondsPerInvocation='2' invocations='1878158'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='105' totalMilliseconds='758' name='edu.umd.cs.findbugs.detect.UnreadFields' maxMicrosecondsPerInvocation='5424' standardDeviationMicrosecondsPerInvocation='183' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='80' totalMilliseconds='736' name='com.mebigfatguy.fbcontrib.collect.CollectStatistics' maxMicrosecondsPerInvocation='48804' standardDeviationMicrosecondsPerInvocation='582' invocations='9125'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='101' totalMilliseconds='735' name='com.mebigfatguy.fbcontrib.detect.DeletingWhileIterating' maxMicrosecondsPerInvocation='25941' standardDeviationMicrosecondsPerInvocation='745' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='15' totalMilliseconds='706' name='edu.umd.cs.findbugs.classfile.engine.bcel.MethodGenFactory' maxMicrosecondsPerInvocation='304002' standardDeviationMicrosecondsPerInvocation='1417' invocations='46012'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='97' totalMilliseconds='702' name='edu.umd.cs.findbugs.detect.LoadOfKnownNullValue' maxMicrosecondsPerInvocation='26633' standardDeviationMicrosecondsPerInvocation='493' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='13' totalMilliseconds='652' name='edu.umd.cs.findbugs.OpcodeStack$JumpInfoFactory' maxMicrosecondsPerInvocation='45496' standardDeviationMicrosecondsPerInvocation='212' invocations='47949'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='12' totalMilliseconds='577' name='edu.umd.cs.findbugs.classfile.engine.bcel.ConstantDataflowFactory' maxMicrosecondsPerInvocation='8385' standardDeviationMicrosecondsPerInvocation='63' invocations='45418'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='78' totalMilliseconds='569' name='edu.umd.cs.findbugs.detect.FindReturnRef' maxMicrosecondsPerInvocation='54799' standardDeviationMicrosecondsPerInvocation='657' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='76' totalMilliseconds='553' name='edu.umd.cs.findbugs.detect.DumbMethods' maxMicrosecondsPerInvocation='4317' standardDeviationMicrosecondsPerInvocation='186' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='71' totalMilliseconds='516' name='edu.umd.cs.findbugs.detect.FindBadCast2' maxMicrosecondsPerInvocation='29578' standardDeviationMicrosecondsPerInvocation='545' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='68' totalMilliseconds='492' name='com.h3xstream.findsecbugs.password.ConstantPasswordDetector' maxMicrosecondsPerInvocation='10394' standardDeviationMicrosecondsPerInvocation='294' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='66' totalMilliseconds='479' name='com.h3xstream.findsecbugs.file.PathTraversalDetector' maxMicrosecondsPerInvocation='5063' standardDeviationMicrosecondsPerInvocation='178' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='48' totalMilliseconds='443' name='com.mebigfatguy.fbcontrib.collect.CollectNullableMethodStatus' maxMicrosecondsPerInvocation='10507' standardDeviationMicrosecondsPerInvocation='196' invocations='9125'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='55' totalMilliseconds='399' name='edu.umd.cs.findbugs.detect.FindHEmismatch' maxMicrosecondsPerInvocation='33882' standardDeviationMicrosecondsPerInvocation='411' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='53' totalMilliseconds='386' name='com.mebigfatguy.fbcontrib.detect.InvalidConstantArgument' maxMicrosecondsPerInvocation='51626' standardDeviationMicrosecondsPerInvocation='621' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='51' totalMilliseconds='372' name='com.mebigfatguy.fbcontrib.detect.SillynessPotPourri' maxMicrosecondsPerInvocation='3662' standardDeviationMicrosecondsPerInvocation='112' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='51' totalMilliseconds='371' name='com.mebigfatguy.fbcontrib.detect.DubiousMapCollection' maxMicrosecondsPerInvocation='3053' standardDeviationMicrosecondsPerInvocation='114' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='9' totalMilliseconds='370' name='edu.umd.cs.findbugs.detect.FindNullDeref$CheckCallSitesAndReturnInstructions' maxMicrosecondsPerInvocation='15875' standardDeviationMicrosecondsPerInvocation='105' invocations='39221'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='51' totalMilliseconds='369' name='com.mebigfatguy.fbcontrib.detect.PossiblyRedundantMethodCalls' maxMicrosecondsPerInvocation='4241' standardDeviationMicrosecondsPerInvocation='127' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='50' totalMilliseconds='363' name='com.mebigfatguy.fbcontrib.detect.ClassEnvy' maxMicrosecondsPerInvocation='4026' standardDeviationMicrosecondsPerInvocation='131' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='50' totalMilliseconds='361' name='edu.umd.cs.findbugs.detect.FindInconsistentSync2' maxMicrosecondsPerInvocation='2044' standardDeviationMicrosecondsPerInvocation='93' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='49' totalMilliseconds='359' name='com.mebigfatguy.fbcontrib.detect.OverlyConcreteParameter' maxMicrosecondsPerInvocation='2360' standardDeviationMicrosecondsPerInvocation='81' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='49' totalMilliseconds='353' name='edu.umd.cs.findbugs.detect.MethodReturnCheck' maxMicrosecondsPerInvocation='4263' standardDeviationMicrosecondsPerInvocation='137' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='48' totalMilliseconds='348' name='com.mebigfatguy.fbcontrib.detect.LocalSynchronizedCollection' maxMicrosecondsPerInvocation='4793' standardDeviationMicrosecondsPerInvocation='136' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='8' totalMilliseconds='346' name='edu.umd.cs.findbugs.classfile.engine.bcel.LiveLocalStoreDataflowFactory' maxMicrosecondsPerInvocation='47684' standardDeviationMicrosecondsPerInvocation='272' invocations='38920'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='47' totalMilliseconds='341' name='edu.umd.cs.findbugs.detect.FindPuzzlers' maxMicrosecondsPerInvocation='3405' standardDeviationMicrosecondsPerInvocation='126' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='46' totalMilliseconds='338' name='edu.umd.cs.findbugs.detect.FindRefComparison' maxMicrosecondsPerInvocation='3505' standardDeviationMicrosecondsPerInvocation='116' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='46' totalMilliseconds='333' name='com.mebigfatguy.fbcontrib.detect.WriteOnlyCollection' maxMicrosecondsPerInvocation='22753' standardDeviationMicrosecondsPerInvocation='288' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='45' totalMilliseconds='329' name='com.mebigfatguy.fbcontrib.detect.HangingExecutors' maxMicrosecondsPerInvocation='3777' standardDeviationMicrosecondsPerInvocation='130' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='45' totalMilliseconds='327' name='com.mebigfatguy.fbcontrib.detect.LoggerOddities' maxMicrosecondsPerInvocation='3131' standardDeviationMicrosecondsPerInvocation='103' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='44' totalMilliseconds='324' name='com.mebigfatguy.fbcontrib.detect.SloppyClassReflection' maxMicrosecondsPerInvocation='3117' standardDeviationMicrosecondsPerInvocation='105' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='44' totalMilliseconds='321' name='com.h3xstream.findsecbugs.xpath.XPathInjectionDetector' maxMicrosecondsPerInvocation='43096' standardDeviationMicrosecondsPerInvocation='523' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='43' totalMilliseconds='314' name='com.mebigfatguy.fbcontrib.detect.UseAddAll' maxMicrosecondsPerInvocation='65627' standardDeviationMicrosecondsPerInvocation='777' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='42' totalMilliseconds='303' name='com.h3xstream.findsecbugs.xml.StdXmlTransformDetector' maxMicrosecondsPerInvocation='64290' standardDeviationMicrosecondsPerInvocation='766' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='41' totalMilliseconds='301' name='com.h3xstream.findsecbugs.PredictableRandomDetector' maxMicrosecondsPerInvocation='3656' standardDeviationMicrosecondsPerInvocation='111' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='41' totalMilliseconds='301' name='com.h3xstream.findsecbugs.injection.script.OgnlInjectionDetector' maxMicrosecondsPerInvocation='3968' standardDeviationMicrosecondsPerInvocation='124' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='40' totalMilliseconds='294' name='com.h3xstream.findsecbugs.injection.ssrf.SSRFDetector' maxMicrosecondsPerInvocation='59007' standardDeviationMicrosecondsPerInvocation='705' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='40' totalMilliseconds='294' name='com.h3xstream.findsecbugs.file.FileUploadFilenameDetector' maxMicrosecondsPerInvocation='91228' standardDeviationMicrosecondsPerInvocation='1076' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='40' totalMilliseconds='291' name='edu.umd.cs.findbugs.detect.FindDeadLocalStores' maxMicrosecondsPerInvocation='25121' standardDeviationMicrosecondsPerInvocation='319' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='40' totalMilliseconds='290' name='edu.umd.cs.findbugs.detect.CheckRelaxingNullnessAnnotation' maxMicrosecondsPerInvocation='6408' standardDeviationMicrosecondsPerInvocation='94' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='40' totalMilliseconds='290' name='com.mebigfatguy.fbcontrib.detect.LingeringGraphicsObjects' maxMicrosecondsPerInvocation='65554' standardDeviationMicrosecondsPerInvocation='776' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='40' totalMilliseconds='290' name='com.h3xstream.findsecbugs.WeakFilenameUtilsMethodDetector' maxMicrosecondsPerInvocation='3512' standardDeviationMicrosecondsPerInvocation='105' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='290' name='edu.umd.cs.findbugs.detect.NoteDirectlyRelevantTypeQualifiers' maxMicrosecondsPerInvocation='3248' standardDeviationMicrosecondsPerInvocation='90' invocations='9125'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='39' totalMilliseconds='288' name='edu.umd.cs.findbugs.detect.RuntimeExceptionCapture' maxMicrosecondsPerInvocation='3538' standardDeviationMicrosecondsPerInvocation='115' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='39' totalMilliseconds='287' name='com.h3xstream.findsecbugs.injection.command.CommandInjectionDetector' maxMicrosecondsPerInvocation='4195' standardDeviationMicrosecondsPerInvocation='142' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='39' totalMilliseconds='285' name='edu.umd.cs.findbugs.detect.RepeatedConditionals' maxMicrosecondsPerInvocation='3070' standardDeviationMicrosecondsPerInvocation='108' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='39' totalMilliseconds='283' name='edu.umd.cs.findbugs.detect.FindNonShortCircuit' maxMicrosecondsPerInvocation='56644' standardDeviationMicrosecondsPerInvocation='672' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='38' totalMilliseconds='281' name='edu.umd.cs.findbugs.detect.FindUselessObjects' maxMicrosecondsPerInvocation='3282' standardDeviationMicrosecondsPerInvocation='115' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='38' totalMilliseconds='279' name='com.mebigfatguy.fbcontrib.detect.JDBCVendorReliance' maxMicrosecondsPerInvocation='3439' standardDeviationMicrosecondsPerInvocation='102' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='279' name='edu.umd.cs.findbugs.detect.BuildObligationPolicyDatabase' maxMicrosecondsPerInvocation='2004' standardDeviationMicrosecondsPerInvocation='66' invocations='9125'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='38' totalMilliseconds='279' name='com.mebigfatguy.fbcontrib.detect.ModifyingUnmodifiableCollection' maxMicrosecondsPerInvocation='3363' standardDeviationMicrosecondsPerInvocation='107' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='38' totalMilliseconds='276' name='com.mebigfatguy.fbcontrib.detect.OverlyPermissiveMethod' maxMicrosecondsPerInvocation='3179' standardDeviationMicrosecondsPerInvocation='100' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='38' totalMilliseconds='275' name='com.mebigfatguy.fbcontrib.detect.Section508Compliance' maxMicrosecondsPerInvocation='3092' standardDeviationMicrosecondsPerInvocation='95' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='38' totalMilliseconds='275' name='edu.umd.cs.findbugs.detect.ReflectionIncreaseAccessibility' maxMicrosecondsPerInvocation='3365' standardDeviationMicrosecondsPerInvocation='107' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='38' totalMilliseconds='275' name='edu.umd.cs.findbugs.detect.FindSelfComparison' maxMicrosecondsPerInvocation='3290' standardDeviationMicrosecondsPerInvocation='109' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='37' totalMilliseconds='271' name='edu.umd.cs.findbugs.detect.SwitchFallthrough' maxMicrosecondsPerInvocation='2785' standardDeviationMicrosecondsPerInvocation='96' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='37' totalMilliseconds='270' name='com.h3xstream.findsecbugs.crypto.cipher.DesUsageDetector' maxMicrosecondsPerInvocation='56765' standardDeviationMicrosecondsPerInvocation='674' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='37' totalMilliseconds='269' name='edu.umd.cs.findbugs.detect.FindOpenStream' maxMicrosecondsPerInvocation='13163' standardDeviationMicrosecondsPerInvocation='316' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='37' totalMilliseconds='269' name='com.mebigfatguy.fbcontrib.detect.NonProductiveMethodCall' maxMicrosecondsPerInvocation='3186' standardDeviationMicrosecondsPerInvocation='124' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='37' totalMilliseconds='268' name='edu.umd.cs.findbugs.detect.FindBadEndOfStreamCheck' maxMicrosecondsPerInvocation='34999' standardDeviationMicrosecondsPerInvocation='421' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='37' totalMilliseconds='267' name='com.mebigfatguy.fbcontrib.detect.PossibleConstantAllocationInLoop' maxMicrosecondsPerInvocation='3121' standardDeviationMicrosecondsPerInvocation='101' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='36' totalMilliseconds='263' name='com.mebigfatguy.fbcontrib.detect.HttpClientProblems' maxMicrosecondsPerInvocation='3015' standardDeviationMicrosecondsPerInvocation='99' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='36' totalMilliseconds='262' name='edu.umd.cs.findbugs.detect.IncompatMask' maxMicrosecondsPerInvocation='2974' standardDeviationMicrosecondsPerInvocation='99' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='36' totalMilliseconds='261' name='com.h3xstream.findsecbugs.injection.sql.SqlInjectionDetector' maxMicrosecondsPerInvocation='3972' standardDeviationMicrosecondsPerInvocation='127' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='36' totalMilliseconds='260' name='edu.umd.cs.findbugs.detect.Naming' maxMicrosecondsPerInvocation='718' standardDeviationMicrosecondsPerInvocation='34' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='259' name='com.mebigfatguy.fbcontrib.detect.IOIssues' maxMicrosecondsPerInvocation='3031' standardDeviationMicrosecondsPerInvocation='102' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='258' name='com.mebigfatguy.fbcontrib.detect.OrphanedDOMNode' maxMicrosecondsPerInvocation='3441' standardDeviationMicrosecondsPerInvocation='100' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='258' name='com.h3xstream.findsecbugs.android.WebViewJavascriptEnabledDetector' maxMicrosecondsPerInvocation='51525' standardDeviationMicrosecondsPerInvocation='612' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='257' name='edu.umd.cs.findbugs.detect.FindNullDeref' maxMicrosecondsPerInvocation='1926' standardDeviationMicrosecondsPerInvocation='80' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='257' name='edu.umd.cs.findbugs.detect.InfiniteLoop' maxMicrosecondsPerInvocation='2659' standardDeviationMicrosecondsPerInvocation='93' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='257' name='com.mebigfatguy.fbcontrib.detect.PossibleUnsuspectedSerialization' maxMicrosecondsPerInvocation='43158' standardDeviationMicrosecondsPerInvocation='514' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='254' name='com.h3xstream.findsecbugs.injection.ldap.LdapInjectionDetector' maxMicrosecondsPerInvocation='3675' standardDeviationMicrosecondsPerInvocation='124' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='254' name='edu.umd.cs.findbugs.detect.CrossSiteScripting' maxMicrosecondsPerInvocation='2904' standardDeviationMicrosecondsPerInvocation='98' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='254' name='edu.umd.cs.findbugs.detect.NoteNonnullReturnValues' maxMicrosecondsPerInvocation='4991' standardDeviationMicrosecondsPerInvocation='172' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='35' totalMilliseconds='252' name='com.mebigfatguy.fbcontrib.detect.SuspiciousClusteredSessionSupport' maxMicrosecondsPerInvocation='4791' standardDeviationMicrosecondsPerInvocation='106' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='251' name='com.h3xstream.findsecbugs.injection.crlf.CrlfLogInjectionDetector' maxMicrosecondsPerInvocation='3995' standardDeviationMicrosecondsPerInvocation='126' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='251' name='com.mebigfatguy.fbcontrib.detect.SuboptimalExpressionOrder' maxMicrosecondsPerInvocation='3071' standardDeviationMicrosecondsPerInvocation='96' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='250' name='edu.umd.cs.findbugs.detect.ReadOfInstanceFieldInMethodInvokedByConstructorInSuperclass' maxMicrosecondsPerInvocation='3101' standardDeviationMicrosecondsPerInvocation='91' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='249' name='com.h3xstream.findsecbugs.injection.script.ScriptInjectionDetector' maxMicrosecondsPerInvocation='3970' standardDeviationMicrosecondsPerInvocation='126' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='248' name='com.mebigfatguy.fbcontrib.detect.PresizeCollections' maxMicrosecondsPerInvocation='2670' standardDeviationMicrosecondsPerInvocation='89' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='248' name='edu.umd.cs.findbugs.detect.FindOverridableMethodCall' maxMicrosecondsPerInvocation='3128' standardDeviationMicrosecondsPerInvocation='107' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='247' name='edu.umd.cs.findbugs.detect.FindInstanceLockOnSharedStaticData' maxMicrosecondsPerInvocation='2578' standardDeviationMicrosecondsPerInvocation='90' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='245' name='com.mebigfatguy.fbcontrib.detect.InefficientStringBuffering' maxMicrosecondsPerInvocation='3285' standardDeviationMicrosecondsPerInvocation='94' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='34' totalMilliseconds='245' name='com.h3xstream.findsecbugs.HttpResponseSplittingDetector' maxMicrosecondsPerInvocation='3951' standardDeviationMicrosecondsPerInvocation='125' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='244' name='edu.umd.cs.findbugs.detect.FindDoubleCheck' maxMicrosecondsPerInvocation='2880' standardDeviationMicrosecondsPerInvocation='92' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='244' name='com.h3xstream.findsecbugs.taintanalysis.extra.JstlExpressionWhiteLister' maxMicrosecondsPerInvocation='27111' standardDeviationMicrosecondsPerInvocation='338' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='244' name='com.mebigfatguy.fbcontrib.detect.ArrayIndexOutOfBounds' maxMicrosecondsPerInvocation='2655' standardDeviationMicrosecondsPerInvocation='90' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='243' name='com.h3xstream.findsecbugs.scala.XssTwirlDetector' maxMicrosecondsPerInvocation='25674' standardDeviationMicrosecondsPerInvocation='322' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='242' name='com.mebigfatguy.fbcontrib.detect.ConstantListIndex' maxMicrosecondsPerInvocation='3034' standardDeviationMicrosecondsPerInvocation='88' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='241' name='com.h3xstream.findsecbugs.jsp.JspIncludeDetector' maxMicrosecondsPerInvocation='3299' standardDeviationMicrosecondsPerInvocation='94' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='240' name='com.h3xstream.findsecbugs.injection.redirect.UnvalidatedRedirectDetector' maxMicrosecondsPerInvocation='3803' standardDeviationMicrosecondsPerInvocation='122' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='240' name='com.mebigfatguy.fbcontrib.detect.UnrelatedCollectionContents' maxMicrosecondsPerInvocation='3137' standardDeviationMicrosecondsPerInvocation='93' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='240' name='com.mebigfatguy.fbcontrib.detect.UseToArray' maxMicrosecondsPerInvocation='3072' standardDeviationMicrosecondsPerInvocation='100' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='239' name='com.h3xstream.findsecbugs.injection.trust.TrustBoundaryViolationAttributeDetector' maxMicrosecondsPerInvocation='3902' standardDeviationMicrosecondsPerInvocation='123' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='238' name='com.mebigfatguy.fbcontrib.detect.SuspiciousNullGuard' maxMicrosecondsPerInvocation='2901' standardDeviationMicrosecondsPerInvocation='91' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='33' totalMilliseconds='238' name='com.h3xstream.findsecbugs.injection.custom.CustomInjectionDetector' maxMicrosecondsPerInvocation='3819' standardDeviationMicrosecondsPerInvocation='119' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='17' totalMilliseconds='236' name='edu.umd.cs.findbugs.util.TopologicalSort' maxMicrosecondsPerInvocation='54298' standardDeviationMicrosecondsPerInvocation='511' invocations='13798'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='236' name='com.h3xstream.findsecbugs.injection.sql.AndroidSqlInjectionDetector' maxMicrosecondsPerInvocation='3893' standardDeviationMicrosecondsPerInvocation='119' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='234' name='com.mebigfatguy.fbcontrib.detect.ReflectionOnObjectMethods' maxMicrosecondsPerInvocation='2821' standardDeviationMicrosecondsPerInvocation='87' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='234' name='com.mebigfatguy.fbcontrib.detect.NeedlessAutoboxing' maxMicrosecondsPerInvocation='3148' standardDeviationMicrosecondsPerInvocation='92' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='234' name='com.mebigfatguy.fbcontrib.detect.UseEnumCollections' maxMicrosecondsPerInvocation='3067' standardDeviationMicrosecondsPerInvocation='89' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='234' name='com.h3xstream.findsecbugs.scala.ScalaSensitiveDataExposureDetector' maxMicrosecondsPerInvocation='3891' standardDeviationMicrosecondsPerInvocation='123' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='234' name='com.mebigfatguy.fbcontrib.detect.SideEffectConstructor' maxMicrosecondsPerInvocation='2769' standardDeviationMicrosecondsPerInvocation='89' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='234' name='com.h3xstream.findsecbugs.injection.aws.AwsQueryInjectionDetector' maxMicrosecondsPerInvocation='3485' standardDeviationMicrosecondsPerInvocation='120' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='232' name='com.mebigfatguy.fbcontrib.detect.UseSplit' maxMicrosecondsPerInvocation='2994' standardDeviationMicrosecondsPerInvocation='89' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='232' name='com.h3xstream.findsecbugs.scala.PlayUnvalidatedRedirectDetector' maxMicrosecondsPerInvocation='3240' standardDeviationMicrosecondsPerInvocation='92' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='231' name='com.h3xstream.findsecbugs.taintanalysis.extra.PotentialValueTracker' maxMicrosecondsPerInvocation='3376' standardDeviationMicrosecondsPerInvocation='117' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='231' name='com.mebigfatguy.fbcontrib.detect.InappropriateToStringUse' maxMicrosecondsPerInvocation='2893' standardDeviationMicrosecondsPerInvocation='90' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='32' totalMilliseconds='231' name='com.mebigfatguy.fbcontrib.detect.StringifiedTypes' maxMicrosecondsPerInvocation='2676' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='230' name='com.mebigfatguy.fbcontrib.detect.CopiedOverriddenMethod' maxMicrosecondsPerInvocation='1093' standardDeviationMicrosecondsPerInvocation='39' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='230' name='edu.umd.cs.findbugs.detect.BadSyntaxForRegularExpression' maxMicrosecondsPerInvocation='4594' standardDeviationMicrosecondsPerInvocation='102' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='230' name='com.h3xstream.findsecbugs.ldap.LdapEntryPoisoningDetector' maxMicrosecondsPerInvocation='3273' standardDeviationMicrosecondsPerInvocation='94' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='229' name='com.h3xstream.findsecbugs.spring.CorsRegistryCORSDetector' maxMicrosecondsPerInvocation='3435' standardDeviationMicrosecondsPerInvocation='94' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='229' name='com.mebigfatguy.fbcontrib.detect.ContraVariantArrayAssignment' maxMicrosecondsPerInvocation='2713' standardDeviationMicrosecondsPerInvocation='90' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='229' name='com.mebigfatguy.fbcontrib.detect.SyncCollectionIterators' maxMicrosecondsPerInvocation='3081' standardDeviationMicrosecondsPerInvocation='89' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='228' name='edu.umd.cs.findbugs.detect.FormatStringChecker' maxMicrosecondsPerInvocation='2570' standardDeviationMicrosecondsPerInvocation='88' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='228' name='com.h3xstream.findsecbugs.injection.script.SpelViewDetector' maxMicrosecondsPerInvocation='3250' standardDeviationMicrosecondsPerInvocation='93' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='228' name='com.h3xstream.findsecbugs.android.ExternalFileAccessDetector' maxMicrosecondsPerInvocation='3216' standardDeviationMicrosecondsPerInvocation='94' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='228' name='com.h3xstream.findsecbugs.injection.fileDisclosure.FileDisclosureDetector' maxMicrosecondsPerInvocation='3471' standardDeviationMicrosecondsPerInvocation='117' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='227' name='com.h3xstream.findsecbugs.csrf.SpringCsrfProtectionDisabledDetector' maxMicrosecondsPerInvocation='2976' standardDeviationMicrosecondsPerInvocation='91' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='227' name='com.mebigfatguy.fbcontrib.detect.ArrayBasedCollections' maxMicrosecondsPerInvocation='3582' standardDeviationMicrosecondsPerInvocation='92' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='com.mebigfatguy.fbcontrib.detect.CharsetIssues' maxMicrosecondsPerInvocation='2731' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='edu.umd.cs.findbugs.detect.InfiniteRecursiveLoop' maxMicrosecondsPerInvocation='2654' standardDeviationMicrosecondsPerInvocation='88' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='edu.umd.cs.findbugs.detect.FindBadForLoop' maxMicrosecondsPerInvocation='2820' standardDeviationMicrosecondsPerInvocation='92' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='com.h3xstream.findsecbugs.crypto.ErrorMessageExposureDetector' maxMicrosecondsPerInvocation='3388' standardDeviationMicrosecondsPerInvocation='95' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='com.h3xstream.findsecbugs.serial.ObjectDeserializationDetector' maxMicrosecondsPerInvocation='2214' standardDeviationMicrosecondsPerInvocation='71' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='com.mebigfatguy.fbcontrib.detect.CommonsStringBuilderToString' maxMicrosecondsPerInvocation='2735' standardDeviationMicrosecondsPerInvocation='88' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='com.h3xstream.findsecbugs.ImproperHandlingUnicodeDetector' maxMicrosecondsPerInvocation='3291' standardDeviationMicrosecondsPerInvocation='93' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='com.h3xstream.findsecbugs.crypto.HazelcastSymmetricEncryptionDetector' maxMicrosecondsPerInvocation='2975' standardDeviationMicrosecondsPerInvocation='90' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='226' name='com.mebigfatguy.fbcontrib.detect.WiringIssues' maxMicrosecondsPerInvocation='2626' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='225' name='com.mebigfatguy.fbcontrib.detect.ConflictingTimeUnits' maxMicrosecondsPerInvocation='2640' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='224' name='com.h3xstream.findsecbugs.template.VelocityDetector' maxMicrosecondsPerInvocation='3440' standardDeviationMicrosecondsPerInvocation='93' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='224' name='edu.umd.cs.findbugs.detect.SynchronizingOnContentsOfFieldToProtectField' maxMicrosecondsPerInvocation='2598' standardDeviationMicrosecondsPerInvocation='87' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='224' name='com.h3xstream.findsecbugs.PermissiveCORSDetector' maxMicrosecondsPerInvocation='34087' standardDeviationMicrosecondsPerInvocation='411' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='224' name='com.h3xstream.findsecbugs.injection.formatter.FormatStringManipulationDetector' maxMicrosecondsPerInvocation='3428' standardDeviationMicrosecondsPerInvocation='116' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='224' name='com.mebigfatguy.fbcontrib.detect.ContainsBasedConditional' maxMicrosecondsPerInvocation='2747' standardDeviationMicrosecondsPerInvocation='91' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='223' name='com.h3xstream.findsecbugs.xml.EnabledExtensionsInApacheXmlRpcDetector' maxMicrosecondsPerInvocation='3293' standardDeviationMicrosecondsPerInvocation='92' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='31' totalMilliseconds='223' name='com.h3xstream.findsecbugs.xml.XmlDecoderDetector' maxMicrosecondsPerInvocation='3098' standardDeviationMicrosecondsPerInvocation='90' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='223' name='com.h3xstream.findsecbugs.ExternalConfigurationControlDetector' maxMicrosecondsPerInvocation='3800' standardDeviationMicrosecondsPerInvocation='122' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='222' name='edu.umd.cs.findbugs.detect.SynchronizationOnSharedBuiltinConstant' maxMicrosecondsPerInvocation='2607' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='222' name='edu.umd.cs.findbugs.detect.IntCast2LongAsInstant' maxMicrosecondsPerInvocation='2669' standardDeviationMicrosecondsPerInvocation='92' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='222' name='com.h3xstream.findsecbugs.injection.trust.TrustBoundaryViolationValueDetector' maxMicrosecondsPerInvocation='3877' standardDeviationMicrosecondsPerInvocation='118' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='221' name='com.mebigfatguy.fbcontrib.detect.MapUsageIssues' maxMicrosecondsPerInvocation='2627' standardDeviationMicrosecondsPerInvocation='87' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='221' name='com.mebigfatguy.fbcontrib.detect.SpuriousThreadStates' maxMicrosecondsPerInvocation='3022' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='220' name='com.mebigfatguy.fbcontrib.detect.ConcurrentCollectionIssues' maxMicrosecondsPerInvocation='2612' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='220' name='com.h3xstream.findsecbugs.endpoint.ServletEndpointDetector' maxMicrosecondsPerInvocation='2999' standardDeviationMicrosecondsPerInvocation='90' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='220' name='com.h3xstream.findsecbugs.injection.beans.BeanInjectionDetector' maxMicrosecondsPerInvocation='3418' standardDeviationMicrosecondsPerInvocation='115' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='220' name='com.h3xstream.findsecbugs.injection.smtp.SmtpHeaderInjectionDetector' maxMicrosecondsPerInvocation='3424' standardDeviationMicrosecondsPerInvocation='115' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='220' name='com.mebigfatguy.fbcontrib.detect.CustomBuiltXML' maxMicrosecondsPerInvocation='3118' standardDeviationMicrosecondsPerInvocation='89' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='219' name='com.h3xstream.findsecbugs.scala.XssMvcApiDetector' maxMicrosecondsPerInvocation='3402' standardDeviationMicrosecondsPerInvocation='114' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='219' name='com.h3xstream.findsecbugs.injection.http.HttpParameterPollutionDetector' maxMicrosecondsPerInvocation='3417' standardDeviationMicrosecondsPerInvocation='115' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='219' name='com.mebigfatguy.fbcontrib.detect.DubiousSetOfCollections' maxMicrosecondsPerInvocation='2852' standardDeviationMicrosecondsPerInvocation='88' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='219' name='edu.umd.cs.findbugs.detect.FindFieldSelfAssignment' maxMicrosecondsPerInvocation='2563' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile><ClassProfile avgMicrosecondsPerInvocation='30' totalMilliseconds='219' name='com.mebigfatguy.fbcontrib.detect.BackportReusePublicIdentifiers' maxMicrosecondsPerInvocation='2670' standardDeviationMicrosecondsPerInvocation='86' invocations='7216'></ClassProfile></FindBugsProfile></FindBugsSummary><ClassFeatures></ClassFeatures><History></History></BugCollection>